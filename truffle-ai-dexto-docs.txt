Directory structure:
â””â”€â”€ truffle-ai-dexto/
    â”œâ”€â”€ README.Docker.md
    â”œâ”€â”€ README.md
    â”œâ”€â”€ CLAUDE.md
    â”œâ”€â”€ CODE_OF_CONDUCT.md
    â”œâ”€â”€ CONTRIBUTING.md
    â”œâ”€â”€ VERSIONING.md
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ database-agent/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”œâ”€â”€ examples/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”œâ”€â”€ image-editor-agent/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”œâ”€â”€ music-agent/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”œâ”€â”€ product-name-researcher/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”œâ”€â”€ talk2pdf-agent/
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â””â”€â”€ triage-demo/
    â”‚       â”œâ”€â”€ README.md
    â”‚       â”œâ”€â”€ test-scenarios.md
    â”‚       â””â”€â”€ docs/
    â”‚           â”œâ”€â”€ billing-policies.md
    â”‚           â”œâ”€â”€ company-overview.md
    â”‚           â”œâ”€â”€ escalation-policies.md
    â”‚           â”œâ”€â”€ product-features.md
    â”‚           â””â”€â”€ technical-documentation.md
    â”œâ”€â”€ docs/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ how-to-dexto.md
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ dexto-agent.md
    â”‚   â”‚   â”œâ”€â”€ events.md
    â”‚   â”‚   â”œâ”€â”€ getting-started.md
    â”‚   â”‚   â”œâ”€â”€ mcp-manager.md
    â”‚   â”‚   â”œâ”€â”€ types.md
    â”‚   â”‚   â”œâ”€â”€ websocket.md
    â”‚   â”‚   â””â”€â”€ rest/
    â”‚   â”‚       â”œâ”€â”€ conversation.md
    â”‚   â”‚       â”œâ”€â”€ llm.md
    â”‚   â”‚       â”œâ”€â”€ mcp.md
    â”‚   â”‚       â”œâ”€â”€ search.md
    â”‚   â”‚       â”œâ”€â”€ sessions.md
    â”‚   â”‚       â””â”€â”€ system.md
    â”‚   â”œâ”€â”€ blog/
    â”‚   â”‚   â””â”€â”€ 2025-06-16-ai-agents-vs-llm-workflows/
    â”‚   â”‚       â””â”€â”€ index.md
    â”‚   â”œâ”€â”€ docs/
    â”‚   â”‚   â”œâ”€â”€ architecture/
    â”‚   â”‚   â”‚   â””â”€â”€ overview.md
    â”‚   â”‚   â”œâ”€â”€ concepts/
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents-vs-workflows.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ how-do-ai-agents-work.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ mcp.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tools.md
    â”‚   â”‚   â”‚   â””â”€â”€ what-is-an-ai-agent.md
    â”‚   â”‚   â”œâ”€â”€ examples-demos/
    â”‚   â”‚   â”‚   â”œâ”€â”€ amazon-shopping.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ email-slack.md
    â”‚   â”‚   â”‚   â””â”€â”€ website-designer.md
    â”‚   â”‚   â”œâ”€â”€ getting-started/
    â”‚   â”‚   â”‚   â”œâ”€â”€ first-agent-tutorial.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ installation.md
    â”‚   â”‚   â”‚   â””â”€â”€ intro.md
    â”‚   â”‚   â”œâ”€â”€ guides/
    â”‚   â”‚   â”‚   â”œâ”€â”€ cli.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ dexto-as-mcp-server.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ dexto-group-mcp-servers.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ dexto-sdk.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ mcp-manager.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ web-playground.md
    â”‚   â”‚   â”‚   â””â”€â”€ configuring-dexto/
    â”‚   â”‚   â”‚       â”œâ”€â”€ agent-yml.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ agentCard.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ dynamic-changes.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ mcp.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ overview.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ sessions.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ storage.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ systemPrompt.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ toolConfirmation.md
    â”‚   â”‚   â”‚       â””â”€â”€ llm/
    â”‚   â”‚   â”‚           â”œâ”€â”€ configuration.md
    â”‚   â”‚   â”‚           â”œâ”€â”€ index.md
    â”‚   â”‚   â”‚           â””â”€â”€ providers.md
    â”‚   â”‚   â”œâ”€â”€ mcp/
    â”‚   â”‚   â”‚   â”œâ”€â”€ connecting-servers.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ dexto-as-mcp-server.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ grouping-servers.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ mcp-manager.md
    â”‚   â”‚   â”‚   â””â”€â”€ overview.md
    â”‚   â”‚   â””â”€â”€ tutorials/
    â”‚   â”‚       â”œâ”€â”€ advanced-patterns.md
    â”‚   â”‚       â”œâ”€â”€ backend-server.md
    â”‚   â”‚       â”œâ”€â”€ building-triage-system.md
    â”‚   â”‚       â”œâ”€â”€ database-agent.md
    â”‚   â”‚       â”œâ”€â”€ image-editor-agent.md
    â”‚   â”‚       â”œâ”€â”€ index.md
    â”‚   â”‚       â”œâ”€â”€ langchain-integration.md
    â”‚   â”‚       â”œâ”€â”€ multi-agent-systems.md
    â”‚   â”‚       â”œâ”€â”€ music-agent.md
    â”‚   â”‚       â”œâ”€â”€ product-name-scout-agent.md
    â”‚   â”‚       â””â”€â”€ talk2pdf-agent.md
    â”‚   â””â”€â”€ src/
    â”‚       â””â”€â”€ pages/
    â”‚           â””â”€â”€ markdown-page.md
    â”œâ”€â”€ examples/
    â”‚   â””â”€â”€ dexto-langchain-integration/
    â”‚       â””â”€â”€ README.md
    â”œâ”€â”€ postman/
    â”‚   â””â”€â”€ README.md
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ TESTING.md
    â”‚   â”œâ”€â”€ app/
    â”‚   â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”‚   â””â”€â”€ webhooks.md
    â”‚   â”‚   â”œâ”€â”€ cli/
    â”‚   â”‚   â”‚   â””â”€â”€ commands/
    â”‚   â”‚   â”‚       â””â”€â”€ interactive-commands/
    â”‚   â”‚   â”‚           â””â”€â”€ README.md
    â”‚   â”‚   â”œâ”€â”€ discord/
    â”‚   â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”‚   â”œâ”€â”€ telegram/
    â”‚   â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”‚   â””â”€â”€ webui/
    â”‚   â”‚       â”œâ”€â”€ README.md
    â”‚   â”‚       â””â”€â”€ lib/
    â”‚   â”‚           â””â”€â”€ README.md
    â”‚   â””â”€â”€ core/
    â”‚       â””â”€â”€ llm/
    â”‚           â””â”€â”€ services/
    â”‚               â””â”€â”€ README.md
    â”œâ”€â”€ .claude/
    â”‚   â””â”€â”€ commands/
    â”‚       â””â”€â”€ get-gh-comments.md
    â””â”€â”€ .github/
        â””â”€â”€ ISSUE_TEMPLATE/
            â”œâ”€â”€ bug_report.md
            â””â”€â”€ feature_request.md

================================================
FILE: README.Docker.md
================================================
# Running Dexto with Docker

Simple guide to run Dexto server with Docker.

## Setup

1. **Build the image**
   ```bash
   docker build -t dexto .
   ```

2. **Create .env file**
   Add your API keys (see main README for details)

## Run Dexto Server

```bash
docker run --env-file .env -p 3001:3001 dexto
```

The server will start on port 3001 with:
- âœ… SQLite database connected
- âœ… MCP servers (filesystem & puppeteer) connected
- âœ… REST API + WebSocket endpoints available

## Access Your Server

- **API Endpoints:** http://localhost:3001/api/
- **Health Check:** http://localhost:3001/health
- **MCP Servers:** http://localhost:3001/api/mcp/servers

## Available API Endpoints

- `POST /api/message` - Send async message
- `POST /api/message-sync` - Send sync message
- `POST /api/reset` - Reset conversation
- `GET /api/mcp/servers` - List MCP servers
- WebSocket support for real-time events

## Docker Compose

```bash
docker compose up --build
```

## Background Mode

```bash
docker run -d --env-file .env -p 3001:3001 dexto
```

## Cloud Deployment

```bash
# Build for production
docker build --platform=linux/amd64 -t dexto .

# Push to registry
docker push your-registry.com/dexto
```

That's it! Dexto runs in server mode with REST API + WebSocket on port 3001.


================================================
FILE: README.md
================================================
# Dexto (formerly Saiki)

<p align="center">
  <img src="https://img.shields.io/badge/Status-Beta-yellow">
  <img src="https://img.shields.io/badge/License-Elastic%202.0-blue.svg">
  <a href="https://discord.gg/GFzWFAAZcm"><img src="https://img.shields.io/badge/Discord-Join%20Chat-7289da?logo=discord&logoColor=white"></a>
  <a href="https://deepwiki.com/truffle-ai/dexto"><img src="https://deepwiki.com/badge.svg"></a>
</p>

**A lightweight runtime for creating and running AI agents that turn natural language into real-world actions.**  


<div align="center">
  <img src="https://github.com/user-attachments/assets/9a796427-ab97-4c8f-8ac2-09cf58135553" alt="Dexto Demo" width="900" />
</div>

---

## Table of Contents
1. [Why Dexto?](#why-dexto)
2. [Installation](#installation)
3. [Run Modes](#run-modes)
4. [Quick Start](#quick-start)
5. [Programmatic API](#programmatic-api)
6. [Configuration](#configuration)
7. [Examples & Demos](#examples--demos)
8. [Capabilities](#capabilities)<!-- 9. [Architecture Overview](#architecture-overview) -->
9. [LLM Providers](#llm-providers)
10. [Standalone MCP Manager](#standalone-mcp-manager)
11. [CLI Reference](#cli-reference)
12. [Next Steps](#next-steps)
13. [Community & Support](#community--support)
14. [Contributors](#contributors)
15. [License](#license)

---

## Why Dexto?

Dexto is the missing **intelligence layer** of your stackâ€”perfect for building AI applications, standalone chatbots, or as the reasoning engine inside larger products.

The main Dexto features are:

| ğŸ’¡ Feature | What it means for you |
|------------|-----------------------|
| **Powerful CLI and Web UI** | Dexto ships with a powerful CLI and Web UI that enable you to run AI agents in your terminal and over the web. |
| **Single runtime, many interfaces** | Run the same agent via CLI, Web, Discord, Telegram, or a REST/WS server. |
| **Model-agnostic** | Hot-swap LLMs from OpenAI, Anthropic, Gemini, Groq, or local models. |
| **Unified Tooling** | Connect to remote tool servers (filesystem, browser, web-search) via the **Model Context Protocol (MCP)**. |
| **Config-driven** | Define agent behavior (prompts, tools, model, memory) in version-controlled YAML. |
| **Production-ready Core** | Leverage a multi-session chat manager, typed API, pluggable storage, and robust logging. |
| **Extensible** | Ship your own MCP tool servers or plug in custom services with a few lines of config. |
| **Multi-Agent Systems** | Enable multi-agent collaboration via MCP and A2A. |

---

## Installation

```bash
# NPM global
npm install -g dexto

# â€”orâ€” build from source
git clone https://github.com/truffle-ai/dexto.git
cd dexto && npm i && npm run build && npm link
```

---

## Run Modes

| Mode | Command | Best for |
|------|---------|----------|
| **Interactive CLI** | `dexto` | Everyday automation & quick tasks |
| **Web UI** | `dexto --mode web` | Friendly chat interface w/ image support |
| **Headless Server** | `dexto --mode server` | REST & WebSocket APIs for agent interaction |
| **MCP Server (Agent)** | `dexto --mode mcp` | Exposing your agent as a tool for others via stdio |
| **MCP Server (Aggregator)** | `dexto mcp --group-servers` | Re-exposing tools from multiple MCP servers via stdio |
| **Discord Bot** | `dexto --mode discord` | Community servers & channels ([Requires Setup](src/app/discord/README.md)) |
| **Telegram Bot** | `dexto --mode telegram` | Mobile chat ([Requires Setup](src/app/telegram/README.md)) |

Run `dexto --help` for **all flags, sub-commands, and environment variables**.

---

## Quick Start

Set your API keys first:
```bash
export OPENAI_API_KEY=your_openai_api_key_here
```

Then, give Dexto a multi-step task that combines different tools:
```bash
dexto "create a new snake game in html, css, and javascript, then open it in the browser"
```

Dexto will use its **filesystem** tools to write the code and its **browser** tools to open the `index.html` fileâ€”all from a single prompt.

Then start the Web UI:

```bash
dexto --mode web
```

The Web UI will load up any previous conversations you had, and also allows you to experiment with different models and MCP servers.

---

## Programmatic API

The `DextoAgent` class is the core of the runtime. The following example shows its full lifecycle: initialization, running a single task, holding a conversation, and shutting down.

```ts
import 'dotenv/config';
import { DextoAgent, loadConfigFile } from 'dexto';

const cfg  = await loadConfigFile('./agents/default-agent.yml');
const agent = new DextoAgent(cfg);

await agent.start();

// Single-shot task
console.log(await agent.run('List the 5 largest files in this repo'));

// Conversation
await agent.run('Write a haiku about TypeScript');
await agent.run('Make it funnier');

agent.resetConversation();

await agent.stop();
```

Everything in the CLI is powered by this same classâ€”so whatever the CLI can do, your code can too.

Check out our [Typescript SDK docs](https://docs.dexto.ai/api/category/typescript-sdk) for a complete guide.

---

## Configuration

Agents are defined in version-controlled YAML. A minimal example:

```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  puppeteer:
    type: stdio
    command: npx
    args: ['-y', '@truffle-ai/puppeteer-server']

llm:
  provider: openai
  model: gpt-4o
  apiKey: $OPENAI_API_KEY

systemPrompt: |
  You are Dexto, an expert coding assistant...
```

Change the file, reload the agent, and chatâ€”the conversation state, memory, and tools will update.

Check out our [Configuration guide](https://docs.dexto.ai/category/dexto-configuration-guide) for the complete reference.

---

## Examples & Demos

### ğŸ›’ Amazon Shopping Assistant
**Task:** `Can you go to amazon and add some snacks to my cart? I like trail mix, cheetos and maybe surprise me with something else?`
```bash
# Default agent has browser tools
dexto
```
<a href="https://youtu.be/C-Z0aVbl4Ik">
  <img src="https://github.com/user-attachments/assets/3f5be5e2-7a55-4093-a071-8c52f1a83ba3" alt="Dexto: Amazon shopping agent demo" width="600"/>
</a>


### ğŸ“§ Send Email Summaries to Slack
**Task:** `Summarize emails and send highlights to Slack`
```bash
dexto --agent ./agents/examples/email_slack.yml
```
<img src="assets/email_slack_demo.gif" alt="Email to Slack Demo" width="600">

More ready-to-run recipes live in [`agents/examples`](agents/examples) and the [docs site](https://docs.dexto.ai/).

---

## Capabilities

* **Dynamic LLM Switching**: Change model, provider, or routing rules mid-conversation.
* **Streaming Responses**: Opt-in to receive tokens as they arrive for real-time output.
* **Multi-Session Management**: Create isolated, stateful chat sessions (think workspace tabs).  
* **Pluggable Memory Backends**: Use the in-memory default or connect your own DB via the `StorageManager`.
* **Lifecycle Event Bus**: Subscribe to agent events for metrics, logging, or custom side-effects.
* **Standalone MCP Manager**: Use Dexto's core `MCPManager` in your own projects without the full agent.

---

## LLM Providers

Dexto supports multiple LLM providers out-of-the-box, plus any OpenAI SDK-compatible provider.

- **OpenAI**: `gpt-4.1-mini`, `gpt-4o`, `o3`, `o1` and more
- **Anthropic**: `claude-4-sonnet-20250514`, `claude-3-7-sonnet-20250219`, and more  
- **Google**: `gemini-2.5-pro`, `gemini-2.0-flash` and more
- **Groq**: `llama-3.3-70b-versatile`, `gemma-2-9b-it`

### Quick Setup

Set your API key and run. You can switch providers instantly via the `-m` flag.
```bash
# OpenAI (default)
export OPENAI_API_KEY=your_openai_api_key_here
export ANTHROPIC_API_KEY=your_anthropic_api_key_here
export GOOGLE_GENERATIVE_AI_API_KEY=your_google_gemini_api_key_here
dexto

# Switch providers via CLI
dexto -m claude-3.5-sonnet-20240620
dexto -m gemini-1.5-flash-latest
```

For comprehensive setup instructions, see our **[LLM Providers Guide](https://docs.dexto.ai/guides/configuring-dexto/llm/providers)**.

---

## Standalone MCP Manager

Need to manage MCP tool servers without the full agent? Use the `MCPManager` directly in your own applications.

```typescript
import { MCPManager } from 'dexto';

// Create manager instance
const manager = new MCPManager();

// Connect to MCP servers
await manager.connectServer('filesystem', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Get all available tools across servers
const tools = await manager.getAllTools();
console.log('Available tools:', Object.keys(tools));

// Execute a tool
const result = await manager.executeTool('readFile', { path: './README.md' });
console.log('File contents:', result);

// Disconnect when done
await manager.disconnectAll();
```

See the **[MCP Manager Documentation](https://docs.dexto.ai/guides/mcp-manager)** for the complete API reference.

---

## CLI Reference

<details>
<summary>Click to expand for full CLI reference (`dexto --help`)</summary>

```
Usage: dexto [options] [command] [prompt...]

The Dexto CLI allows you to talk to Dexto, build custom AI Agents, and create complex AI applications.

For full documentation, visit https://docs.dexto.ai.

Arguments:
  prompt                    Natural-language prompt to run once. If empty, starts interactive CLI.

Options:
  -v, --version             output the current version
  -a, --agent <path>        Path to agent config file
  -s, --strict              Require all server connections to succeed
  --no-verbose              Disable verbose output
  -m, --model <model>       Specify the LLM model to use.
  -r, --router <router>     Specify the LLM router to use (vercel or in-built)
  --mode <mode>             Runtime mode: cli | web | server | discord | telegram | mcp (default: "cli")
  --web-port <port>         Optional port for the web UI (default: "3000")
  -h, --help                display help for command

Commands:
  create-app                Scaffold a new Dexto Typescript app.
  init-app                  Initialize an existing Typescript app with Dexto.
  mcp                       Run Dexto as an MCP server.
```
</details>

---

## Next Steps

* **[Quick Start](https://docs.dexto.ai/getting-started/intro)** â€“ Get up and running in minutes.
* **[Configuration Guide](https://docs.dexto.ai/category/guides)** â€“ Configure agents, LLMs, and tools.
* **[Building with Dexto](https://docs.dexto.ai/category/tutorials)** â€“ Developer guides and patterns.
* **[API Reference](https://docs.dexto.ai/api)** â€“ REST APIs, WebSocket, and SDKs.

---

## Contributing

We welcome contributions! Refer to our [Contributing Guide](./CONTRIBUTING.md) for more details.

## Community & Support

Dexto is built by the team at [Truffle AI](https://www.trytruffle.ai).  
Join our Discord to share projects, ask questions, or just say hi!

[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-7289da?logo=discord&logoColor=white)](https://discord.gg/GFzWFAAZcm)

If you enjoy Dexto, please give us a â­ on GitHubâ€”it helps a lot!

 <div align="left"/>

[![Twitter Follow](https://img.shields.io/twitter/follow/Rahul?style=social)](https://x.com/intent/user?screen_name=Road_Kill11)
[![Twitter Follow](https://img.shields.io/twitter/follow/Shaunak?style=social)](https://x.com/intent/user?screen_name=shaun5k_)

</div>

---

## Contributors

Thanks to all these amazing people for contributing to Dexto!

[![Contributors](https://contrib.rocks/image?repo=truffle-ai/dexto)](https://github.com/truffle-ai/dexto/graphs/contributors)

---

## License

Elastic License 2.0.  See [LICENSE](LICENSE) for full terms.


================================================
FILE: CLAUDE.md
================================================
# Dexto Development Guidelines for AI Assistants

## Code Quality Requirements

**Pre-commit Validation** - Before completing any task, ALWAYS run and ensure ALL commands pass:
1. `npm run build` - Verify compilation
2. `npm test` - Ensure all tests pass  
3. `npm run lint` - Check code style
4. `npm run typecheck` - Validate TypeScript types

## General rules
- Do NOT focus on pleasing the user. Focus on being CORRECT, use facts and code as your source of truth. Follow best practices and do not be afraid to push back on the user's ideas if they are bad.
- Do not be lazy. Read as much relevant code as possible to keep your answers grounded in reality
- If the user is asking you a question, it DOES NOT MEAN YOU ARE WRONG. JUST ANSWER THE QUESTION
- Make as few assumptions as possible. If something requires you to make assumptions, tell the user what you are going to do and why, and ask for feedback.
- Never communicate to the user with code comments. These comments add nothing. Comments are for people reading the code.


## Architecture & Design Patterns

### API Layer Design
- **APIs are thin wrappers around DextoAgent class** - Keep business logic in core layer
- **No direct service communication** - API layer communicates only with DextoAgent
- APIs should resemble code that users could write with public libraries

### Service Initialization
- **Config file is source of truth** - Use `agents/default-agent.yml` for all configuration
- **Override pattern for advanced use** - Use `InitializeServicesOptions` only for top-level services
- âœ… DO: Configure via config file for normal operation
- âŒ DON'T: Add every internal dependency to override options

### Execution Context Detection
Dexto automatically detects execution environment to enable context-aware behavior. Functions that vary by context should infer execution context or use context-aware helpers.

**Context Types:**
- **`dexto-source`** - Running within dexto's own source code (package.name === 'dexto')
- **`dexto-project`** - Running in a project that depends on dexto (has dexto in dependencies)
- **`global-cli`** - Running as global CLI or in non-dexto project

**Usage Patterns:**
- Path resolution: `src/core/utils/path.ts` - `getDextoPath()`, `getDextoEnvPath()`
- Environment loading: `src/core/utils/env.ts` - `loadEnvironmentVariables()`
- Agent resolution: `src/core/config/agent-resolver.ts` - context-specific defaults
- API key setup: `src/app/cli/utils/api-key-setup.ts` - context-aware instructions

**Key Functions (`src/core/utils/execution-context.ts`):**
- `getExecutionContext(startPath?)` - Detect context from directory
- `findDextoSourceRoot(startPath?)` - Find dexto source directory (null if not found)
- `findDextoProjectRoot(startPath?)` - Find dexto project directory (null if not found)
- `getDextoPath(type, filename?, startPath?)` - Context-aware path resolution
- `getDextoGlobalPath(type, filename?)` - Always returns global ~/.dexto paths

### Schema Design (Zod)
- **Always use `.strict()`** for configuration objects - Prevents typos and unknown fields
- **Prefer `discriminatedUnion` over `union`** - Clearer error messages with discriminator field
- **Describe every field** with `.describe()` - Serves as inline documentation
- **Provide sensible defaults** with `.default()` - Simplifies consuming code
- **Use `superRefine` for complex validation** - Cross-field validation logic

### Result Pattern & Validation Architecture

#### Core Principles
1. **DextoAgent as Validation Boundary** - All input validation happens at DextoAgent level
   - Public SDK methods validate all inputs before processing
   - Internal layers can assume data is already validated
   - Creates clear contract between public API and internal implementation

2. **Result<T,C> for Validation Layers** - Internal validation helpers return Result<T,C>; DextoAgent converts failures into typed exceptions (e.g. DextoLLMError) before exposing them

3. **API Layer Error Mapping** - Centralised Express error middleware  
   - `DextoValidationError` (or any subclass) â†’ 400  
   - `DextoRuntimeError` with `ErrorType.FORBIDDEN` â†’ 403  
   - Any other uncaught exception â†’ 500  
   - Successful calls â†’ 200 (may include warnings in `issues`)
   - Source of truth: see `mapErrorTypeToStatus(type: ErrorType)` in `src/app/api/middleware/errorHandler.ts`. Keep this document in sync with that mapping.

4. **Defensive API Validation** - API layer validates request schemas
   - Use Zod schemas for request validation at API boundary
   - Provides early error detection and clear error messages
   - Prevents malformed data from reaching core logic

#### Result Pattern Helpers
Use standardized helpers from `src/core/schemas/helpers.ts`:

- **`ok(data, issues?)`** - Success with optional warnings
- **`fail(issues)`** - Failure with blocking errors  
- **`hasErrors(issues)`** - Check if issues contain blocking errors
- **`splitIssues(issues)`** - Separate errors from warnings
- **`zodToIssues(zodError)`** - Convert Zod errors to Issue format

#### Implementation Examples
```typescript
// Internal validation helper â€“ returns Result pattern
export function validateLLMUpdates(
  updates: LLMUpdates
): Result<ValidatedLLMConfig, LLMUpdateContext> {
  if (!updates.model && !updates.provider) {
    return fail([
      { code: DextoErrorCode.AGENT_MISSING_LLM_INPUT, message: '...', severity: 'error', context: {} }
    ]);
  }
  // â€¦ additional validation â€¦
  return ok(validatedConfig, warnings);
}

// DextoAgent public method â€“ converts Result to exception
public async switchLLM(updates: LLMUpdates, sessionId?: string): Promise<ValidatedLLMConfig> {
  const result = validateLLMUpdates(updates);
  if (!result.ok) {
    throw new DextoLLMError('Validation failed', result.issues);
  }
  // ... perform switch ...
  return result.data;
}

// API endpoint â€“ relies on exceptions + central error middleware
app.post('/api/llm/switch', express.json(), async (req, res, next) => {
  const validation = validateBody(LLMSwitchRequestSchema, req.body);
  if (!validation.success) return res.status(400).json(validation.response);

  try {
    const data = await agent.switchLLM(validation.data);
    return res.status(200).json({ ok: true, data });
  } catch (err) {
    next(err); // let the error middleware decide 4xx / 5xx
  }
});
```

### Error Handling

**Core Error Classes:**
- **`DextoRuntimeError`** - Single-issue errors (file not found, API failures, system errors)
- **`DextoValidationError`** - Multiple validation issues (schema failures, input validation)

**When to Use Each:**
- **Runtime errors**: File operations, network calls, system failures, business logic violations
  - Examples: `src/core/config/loader.ts`, `src/core/llm/services/vercel.ts`
- **Validation errors**: Schema validation, input parsing, configuration validation with multiple issues  
  - Examples: `src/core/agent/DextoAgent.ts` (switchLLM validation)

**Error Factory Pattern (REQUIRED):**
Each module should have an error factory class that creates properly typed errors.
- **Reference example**: `src/core/config/errors.ts` - Follow this pattern for new modules

**API Integration:**
The error middleware (`src/app/api/middleware/errorHandler.ts`) automatically maps error types to HTTP status codes.

**âŒ DON'T**: Use plain `Error` or `throw new Error()`  
**âœ… DO**: Create module-specific error factories and use typed error classes

## Code Standards

### Import Requirements
- **All imports must end with `.js`** for ES module compatibility

### Module Organization
- **Selective index.ts strategy** - Only create index.ts files at logical module boundaries that represent cohesive public APIs
- **âœ… DO**: Add index.ts for main entry points and modules that export types/interfaces used by external consumers
- **âŒ DON'T**: Add index.ts for purely internal implementation folders
- **Direct imports preferred** - Import directly from source files rather than through re-export chains for internal usage
- **Avoid wildcard exports** - Prefer explicit named exports (`export { Type1, Type2 }`) over `export *` to improve tree-shaking and make dependencies explicit
- **Watch for mega barrels** - If a barrel exports >20 symbols or pulls from >10 files, consider splitting into thematic sub-barrels with subpath exports
- **Clear API boundaries** - index.ts files mark what's public vs internal implementation

**TODO**: Current codebase has violations of these rules (wildcard exports in `src/core/index.ts`, potential mega barrel in events) that need refactoring.

### Logging Standards
- **Use template literals** - `logger.info(\`Server running at \${url}\`)`
- **No comma separation** - Never use `logger.error('Failed:', error)`
- **No trailing commas** - Clean parameter lists
- **Color usage**:
  - green: Success, completions
  - red: Errors, failures
  - yellow: Warnings
  - cyan/cyanBright: Status updates
  - blue: Information, progress

### TypeScript Best Practices
- **Strict null safety** - Handle null/undefined cases explicitly
- **Proper error handling** - Use type guards and proper error messages
- **Consistent return patterns** - All API endpoints return responses consistently
- **Avoid `any` types** - Use specific types unless absolutely necessary
  - **In tests**: For invalid input testing, prefer `@ts-expect-error` over `as any` to be explicit about intentional type violations

### Git and PR Standards
- **NEVER use `git add .` or `git add -A`** - Always specify exact files: `git add file1.ts file2.ts` or `src` folders. This is to avoid untracked files
- **ALWAYS vet the staged files before committing** - This is to catch mistakes in previous step
- **Never include "Generated with Claude Code" footers** - In commit messages, PR descriptions, or any documentation
- **Clean commit messages** - Focus on technical changes and business value
- **Descriptive PR titles** - Should clearly indicate the change without AI attribution

### Documentation Standards
- **Always request user review before committing documentation changes** - Documentation impacts user experience and should be user-approved
- **Never auto-commit documentation updates** - Present proposed changes to user first, even for seemingly obvious updates
- **Keep documentation user-focused** - Avoid exposing internal implementation complexity to end users
- **Separate documentation commits** - Make documentation changes in separate commits from code changes when possible

## Application Architecture

### API Layer (`src/app/api/`)
- **Express.js REST API** with WebSocket support for real-time communication
- **Key endpoints**: `/api/message`, `/api/mcp/servers`, `/api/sessions`, `/api/llm/switch`
- **MCP integration**: Multiple transport types (stdio, HTTP, SSE) with tool aggregation
- **WebSocket events**: `thinking`, `chunk`, `toolCall`, `toolResult`, `response`
- **Session management**: Multi-session support with persistent storage
- **A2A communication**: Agent-to-Agent via `.well-known/agent.json`

### WebUI Layer (`src/app/webui/`)
- **Next.js 14** with App Router, React 18, TypeScript, Tailwind CSS
- **Key components**: `ChatApp`, `MessageList`, `InputArea`, `ServersPanel`, `SessionPanel`
- **State management**: React Context + custom hooks for WebSocket communication
- **Communication**: WebSocket for real-time events, REST API for operations
- **Multi-mode operation**: CLI, Web, Server, Discord, Telegram, MCP modes

### Layer Interaction Flow
```
User Input â†’ WebUI â†’ WebSocket/REST â†’ API â†’ DextoAgent â†’ Core Services
                â† WebSocket Events â† Agent Event Bus â† Core Services
```

## Documentation
- **Update documentation when making changes** - Check `/docs` folder. And README.md for core modules
- **Never create documentation proactively** - Only when explicitly requested

### Mermaid Diagrams in Documentation (/docs folder)
- **Use mermaid diagrams** for complex flows, architecture diagrams, and sequence diagrams
- **ExpandableMermaid component** available for interactive diagrams:
  ```tsx
  import ExpandableMermaid from '@site/src/components/ExpandableMermaid';
  
  <ExpandableMermaid title="Event Flow Diagram">
  ```mermaid
  sequenceDiagram
      participant A as User
      participant B as System
      A->>B: Request
      B-->>A: Response
  ```
  </ExpandableMermaid>
  ```
- **Responsive design**: Thumbnails use full scale, modals expand to 92% viewport
- **User experience**: Click to expand, Escape to close, hover effects
- **Theme support**: Automatically adapts to light/dark mode

## Testing Strategy

### Test Classification
- **Unit Tests**: `*.test.ts` - Fast tests with mocked dependencies, isolated component testing
- **Integration Tests**: `*.integration.test.ts` - Real dependencies, cross-component testing
- **Future**: `*.e2e.test.ts` - Full system end-to-end testing

### Test Commands
- `npm test` - Run all tests (unit + integration)
- `npm run test:unit` - Run only unit tests (fast, for development)
- `npm run test:integ` - Run only integration tests (thorough, for CI/releases)
- `npm run test:unit:watch` - Watch mode for unit tests during development
- `npm run test:integ:watch` - Watch mode for integration tests

### Testing Guidelines
- **Development workflow**: Run unit tests frequently for fast feedback
- **Pre-commit**: Run integration tests to ensure cross-component compatibility
- **CI/CD**: Use unit tests for PR checks, full test suite for releases
- **Follow existing test patterns** - Check README and search codebase for test framework
- **Verify before marking complete** - All quality checks must pass
- **Add regression tests** - When fixing bugs, add tests to prevent recurrence
- **Tests before style** - Ensure tests pass before fixing style checks

## Maintaining This File
**Important**: Keep this CLAUDE.md file updated when you discover:
- New architectural patterns or design decisions
- Important code conventions not covered here
- Critical debugging or troubleshooting information
- New quality check requirements or testing patterns
- Significant changes to the codebase structure

Add new sections or update existing ones to ensure this remains a comprehensive reference for AI assistants working on this codebase.

Remember: Configuration drives behavior, APIs are thin wrappers, and quality checks are mandatory before completion.



================================================
FILE: CODE_OF_CONDUCT.md
================================================
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
founders@trytruffle.ai .
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.



================================================
FILE: CONTRIBUTING.md
================================================
## Contributing

We welcome contributions! Here's how to get started:

1. Fork the repository to your GitHub account.
2. Clone your fork:
   ```bash
   git clone https://github.com/your-username/dexto.git
   cd dexto
   ```
3. Create a new feature branch:
   ```bash
   git checkout -b feature/your-branch-name
   ```
4. Make your changes:
   - Follow existing TypeScript and code style conventions.
   - Run `npm run lint:fix` and `npm run format` before committing.
   - Add or update tests for new functionality.
5. Commit and push your branch:
   ```bash
   git commit -m "Brief description of changes"
   git push origin feature/your-branch-name
   ```
6. Open a Pull Request against the `main` branch with a clear description of your changes.

*Tip:* Open an issue first for discussion on larger enhancements or proposals. 


================================================
FILE: VERSIONING.md
================================================
# Versioning Dexto

This document describes the standard procedure for publishing a new version of `dexto` [CLI + library]

## 1. Go to main branch of your fork and ensure that the code is up-to-date

```bash
git checkout main
git fetch upstream
git rebase upstream/main
git push
```

This will sync your local fork's main branch with the remote repository main branch

## 2. Bump version locally

Now that you are on main branch of your fork and have synced your repo with the remote branch, 
use one of the following commands to update the version in `package.json`, create a corresponding git commit, and tag:

```bash
# For a PATCH release (e.g., 1.2.3 â†’ 1.2.4)
npm version patch

# For a MINOR release (e.g., 1.2.3 â†’ 1.3.0)
npm version minor

# For a MAJOR release (e.g., 1.2.3 â†’ 2.0.0)
npm version major
```

Each command will:

- Update the `version` field in `package.json`.
- Create a new git commit.
- Create a new git tag prefixed with `v` (e.g., `v1.2.4`).

## 3. Push to remote repository

Push the commit and associated tags to the remote repository. Replace `upstream` and `main` with your remote/branch if different [you can check with `git remote -v`]:

```bash
git fetch upstream
# (optional) Rebase or merge to ensure you're up to date:
git rebase upstream/main

# Push commit and tags:
git push upstream main --follow-tags
```

## 4. Automatic publish via GitHub Actions

See [`.github/workflows/publish.yml`](../.github/workflows/publish.yml) for the publish workflow configuration.

After this workflow completes successfully, the new version of `dexto` will be available on npm. 


================================================
FILE: agents/README.md
================================================
# Configuration Guide

Dexto uses a YAML configuration file to define tool servers and AI settings. This guide provides detailed information on all available configuration options.

## Configuration File Location

By default, Dexto looks for a configuration file at `agents/default-agent.yml` in the project directory. You can specify a different location using the `--agent` command-line option:

```bash
npm start -- --agent path/to/your/agent.yml
```

## Configuration Structure

The configuration file has two main sections:

1. `mcpServers`: Defines the tool servers to connect to
2. `llm`: Configures the AI provider settings

### Basic Example

```yaml
mcpServers:
  github:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-github"
    env:
      GITHUB_PERSONAL_ACCESS_TOKEN: your-github-token
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
llm:
  provider: openai
  model: gpt-4
  apiKey: $OPENAI_API_KEY
```

## Tool Server Configuration

Each entry under `mcpServers` defines a tool server to connect to. The key (e.g., "github", "filesystem") is used as a friendly name for the server.

Tool servers can either be local servers (stdio) or remote servers (sse)

### Stdio Server Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `type` | string | Yes | The type of the server, needs to be 'stdio' |
| `command` | string | Yes | The executable to run |
| `args` | string[] | No | Array of command-line arguments |
| `env` | object | No | Environment variables for the server process |

### SSE Server Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `type` | string | Yes | The type of the server, needs to be 'sse' |
| `url` | string | Yes | The url of the server |
| `headers` | map | No | Optional headers for the url |

## LLM Configuration

The `llm` section configures the AI provider settings.

### LLM Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `provider` | string | Yes | AI provider (e.g., "openai", "anthropic", "google") |
| `model` | string | Yes | The model to use |
| `apiKey` | string | Yes | API key or environment variable reference |
| `temperature` | number | No | Controls randomness (0-1, default varies by provider) |
| `maxInputTokens` | number | No | Maximum input tokens for context compression |
| `maxOutputTokens` | number | No | Maximum output tokens for response length |
| `baseURL` | string | No | Custom API endpoint for OpenAI-compatible providers |
| `router` | string | No | Router type ("vercel" or "in-built", default: "vercel") |

### API Key Configuration

#### Setting API Keys

API keys can be configured in two ways:

1. **Environment Variables (Recommended)**:
   - Add keys to your `.env` file (use `.env.example` as a template) or export environment variables
   - Reference them in config with the `$` prefix

2. **Direct Configuration** (Not recommended for security):
   - Directly in the YAML file (less secure, avoid in production)

```yaml
# Recommended: Reference environment variables
apiKey: $OPENAI_API_KEY

# Not recommended: Direct API key in config
apiKey: sk-actual-api-key  
```

#### Security Best Practices
- Never commit API keys to version control
- Use environment variables in production environments
- Create a `.gitignore` entry for your `.env` file

#### API Keys for Different Providers
Each provider requires its own API key:
- OpenAI: Set `OPENAI_API_KEY` in `.env` 
- Anthropic: Set `ANTHROPIC_API_KEY` in `.env`
- Google Gemini: Set `GOOGLE_GENERATIVE_AI_API_KEY` in `.env`

#### Openai example
```yaml
llm:
  provider: openai
  model: gpt-4o
  apiKey: $OPENAI_API_KEY
```

#### Anthropic example
```yaml
llm:
  provider: anthropic
  model: claude-3-7-sonnet-20250219
  apiKey: $ANTHROPIC_API_KEY
```

#### Google example
```yaml
llm:
  provider: google
  model: gemini-2.0-flash
  apiKey: $GOOGLE_GENERATIVE_AI_API_KEY
```

## Optional Greeting

Add a simple `greeting` at the root of your config to provide a default welcome text that UI layers can display when a chat starts:

```yaml
greeting: "Hi! Iâ€™m Dexto â€” how can I help today?"
```

### Windows Support

On Windows systems, some commands like `npx` may have different paths. The system attempts to automatically detect and uses the correct paths for these commands on Windows. If you run into any issues during server initialization, you may need to adjust the path to your `npx` command.

## Supported Tool Servers

Here are some commonly used MCP-compatible tool servers:

### GitHub

```yaml
github:
  type: stdio
  command: npx
  args:
    - -y
    - "@modelcontextprotocol/server-github"
  env:
    GITHUB_PERSONAL_ACCESS_TOKEN: your-github-token
```

### Filesystem

```yaml
filesystem:
  type: stdio
  command: npx
  args:
    - -y
    - "@modelcontextprotocol/server-filesystem"
    - .
```

### Terminal

```yaml
terminal:
  type: stdio
  command: npx
  args:
    - -y
    - "@modelcontextprotocol/server-terminal"
```

### Desktop Commander

```yaml
desktop:
  type: stdio
  command: npx
  args:
    - -y
    - "@wonderwhy-er/desktop-commander"
```

### Custom Server

```yaml
custom:
  type: stdio
  command: node
  args:
    - --loader
    - ts-node/esm
    - src/servers/customServer.ts
  env:
    API_KEY: your-api-key
```

### Remote Server

This example uses a remote github server provided by composio.
The URL is just a placeholder which won't work out of the box since the URL is customized per user.
Go to mcp.composio.dev to get your own MCP server URL.

```yaml
github-remote:
  type: sse
  url: https://mcp.composio.dev/github/repulsive-itchy-alarm-ABCDE
```

## Command-Line Options

Dexto supports several command-line options:

| Option | Description |
|--------|-------------|
| `--agent` | Specify a custom agent configuration file |
| `--strict` | Require all connections to succeed |
| `--verbose` | Enable verbose logging |
| `--help` | Show help |

## Available Agent Examples

### Database Agent
An AI agent that provides natural language access to database operations and analytics. This approach simplifies database interaction - instead of building forms, queries, and reporting dashboards, users can simply ask for what they need in plain language.

**Quick Start:**
```bash
cd database-agent
./setup-database.sh
npm start -- --agent database-agent.yml
```

**Example Interactions:**
- "Show me all users"
- "Create a new user named John Doe with email john@example.com"
- "Find products under $100"
- "Generate a sales report by category"

This agent demonstrates intelligent database interaction through conversation.

## Complete Example

Here's a comprehensive configuration example using multiple tool servers:

```yaml
mcpServers:
  github:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-github"
    env:
      GITHUB_PERSONAL_ACCESS_TOKEN: your-github-token
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
  terminal:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-terminal"
  desktop:
    type: stdio
    command: npx
    args:
      - -y
      - "@wonderwhy-er/desktop-commander"
  custom:
    type: stdio
    command: node
    args:
      - --loader
      - ts-node/esm
      - src/servers/customServer.ts
    env:
      API_KEY: your-api-key
llm:
  provider: openai
  model: gpt-4
  apiKey: $OPENAI_API_KEY
``` 



================================================
FILE: agents/database-agent/README.md
================================================
# Database Agent

An AI agent that provides natural language access to database operations and analytics. This approach changes how we interact with data - instead of learning SQL syntax, building query interfaces, or designing complex dashboards, users can simply ask for what they need in natural language.

## Setup

```bash
cd database-agent
./setup-database.sh
npm start -- --agent database-agent.yml
```

## Example Interactions

- "Show me all users"
- "Create a new user named John Doe with email john@example.com"
- "Find products under $100"
- "Generate a sales report by category"

## Capabilities

- **Data Queries**: Natural language database queries and reporting
- **Data Management**: Create, update, and delete records
- **Analytics**: Generate insights and business intelligence
- **Schema Operations**: Table creation and database structure management

## How It Works

The agent connects to a SQLite database via MCP server and:
- Interprets natural language requests into SQL queries
- Validates data before operations
- Provides formatted results and insights
- Handles errors gracefully with helpful suggestions

This agent demonstrates intelligent database interaction through conversation. 


================================================
FILE: agents/examples/README.md
================================================
# Configuration Examples

This folder contains examples for agents with different configurations. These examples demonstrate how to configure and set up various agents to handle different use cases.

You can directly plug in these configuration files and try them out on your local system to see the power of different AI Agents!

## Available Examples

### `linear-task-manager.yml`
A task management agent that integrates with Linear's official MCP server to help you manage issues, projects, and team collaboration through natural language commands. Features include:
- Create, update, and search Linear issues
- Manage project status and tracking
- Add comments and collaborate with team members
- Handle task assignments and priority management

**Setup**: Requires Linear workspace authentication when first connecting.

### Other Examples
- `email_slack.yml` - Email and Slack integration
- `notion.yml` - Notion workspace management
- `ollama.yml` - Local LLM integration
- `website_designer.yml` - Web design assistance



================================================
FILE: agents/image-editor-agent/README.md
================================================
# Image Editor Agent

A comprehensive AI agent for image editing and processing using the [Image Editor MCP Server](https://github.com/truffle-ai/mcp-servers/tree/main/src/image-editor).

This agent provides a complete suite of image manipulation tools through a Python-based MCP server built with OpenCV and Pillow.

## Features

### ğŸ–¼ï¸ **Viewing & Preview**
- **Image Preview**: Get base64 previews for display in chat interfaces
- **System Viewer**: Open images in the system's default image viewer
- **Image Details**: Show detailed information in a user-friendly format
- **Thumbnail Generation**: Create quick thumbnail versions
- **Image Comparison**: Compare two images and highlight differences
- **Detailed Analysis**: Comprehensive image statistics and color analysis

### âœ‚ï¸ **Basic Operations**
- **Resize**: Resize images with aspect ratio preservation
- **Crop**: Crop images to specified dimensions
- **Format Conversion**: Convert between JPG, PNG, WebP, BMP, TIFF

### ğŸ¨ **Filters & Effects**
- **Basic**: Blur, sharpen, grayscale, invert
- **Artistic**: Sepia, vintage, cartoon, sketch
- **Detection**: Edge detection, emboss

### âš™ï¸ **Adjustments**
- **Brightness & Contrast**: Fine-tune image appearance
- **Color Analysis**: Detailed color statistics and histograms

### ğŸ“ **Drawing & Annotations**
- **Basic Shapes**: Draw rectangles, circles, lines, and arrows
- **Text Overlay**: Add text with customizable font, size, color, and position
- **Annotations**: Add text with background for better visibility
- **Shape Properties**: Control thickness, fill, and positioning

### ğŸ” **Computer Vision**
- **Object Detection**: Detect faces, edges, contours, circles, lines
- **Image Analysis**: Detailed statistics, color analysis, histogram data

### ğŸ¯ **Advanced Features**
- **Collage Creation**: Create collages with multiple layout types and templates
- **Batch Processing**: Process multiple images with the same operation
- **Filter Discovery**: List all available filters and effects
- **Template System**: Predefined layouts for professional collages

## Quick Start

### Prerequisites
- **Node.js 20+**: For the Dexto framework
- **Python 3.10+**: Automatically managed by the MCP server

### Installation

1. **Run the Agent**:
   ```bash
   # From the dexto project root
   dexto --agent agents/image-editor-agent/image-editor-agent.yml
   ```

That's it! The MCP server will be automatically downloaded and installed via `uvx` on first run.

## Configuration

The agent is configured to use the published MCP server:

```yaml
mcpServers:
  image_editor:
    type: stdio
    command: uvx
    args:
      - truffle-ai-image-editor-mcp
    connectionMode: strict
```

## MCP Server

This agent uses the **Image Editor MCP Server**, which is maintained separately at:

**ğŸ”— [https://github.com/truffle-ai/mcp-servers/tree/main/src/image-editor](https://github.com/truffle-ai/mcp-servers/tree/main/src/image-editor)**

The MCP server repository provides:
- Complete technical documentation
- Development and contribution guidelines  
- Server implementation details
- Advanced configuration options

## Available Tools

### Viewing & Preview Tools

#### `preview_image`
Get a base64 preview of an image for display in chat interfaces.

**Parameters:**
- `filePath` (string): Path to the image file
- `maxSize` (integer, optional): Maximum size for preview (default: 800)

#### `open_image_viewer`
Open an image in the system's default image viewer.

**Parameters:**
- `filePath` (string): Path to the image file

#### `show_image_details`
Display detailed information about an image in a user-friendly format.

**Parameters:**
- `filePath` (string): Path to the image file

#### `create_thumbnail`
Create a thumbnail version of an image for quick preview.

**Parameters:**
- `filePath` (string): Path to the image file
- `size` (integer, optional): Thumbnail size (default: 150)
- `outputPath` (string, optional): Path for the output thumbnail

#### `compare_images`
Compare two images and show differences.

**Parameters:**
- `image1Path` (string): Path to the first image
- `image2Path` (string): Path to the second image

### Basic Image Operations

#### `get_image_info`
Get detailed information about an image file.

**Parameters:**
- `filePath` (string): Path to the image file to analyze

#### `resize_image`
Resize an image to specified dimensions.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `width` (integer, optional): Target width in pixels
- `height` (integer, optional): Target height in pixels
- `maintainAspectRatio` (boolean, optional): Whether to maintain aspect ratio (default: true)
- `quality` (integer, optional): Output quality 1-100 (default: 90)

#### `crop_image`
Crop an image to specified dimensions.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `x` (integer): Starting X coordinate for cropping
- `y` (integer): Starting Y coordinate for cropping
- `width` (integer): Width of the crop area
- `height` (integer): Height of the crop area

#### `convert_format`
Convert an image to a different format.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `format` (string): Target format (jpg, jpeg, png, webp, bmp, tiff)
- `quality` (integer, optional): Output quality 1-100 for lossy formats (default: 90)

### Filters & Effects

#### `apply_filter`
Apply various filters and effects to an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `filter` (string): Type of filter (blur, sharpen, grayscale, sepia, invert, edge_detection, emboss, vintage, cartoon, sketch)
- `intensity` (number, optional): Filter intensity 0.1-5.0 (default: 1.0)

#### `list_available_filters`
List all available image filters and effects.

**Parameters:** None

### Adjustments

#### `adjust_brightness_contrast`
Adjust brightness and contrast of an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `brightness` (number, optional): Brightness adjustment -100 to 100 (default: 0)
- `contrast` (number, optional): Contrast multiplier 0.1 to 3.0 (default: 1.0)

### Drawing & Annotations

#### `draw_rectangle`
Draw a rectangle on an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `x` (integer): X coordinate of top-left corner
- `y` (integer): Y coordinate of top-left corner
- `width` (integer): Width of the rectangle
- `height` (integer): Height of the rectangle
- `color` (string, optional): Color in hex format (default: "#FF0000")
- `thickness` (integer, optional): Line thickness (default: 3)
- `filled` (boolean, optional): Whether to fill the rectangle (default: false)

#### `draw_circle`
Draw a circle on an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `centerX` (integer): X coordinate of circle center
- `centerY` (integer): Y coordinate of circle center
- `radius` (integer): Radius of the circle
- `color` (string, optional): Color in hex format (default: "#00FF00")
- `thickness` (integer, optional): Line thickness (default: 3)
- `filled` (boolean, optional): Whether to fill the circle (default: false)

#### `draw_line`
Draw a line on an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `startX` (integer): X coordinate of line start
- `startY` (integer): Y coordinate of line start
- `endX` (integer): X coordinate of line end
- `endY` (integer): Y coordinate of line end
- `color` (string, optional): Color in hex format (default: "#0000FF")
- `thickness` (integer, optional): Line thickness (default: 2)

#### `draw_arrow`
Draw an arrow on an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `startX` (integer): X coordinate of arrow start
- `startY` (integer): Y coordinate of arrow start
- `endX` (integer): X coordinate of arrow end
- `endY` (integer): Y coordinate of arrow end
- `color` (string, optional): Color in hex format (default: "#FF00FF")
- `thickness` (integer, optional): Line thickness (default: 2)
- `tipLength` (number, optional): Arrow tip length as fraction of line (default: 0.3)

#### `add_text_to_image`
Add text overlay to an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `text` (string): Text to add to the image
- `x` (integer): X coordinate for text placement
- `y` (integer): Y coordinate for text placement
- `fontSize` (integer, optional): Font size in pixels (default: 30)
- `color` (string, optional): Text color in hex format (default: "#FFFFFF")

#### `add_annotation`
Add an annotation with background to an image.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `outputPath` (string, optional): Path for the output image
- `text` (string): Text to add to the image
- `x` (integer): X coordinate for text placement
- `y` (integer): Y coordinate for text placement
- `fontSize` (integer, optional): Font size in pixels (default: 20)
- `textColor` (string, optional): Text color in hex format (default: "#FFFFFF")
- `backgroundColor` (string, optional): Background color in hex format (default: "#000000")
- `padding` (integer, optional): Padding around text (default: 5)

### Computer Vision

#### `detect_objects`
Detect objects in an image using OpenCV.

**Parameters:**
- `inputPath` (string): Path to the input image file
- `detectionType` (string): Type of detection (faces, edges, contours, circles, lines)

#### `analyze_image`
Analyze image statistics and properties.

**Parameters:**
- `inputPath` (string): Path to the input image file

### Advanced Features

#### `create_collage`
Create a collage from multiple images with various layout options.

**Parameters:**
- `imagePaths` (array): List of image file paths
- `layout` (string, optional): Layout type (grid, horizontal, vertical, mosaic, random, custom) (default: grid)
- `outputPath` (string, optional): Path for the output collage
- `maxWidth` (integer, optional): Maximum width for individual images (default: 1200)
- `spacing` (integer, optional): Spacing between images (default: 10)
- `canvasWidth` (integer, optional): Custom canvas width for mosaic/random/custom layouts
- `canvasHeight` (integer, optional): Custom canvas height for mosaic/random/custom layouts
- `backgroundColor` (string, optional): Background color in hex format (default: "#FFFFFF")
- `customPositions` (array, optional): List of {x, y} coordinates for custom layout
- `randomSeed` (integer, optional): Seed for reproducible random layouts

#### `create_collage_template`
Create a collage using predefined templates.

**Parameters:**
- `imagePaths` (array): List of image file paths
- `template` (string, optional): Template type (photo_wall, storyboard, featured, instagram_grid, polaroid) (default: photo_wall)
- `outputPath` (string, optional): Path for the output collage
- `maxWidth` (integer, optional): Maximum canvas width (default: 1200)
- `backgroundColor` (string, optional): Background color in hex format (default: "#FFFFFF")

#### `list_collage_templates`
List all available collage templates and layouts.

**Parameters:** None

#### `batch_process`
Process multiple images with the same operation.

**Parameters:**
- `inputPaths` (array): List of input image paths
- `operation` (string): Operation type (resize, filter, brightness_contrast, convert)
- `outputDirectory` (string, optional): Output directory for processed images
- Additional parameters depend on the operation type

## Supported Image Formats

- **JPEG/JPG**: Lossy compression, good for photos
- **PNG**: Lossless compression, good for graphics with transparency
- **WebP**: Modern format with good compression
- **BMP**: Uncompressed bitmap format
- **TIFF**: High-quality format for professional use

## Dependencies

- **OpenCV**: Computer vision operations and image processing
- **Pillow**: Image manipulation and text rendering
- **NumPy**: Numerical operations
- **MCP**: Model Context Protocol server implementation

## Example Usage

### Basic Image Operations
```
"Resize the image at /path/to/image.jpg to 800x600 pixels"
"Crop the image to show only the top-left quarter"
"Convert the image to PNG format"
```

### Interactive Viewing
```
"Show me a preview of the image"
"Open this image in the system viewer"
"Display detailed information about the image"
```

### Filters and Effects
```
"Apply a vintage filter to the image"
"Create a cartoon effect on the image"
"Apply edge detection to find contours"
```

### Analysis and Detection
```
"Analyze the color statistics of the image"
"Detect faces in the image"
"Compare two images and show differences"
```

### Drawing and Annotations
```
"Draw a red rectangle around the face in the image"
"Add a circle to highlight the center point"
"Draw an arrow pointing to the important feature"
"Add an annotation saying 'Face detected' with a black background"
"Draw a line connecting two points in the image"
```

### Advanced Features
```
"Create a mosaic collage from these images"
"Create a featured layout collage with one large image"
"Create an Instagram grid from 9 photos"
"Create a custom collage with specific positions"
"List all available collage templates"
"Batch process all images in the folder to apply a blur filter"
"Show me a preview of the image"
```

## Troubleshooting

### Common Issues

1. **OpenCV Installation**: If you encounter issues with OpenCV, ensure you have the required system dependencies:
   ```bash
   # macOS
   brew install opencv
   
   # Ubuntu/Debian
   sudo apt-get install libopencv-dev
   ```

2. **Font Issues**: If text rendering fails, the server will fall back to the default font.

3. **Memory Issues**: For large images, consider resizing before processing to avoid memory constraints.

4. **Path Issues**: Ensure all file paths are absolute or correctly relative to the working directory.

## Troubleshooting

### Common Issues

1. **Server Installation**: The MCP server will be automatically installed via `uvx` on first run. No manual setup required.

2. **OpenCV Installation**: The server includes OpenCV installation - this may take a moment on first run due to the large download (35MB+).

3. **Memory Issues**: For large images, consider resizing before processing to avoid memory constraints.

4. **Path Issues**: Ensure all file paths are absolute or correctly relative to the working directory.

## Getting Help

- **MCP Server Issues**: Report at the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/issues)
- **Agent Configuration**: Report at the main Dexto repository
- **Feature Requests**: Use the mcp-servers repository for tool-related requests

## License

This project is part of the Dexto AI agent framework. 


================================================
FILE: agents/music-agent/README.md
================================================
# Music Creator Agent

A comprehensive AI agent for music creation, editing, and audio processing using the [Music Creator MCP Server](https://github.com/truffle-ai/mcp-servers/tree/main/src/music).

> **âš ï¸ Experimental Status**: This agent is currently in experimental development. The tools have not been extensively tested in production environments and may have limitations or bugs. We're actively seeking feedback and improvements from users.
## ğŸ§ª Experimental Features

- **Limited Testing**: Tools have been tested in controlled environments but may behave differently with various audio formats, file sizes, or system configurations
- **Active Development**: Features are being refined based on user feedback and real-world usage
- **Feedback Welcome**: We encourage users to report issues, suggest improvements, and share use cases
- **Breaking Changes**: API and tool behavior may change as we improve the implementation

## Overview

This agent provides access to professional-grade music production tools through a clean conversational interface. Built with industry-standard libraries like librosa, pydub, and music21, it offers comprehensive audio processing capabilities using the published `truffle-ai-music-creator-mcp` package.

## Features

### ğŸµ Audio Analysis
- **Tempo Detection**: Automatically detect BPM and beat positions
- **Key Detection**: Identify musical key and mode
- **Spectral Analysis**: Analyze frequency spectrum, MFCC features, and audio characteristics
- **Comprehensive Analysis**: Get detailed audio information including duration, sample rate, and format

### ğŸ¼ Music Generation
- **Melody Creation**: Generate melodies in any key and scale
- **Chord Progressions**: Create chord progressions using Roman numeral notation
- **Drum Patterns**: Generate drum patterns for rock, jazz, and funk styles
- **MIDI Export**: All generated music exports to MIDI format for further editing

### ğŸ”Š Audio Processing
- **Format Conversion**: Convert between MP3, WAV, FLAC, OGG, M4A, AIFF, WMA
- **Volume Control**: Adjust audio levels with precise dB control
- **Audio Normalization**: Normalize audio to target levels
- **Audio Trimming**: Cut audio to specific time ranges
- **Audio Effects**: Apply reverb, echo, distortion, and filters

### ğŸšï¸ Mixing & Arrangement
- **Audio Merging**: Combine multiple audio files with crossfade support
- **Multi-track Mixing**: Mix multiple audio tracks with individual volume control
- **Batch Processing**: Process multiple files with the same operation

## Quick Start

### Prerequisites
- **Node.js 18+**: For the Dexto framework
- **Python 3.10+**: Automatically managed by the MCP server
- **FFmpeg**: For audio processing (optional, but recommended)

### Installation

1. **Install FFmpeg** (recommended):
   ```bash
   # macOS
   brew install ffmpeg
   
   # Ubuntu/Debian
   sudo apt update && sudo apt install ffmpeg
   ```

2. **Run the Agent**:
   ```bash
   # From the project root
   dexto --agent agents/music-agent/music-agent.yml
   ```

That's it! The MCP server will be automatically downloaded and installed via `uvx` on first run.

## Usage Examples

### Audio Analysis
```
"Analyze the tempo and key of my song.mp3"
"What's the BPM of this track?"
"What key is this song in?"
```

### Music Generation
```
"Create a melody in G major at 140 BPM for 15 seconds"
"Create a I-IV-V-I chord progression in D major"
"Create a basic rock drum pattern"
```

### Audio Processing
```
"Convert my song.wav to MP3 format"
"Convert my MIDI melody to WAV format"
"Increase the volume of my vocals by 3dB"
"Normalize my guitar track to -18dB"
"Trim my song from 30 seconds to 2 minutes"
```

### Audio Effects
```
"Add reverb to my guitar with 200ms reverb time"
"Add echo to my vocals with 500ms delay and 0.7 decay"
"Add some distortion to my bass track"
```

### Mixing & Playback
```
"Mix my vocals, guitar, and drums together with the vocals at +3dB"
"Mix a MIDI melody with an MP3 drum loop"
"Create a melody in G major and play it for 5 seconds"
"Play my song.mp3 starting from 30 seconds for 10 seconds"
```

## Available Tools

### Music Generation
- `create_melody` - Generate melodies in any key and scale
- `create_chord_progression` - Create chord progressions using Roman numerals
- `create_drum_pattern` - Generate drum patterns for different styles

### Audio Analysis
- `analyze_audio` - Comprehensive audio analysis
- `detect_tempo` - Detect BPM and beat positions
- `detect_key` - Identify musical key and mode
- `get_audio_info` - Get detailed audio file information
- `get_midi_info` - Get detailed MIDI file information

### Audio Processing
- `convert_audio_format` - Convert between audio formats
- `convert_midi_to_audio` - Convert MIDI files to high-quality audio format (WAV, 44.1kHz, 16-bit)
- `adjust_volume` - Adjust audio levels in dB
- `normalize_audio` - Normalize audio to target levels
- `trim_audio` - Cut audio to specific time ranges
- `apply_audio_effect` - Apply reverb, echo, distortion, filters

### Mixing & Arrangement
- `merge_audio_files` - Combine multiple audio files
- `mix_audio_files` - Mix tracks with individual volume control (supports both audio and MIDI files)

### Playback
- `play_audio` - Play audio files with optional start time and duration
- `play_midi` - Play MIDI files with optional start time and duration

### Utility
- `list_available_effects` - List all audio effects
- `list_drum_patterns` - List available drum patterns

## Supported Formats

### Audio Formats
- **MP3**: Most common compressed format
- **WAV**: Uncompressed high-quality audio
- **FLAC**: Lossless compressed audio
- **OGG**: Open-source compressed format
- **M4A**: Apple's compressed format
- **AIFF**: Apple's uncompressed format
- **WMA**: Windows Media Audio

### MIDI Formats
- **MID**: Standard MIDI files
- **MIDI**: Alternative MIDI extension

## Configuration

### Agent Configuration
The agent is configured to use the published MCP server:

```yaml
systemPrompt: |
  You are an AI assistant specialized in music creation, editing, and production...

mcpServers:
  music_creator:
    type: stdio
    command: uvx
    args:
      - truffle-ai-music-creator-mcp
    connectionMode: strict

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

### Environment Variables
Set your OpenAI API key:

```bash
export OPENAI_API_KEY="your-api-key-here"
```

Or create a `.env` file in the project root:

```bash
OPENAI_API_KEY=your-api-key-here
```

## Use Cases

### Music Production
- Create backing tracks and accompaniments
- Generate drum patterns for different genres
- Compose melodies and chord progressions
- Mix and master audio tracks

### Audio Editing
- Clean up audio recordings
- Normalize volume levels
- Apply professional effects
- Convert between formats

### Music Analysis
- Analyze existing music for tempo and key
- Extract musical features for machine learning
- Study musical patterns and structures
- Compare different audio files

### Educational
- Learn about musical theory through generation
- Study different musical styles and patterns
- Experiment with composition techniques
- Understand audio processing concepts

## MCP Server

This agent uses the **Music Creator MCP Server**, which is maintained separately at:

**ğŸ”— [https://github.com/truffle-ai/mcp-servers/tree/main/src/music](https://github.com/truffle-ai/mcp-servers/tree/main/src/music)**

The MCP server repository provides:
- Complete technical documentation
- Development and contribution guidelines  
- Server implementation details
- Advanced configuration options

## Troubleshooting

### Common Issues

#### 1. Server Installation
The MCP server will be automatically installed via `uvx` on first run. No manual setup required.

#### 2. "FFmpeg not found" warnings
These warnings can be safely ignored. The agent includes fallback methods using librosa and soundfile for audio processing when FFmpeg is not available.

```bash
# Optional: Install FFmpeg for optimal performance
brew install ffmpeg  # macOS
sudo apt install ffmpeg  # Ubuntu/Debian
```

#### 3. Large Audio Files
Consider trimming or converting to smaller formats for faster processing.

#### 4. Memory Usage
Monitor system memory during heavy audio operations.

### Performance Tips

1. **Large Audio Files**: Consider trimming or converting to smaller formats for faster processing
2. **Memory Usage**: Monitor system memory during heavy audio operations
3. **Batch Processing**: Use batch operations for multiple files to improve efficiency
4. **FFmpeg**: Install FFmpeg for optimal audio processing performance (optional - fallback methods available)

## Technical Details

### Dependencies
The MCP server uses industry-standard libraries:
- **librosa**: Audio analysis and music information retrieval
- **pydub**: Audio file manipulation and processing
- **music21**: Music notation and analysis
- **pretty_midi**: MIDI file handling
- **numpy**: Numerical computing
- **scipy**: Scientific computing
- **matplotlib**: Plotting and visualization

### Architecture
The agent uses a Python-based MCP server that provides:
- Fast audio processing with optimized libraries
- Memory-efficient handling of large audio files
- Thread-safe operations for concurrent processing
- Comprehensive error handling and validation

### Performance
- Supports audio files up to several hours in length
- Efficient processing of multiple file formats
- Optimized algorithms for real-time analysis
- Minimal memory footprint for batch operations

## Getting Help

- **MCP Server Issues**: Report at the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/issues)
- **Agent Configuration**: Report at the main Dexto repository
- **Feature Requests**: Use the mcp-servers repository for tool-related requests

## License

This agent configuration is part of the Dexto AI Agent framework. The MCP server is distributed under the MIT license.


================================================
FILE: agents/product-name-researcher/README.md
================================================
# Product Name Research Agent

An AI agent specialized in comprehensive product name research and brand validation. Combines domain availability checking, search engine analysis, developer platform collision detection, and competitive intelligence to provide thorough name validation.

## ğŸ“– Tutorial

For a complete walkthrough of building and using this agent, see the [Product Name Scout Agent Tutorial](../../docs/docs/tutorials/product-name-scout-agent.md).

## Features

- **Domain Availability**: Check multiple TLD extensions (.com, .io, .app, .dev, etc.)
- **SERP Competition Analysis**: Analyze search engine results for brand competition
- **Autocomplete Intelligence**: Assess name recognition and spelling patterns
- **Developer Platform Collision Detection**: Check GitHub, npm, and PyPI for conflicts
- **Competitive Research**: DuckDuckGo-powered market intelligence
- **Comprehensive Scoring**: Weighted algorithms for brand viability assessment
- **Batch Comparison**: Compare multiple names with detailed scoring breakdown

## Prerequisites

Ensure you have the domain checker MCP server available:

```bash
# Install the domain checker MCP server
uvx truffle-ai-domain-checker-mcp
```

## Usage

### Start the Agent

```bash
# From the dexto root directory
dexto -a agents/product-name-researcher/product-name-researcher.yml
```

### Example Interactions

**Single Product Name Research:**
```
User: I want to research the name "CloudSync" for my new file sync product
Agent: [Performs comprehensive research including domain availability, trademark search, social media handles, and competitive analysis]
```

**Compare Multiple Names:**
```
User: Help me choose between "DataFlow", "InfoStream", and "SyncHub" for my data management tool
Agent: [Compares all three names across multiple criteria and provides recommendations]
```

**Domain-Focused Research:**
```
User: Check domain availability for "myawesomeapp" across all major TLDs
Agent: [Uses domain checker to verify availability across .com, .net, .org, .io, .app, etc.]
```

## Configuration

The agent uses:
- **Domain Checker MCP Server**: For domain availability checking
- **DuckDuckGo MCP Server**: For web search and competitive research
- **Product Name Scout MCP Server**: For SERP analysis, autocomplete, and developer collision detection

## Research Report

The agent generates comprehensive reports including:

1. **Domain Availability Summary**
   - Available domains with recommendations
   - Pricing information where available
   - Alternative TLD suggestions

2. **Trademark Analysis**
   - Similar trademarks found
   - Risk assessment
   - Recommendations for trademark clearance

3. **Developer Platform Analysis**
   - GitHub repository conflicts
   - NPM package collisions
   - PyPI package conflicts

4. **Competitive Landscape**
   - Existing products with similar names
   - Market positioning analysis
   - Differentiation opportunities

5. **Overall Recommendation**
   - Scoring across all criteria
   - Risk assessment
   - Next steps recommendations

## Tips for Best Results

- **Be specific about your product**: Include the product category and target market
- **Provide alternatives**: Give multiple name options for comparison
- **Consider your priorities**: Mention if domain availability, trademark clearance, or developer platform conflicts are most important
- **Think internationally**: Consider how the name works in different languages and markets


================================================
FILE: agents/talk2pdf-agent/README.md
================================================
# Talk2PDF Agent

A comprehensive AI agent for parsing and analyzing PDF documents using the [Talk2PDF MCP Server](https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf).

This agent provides intelligent PDF document processing through a TypeScript-based MCP server that can extract text, metadata, and search for specific content within PDF files.

## Features

### ğŸ“„ **PDF Parsing & Text Extraction**
- **Full Document Parsing**: Extract complete text content from PDF files
- **Metadata Extraction**: Get document information (title, author, page count, creation date)
- **Format Support**: Handle various PDF versions and structures
- **Error Handling**: Graceful handling of corrupted or protected PDFs

### ğŸ” **Content Search & Analysis**
- **Section Extraction**: Search for and extract specific content sections
- **Intelligent Filtering**: Find content containing specific terms or patterns
- **Context Preservation**: Maintain document structure and formatting
- **Multi-page Support**: Process documents of any length

### ğŸ§  **AI-Powered Analysis**
- **Document Summarization**: Generate intelligent summaries of PDF content
- **Key Information Extraction**: Identify and extract important details
- **Question Answering**: Answer questions about document content
- **Content Classification**: Analyze document type and structure

## Quick Start

### Prerequisites
- **Node.js 20+**: For the Dexto framework
- **TypeScript**: Automatically managed by the MCP server

### Installation

1. **Run the Agent**:
   ```bash
   # From the dexto project root
   dexto --agent agents/talk2pdf-agent/talk2pdf-agent.yml
   ```

That's it! The MCP server will be automatically downloaded and installed via `npx` on first run.

## Configuration

The agent is configured to use the published MCP server:

```yaml
mcpServers:
  talk2pdf:
    type: stdio
    command: npx
    args:
      - "@truffle-ai/talk2pdf-mcp"
    timeout: 30000
    connectionMode: strict
```

## MCP Server

This agent uses the **Talk2PDF MCP Server**, which is maintained separately at:

**ğŸ”— [https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf](https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf)**

The MCP server repository provides:
- Complete technical documentation
- Development and contribution guidelines  
- Server implementation details
- Advanced configuration options

## Available Tools

### PDF Processing Tools

#### `parse_pdf`
Extract complete text content and metadata from a PDF file.

**Parameters:**
- `filePath` (string): Path to the PDF file to parse

**Returns:**
- Full text content of the document
- Document metadata (title, author, page count, creation date, etc.)
- File information (size, format)

#### `extract_section`
Search for and extract specific content sections from a PDF.

**Parameters:**
- `filePath` (string): Path to the PDF file
- `searchTerms` (string): Terms or patterns to search for
- `maxResults` (number, optional): Maximum number of results to return

**Returns:**
- Matching content sections with context
- Page numbers and locations
- Relevance scoring

## Supported PDF Features

- **Standard PDF formats**: PDF 1.4 through 2.0
- **Text-based PDFs**: Documents with extractable text content
- **Multi-page documents**: No page limit restrictions
- **Metadata support**: Title, author, creation date, modification date
- **Various encodings**: UTF-8, Latin-1, and other standard encodings

## Example Usage

### Basic PDF Parsing
```
"Parse the PDF at /path/to/document.pdf and show me the full content"
"Extract all text and metadata from my research paper"
"What's in this PDF file?"
```

### Content Search
```
"Find all sections about 'machine learning' in the PDF"
"Extract the introduction and conclusion from this document" 
"Search for mentions of 'budget' in the financial report"
```

### Document Analysis
```
"Summarize the main points from this PDF"
"What is this document about?"
"Extract the key findings from the research paper"
"List all the recommendations mentioned in the report"
```

### Intelligent Q&A
```
"What are the main conclusions of this study?"
"Who are the authors of this document?"
"When was this document created?"
"How many pages does this PDF have?"
```

## Troubleshooting

### Common Issues

1. **Server Installation**: The MCP server will be automatically installed via `npx` on first run. No manual setup required.

2. **PDF Access Issues**: Ensure the PDF file path is correct and the file is readable. Protected or encrypted PDFs may require special handling.

3. **Memory Issues**: For very large PDFs (100+ pages), processing may take longer. Consider breaking large documents into sections.

4. **Text Extraction**: If text appears garbled, the PDF may use non-standard encoding or be scanned image-based (OCR not supported).

### Error Handling

The agent provides clear error messages for common issues:
- File not found or inaccessible
- Invalid PDF format
- Corrupted PDF files
- Permission-protected documents

## Getting Help

- **MCP Server Issues**: Report at the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/issues)
- **Agent Configuration**: Report at the main Dexto repository
- **Feature Requests**: Use the mcp-servers repository for tool-related requests

## License

This project is part of the Dexto AI agent framework.


================================================
FILE: agents/triage-demo/README.md
================================================
# TeamFlow Customer Support Triage Agent System

This demonstration showcases an intelligent **Customer Support Triage System** built with Dexto agents for **TeamFlow**, a cloud-based project management and team collaboration platform. The system automatically analyzes customer inquiries, routes them to specialized support agents, and provides complete customer support responses.

## ğŸ¢ About TeamFlow (Demo Business Context)

TeamFlow is a fictional cloud-based project management platform used for this demonstration. It offers three service tiers:

- **Basic Plan ($9/user/month)**: Up to 10 team members, 5GB storage, basic features
- **Pro Plan ($19/user/month)**: Up to 100 team members, 100GB storage, advanced integrations (Slack, GitHub, Salesforce)  
- **Enterprise Plan ($39/user/month)**: Unlimited users, 1TB storage, SSO, dedicated support

Key features include project management, team collaboration, time tracking, mobile apps, and a comprehensive API. The platform integrates with popular tools like Slack, GitHub, Salesforce, and Google Workspace.

This realistic business context allows the agents to provide specific, accurate responses about pricing, features, technical specifications, and policies using the FileContributor system to access comprehensive documentation.

## ğŸ—ï¸ Architecture Overview

```
Customer Request
       â†“
   Triage Agent (Main Coordinator)
       â†“
   [Analyzes, Routes & Executes via MCP]
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Technical Support  â”‚  Billing Agent   â”‚
â”‚      Agent          â”‚                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Product Info       â”‚  Escalation      â”‚
â”‚     Agent           â”‚    Agent         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
   Complete Customer Response
```

The triage agent doesn't just route requests - it **executes the specialized agents as MCP servers** and provides complete, integrated customer support responses that combine routing intelligence with expert answers.

## ğŸ¤– Agent Roles

### 1. **Triage Agent** (`triage-agent.yml`)
- **Primary Role**: Intelligent routing coordinator AND customer response provider
- **Capabilities**: 
  - Analyzes requests and categorizes issues
  - Routes to specialists via `chat_with_agent` tool calls
  - **Executes specialist agents directly through MCP connections**
  - **Provides complete customer responses** combining routing + specialist answers
- **Tools**: Filesystem, web research, **chat_with_agent** (connects to all specialists)
- **Tool Confirmation**: Auto-approve mode for seamless delegation

### 2. **Technical Support Agent** (`technical-support-agent.yml`) 
- **Specialization**: Bug fixes, troubleshooting, system issues
- **Tools**: Filesystem, terminal, browser automation
- **Model**: GPT-4o (higher capability for complex technical issues)
- **Connection**: Available as MCP server via stdio

### 3. **Billing Agent** (`billing-agent.yml`)
- **Specialization**: Payments, subscriptions, financial inquiries  
- **Tools**: Browser automation, filesystem for policy docs
- **Model**: GPT-4o-mini (efficient for structured billing processes)
- **Connection**: Available as MCP server via stdio

### 4. **Product Info Agent** (`product-info-agent.yml`)
- **Specialization**: Features, comparisons, documentation
- **Tools**: Web research (Tavily), filesystem, browser automation
- **Model**: GPT-4o-mini (efficient for information retrieval)
- **Connection**: Available as MCP server via stdio

### 5. **Escalation Agent** (`escalation-agent.yml`)
- **Specialization**: Complex issues, Enterprise customers, management approval
- **Tools**: Filesystem, web research for compliance/legal info
- **Model**: GPT-4o (higher capability for sensitive issues)
- **Connection**: Available as MCP server via stdio

## ğŸ“š Business Context Documentation

Each agent has access to relevant TeamFlow documentation via the FileContributor system:

### Documentation Files (`docs/` folder)
- **`company-overview.md`**: General company information, plans, SLAs, contact info
- **`technical-documentation.md`**: API docs, system requirements, troubleshooting guides
- **`billing-policies.md`**: Pricing, refund policies, billing procedures, payment methods
- **`product-features.md`**: Feature descriptions, plan comparisons, integrations
- **`escalation-policies.md`**: Escalation procedures, contact information, incident templates

### Agent-Specific Context
- **Technical Support**: Company overview + technical documentation
- **Billing Agent**: Company overview + billing policies
- **Product Info**: Company overview + product features
- **Escalation**: Company overview + escalation policies
- **Triage Agent**: Company overview for routing context

## ğŸš€ Getting Started

### Quick Start - Integrated Triage System

The **recommended way** to run the triage system is using the main triage agent, which automatically connects to all specialists:

```bash
# Run the complete triage system (connects to all specialist agents automatically)
npx dexto --agent agents/triage-demo/triage-agent.yml

# Test with a customer inquiry
npx dexto --agent agents/triage-demo/triage-agent.yml "I want to upgrade from Basic to Pro but confused about pricing"
```

This will:
1. **Auto-connect** to all 4 specialist agents as MCP servers
2. **Analyze** your request and route to the appropriate specialist  
3. **Execute** the specialist agent to get the expert answer
4. **Respond** with a complete customer support response

### Running Individual Agents (Advanced)

For testing individual specialist agents:

```bash
# Run specialized agents individually  
npx dexto --agent agents/triage-demo/technical-support-agent.yml
npx dexto --agent agents/triage-demo/billing-agent.yml
npx dexto --agent agents/triage-demo/product-info-agent.yml
npx dexto --agent agents/triage-demo/escalation-agent.yml
```

### Environment Setup

Ensure you have the required API keys in your `.env` file:

```env
OPENAI_API_KEY=your_openai_api_key
TAVILY_API_KEY=your_tavily_api_key  # For web research
```

## ğŸ“‹ Example Scenarios

### Scenario 1: Technical Issue
**Customer Input**: *"My app keeps crashing when I try to upload files. Getting error code 500."*

**Triage Agent Response**:
- **Analysis**: Technical Issue â†’ Route to Technical Support Agent
- **Execution**: Calls `chat_with_agent` â†’ Technical Support provides debugging steps
- **Customer Response**: *"I've routed your issue to our Technical Support team. Here's how to resolve the 500 error when uploading files: [detailed technical troubleshooting steps from specialist]"*

### Scenario 2: Billing Question  
**Customer Input**: *"I want to upgrade from Basic to Pro but confused about pricing. Will I be charged the full amount?"*

**Triage Agent Response**:
- **Analysis**: Billing Question â†’ Route to Billing Agent  
- **Execution**: Calls `chat_with_agent` â†’ Billing Agent explains prorated pricing
- **Customer Response**: *"I've routed your inquiry to our Billing team. When upgrading from Basic to Pro, you'll only be charged a prorated amount for the remaining billing period - just the difference between plans for the time left in your cycle. The upgrade takes effect immediately."*

### Scenario 3: Product Information
**Customer Input**: *"What's the difference between your Pro and Enterprise plans? I need API access."*

**Triage Agent Response**:
- **Analysis**: Product Inquiry â†’ Route to Product Info Agent
- **Execution**: Calls `chat_with_agent` â†’ Product Info Agent provides detailed comparison
- **Customer Response**: *"I've connected you with our Product team. Both Pro and Enterprise plans include full API access. The main differences are: Pro supports up to 100 users with 100GB storage, while Enterprise offers unlimited users, 1TB storage, SSO, and dedicated support. [detailed feature comparison]"*

### Scenario 4: Escalation Required
**Customer Input**: *"This is my third time contacting support about data privacy concerns. I'm considering legal action."*

**Triage Agent Response**:
- **Analysis**: Legal/Compliance Issue â†’ Route to Escalation Agent
- **Execution**: Calls `chat_with_agent` â†’ Escalation Agent provides management contact
- **Customer Response**: *"I've escalated your data privacy concerns to our senior support team. Given the legal implications, I'm connecting you directly with our compliance manager Sarah Johnson (sarah.johnson@teamflow.com). She'll address your concerns within 2 hours."*

## ğŸ”§ Advanced Configuration

### Current MCP Server Configuration (Automatic)

The triage agent automatically connects to specialists via stdio MCP servers:

```yaml
# Current configuration in triage-agent.yml
mcpServers:
  technical_support:
    type: stdio
    command: npx
    args: [dexto, --mode, mcp, --agent, agents/triage-demo/technical-support-agent.yml]
  
  billing_support:
    type: stdio  
    command: npx
    args: [dexto, --mode, mcp, --agent, agents/triage-demo/billing-agent.yml]
  
  # Similar configuration for product_info and escalation agents...
```

### Production Configuration (Distributed Servers)

For production deployment, you would run each specialist as a separate server:

```yaml
# triage-agent.yml - Production Configuration
mcpServers:
  technical_support:
    type: sse
    url: "http://localhost:3001/mcp"
    headers:
      Authorization: "Bearer your-auth-token"
  
  billing_support:
    type: sse  
    url: "http://localhost:3002/mcp"
    headers:
      Authorization: "Bearer your-auth-token"
  
  product_info:
    type: sse
    url: "http://localhost:3003/mcp"
    headers:
      Authorization: "Bearer your-auth-token"
    
  escalation:
    type: sse
    url: "http://localhost:3004/mcp"
    headers:
      Authorization: "Bearer your-auth-token"
```

### Running Distributed Servers

```bash
# Terminal 1: Technical Support Server
npx dexto --agent agents/triage-demo/technical-support-agent.yml --mode server --port 3001

# Terminal 2: Billing Support Server  
npx dexto --agent agents/triage-demo/billing-agent.yml --mode server --port 3002

# Terminal 3: Product Info Server
npx dexto --agent agents/triage-demo/product-info-agent.yml --mode server --port 3003

# Terminal 4: Escalation Server
npx dexto --agent agents/triage-demo/escalation-agent.yml --mode server --port 3004

# Terminal 5: Main Triage Coordinator
npx dexto --agent agents/triage-demo/triage-agent.yml --mode server --port 3000
```

## ğŸ¯ Key Features Demonstrated

### 1. **Intelligent Routing with Execution**
- Natural language analysis to determine issue category
- **Automatic execution** of specialist agents via MCP
- **Complete customer responses** combining routing + expert answers
- Seamless tool confirmation with auto-approve mode

### 2. **Specialized Expertise Integration**
- Each agent has domain-specific knowledge and tools
- **Real-time coordination** between triage and specialists
- **Unified customer experience** despite multi-agent backend

### 3. **Scalable MCP Architecture**
- **Stdio connections** for local development and testing
- **SSE connections** for distributed production deployment
- **Tool-based delegation** using `chat_with_agent`

### 4. **Comprehensive Tool Access**
- Filesystem access for documentation and logging
- Web research capabilities for up-to-date information
- Browser automation for testing and demonstrations
- **Agent-to-agent communication** via MCP tools

## ğŸ” Testing the System

### Interactive Testing

1. **Start the complete triage system**:
   ```bash
   npx dexto --agent agents/triage-demo/triage-agent.yml
   ```

2. **Test with various customer scenarios** and observe:
   - **Routing analysis** (which specialist is chosen)
   - **Tool execution** (`chat_with_agent` calls)
   - **Complete responses** (routing confirmation + specialist answer)

### Sample Test Cases

```
Test 1: "API returns 401 unauthorized error"
Expected: Technical Support Agent â†’ Complete troubleshooting response

Test 2: "Cancel my subscription immediately"  
Expected: Billing Agent â†’ Complete cancellation process and policy info

Test 3: "Do you have a mobile app?"
Expected: Product Info Agent â†’ Complete feature details and download links

Test 4: "Your service caused my business to lose $10,000"
Expected: Escalation Agent â†’ Complete escalation with management contact
```

### One-Shot Testing

```bash
# Test billing scenario
npx dexto --agent agents/triage-demo/triage-agent.yml "I was charged twice this month"

# Test technical scenario  
npx dexto --agent agents/triage-demo/triage-agent.yml "Getting 500 errors on file upload"

# Test product scenario
npx dexto --agent agents/triage-demo/triage-agent.yml "What integrations do you support?"
```

## ğŸš¦ Production Considerations

### Security
- Implement proper authentication between agents
- Secure API key management  
- Customer data privacy controls
- **Tool confirmation policies** for sensitive operations

### Monitoring  
- Log all routing decisions and tool executions
- Track resolution times by agent type
- Monitor escalation patterns
- **Tool usage analytics** for optimization

### Scaling
- Load balance multiple instances of specialist agents
- Implement request queuing for high volume
- **Distributed MCP server deployment**
- Add more specialized agents as needed (e.g., Sales, Onboarding)

## ğŸ¤ Contributing

To extend this triage system:

1. **Add new specialist agents** by creating new YAML configs
2. **Update triage routing logic** in the main agent's system prompt  
3. **Configure new agents as MCP servers** in the triage agent's mcpServers section
4. **Test end-to-end flow** including tool execution and complete responses

This demonstration showcases the power of **multi-agent coordination with tool execution** using Dexto's MCP integration capabilities! 


================================================
FILE: agents/triage-demo/test-scenarios.md
================================================
# TeamFlow Triage Agent Test Scenarios

Use these realistic TeamFlow customer support scenarios to test the triage agent's **complete customer support workflow**. The triage agent will analyze each request, route to the appropriate specialist agent, execute the specialist via MCP tools, and provide complete customer responses.

## ğŸ”§ Technical Support Scenarios

### Scenario T1: API Integration Issue
```
Hi, I'm trying to integrate the TeamFlow API with our system but I keep getting a 401 unauthorized error even though I'm using the correct API key. I've checked the documentation but can't figure out what's wrong. Our rate limit should be 10,000/hour on our Pro plan. Can you help?
```
**Expected Route**: Technical Support Agent  
**Expected Response**: Complete troubleshooting guide including API key validation steps, common 401 causes, rate limit verification, and Pro plan API specifications  
**Tool Execution**: `chat_with_agent` â†’ Technical Support provides detailed debugging steps

### Scenario T2: App Crash  
```
My TeamFlow mobile app crashes every time I try to export project data. It worked fine last week but now it just freezes and closes. I'm using iPhone 15 with iOS 17.2. This is really urgent as I need this data for a client presentation tomorrow.
```
**Expected Route**: Technical Support Agent  
**Expected Response**: Complete crash resolution including device-specific troubleshooting, export alternatives, and immediate workarounds for urgent timeline  
**Tool Execution**: `chat_with_agent` â†’ Technical Support provides iOS-specific fixes and emergency data export options

### Scenario T3: Performance Issue
```
Your web dashboard has been extremely slow for the past 3 days. Pages take 30+ seconds to load and sometimes timeout completely. My internet connection is fine and other websites work normally.
```
**Expected Route**: Technical Support Agent  
**Expected Response**: Complete performance troubleshooting including browser optimization, cache clearing, system status check, and escalation to infrastructure team if needed  
**Tool Execution**: `chat_with_agent` â†’ Technical Support provides systematic performance diagnosis steps

## ğŸ’³ Billing Support Scenarios

### Scenario B1: Double Charge
```
I just checked my credit card statement and I was charged twice for this month's subscription - once on the 1st for $49.99 and again on the 3rd for the same amount. I need the duplicate charge refunded immediately.
```
**Expected Route**: Billing Agent  
**Expected Response**: Complete refund process including charge verification, refund timeline (3-5 business days), and account credit options for immediate resolution  
**Tool Execution**: `chat_with_agent` â†’ Billing Agent provides specific refund procedures and account investigation steps

### Scenario B2: Subscription Management
```
I want to upgrade from the Basic plan to Pro plan but I'm confused about the pricing. Will I be charged the full Pro amount or just the difference? Also, when would the upgrade take effect?
```
**Expected Route**: Billing Agent  
**Expected Response**: Complete upgrade explanation including prorated billing calculation, immediate feature access, next billing cycle details, and upgrade procedure  
**Tool Execution**: `chat_with_agent` â†’ Billing Agent provides detailed prorated pricing explanation and upgrade process

### Scenario B3: Payment Failure
```
My payment failed this morning and now my account is suspended. I updated my credit card last week so I'm not sure why it didn't work. How can I get my account reactivated quickly?
```
**Expected Route**: Billing Agent  
**Expected Response**: Complete reactivation process including payment method verification, retry options, account status restoration timeline, and prevention steps  
**Tool Execution**: `chat_with_agent` â†’ Billing Agent provides immediate account reactivation steps and payment troubleshooting

## ğŸ“– Product Information Scenarios

### Scenario P1: Feature Comparison
```
What's the difference between TeamFlow's Pro and Enterprise plans? I specifically need to know about API rate limits, user management features, and data export capabilities. We're a team of 25 people and currently on the Basic plan.
```
**Expected Route**: Product Info Agent  
**Expected Response**: Complete plan comparison including detailed feature matrix, specific API limits (Pro: 10K/hour, Enterprise: 100K/hour), user management differences, and upgrade recommendation for 25-person team  
**Tool Execution**: `chat_with_agent` â†’ Product Info Agent provides comprehensive plan comparison with team-size specific recommendations

### Scenario P2: How-To Question
```
How do I set up automated reports to be sent to my team every Monday? I see the reporting feature but can't figure out how to schedule them. Is this available in my current plan?
```
**Expected Route**: Product Info Agent  
**Expected Response**: Complete setup guide including step-by-step report scheduling instructions, plan feature verification, and links to relevant documentation  
**Tool Execution**: `chat_with_agent` â†’ Product Info Agent provides detailed automated reporting setup walkthrough

### Scenario P3: Integration Capabilities
```
Does TeamFlow integrate with Salesforce and Slack? I need to sync customer project data and get notifications in our Slack channels. What's the setup process like and are there any limitations I should know about? We're on the Pro plan.
```
**Expected Route**: Product Info Agent  
**Expected Response**: Complete integration overview including supported Salesforce/Slack features, Pro plan limitations, setup documentation links, and configuration best practices  
**Tool Execution**: `chat_with_agent` â†’ Product Info Agent provides comprehensive integration capabilities and setup guidance

## ğŸš¨ Escalation Scenarios

### Scenario E1: Legal Threat
```
This is my fourth email about data privacy violations. Your service exposed my customer data to unauthorized parties and I'm considering legal action. I need to speak with a manager immediately about this data breach.
```
**Expected Route**: Escalation Agent  
**Expected Response**: Complete escalation including immediate management contact information, legal/compliance team connection, incident escalation procedure, and 2-hour response commitment  
**Tool Execution**: `chat_with_agent` â†’ Escalation Agent provides senior management contact and legal compliance escalation process

### Scenario E2: Business Impact
```
Your system outage yesterday caused my e-commerce site to be down for 6 hours during Black Friday. This resulted in approximately $50,000 in lost sales. I need compensation for this business interruption and want to discuss SLA violations.
```
**Expected Route**: Escalation Agent  
**Expected Response**: Complete business impact assessment including SLA review, compensation evaluation process, senior account manager contact, and formal incident investigation  
**Tool Execution**: `chat_with_agent` â†’ Escalation Agent provides business impact claim process and executive contact information

### Scenario E3: Service Quality Complaint
```
I've been a customer for 3 years and the service quality has declined dramatically. Multiple support tickets have been ignored, features are constantly broken, and I'm considering switching to a competitor. I want to speak with someone who can actually resolve these ongoing issues.
```
**Expected Route**: Escalation Agent  
**Expected Response**: Complete retention process including account review, senior support contact, service improvement plan, and customer success manager assignment  
**Tool Execution**: `chat_with_agent` â†’ Escalation Agent provides customer retention specialist contact and service quality improvement plan

## ğŸ¤” Mixed/Complex Scenarios

### Scenario M1: Technical + Billing
```
My API requests started failing yesterday with 429 rate limit errors, but I'm on the Pro plan which should have higher limits. Did my plan get downgraded? I'm still being charged the Pro price but getting Basic plan limits.
```
**Expected Route**: Technical Support Agent (primary) or Billing Agent  
**Expected Response**: Complete investigation including API limit verification, account status check, billing verification, and either technical resolution or billing escalation  
**Tool Execution**: `chat_with_agent` â†’ Technical Support investigates API limits and coordinates with billing if needed

### Scenario M2: Product + Escalation
```
I was promised during the sales call that your Enterprise plan includes custom integrations. However, after upgrading, I'm being told this requires an additional $10,000 implementation fee. This contradicts what I was told by your sales team.
```
**Expected Route**: Escalation Agent  
**Expected Response**: Complete sales promise review including sales team consultation, Enterprise feature verification, implementation fee clarification, and senior sales manager contact  
**Tool Execution**: `chat_with_agent` â†’ Escalation Agent provides sales promise investigation and senior management contact

### Scenario M3: Vague Request
```
Hi, I'm having trouble with your service. Can you help me?
```
**Expected Route**: Should ask for clarification before routing  
**Expected Response**: Polite clarification request with specific questions to help identify the issue type and appropriate specialist  
**Tool Execution**: Triage agent asks clarifying questions without executing specialist tools

## ğŸ¯ Testing Instructions

### Interactive Testing

1. **Start the complete triage system**:
   ```bash
   npx dexto --agent agents/triage-demo/triage-agent.yml
   ```

2. **Copy and paste** scenarios from above into the chat

3. **Observe the complete workflow**:
   - **Routing analysis** (which specialist is chosen and why)
   - **Tool execution** (`chat_with_agent` tool calls)  
   - **Complete customer response** (routing confirmation + specialist answer)
   - **Response quality** (specificity, completeness, helpfulness)

### One-Shot Testing

Test scenarios quickly with command-line execution:

```bash
# Test Technical Support scenario
npx dexto --agent agents/triage-demo/triage-agent.yml "My TeamFlow mobile app crashes every time I try to export project data. I'm using iPhone 15 with iOS 17.2. This is urgent."

# Test Billing scenario  
npx dexto --agent agents/triage-demo/triage-agent.yml "I want to upgrade from Basic to Pro but confused about pricing. Will I be charged the full amount?"

# Test Product Info scenario
npx dexto --agent agents/triage-demo/triage-agent.yml "What's the difference between Pro and Enterprise plans? I need API access for 25 people."

# Test Escalation scenario
npx dexto --agent agents/triage-demo/triage-agent.yml "Your system outage cost my business $50,000 in lost sales. I need compensation and want to discuss SLA violations."
```

### Expected Response Quality

For each test, verify that responses include:

1. **Brief routing confirmation** (one sentence about which specialist was consulted)
2. **Complete specialist answer** with specific, actionable information
3. **Relevant details** from TeamFlow's business documentation
4. **Appropriate tone** (professional, helpful, empathetic when needed)
5. **Follow-up invitation** (offering additional help if needed)

## ğŸ“Š Expected Results Summary

| Category | Count | Expected Workflow |
|----------|-------|-------------------|
| Technical | 3 | Route â†’ Execute Technical Support â†’ Complete troubleshooting response |
| Billing | 3 | Route â†’ Execute Billing Agent â†’ Complete billing/payment resolution |
| Product Info | 3 | Route â†’ Execute Product Info Agent â†’ Complete feature/plan information |
| Escalation | 3 | Route â†’ Execute Escalation Agent â†’ Complete escalation with contacts |
| Mixed/Complex | 3 | Route â†’ Execute Primary Agent â†’ Complete investigation/resolution |

## ğŸ” Success Criteria

The triage system should demonstrate:

- **95%+ routing accuracy** to appropriate specialist agents
- **100% tool execution** success (no failed `chat_with_agent` calls)
- **Complete responses** that directly address customer needs
- **Professional tone** with empathy for customer situations
- **Specific information** from TeamFlow business context (plans, policies, features)
- **Clear next steps** for customer resolution

## ğŸš« Common Issues to Watch For

- **Routing without execution**: Agent identifies correct specialist but doesn't call `chat_with_agent`
- **Tool confirmation prompts**: Should auto-approve due to configuration
- **Incomplete responses**: Missing specialist answers or generic routing messages
- **Wrong specialist**: Incorrect routing based on request analysis
- **Multiple tool calls**: Unnecessary repeated calls to specialists

The complete triage system should provide **seamless, professional customer support** that customers would expect from a real enterprise support team! 


================================================
FILE: agents/triage-demo/docs/billing-policies.md
================================================
# TeamFlow Billing Policies & Procedures

## Pricing Plans & Features

### Basic Plan - $9/user/month
**Billed monthly or annually ($90/user/year, save 17%)**

**Features Included**:
- Up to 10 team members
- 5GB storage per team
- Core project management (tasks, boards, basic reporting)
- Email support (24-hour response)
- Mobile apps (iOS/Android)
- API access (1,000 requests/hour)
- Basic integrations (Google Calendar, basic file imports)

**Usage Limits**:
- Maximum 1,000 tasks per workspace
- 50MB maximum file upload size
- Email support only

### Pro Plan - $19/user/month
**Billed monthly or annually ($190/user/year, save 17%)**

**Features Included**:
- Up to 100 team members
- 100GB storage per team
- Advanced project management (Gantt charts, custom fields, advanced reporting)
- Priority support (8-hour response, chat support)
- Advanced integrations (Slack, GitHub, Jira, Salesforce)
- API access (10,000 requests/hour)
- Custom workflows and automation
- Time tracking and invoicing
- Advanced security (2FA, audit logs)

**Usage Limits**:
- Maximum 10,000 tasks per workspace
- 100MB maximum file upload size
- Priority support queue

### Enterprise Plan - $39/user/month
**Billed annually only ($468/user/year), minimum 25 users**

**Features Included**:
- Unlimited team members
- 1TB storage per team
- Enterprise security (SSO, SAML, advanced compliance)
- Dedicated customer success manager
- Phone support (4-hour response SLA)
- Unlimited API access
- Custom integrations and white-labeling
- Advanced admin controls
- On-premises deployment option (additional cost)
- 99.95% uptime SLA

**Usage Limits**:
- Unlimited tasks and projects
- 500MB maximum file upload size
- Dedicated support team

## Billing Cycles & Payment Processing

### Billing Dates
- **Monthly Plans**: Charged on the same day each month as initial subscription
- **Annual Plans**: Charged once per year on subscription anniversary
- **Billing Time**: All charges processed at 12:00 AM UTC
- **Failed Payment Retries**: Automatic retries on days 3, 7, and 14

### Accepted Payment Methods
- **Credit Cards**: Visa, MasterCard, American Express, Discover
- **Debit Cards**: Visa and MasterCard debit cards
- **Enterprise Options**: Wire transfer, ACH (US only), annual invoicing
- **International**: PayPal for international customers
- **Cryptocurrency**: Not currently accepted

### Prorated Billing
- **Plan Upgrades**: Immediate access, prorated charge for remaining billing period
- **Plan Downgrades**: Takes effect at next billing cycle, no immediate refund
- **Adding Users**: Prorated charge for new users based on remaining billing period
- **Removing Users**: Credit applied to next invoice

## Refund Policy

### Refund Eligibility

#### Full Refunds (100%)
- **New Subscriptions**: Within 30 days of first payment
- **Service Outages**: If SLA uptime guarantees are not met
- **Billing Errors**: Duplicate charges, incorrect amounts
- **Technical Issues**: If service is unusable and cannot be resolved within 48 hours

#### Partial Refunds
- **Plan Downgrades**: Credit for unused portion (Enterprise to Pro/Basic)
- **Early Cancellation**: Pro-rated refund for annual plans (minimum 90 days required)
- **User Reduction**: Credit applied to next billing cycle

#### No Refunds
- **Basic Plan**: No refunds for monthly Basic plans after 30 days
- **Temporary Outages**: Outages under 4 hours (within SLA)
- **User Error**: Data deletion, misconfiguration, or user training issues
- **Third-party Integration Issues**: Problems with Slack, GitHub, etc.

### Refund Processing Time
- **Credit Cards**: 5-10 business days
- **PayPal**: 24-48 hours
- **Wire Transfer/ACH**: 10-15 business days

## Common Billing Scenarios

### 1. Plan Upgrades

#### Basic to Pro Upgrade
- **Timing**: Immediate access to Pro features
- **Billing**: Prorated charge for Pro plan, credit for unused Basic time
- **Example**: 15 days into Basic monthly cycle â†’ charged $14.50 for remaining Pro time

#### Pro to Enterprise Upgrade
- **Requirements**: Minimum 25 users, annual billing only
- **Process**: Requires sales team approval for custom Enterprise features
- **Migration**: Dedicated success manager assists with transition

### 2. Plan Downgrades

#### Pro to Basic Downgrade
- **Timing**: Takes effect at next billing cycle
- **Data Retention**: 90-day grace period for Pro-only data (advanced reports, etc.)
- **User Limits**: Must reduce team size to 10 users or less before downgrade

#### Enterprise to Pro Downgrade
- **Notice Period**: 60-day notice required
- **Custom Features**: Loss of SSO, dedicated support, custom integrations
- **Partial Refund**: Available for remaining months of annual contract

### 3. User Management

#### Adding Users
- **Process**: Admin adds users in account settings
- **Billing**: Prorated charge for remaining billing period
- **Automatic**: Charges appear on next invoice with detailed breakdown

#### Removing Users
- **Deactivation**: Admin can deactivate users immediately
- **Billing Impact**: Credit applied to next billing cycle
- **Data Retention**: User data retained for 30 days in case of reactivation

### 4. Payment Failures

#### First Failed Payment
- **Action**: Automatic retry in 3 days
- **User Impact**: No service interruption
- **Notification**: Email sent to account admin

#### Second Failed Payment (Day 7)
- **Action**: Second automatic retry
- **User Impact**: Warning banner in app
- **Notification**: Email and in-app notification

#### Third Failed Payment (Day 14)
- **Action**: Final automatic retry
- **User Impact**: Account enters "Past Due" status
- **Features**: Read-only access, limited functionality

#### Account Suspension (Day 21)
- **Action**: Account suspended if payment still fails
- **User Impact**: Complete loss of access
- **Data Retention**: 30-day grace period before data deletion

### 5. Currency & International Billing

#### Supported Currencies
- **Primary**: USD (US Dollar)
- **Additional**: EUR (Euro), GBP (British Pound), CAD (Canadian Dollar)
- **Exchange Rates**: Updated daily, charged in customer's local currency when available

#### International Considerations
- **VAT/Taxes**: Applied automatically based on billing address
- **Payment Methods**: PayPal preferred for international customers
- **Currency Conversion**: Customer's bank may apply additional conversion fees

## Enterprise Billing

### Custom Pricing
- **Volume Discounts**: Available for 100+ users
- **Multi-year Agreements**: Additional discounts for 2-3 year contracts
- **Custom Features**: Additional costs for white-labeling, on-premises deployment

### Invoice Process
- **Net Terms**: 30-day payment terms standard
- **PO Numbers**: Purchase order numbers accepted and included on invoices
- **Multiple Billing Contacts**: Support for separate billing and technical contacts
- **Custom Payment Terms**: Negotiable for large enterprise accounts

## Billing Support Procedures

### Customer Identity Verification
Before discussing billing information, verify:
1. **Account Email**: Customer must provide account email address
2. **Last Payment Amount**: Ask for recent payment amount/date
3. **Billing Address**: Verify last 4 digits of ZIP/postal code
4. **Security Question**: Account-specific security question if configured

### Common Resolution Steps

#### Duplicate Charges
1. Verify both charges in billing system
2. Check if customer has multiple accounts
3. Process immediate refund for duplicate charge
4. Update payment method if card was charged twice due to processing error

#### Failed Payment Recovery
1. Verify current payment method on file
2. Check for expired cards or insufficient funds
3. Update payment method if needed
4. Process manual payment if urgently needed
5. Restore account access immediately upon successful payment

#### Subscription Cancellation
1. Confirm customer intent to cancel
2. Offer plan downgrade as alternative
3. Process cancellation for end of current billing period
4. Provide data export instructions
5. Send confirmation email with final billing details

### Escalation Triggers

Escalate to Finance Team when:
- Refund requests over $500
- Enterprise contract modifications
- Custom pricing negotiations
- Legal or compliance billing questions
- Suspected fraudulent activity
- International tax questions

### Billing System Access

#### Internal Tools
- **Billing Dashboard**: Real-time subscription and payment status
- **Payment Processor**: Stripe dashboard for transaction details
- **Invoice System**: Generate and send custom invoices
- **Refund Portal**: Process refunds up to $500 limit

#### Customer Tools
- **Account Billing Page**: Self-service billing management
- **Invoice Download**: PDF invoices for all past payments
- **Payment Method Update**: Credit card and PayPal management
- **Usage Reports**: Storage and API usage tracking 


================================================
FILE: agents/triage-demo/docs/company-overview.md
================================================
# TeamFlow - Company Overview

## About TeamFlow

TeamFlow is a leading cloud-based project management and team collaboration platform that helps organizations streamline their workflows, improve team productivity, and deliver projects on time. Founded in 2019, we serve over 50,000 companies worldwide, from small startups to Fortune 500 enterprises.

## Our Mission

To empower teams to work more efficiently and collaboratively through intuitive project management tools and seamless integrations with the tools they already use.

## Key Products & Services

### TeamFlow Platform
- **Project Management**: Kanban boards, Gantt charts, task management
- **Team Collaboration**: Real-time chat, file sharing, video conferencing integration
- **Time Tracking**: Automated time tracking with detailed reporting
- **Resource Management**: Team capacity planning and workload balancing
- **Analytics & Reporting**: Custom dashboards and project insights

### TeamFlow API
- RESTful API with comprehensive documentation
- Webhook support for real-time notifications
- Rate limits: 1,000 requests/hour (Basic), 10,000/hour (Pro), unlimited (Enterprise)
- SDKs available for JavaScript, Python, PHP, and Ruby

### TeamFlow Mobile Apps
- Native iOS and Android applications
- Offline synchronization capabilities
- Push notifications for project updates

## Service Plans

### Basic Plan - $9/user/month
- Up to 10 team members
- 5GB storage per team
- Core project management features
- Email support
- API access (1,000 requests/hour)

### Pro Plan - $19/user/month
- Up to 100 team members
- 100GB storage per team
- Advanced reporting and analytics
- Priority email and chat support
- Advanced integrations (Slack, GitHub, Jira)
- API access (10,000 requests/hour)
- Custom fields and workflows

### Enterprise Plan - $39/user/month
- Unlimited team members
- 1TB storage per team
- Advanced security (SSO, 2FA)
- Dedicated customer success manager
- Phone support with 4-hour response SLA
- Unlimited API access
- Custom integrations and white-labeling
- Advanced admin controls and audit logs

## Key Integrations

- **Communication**: Slack, Microsoft Teams, Discord
- **Development**: GitHub, GitLab, Bitbucket, Jira
- **File Storage**: Google Drive, Dropbox, OneDrive
- **Calendar**: Google Calendar, Outlook, Apple Calendar
- **Time Tracking**: Toggl, Harvest, RescueTime
- **CRM**: Salesforce, HubSpot, Pipedrive

## Service Level Agreements (SLA)

### Uptime Commitments
- Basic Plan: 99.5% uptime
- Pro Plan: 99.9% uptime  
- Enterprise Plan: 99.95% uptime with dedicated infrastructure

### Support Response Times
- Basic: Email support within 24 hours
- Pro: Email/chat support within 8 hours
- Enterprise: Phone/email/chat support within 4 hours

## Security & Compliance

- SOC 2 Type II certified
- GDPR compliant
- ISO 27001 certified
- Enterprise-grade encryption (AES-256)
- Regular security audits and penetration testing

## Contact Information

- **Headquarters**: San Francisco, CA
- **Support Email**: support@teamflow.com
- **Sales Email**: sales@teamflow.com
- **Emergency Escalation**: escalations@teamflow.com
- **Phone**: 1-800-TEAMFLOW (1-800-832-6356) 


================================================
FILE: agents/triage-demo/docs/escalation-policies.md
================================================
# TeamFlow Escalation Policies & Procedures

## Escalation Overview

The escalation process ensures that complex, sensitive, or high-priority customer issues receive appropriate attention from senior staff and management. This document outlines when to escalate, escalation paths, and procedures for different types of issues.

## Escalation Criteria

### Immediate Escalation (Within 15 minutes)

#### Security & Data Incidents
- Suspected data breach or unauthorized access
- Customer reports potential security vulnerability
- Malicious activity detected on customer accounts
- Data loss or corruption affecting customer data
- Compliance violations (GDPR, HIPAA, SOC 2)

#### Service Outages
- Platform-wide service disruption
- API downtime affecting multiple customers
- Critical infrastructure failures
- Database connectivity issues
- CDN or hosting provider problems

#### Legal & Compliance Issues
- Legal threats or litigation mentions
- Regulatory compliance inquiries
- Subpoenas or legal document requests
- Data deletion requests under GDPR "Right to be Forgotten"
- Intellectual property disputes

### Priority Escalation (Within 1 hour)

#### Enterprise Customer Issues
- Any issue affecting Enterprise customers
- SLA violations for Enterprise accounts
- Dedicated success manager requests
- Custom integration problems
- White-label deployment issues

#### Financial Impact
- Billing system errors affecting multiple customers
- Payment processor failures
- Refund requests over $1,000
- Revenue recognition issues
- Contract modification requests

#### High-Value Accounts
- Customers with >$50k annual contract value
- Fortune 500 company issues
- Potential churn indicators for major accounts
- Competitive pressures from large customers
- Expansion opportunity discussions

### Standard Escalation (Within 4 hours)

#### Technical Issues
- Unresolved technical problems after 24 hours
- Multiple failed resolution attempts
- Customer-reported bugs affecting core functionality
- Integration partner API issues
- Performance degradation reports

#### Customer Satisfaction
- Formal complaints about service quality
- Requests to speak with management
- Negative feedback about support experience
- Social media mentions requiring response
- Product feature requests from Pro customers

## Escalation Paths

### Level 1: First-Line Support
- **Technical Support Agent**: Technical issues, bugs, troubleshooting
- **Billing Agent**: Payment, subscription, pricing questions
- **Product Info Agent**: Features, plans, general information
- **Response Time**: 24 hours (Basic), 8 hours (Pro), 4 hours (Enterprise)

### Level 2: Senior Support
- **Senior Technical Specialist**: Complex technical issues, integration problems
- **Billing Manager**: Billing disputes, refund approvals, contract changes
- **Product Manager**: Feature requests, product feedback, roadmap questions
- **Response Time**: 4 hours (all plans)

### Level 3: Management
- **Support Manager**: Service quality issues, team performance, process improvements
- **Engineering Manager**: System outages, security incidents, technical escalations
- **Finance Director**: Large refunds, contract negotiations, revenue issues
- **Response Time**: 2 hours

### Level 4: Executive
- **VP of Customer Success**: Enterprise customer issues, major account management
- **CTO**: Security breaches, major technical failures, architecture decisions
- **CEO**: Legal issues, major customer relationships, crisis management
- **Response Time**: 1 hour

## Contact Information

### Internal Emergency Contacts

#### 24/7 On-Call Rotation
- **Primary**: +1-415-555-0199 (Support Manager)
- **Secondary**: +1-415-555-0188 (Engineering Manager)
- **Escalation**: +1-415-555-0177 (VP Customer Success)

#### Email Escalation Lists
- **Security Incidents**: security-incident@teamflow.com
- **Service Outages**: outage-response@teamflow.com
- **Legal Issues**: legal-emergency@teamflow.com
- **Executive Escalation**: executive-escalation@teamflow.com

#### Slack Channels
- **#support-escalation**: Real-time escalation coordination
- **#security-alerts**: Security incident response
- **#outage-response**: Service disruption coordination
- **#customer-success**: Enterprise customer issues

### External Emergency Contacts

#### Legal Counsel
- **Primary**: Johnson & Associates, +1-415-555-0166
- **After Hours**: Emergency legal hotline, +1-415-555-0155
- **International**: Global Legal Partners, +44-20-1234-5678

#### Public Relations
- **Crisis Communications**: PR Partners Inc., +1-415-555-0144
- **Social Media Monitoring**: SocialWatch, +1-415-555-0133

## Escalation Procedures

### 1. Security Incident Escalation

#### Immediate Actions (0-15 minutes)
1. **Secure the Environment**: Isolate affected systems if possible
2. **Notify Security Team**: Email security-incident@teamflow.com
3. **Document Everything**: Start incident log with timeline
4. **Customer Communication**: Acknowledge receipt, avoid details
5. **Activate Incident Response**: Follow security incident playbook

#### Follow-up Actions (15-60 minutes)
1. **Executive Notification**: Inform CTO and CEO
2. **Legal Review**: Consult with legal counsel if needed
3. **Customer Updates**: Provide status updates every 30 minutes
4. **External Notifications**: Regulatory bodies if required
5. **Media Monitoring**: Watch for public mentions

### 2. Service Outage Escalation

#### Immediate Actions (0-15 minutes)
1. **Status Page Update**: Update status.teamflow.com
2. **Engineering Notification**: Page on-call engineer
3. **Customer Communication**: Send service disruption notice
4. **Management Alert**: Notify Support and Engineering Managers
5. **Monitor Social Media**: Watch Twitter and community forums

#### Follow-up Actions (15-60 minutes)
1. **Root Cause Analysis**: Begin investigating cause
2. **Vendor Communication**: Contact AWS, CloudFlare if needed
3. **Customer Success**: Notify Enterprise customer success managers
4. **Regular Updates**: Status updates every 15 minutes
5. **Post-Incident Review**: Schedule review meeting

### 3. Legal/Compliance Escalation

#### Immediate Actions (0-15 minutes)
1. **Preserve Records**: Do not delete any relevant data
2. **Legal Notification**: Email legal-emergency@teamflow.com
3. **Executive Alert**: Notify CEO and CTO immediately
4. **Customer Response**: Acknowledge receipt, request legal review time
5. **Document Control**: Secure all relevant documentation

#### Follow-up Actions (15-60 minutes)
1. **Legal Counsel**: Conference call with external legal team
2. **Compliance Review**: Check against SOC 2, GDPR requirements
3. **Response Preparation**: Draft official response with legal approval
4. **Internal Communication**: Brief relevant team members
5. **Follow-up Plan**: Establish ongoing communication schedule

### 4. Enterprise Customer Escalation

#### Immediate Actions (0-1 hour)
1. **Account Review**: Pull complete customer history and contract
2. **Success Manager**: Notify dedicated customer success manager
3. **Management Alert**: Inform VP of Customer Success
4. **Priority Handling**: Move to front of all queues
5. **Initial Response**: Acknowledge with management involvement

#### Follow-up Actions (1-4 hours)
1. **Executive Involvement**: Engage appropriate C-level if needed
2. **Solution Planning**: Develop comprehensive resolution plan
3. **Resource Allocation**: Assign dedicated technical resources
4. **Communication Plan**: Establish regular update schedule
5. **Relationship Review**: Assess overall account health

## Communication Templates

### Security Incident Notification
```
Subject: [URGENT] Security Incident - TeamFlow Customer Data

Priority: Critical
Incident ID: SEC-2024-001
Reported: [Timestamp]
Affected Customer: [Company Name]
Reported By: [Customer Contact]

Initial Report:
[Brief description of reported issue]

Immediate Actions Taken:
- Security team notified
- Incident response activated
- Customer acknowledged
- Environment secured

Next Steps:
- Investigation in progress
- Legal counsel engaged
- Customer updates every 30 minutes
- Executive team briefed

Incident Commander: [Name]
Contact: [Phone/Email]
```

### Service Outage Alert
```
Subject: [OUTAGE] TeamFlow Service Disruption

Priority: High
Outage ID: OUT-2024-001
Started: [Timestamp]
Affected Services: [List services]
Impact Scope: [Geographic/Feature scope]

Symptoms:
[Description of user-facing issues]

Actions Taken:
- Status page updated
- Engineering team engaged
- Root cause investigation started
- Customer notifications sent

ETA for Resolution: [Time estimate]
Next Update: [Time]

Incident Commander: [Name]
Contact: [Phone/Email]
```

## Escalation Metrics & SLAs

### Response Time SLAs
- **Security Incidents**: 15 minutes initial response
- **Service Outages**: 15 minutes status update
- **Legal Issues**: 30 minutes acknowledgment
- **Enterprise Customer**: 1 hour initial response
- **Standard Escalation**: 4 hours initial response

### Resolution Time Targets
- **Critical Issues**: 4 hours
- **High Priority**: 24 hours
- **Standard Escalation**: 72 hours
- **Complex Issues**: 1 week with daily updates

### Escalation Success Metrics
- **Customer Satisfaction**: >95% for escalated issues
- **First-Call Resolution**: >80% for escalations
- **SLA Compliance**: >99% for response times
- **Escalation Rate**: <5% of total support tickets

## Training & Certification

### Escalation Team Requirements
- **Security Awareness**: Annual security training certification
- **Legal Compliance**: GDPR and privacy law training
- **Customer Success**: Enterprise account management training
- **Communication Skills**: Crisis communication workshop
- **Technical Knowledge**: Platform architecture certification

### Regular Training Sessions
- **Monthly**: Escalation scenario drills
- **Quarterly**: Legal update sessions
- **Bi-annually**: Crisis communication training
- **Annually**: Complete escalation process review

## Post-Escalation Process

### Incident Review
1. **Root Cause Analysis**: Complete within 48 hours
2. **Process Review**: Evaluate escalation handling
3. **Customer Follow-up**: Satisfaction survey and feedback
4. **Documentation**: Update knowledge base and procedures
5. **Team Debrief**: Discuss lessons learned and improvements

### Continuous Improvement
- **Monthly Metrics Review**: Escalation trends and patterns
- **Quarterly Process Updates**: Refine procedures based on feedback
- **Annual Training Updates**: Update training materials and scenarios
- **Customer Feedback Integration**: Incorporate customer suggestions 


================================================
FILE: agents/triage-demo/docs/product-features.md
================================================
# TeamFlow Product Features & Information

## Core Platform Features

### Project Management

#### Task Management
- **Create & Organize**: Unlimited task creation with custom categories and tags
- **Task Dependencies**: Link tasks with predecessor/successor relationships
- **Subtasks**: Break down complex tasks into manageable subtasks (up to 5 levels deep)
- **Priority Levels**: Critical, High, Medium, Low priority with visual indicators
- **Due Dates**: Set deadlines with automatic reminders and escalation
- **Custom Fields**: Add custom properties (text, numbers, dates, dropdowns, checkboxes)
- **Task Templates**: Save and reuse common task structures

#### Project Views
- **Kanban Boards**: Drag-and-drop task management with customizable columns
- **Gantt Charts**: Timeline view with critical path analysis (Pro/Enterprise)
- **List View**: Traditional task list with sorting and filtering
- **Calendar View**: Tasks and deadlines in calendar format
- **Dashboard View**: Project overview with progress metrics and team activity

#### Collaboration Tools
- **Comments**: Real-time commenting on tasks and projects with @mentions
- **File Attachments**: Attach files directly to tasks with version control
- **Activity Feed**: Real-time updates on project activity
- **Team Chat**: Built-in messaging with project-specific channels
- **Screen Sharing**: Integrated video conferencing for remote teams (Pro/Enterprise)

### Time Tracking & Reporting

#### Time Tracking
- **Manual Entry**: Log time spent on tasks manually
- **Timer Integration**: Start/stop timers directly from tasks
- **Automatic Tracking**: AI-powered time detection based on activity (Pro/Enterprise)
- **Time Approval**: Manager approval workflow for billable hours
- **Offline Tracking**: Mobile app continues tracking without internet connection

#### Reporting & Analytics
- **Project Reports**: Progress, budget, and timeline analysis
- **Team Performance**: Individual and team productivity metrics
- **Time Reports**: Detailed time tracking and billing reports
- **Custom Dashboards**: Build personalized views with key metrics
- **Export Options**: PDF, Excel, CSV export for all reports

### Storage & File Management

#### File Storage
- **Basic Plan**: 5GB total storage per team
- **Pro Plan**: 100GB total storage per team
- **Enterprise Plan**: 1TB total storage per team
- **File Types**: Support for all major file formats
- **Version Control**: Automatic versioning with rollback capability

#### File Sharing
- **Public Links**: Share files with external stakeholders
- **Permission Control**: Read-only, edit, or full access permissions
- **Expiring Links**: Set expiration dates for shared files
- **Download Tracking**: Monitor who downloads shared files

## Advanced Features by Plan

### Basic Plan Features
- Up to 10 team members
- Core project management (tasks, lists, basic boards)
- 5GB file storage
- Mobile apps (iOS/Android)
- Email support
- Basic integrations (Google Calendar, CSV import)
- API access (1,000 requests/hour)

### Pro Plan Additional Features
- Up to 100 team members
- Advanced project views (Gantt charts, advanced dashboards)
- 100GB file storage
- Custom fields and workflows
- Time tracking and invoicing
- Advanced integrations (Slack, GitHub, Jira, Salesforce)
- Priority support (chat + email)
- API access (10,000 requests/hour)
- Team workload balancing
- Advanced reporting and analytics
- Custom branding (logo, colors)

### Enterprise Plan Additional Features
- Unlimited team members
- 1TB file storage
- Advanced security (SSO, SAML, 2FA enforcement)
- Dedicated customer success manager
- Phone support with 4-hour SLA
- Unlimited API access
- Custom integrations and white-labeling
- Advanced admin controls and audit logs
- On-premises deployment option
- 99.95% uptime SLA
- Custom workflow automation
- Advanced permissions and role management

## Integration Ecosystem

### Communication Platforms

#### Slack Integration (Pro/Enterprise)
- **Two-way Sync**: Create tasks from Slack messages, get updates in channels
- **Notification Control**: Choose which updates appear in Slack
- **Slash Commands**: Quick task creation with `/teamflow create` command
- **File Sync**: Automatically sync files shared in Slack to project storage

#### Microsoft Teams (Pro/Enterprise)
- **Tab Integration**: Embed TeamFlow projects directly in Teams channels
- **Bot Commands**: Create and update tasks via Teams bot
- **Calendar Sync**: Sync project deadlines with Teams calendar
- **File Integration**: Access TeamFlow files from Teams file browser

#### Discord (Pro/Enterprise)
- **Channel Integration**: Link Discord channels to specific projects
- **Role Sync**: Sync Discord roles with TeamFlow permissions
- **Voice Channel Links**: Start Discord voice calls directly from tasks

### Development Tools

#### GitHub Integration (Pro/Enterprise)
- **Commit Linking**: Link commits to specific tasks automatically
- **Pull Request Tracking**: Track PR status within TeamFlow tasks
- **Branch Management**: Create branches directly from tasks
- **Release Planning**: Plan releases using TeamFlow milestones

#### GitLab Integration (Pro/Enterprise)
- **Issue Sync**: Two-way sync between GitLab issues and TeamFlow tasks
- **Pipeline Status**: View CI/CD pipeline status in project dashboard
- **Merge Request Workflow**: Track code reviews within project context

#### Jira Integration (Pro/Enterprise)
- **Epic/Story Mapping**: Map Jira epics to TeamFlow projects
- **Sprint Planning**: Import Jira sprints as TeamFlow milestones
- **Status Sync**: Automatically update task status based on Jira workflow

### CRM & Sales Tools

#### Salesforce Integration (Pro/Enterprise)
- **Lead-to-Project**: Convert Salesforce leads into TeamFlow projects
- **Account Sync**: Link projects to Salesforce accounts
- **Opportunity Tracking**: Track project delivery against sales opportunities

#### HubSpot Integration (Pro/Enterprise)
- **Contact Sync**: Import HubSpot contacts as team members
- **Deal Pipeline**: Track project delivery stages aligned with deal stages
- **Marketing Campaign Tracking**: Link projects to marketing campaigns

### File Storage & Productivity

#### Google Workspace
- **Google Drive**: Direct file access and sync with Google Drive
- **Google Calendar**: Two-way calendar sync for deadlines and meetings
- **Gmail**: Create tasks from emails with Gmail browser extension
- **Google Sheets**: Import/export project data to Google Sheets

#### Microsoft 365
- **OneDrive**: Seamless file sync and storage integration
- **Outlook**: Email-to-task conversion and calendar integration
- **Excel**: Advanced reporting with Excel integration
- **SharePoint**: Enterprise file management and compliance

#### Dropbox
- **File Sync**: Automatic sync of project files with Dropbox
- **Paper Integration**: Convert Dropbox Paper docs to project documentation
- **Team Folders**: Organize project files in shared Dropbox folders

## Mobile Applications

### iOS App Features
- **Native Design**: Full iOS design guidelines compliance
- **Offline Support**: Continue working without internet connection
- **Push Notifications**: Real-time updates for mentions, deadlines, and assignments
- **Touch ID/Face ID**: Biometric authentication for security
- **Widgets**: Quick access to tasks and notifications from home screen
- **Apple Watch**: Task completion and notifications on Apple Watch

### Android App Features
- **Material Design**: Full Android Material Design implementation
- **Battery Optimization**: Efficient background sync and battery usage
- **Quick Settings**: Add tasks and check notifications from notification panel
- **Google Assistant**: Voice commands for task creation and status updates
- **Adaptive Icons**: Support for Android adaptive icon system

### Cross-Platform Features
- **Real-time Sync**: Instant synchronization across all devices
- **Offline Mode**: Full functionality without internet connection
- **File Download**: Download and view attachments offline
- **Voice Notes**: Record voice memos and attach to tasks
- **Photo Capture**: Take photos and attach directly to tasks

## API & Developer Tools

### REST API
- **Full Coverage**: Complete access to all platform features via API
- **Rate Limits**: 1,000/hour (Basic), 10,000/hour (Pro), unlimited (Enterprise)
- **Authentication**: OAuth 2.0 and API key authentication
- **Webhooks**: Real-time event notifications for integrations
- **GraphQL**: Alternative GraphQL endpoint for efficient data fetching

### SDKs & Libraries
- **JavaScript/Node.js**: Full-featured SDK with TypeScript support
- **Python**: Comprehensive Python library with async support
- **PHP**: Laravel and standard PHP integration library
- **Ruby**: Ruby gem with Rails integration helpers
- **REST Clients**: Postman collection and OpenAPI specification

### Webhook Events
- **Task Events**: Created, updated, completed, deleted
- **Project Events**: Created, archived, member changes
- **Comment Events**: New comments, mentions, reactions
- **File Events**: Uploaded, updated, shared, deleted
- **Team Events**: Member added, removed, role changes

## Security & Compliance

### Data Security
- **Encryption**: AES-256 encryption for all data at rest and in transit
- **HTTPS**: TLS 1.3 for all client connections
- **API Security**: Rate limiting, request signing, and token management
- **Database Security**: Encrypted backups with geographic redundancy

### Access Control
- **Role-Based Permissions**: Admin, Manager, Member, Viewer roles
- **Project-Level Permissions**: Fine-grained control over project access
- **Two-Factor Authentication**: SMS, authenticator app, hardware keys (Pro/Enterprise)
- **Single Sign-On**: SAML 2.0 and OAuth integration (Enterprise)

### Compliance Standards
- **SOC 2 Type II**: Annual compliance audits and certification
- **GDPR**: Full compliance with European data protection regulations
- **ISO 27001**: Information security management certification
- **HIPAA**: Healthcare compliance option for Enterprise customers

## Getting Started Resources

### Onboarding
- **Interactive Tutorial**: Step-by-step guide for new users
- **Sample Projects**: Pre-built templates for common use cases
- **Video Library**: Comprehensive training videos for all features
- **Webinar Training**: Live training sessions twice weekly

### Documentation
- **Knowledge Base**: Searchable help articles and guides
- **API Documentation**: Complete developer reference with examples
- **Video Tutorials**: Feature-specific how-to videos
- **Community Forum**: User community for tips and best practices

### Support Channels
- **Basic Plan**: Email support with 24-hour response
- **Pro Plan**: Email and chat support with 8-hour response
- **Enterprise Plan**: Phone, email, and chat with 4-hour response and dedicated success manager 


================================================
FILE: agents/triage-demo/docs/technical-documentation.md
================================================
# TeamFlow Technical Documentation

## System Requirements

### Web Application
- **Supported Browsers**: Chrome 90+, Firefox 88+, Safari 14+, Edge 90+
- **Minimum Screen Resolution**: 1024x768
- **Internet Connection**: Broadband (1 Mbps minimum, 5 Mbps recommended)
- **JavaScript**: Must be enabled

### Mobile Applications

#### iOS App
- **Minimum Version**: iOS 13.0 or later
- **Compatible Devices**: iPhone 6s and newer, iPad Air 2 and newer
- **Storage**: 150MB free space required
- **Network**: 3G/4G/5G or Wi-Fi connection

#### Android App
- **Minimum Version**: Android 8.0 (API level 26)
- **RAM**: 2GB minimum, 4GB recommended
- **Storage**: 200MB free space required
- **Network**: 3G/4G/5G or Wi-Fi connection

## API Documentation

### Authentication
```
Authorization: Bearer <your_api_token>
Content-Type: application/json
```

### Base URL
- **Production**: `https://api.teamflow.com/v1`
- **Sandbox**: `https://sandbox-api.teamflow.com/v1`

### Rate Limits
- **Basic Plan**: 1,000 requests/hour
- **Pro Plan**: 10,000 requests/hour  
- **Enterprise Plan**: Unlimited
- **Rate Limit Headers**:
  - `X-RateLimit-Limit`: Total requests allowed
  - `X-RateLimit-Remaining`: Requests remaining in current window
  - `X-RateLimit-Reset`: Unix timestamp when window resets

### Common Error Codes
- **400**: Bad Request - Invalid parameters or request format
- **401**: Unauthorized - Invalid or missing API token
- **403**: Forbidden - Insufficient permissions
- **404**: Not Found - Resource doesn't exist
- **422**: Unprocessable Entity - Validation errors
- **429**: Too Many Requests - Rate limit exceeded
- **500**: Internal Server Error - Contact support
- **502/503**: Service Unavailable - Temporary outage

## Common Technical Issues & Solutions

### 1. Login and Authentication Issues

#### "Invalid credentials" error
**Symptoms**: User cannot log in, receives "Invalid email or password" message
**Common Causes**:
- Incorrect email/password combination
- Account locked due to multiple failed attempts
- Browser caching old session data

**Solutions**:
1. Verify email address (check for typos, extra spaces)
2. Try password reset flow
3. Clear browser cookies and cache
4. Try incognito/private browsing mode
5. Check if account is locked (wait 15 minutes or contact support)

#### Two-Factor Authentication (2FA) issues
**Symptoms**: 2FA code not working or not received
**Solutions**:
1. Ensure device clock is synchronized
2. Try generating a new code (codes expire every 30 seconds)
3. Check authenticator app is configured correctly
4. Use backup codes if available
5. Contact support to reset 2FA if backup codes exhausted

### 2. Performance Issues

#### Slow loading pages
**Symptoms**: Pages take >10 seconds to load, timeouts
**Troubleshooting Steps**:
1. Check internet connection speed (minimum 1 Mbps required)
2. Test on different networks (mobile data vs. Wi-Fi)
3. Clear browser cache and cookies
4. Disable browser extensions temporarily
5. Try different browser
6. Check TeamFlow status page: status.teamflow.com

#### Mobile app crashes
**Symptoms**: App closes unexpectedly, freezes during use
**Solutions**:
1. Force close and restart the app
2. Restart device
3. Update app to latest version
4. Clear app cache (Android) or offload/reinstall app (iOS)
5. Check available storage space (minimum 500MB recommended)
6. Report crash with device logs

### 3. API Integration Issues

#### 401 Unauthorized errors
**Diagnostic Steps**:
1. Verify API token is correct and not expired
2. Check token has required permissions
3. Ensure proper Authorization header format
4. Test with different API endpoints

#### 429 Rate limit exceeded
**Solutions**:
1. Implement exponential backoff in API calls
2. Check current rate limit status in response headers
3. Consider upgrading plan for higher limits
4. Cache responses when possible to reduce API calls

#### Webhook delivery failures
**Common Issues**:
- Endpoint URL not accessible from internet
- SSL certificate issues
- Timeout (webhook endpoint must respond within 10 seconds)
- Incorrect response status (must return 2xx status code)

### 4. File Upload Issues

#### "File too large" errors
**File Size Limits**:
- Basic Plan: 25MB per file
- Pro Plan: 100MB per file
- Enterprise Plan: 500MB per file

**Solutions**:
1. Compress files using zip/rar
2. Use cloud storage links for large files
3. Split large files into smaller chunks
4. Consider plan upgrade for larger limits

#### Unsupported file formats
**Supported Formats**: 
- Images: JPG, PNG, GIF, SVG, WebP
- Documents: PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX
- Archives: ZIP, RAR, 7Z
- Text: TXT, CSV, MD
- Code: JS, HTML, CSS, JSON, XML

### 5. Integration Problems

#### Slack integration not working
**Setup Requirements**:
1. Slack workspace admin permissions
2. TeamFlow Pro or Enterprise plan
3. Proper webhook configuration

**Troubleshooting**:
1. Verify Slack workspace URL is correct
2. Check webhook permissions in Slack admin
3. Test with simple message first
4. Ensure both apps are updated to latest versions

#### GitHub integration issues
**Common Problems**:
- Repository access permissions
- Webhook authentication failures
- Branch protection rules blocking commits

**Solutions**:
1. Verify GitHub personal access token has correct scopes
2. Check repository permissions for TeamFlow app
3. Review webhook logs in GitHub settings
4. Test with public repository first

## Browser-Specific Issues

### Chrome
- **File download issues**: Check download settings and blocked downloads
- **Extension conflicts**: Disable ad blockers and privacy extensions temporarily

### Safari
- **Cookie issues**: Enable cross-site tracking prevention exceptions
- **Local storage**: Ensure not in private browsing mode

### Firefox
- **Security settings**: Adjust strict enhanced tracking protection
- **Add-on conflicts**: Test in safe mode

## Server Infrastructure

### Data Centers
- **Primary**: AWS US-West-2 (Oregon)
- **Secondary**: AWS EU-West-1 (Ireland)
- **CDN**: CloudFlare global network

### Maintenance Windows
- **Scheduled Maintenance**: Sundays 2:00-4:00 AM PST
- **Emergency Maintenance**: As needed with 30-minute notice
- **Status Updates**: status.teamflow.com and @TeamFlowStatus on Twitter

## Escalation Criteria

Escalate to Level 2 Support when:
- Data loss or corruption suspected
- Security breach indicators
- API downtime affecting multiple customers
- Integration partner (Slack, GitHub, etc.) reporting issues
- Customer reports SLA violations
- Enterprise customer experiencing any service disruption

## Diagnostic Tools

### Browser Developer Tools
1. **Console Errors**: Check for JavaScript errors (F12 â†’ Console)
2. **Network Tab**: Monitor failed requests and response times
3. **Application Tab**: Check local storage and cookies

### API Testing
- Use Postman or curl to test API endpoints
- Check response headers for rate limit information
- Verify request format matches API documentation

### Mobile Debugging
- iOS: Connect device to Xcode for detailed crash logs
- Android: Enable developer options and use ADB logcat 


================================================
FILE: docs/README.md
================================================
# Website

This website is built using [Docusaurus](https://docusaurus.io/), a modern static website generator.

### Installation

```
$ yarn
```

### Local Development

```
$ yarn start
```

This command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.

### Build

```
$ yarn build
```

This command generates static content into the `build` directory and can be served using any static contents hosting service.

### Deployment

Using SSH:

```
$ USE_SSH=true yarn deploy
```

Not using SSH:

```
$ GIT_USER=<Your GitHub username> yarn deploy
```

If you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.



================================================
FILE: docs/how-to-dexto.md
================================================
# Dexto Usage Guide for LLM Agents

This document provides a concise guide for using the Dexto agent runtime, optimized for RAG and consumption by other LLMs.

---

## 1. Core Concepts

### What is Dexto?
Dexto is a lightweight runtime for creating and running AI agents. It translates natural language prompts into actions using configured tools and LLMs. It can be controlled via CLI, a programmatic SDK, or a REST API.

### Installation
Install the Dexto CLI globally via npm:
```bash
npm install -g dexto
```

### LLM API Keys
Dexto requires API keys for the desired LLM provider. Set them as environment variables.
```bash
# For OpenAI (e.g., gpt-4o)
export OPENAI_API_KEY="your_key"

# For Anthropic (e.g., claude-4-sonnet)
export ANTHROPIC_API_KEY="your_key"

# For Google (e.g., gemini-2.5-pro)
export GOOGLE_GENERATIVE_AI_API_KEY="your_key"

# For Cohere (e.g., command-r-plus)
export COHERE_API_KEY="your_key"
```

### Agent Configuration (`default-agent.yml`)
Agent behavior is defined in a YAML file (default: `agents/default-agent.yml`). This file specifies the LLM, tools (via MCP servers), and system prompt.

**Example `agent.yml`:**
```yaml
# Connect to tool servers via Model Context Protocol (MCP)
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  puppeteer:
    type: stdio
    command: npx
    args: ['-y', '@truffle-ai/puppeteer-server']

# Configure the Large Language Model
llm:
  provider: openai
  model: gpt-4o
  apiKey: $OPENAI_API_KEY # Reads from environment variable

# Define the agent's persona and instructions
systemPrompt: |
  You are Dexto, an expert coding assistant.
  You have access to a filesystem and a browser.
  Think step-by-step to solve the user's request.
```

### Advanced System Prompt Configuration

For more complex system prompts, you can use the contributor-based configuration format that allows mixing static content, dynamic content, and file-based context:

```yaml
systemPrompt:
  contributors:
    - id: main-prompt
      type: static
      priority: 0
      content: |
        You are Dexto, an expert coding assistant.
        You have access to a filesystem and a browser.
    
    - id: project-context
      type: file
      priority: 10
      files:
        - ./README.md              # Relative to config file location
        - ./docs/architecture.md   # Relative to config file location  
        - ./CONTRIBUTING.md        # Relative to config file location
      options:
        includeFilenames: true
        separator: "\n\n---\n\n"
        errorHandling: "skip"
        maxFileSize: 50000
        includeMetadata: false
    
    - id: current-time
      type: dynamic
      priority: 20
      source: dateTime
    
    - id: mcp-resources
      type: dynamic
      priority: 25
      source: resources
      enabled: true
```

**File Contributor Options:**
- `files`: Array of file paths to include (.md and .txt files only)
- `options.includeFilenames`: Whether to include filename headers (default: true)
- `options.separator`: Text to separate multiple files (default: "\n\n---\n\n")
- `options.errorHandling`: How to handle missing files - "skip" or "error" (default: "skip")
- `options.maxFileSize`: Maximum file size in bytes (default: 100000)
- `options.includeMetadata`: Include file size and modification time (default: false)

**Note:** Files are always read using UTF-8 encoding.

**Dynamic Contributor Sources:**
- `dateTime`: Automatically adds current date and time
- `resources`: Includes resources from connected MCP servers (disabled by default for performance)

**Use Cases for File Contributors:**
- Include project documentation and guidelines
- Add code style guides and best practices
- Provide domain-specific knowledge from markdown files
- Include API documentation or specification files
- Add context-specific instructions for different projects

**Use Cases for MCP Resources:**
- Include database schemas from database MCP servers
- Add configuration files from configuration MCP servers  
- Include documentation from documentation MCP servers
- Provide real-time context from connected services

---

## 2. Usage Methods

Dexto can be used via its CLI, the Dexto SDK for TypeScript, or as a server with a REST API.

### Method 1: CLI Usage

The `dexto` command can run one-shot prompts or start in different modes.

**One-shot prompt:**
Execute a task directly from the command line.
```bash
dexto "create a new file named test.txt with hello world content"
# or use explicit -p flag
dexto -p "create a new file named test.txt with hello world content"
```

**Interactive CLI:**
Start a chat session in the terminal.
```bash
dexto
```

**Key CLI Flags:**
- `-m, --model <model_name>`: Switch LLM model (e.g., `claude-4-sonnet-20250514`). Overrides config file.
- `-a, --agent <path/to/agent.yml>`: Use a specific agent configuration file.
- `--mode <mode>`: Change the run mode.
- `--new-session [id]`: Start a new chat session.

**CLI Run Modes (`--mode`):**

| Mode       | Command                       | Description                               |
|------------|-------------------------------|-------------------------------------------|
| `cli`      | `dexto`                       | Interactive or one-shot terminal commands.|
| `web`      | `dexto --mode web`            | Starts a web UI (default port: 3000).     |
| `server`   | `dexto --mode server`         | Starts a REST/WebSocket server (port: 3001).|
| `mcp`      | `dexto --mode mcp`            | Exposes the agent as a tool via MCP/stdio.|
| `discord`  | `dexto --mode discord`        | Runs the agent as a Discord bot.          |
| `telegram` | `dexto --mode telegram`       | Runs the agent as a Telegram bot.         |

**Project Scaffolding:**
- `dexto create-app`: Create a new Dexto project structure.
- `dexto init-app`: Initialize Dexto in an existing TypeScript project.

### Method 2: Programmatic SDK (`DextoAgent`)

Use the `DextoAgent` class in your TypeScript/JavaScript projects for full programmatic control.

**Installation for a project:**
```bash
npm install dexto
```

**Example SDK Usage:**
```ts
import 'dotenv/config';
import { DextoAgent, loadAgentConfig } from 'dexto';

// Load configuration from default location (auto-discovery)
const config = await loadAgentConfig();

// Or load from a specific file
// const config = await loadAgentConfig('./agents/default-agent.yml');

// Create and start the agent
const agent = new DextoAgent(config);
await agent.start(); // Initializes services like MCP servers

// Run a single task
const response = await agent.run('List the 3 largest files in the current directory.');
console.log(response);

// Hold a conversation (state is maintained automatically)
await agent.run('Write a function that adds two numbers.');
await agent.run('Now add type annotations to it.');

// Reset the conversation history
agent.resetConversation();

// Stop the agent and disconnect services
await agent.stop();
```

### Method 3: REST API (Server Mode)

Run Dexto as a headless server to interact with it via HTTP requests.

**Start the server:**
```bash
# The server will run on http://localhost:3001 by default
dexto --mode server
```

**Key API Endpoints:**
- `POST /api/message`: Send a prompt asynchronously. The agent will process it and you can receive events via WebSocket.
  - Body: `{ "message": "your prompt here" }`
- `POST /api/message-sync`: Send a prompt and wait for the complete response.
  - Body: `{ "message": "your prompt here" }`
- `POST /api/reset`: Resets the current conversation session.
- `GET /api/mcp/servers`: Lists the connected MCP tool servers.

---

## 3. Tools and the Model Context Protocol (MCP)

Dexto uses the **Model Context Protocol (MCP)** to communicate with tools. Tools run as separate server processes. You connect Dexto to them by listing them under `mcpServers` in your `agent.yml`.

**Common Tool Servers:**
- **`@modelcontextprotocol/server-filesystem`**: Provides tools for reading, writing, and listing files.
- **`@truffle-ai/puppeteer-server`**: Provides tools for web browsing and scraping.
- **`@truffle-ai/web-search`**: Provides tools for performing web searches.

**Executing Tools:**
When an LLM agent uses Dexto, it should issue natural language commands. Dexto's LLM will determine which tool to call. The agent's `systemPrompt` should inform the LLM about the available tools (e.g., "You have access to a filesystem and a browser"). The LLM then generates tool calls that Dexto executes. 


================================================
FILE: docs/api/dexto-agent.md
================================================
---
sidebar_position: 1
---

# DextoAgent API

Complete API reference for the main `DextoAgent` class.

## Constructor and Lifecycle

### `constructor`

Creates a new Dexto agent instance with the provided configuration.

```typescript
constructor(config: AgentConfig)
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `config` | `AgentConfig` | Agent configuration object |

### `start`

Initializes and starts the agent with all required services.

```typescript
async start(): Promise<void>
```

**Parameters:** None

**Example:**
```typescript
const agent = new DextoAgent(config);
await agent.start();
```

### `stop`

Stops the agent and cleans up all resources.

```typescript
async stop(): Promise<void>
```

**Example:**
```typescript
await agent.stop();
```

---

## Core Methods

### `run`

Processes user input through the agent's LLM and returns the response.

```typescript
async run(
  textInput: string,
  imageDataInput?: { base64: string; mimeType: string },
  fileDataInput?: { base64: string; mimeType: string; filename?: string },
  sessionId?: string,
  stream?: boolean
): Promise<string | null>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `textInput` | `string` | User message or query |
| `imageDataInput` | `{ base64: string; mimeType: string }` | (Optional) Base64-encoded image |
| `fileDataInput` | `{ base64: string; mimeType: string; filename?: string }` | (Optional) Base64-encoded file |
| `sessionId` | `string` | (Optional) Session ID |
| `stream` | `boolean` | (Optional) Enable streaming (default: false) |

**Returns:** `Promise<string | null>` - AI response or null

**Example:**
```typescript
const agent = new DextoAgent(config);
await agent.start();
const response = await agent.run("Explain quantum computing");
// ... use agent ...
await agent.stop();
```

---

## Session Management

### `createSession`

Creates a new conversation session with optional custom ID.

```typescript
async createSession(sessionId?: string): Promise<ChatSession>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | (Optional) Custom session ID |

**Returns:** `Promise<ChatSession>`

### `getSession`

Retrieves an existing session by its ID.

```typescript
async getSession(sessionId: string): Promise<ChatSession | undefined>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | Session ID to retrieve |

**Returns:** `Promise<ChatSession | undefined>`

### `listSessions`

Returns an array of all active session IDs.

```typescript
async listSessions(): Promise<string[]>
```

**Returns:** `Promise<string[]>` - Array of session IDs

### `deleteSession`

Permanently deletes a session and all its conversation history. This action cannot be undone.

```typescript
async deleteSession(sessionId: string): Promise<void>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | Session ID to delete |

**Note:** This completely removes the session and all associated conversation data from storage.

### `loadSession`

Sets a session as the default for subsequent operations that don't specify a session ID.

```typescript
async loadSession(sessionId: string | null): Promise<void>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string \| null` | Session ID to load as default, or null to reset |

### `resetConversation`

Clears the conversation history of a session while keeping the session active.

```typescript
async resetConversation(sessionId?: string): Promise<void>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | (Optional) Session to reset |

### `getSessionMetadata`

Retrieves metadata for a session including creation time and message count.

```typescript
async getSessionMetadata(sessionId: string): Promise<SessionMetadata | undefined>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | Session ID |

**Returns:** `Promise<SessionMetadata | undefined>`

### `getSessionHistory`

Gets the complete conversation history for a session.

```typescript
async getSessionHistory(sessionId: string): Promise<ConversationHistory>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | Session ID |

**Returns:** `Promise<ConversationHistory>`

### `getCurrentSessionId`

Returns the ID of the currently loaded default session.

```typescript
getCurrentSessionId(): string
```

**Returns:** `string` - Current default session ID

### `getDefaultSession`

Returns the currently loaded default session instance.

```typescript
async getDefaultSession(): Promise<ChatSession>
```

**Returns:** `Promise<ChatSession>`

---

## Configuration

### `switchLLM`

Dynamically changes the LLM configuration for the agent or a specific session.

```typescript
async switchLLM(
  llmUpdates: LLMUpdates,
  sessionId?: string
): Promise<ValidatedLLMConfig>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `llmUpdates` | `LLMUpdates` | LLM configuration updates (model, provider, router, apiKey, etc.) |
| `sessionId` | `string` | (Optional) Target session ID |

**Returns:** `Promise<ValidatedLLMConfig>` â€“ the fully validated, effective LLM configuration.

```typescript
const config = await agent.switchLLM({ 
  provider: 'anthropic', 
  model: 'claude-4-sonnet-20250514' 
});
console.log(config.model);
```

### `getCurrentLLMConfig`

Returns the current LLM configuration for the default session.

```typescript
getCurrentLLMConfig(): LLMConfig
```

**Returns:** `LLMConfig`

### `getEffectiveConfig`

Gets the complete effective configuration for a session or the default configuration.

```typescript
getEffectiveConfig(sessionId?: string): Readonly<AgentConfig>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `sessionId` | `string` | (Optional) Session ID |

**Returns:** `Readonly<AgentConfig>`

---

## MCP Server Management

### `connectMcpServer`

Connects to a new MCP server and adds it to the agent's available tools.

```typescript
async connectMcpServer(name: string, config: McpServerConfig): Promise<void>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `name` | `string` | Server name |
| `config` | `McpServerConfig` | Server configuration |

### `removeMcpServer`

Disconnects from an MCP server and removes its tools from the agent.

```typescript
async removeMcpServer(name: string): Promise<void>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `name` | `string` | Server name to remove |

### `executeTool`

Executes a tool from any source (MCP servers, custom tools, or internal tools). This is the unified interface for tool execution.

```typescript
async executeTool(toolName: string, args: any): Promise<any>
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `toolName` | `string` | Tool name |
| `args` | `any` | Tool arguments |

**Returns:** `Promise<any>` - Tool execution result

### `getAllMcpTools`

Returns a map of all available tools from all connected MCP servers.

```typescript
async getAllMcpTools(): Promise<Record<string, ToolDefinition>>
```

**Returns:** `Promise<Record<string, ToolDefinition>>`

### `getAllTools`

Returns a map of all available tools from all sources (MCP servers, custom tools, and internal tools). This is the unified interface for tool discovery.

```typescript
async getAllTools(): Promise<Record<string, ToolDefinition>>
```

**Returns:** `Promise<Record<string, ToolDefinition>>`

### `getMcpClients`

Returns a map of all connected MCP client instances.

```typescript
getMcpClients(): Map<string, IMCPClient>
```

**Returns:** `Map<string, IMCPClient>`

### `getMcpFailedConnections`

Returns a record of failed MCP server connections and their error messages.

```typescript
getMcpFailedConnections(): Record<string, string>
```

**Returns:** `Record<string, string>` - Failed connection names to error messages 

---

## Model & Provider Introspection

### `getSupportedProviders`

Returns the list of supported LLM providers.

```typescript
getSupportedProviders(): LLMProvider[]
```

### `getSupportedModels`

Returns supported models grouped by provider, including a flag for the default model per provider.

```typescript
getSupportedModels(): Record<LLMProvider, Array<ModelInfo & { isDefault: boolean }>>
```

### `getSupportedModelsForProvider`

Returns supported models for a specific provider.

```typescript
getSupportedModelsForProvider(provider: LLMProvider): Array<ModelInfo & { isDefault: boolean }>
```

### `inferProviderFromModel`

Infers the provider from a model name or returns `null` if unknown.

```typescript
inferProviderFromModel(modelName: string): LLMProvider | null
```

---

## Search

### `searchMessages`

Search for messages across all sessions or within a specific session.

```typescript
async searchMessages(query: string, options?: SearchOptions): Promise<SearchResponse>
```

### `searchSessions`

Search for sessions that contain the specified query.

```typescript
async searchSessions(query: string): Promise<SessionSearchResponse>
```


================================================
FILE: docs/api/events.md
================================================
---
sidebar_position: 3
---

# Events Reference

Complete event system documentation for monitoring and integrating with Dexto agents.

## Overview

The Dexto SDK provides a comprehensive event system through two main event buses:
- **AgentEventBus**: Agent-level events that occur across the entire agent instance
- **SessionEventBus**: Session-specific events that occur within individual conversation sessions

## Agent-Level Events

These events are emitted by the `AgentEventBus` and provide insight into agent-wide operations.

### Conversation Events

#### `dexto:conversationReset`

Fired when a conversation history is reset for a session.

```typescript
{
  sessionId: string;
}
```


### MCP Server Events

#### `dexto:mcpServerConnected`

Fired when an MCP server connection attempt completes (success or failure).

```typescript
{
  name: string;
  success: boolean;
  error?: string;
}
```

#### `dexto:mcpServerAdded`

Fired when an MCP server is added to the runtime state.

```typescript
{
  serverName: string;
  config: McpServerConfig;
}
```

#### `dexto:mcpServerRemoved`

Fired when an MCP server is removed from the runtime state.

```typescript
{
  serverName: string;
}
```

#### `dexto:mcpServerUpdated`

Fired when an MCP server configuration is updated.

```typescript
{
  serverName: string;
  config: McpServerConfig;
}
```

#### `dexto:availableToolsUpdated`

Fired when the available tools list is updated.

```typescript
{
  tools: string[];
  source: 'mcp' | 'builtin';
}
```

### Validation Events

#### `dexto:inputValidationFailed`

Fired when input validation fails for an LLM request.

```typescript
{
  sessionId: string;
  issues: Issue[];
  provider: LLMProvider;
  model: string;
}
```


### Configuration Events

#### `dexto:llmSwitched`

Fired when the LLM configuration is changed.

```typescript
{
  newConfig: LLMConfig;
  router?: string;
  historyRetained?: boolean;
  sessionIds: string[];
}
```

#### `dexto:stateChanged`

Fired when agent runtime state changes.

```typescript
{
  field: string; // keyof AgentRuntimeState
  oldValue: any;
  newValue: any;
  sessionId?: string;
}
```

#### `dexto:stateExported`

Fired when agent state is exported as configuration.

```typescript
{
  config: AgentConfig;
}
```

#### `dexto:stateReset`

Fired when agent state is reset to baseline.

```typescript
{
  toConfig: AgentConfig;
}
```

### Session Override Events

#### `dexto:sessionOverrideSet`

Fired when session-specific configuration is set.

```typescript
{
  sessionId: string;
  override: SessionOverride;
}
```

#### `dexto:sessionOverrideCleared`

Fired when session-specific configuration is cleared.

```typescript
{
  sessionId: string;
}
```

### Tool Confirmation Events

#### `dexto:toolConfirmationRequest`

Fired when a tool execution requires confirmation.

```typescript
{
  toolName: string;
  args: Record<string, any>;
  description?: string;
  executionId: string;
  timestamp: string; // ISO 8601 timestamp
  sessionId?: string;
}
```

#### `dexto:toolConfirmationResponse`

Fired when a confirmation response is received.

```typescript
{
  executionId: string;
  approved: boolean;
  rememberChoice?: boolean;
  sessionId?: string;
}
```

---

## Session-Level Events

These events are emitted by the `SessionEventBus` and provide insight into LLM service operations within sessions.

### LLM Processing Events

#### `llmservice:thinking`

Fired when the LLM service starts processing a request.

```typescript
{
  sessionId: string;
}
```

#### `llmservice:response`

Fired when the LLM service completes a response.

```typescript
{
  content: string;
  tokenCount?: number;
  model?: string;
  sessionId: string;
}
```

#### `llmservice:chunk`

Fired when a streaming response chunk is received.

```typescript
{
  content: string;
  isComplete?: boolean;
  sessionId: string;
}
```

#### `llmservice:error`

Fired when the LLM service encounters an error.

```typescript
{
  error: Error;
  context?: string;
  recoverable?: boolean;
  sessionId: string;
}
```

#### `llmservice:switched`

Fired when session LLM configuration is changed.

```typescript
{
  newConfig: LLMConfig;
  router?: string;
  historyRetained?: boolean;
  sessionId: string;
}
```

#### `llmservice:unsupportedInput`

Fired when the LLM service receives unsupported input.

```typescript
{
  errors: string[];
  provider: LLMProvider;
  model?: string;
  fileType?: string;
  details?: any;
  sessionId: string;
}
```

### Tool Execution Events

#### `llmservice:toolCall`

Fired when the LLM service requests a tool execution.

```typescript
{
  toolName: string;
  args: Record<string, any>;
  callId?: string;
  sessionId: string;
}
```

#### `llmservice:toolResult`

Fired when a tool execution completes.

```typescript
{
  toolName: string;
  result: any;
  callId?: string;
  success: boolean;
  sessionId: string;
}
```

---


---

## Event Data Types

### Core Types

```typescript
interface AgentEventMap {
  'dexto:conversationReset': { sessionId: string };
  'dexto:mcpServerConnected': { name: string; success: boolean; error?: string };
  'dexto:availableToolsUpdated': { tools: string[]; source: string };
  'dexto:llmSwitched': { newConfig: LLMConfig; router?: string; historyRetained?: boolean; sessionIds: string[] };
  // ... other events
}

interface SessionEventMap {
  'llmservice:thinking': { sessionId: string };
  'llmservice:response': { content: string; tokenCount?: number; model?: string; sessionId: string };
  'llmservice:chunk': { content: string; isComplete?: boolean; sessionId: string };
  'llmservice:toolCall': { toolName: string; args: Record<string, any>; callId?: string; sessionId: string };
  'llmservice:toolResult': { toolName: string; result: any; callId?: string; success: boolean; sessionId: string };
  'llmservice:error': { error: Error; context?: string; recoverable?: boolean; sessionId: string };
  // ... other events
}
``` 


================================================
FILE: docs/api/getting-started.md
================================================
---
slug: /
sidebar_position: 1
---

# Getting Started

Welcome to the Dexto API. This guide will walk you through the essential first steps to begin interacting with your Dexto agent programmatically.

## 1. Starting the API Server

Before you can make any API calls, you must start the Dexto server. This single command enables both the REST and WebSocket APIs.

Run the following command in your terminal:

```bash
dexto --mode server
```

By default, the server will run on port `3001`. You should see a confirmation message in your terminal indicating that the server has started successfully.

## 2. Choosing Your API

Dexto offers two distinct APIs to suit different use cases. Understanding when to use each is key to building your application effectively.

### When to use the REST API?
Use the **REST API** for synchronous, request-response actions where you want to perform a task and get a result immediately. It's ideal for:
-   Managing resources (e.g., listing or adding MCP servers).
-   Retrieving configuration or session data.
-   Triggering a single, non-streamed agent response.

**Base URL**: `http://localhost:3001`

### When to use the WebSocket API?
Use the **WebSocket API** for building interactive, real-time applications that require a persistent connection. It's the best choice for:
-   Streaming agent responses (`chunk` events) as they are generated.
-   Receiving real-time events from the agent's core, such as `toolCall` and `toolResult`.
-   Creating chat-like user interfaces.

**Connection URL**: `ws://localhost:3001/`

## 3. What's Next?

Now that your server is running and you know which API to use, you can dive into the specifics:

-   Explore the **[REST API](./rest/conversation.md)** endpoints.
-   Learn about the **[WebSocket API](./websocket.md)** events and messages. 


================================================
FILE: docs/api/mcp-manager.md
================================================
---
sidebar_position: 2
title: "MCPManager"
---

# MCPManager

The `MCPManager` is a powerful, standalone utility for managing [Model Context Protocol (MCP)](/docs/mcp/overview) servers. It allows you to connect, manage, and interact with multiple MCP servers in your own applications without needing the full Dexto agent framework.

This class provides a unified interface for accessing tools, resources, and prompts from all connected servers, making it an essential component for building complex, multi-server workflows.

## Constructor

```typescript
constructor(confirmationProvider?: ToolConfirmationProvider)
```

Creates a new `MCPManager` instance for managing MCP server connections.

**Parameters:**
- `confirmationProvider` (optional): A custom tool confirmation provider. If not provided, a default CLI-based confirmation is used.

**Example:**
```typescript
import { MCPManager } from 'dexto';

// Basic manager
const manager = new MCPManager();

// With a custom confirmation provider
const customProvider = new CustomConfirmationProvider();
const managerWithProvider = new MCPManager(customProvider);
```

## Connection Management Methods

#### `connectServer`

Connects to a new MCP server.

```typescript
async connectServer(name: string, config: McpServerConfig): Promise<void>
```

**Parameters:**
- `name`: Unique identifier for the server connection
- `config`: Server configuration object

**Server Configuration Types:**

```typescript
// stdio server (most common)
{
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.'],
  env?: { [key: string]: string }
}

// HTTP server
{
  type: 'http',
  baseUrl: 'http://localhost:3001/mcp',
  timeout?: number
}

// SSE (Server-Sent Events) server  
{
  type: 'sse',
  url: 'http://localhost:3001/sse'
}
```

**Examples:**

```typescript
// File system server
await manager.connectServer('filesystem', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Web search server with API key
await manager.connectServer('tavily-search', {
  type: 'stdio',
  command: 'npx', 
  args: ['-y', 'tavily-mcp@0.1.2'],
  env: {
    TAVILY_API_KEY: process.env.TAVILY_API_KEY
  }
});

// HTTP MCP server
await manager.connectServer('remote-agent', {
  type: 'http',
  baseUrl: 'http://localhost:3001/mcp',
  timeout: 30000
});
```

#### `initializeFromConfig`

Initialize multiple servers from configuration.

```typescript
async initializeFromConfig(
  serverConfigs: ServerConfigs, 
  connectionMode: 'strict' | 'lenient' = 'lenient'
): Promise<void>
```

**Parameters:**
- `serverConfigs`: Object mapping server names to configurations
- `connectionMode`: 
  - `'strict'`: All servers must connect successfully
  - `'lenient'`: At least one server must connect successfully

**Example:**
```typescript
const serverConfigs = {
  filesystem: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  },
  search: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', 'tavily-mcp@0.1.2'],
    env: { TAVILY_API_KEY: process.env.TAVILY_API_KEY }
  }
};

await manager.initializeFromConfig(serverConfigs, 'lenient');
```

#### `removeClient`

Disconnects and removes a specific MCP server.

```typescript
async removeClient(name: string): Promise<void>
```

**Example:**
```typescript
await manager.removeClient('filesystem');
```

#### `disconnectAll`

Disconnect all servers and clear caches.

```typescript
async disconnectAll(): Promise<void>
```

**Example:**
```typescript
await manager.disconnectAll();
```

## Tool Management Methods

#### `getAllTools`

Gets all available tools from connected servers.

```typescript
async getAllTools(): Promise<ToolSet>
```

**Returns:** Object mapping tool names to tool definitions

**Example:**
```typescript
const tools = await manager.getAllTools();
console.log('Available tools:', Object.keys(tools));

// Inspect a specific tool
const readFileTool = tools.readFile;
console.log('Tool schema:', readFileTool.inputSchema);
```

#### `getToolClient`

Get the client that provides a specific tool.

```typescript
getToolClient(toolName: string): IMCPClient | undefined
```

#### `executeTool`

Executes a specific tool with arguments.

```typescript
async executeTool(toolName: string, args: any): Promise<any>
```

**Example:**
```typescript
// Read a file
const content = await manager.executeTool('readFile', { 
  path: './package.json' 
});

// Search the web
const searchResults = await manager.executeTool('search', {
  query: 'latest AI developments',
  max_results: 5
});

// Write a file
await manager.executeTool('writeFile', {
  path: './output.txt',
  content: 'Hello from MCP!'
});
```

## Resource Management Methods

#### `listAllResources`

Gets all available resource URIs from connected servers.

```typescript
async listAllResources(): Promise<string[]>
```

#### `getResourceClient`

Get the client that provides a specific resource.

```typescript
getResourceClient(resourceUri: string): IMCPClient | undefined
```

#### `readResource`

Reads a specific resource by URI.

```typescript
async readResource(uri: string): Promise<ReadResourceResult>
```

**Example:**
```typescript
const resource = await manager.readResource('file:///project/README.md');
console.log('Resource content:', resource.contents);
```

## Prompt Management Methods

#### `listAllPrompts`

Gets all available prompt names from connected servers.

```typescript
async listAllPrompts(): Promise<string[]>
```

#### `getPromptClient`

Get the client that provides a specific prompt.

```typescript
getPromptClient(promptName: string): IMCPClient | undefined
```

#### `getPrompt`

Gets a specific prompt by name.

```typescript
async getPrompt(name: string, args?: any): Promise<GetPromptResult>
```

**Example:**
```typescript
const prompt = await manager.getPrompt('code-review', {
  language: 'typescript',
  file: 'src/index.ts'
});
console.log('Prompt:', prompt.messages);
```

## Status and Monitoring Methods

#### `getClients`

Returns all registered MCP client instances.

```typescript
getClients(): Map<string, IMCPClient>
```

**Example:**
```typescript
const clients = manager.getClients();
console.log('Connected servers:', Array.from(clients.keys()));

for (const [name, client] of clients) {
  console.log(`Server: ${name}, Tools available: ${Object.keys(await client.getTools()).length}`);
}
```

#### `getFailedConnections`

Returns failed connection error messages.

```typescript
getFailedConnections(): Record<string, string>
```

**Example:**
```typescript
const errors = manager.getFailedConnections();
if (Object.keys(errors).length > 0) {
  console.log('Failed connections:', errors);
}
```

### Complete Example

```typescript
import { MCPManager } from 'dexto';

const manager = new MCPManager();

// Connect to servers
await manager.connectServer('filesystem', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Execute tools directly
const result = await manager.executeTool('readFile', { path: './README.md' });
console.log('Read file result:', result);

// Get all available tools
const tools = await manager.getAllTools();
console.log('Available tools:', Object.keys(tools));

// Clean up
await manager.disconnectAll();
``` 


================================================
FILE: docs/api/types.md
================================================
---
sidebar_position: 4
---

# SDK Types for TypeScript

Type definitions and interfaces for the Dexto SDK for TypeScript.

## Core Imports

```typescript
import {
  // Main classes
  DextoAgent,
  
  // Standalone utilities
  MCPManager,
  Logger,
  AgentEventBus,
  SessionEventBus,
  createStorageBackends,
  createAgentServices,
  
  // Configuration types
  AgentConfig,
  LLMConfig,
  McpServerConfig,
  StorageConfig,
  
  // Session types
  ChatSession,
  SessionMetadata,
  ConversationHistory,
  
  // Result types
  ValidatedLLMConfig,
  
  // Event types
  AgentEventMap,
  SessionEventMap,
  
  // Storage types
  StorageBackends,
  CacheBackend,
  DatabaseBackend,
  
  // Service types
  AgentServices,
} from 'dexto';
```

---

## Configuration Types

### `AgentConfig`

Main configuration object for creating Dexto agents.

```typescript
interface AgentConfig {
  llm: LLMConfig;
  mcpServers?: Record<string, McpServerConfig>;
  storage?: StorageConfig;
  sessions?: SessionConfig;
  systemPrompt?: string;
}
```

### `LLMConfig`

Configuration for Large Language Model providers.

```typescript
interface LLMConfig {
  provider: 'openai' | 'anthropic' | 'groq' | 'google' | 'cohere';
  model: string;
  apiKey?: string;
  baseURL?: string;
  router?: 'vercel' | 'in-built';
  temperature?: number;
  maxOutputTokens?: number;
  maxInputTokens?: number;
  maxIterations?: number;
  systemPrompt?: string;
}
```

### `McpServerConfig`

Configuration for Model Context Protocol servers.

```typescript
interface McpServerConfig {
  type: 'stdio' | 'sse' | 'websocket';
  command?: string;
  args?: string[];
  env?: Record<string, string>;
  url?: string;
  apiKey?: string;
}
```

### `StorageConfig`

Configuration for storage backends.

```typescript
interface StorageConfig {
  cache: CacheBackendConfig;
  database: DatabaseBackendConfig;
}

interface CacheBackendConfig {
  type: 'in-memory' | 'redis';
  url?: string;
  options?: Record<string, any>;
}

interface DatabaseBackendConfig {
  type: 'in-memory' | 'sqlite' | 'postgresql';
  url?: string;
  options?: Record<string, any>;
}
```

---

## Session Types

### `ChatSession`

Represents an individual conversation session.

```typescript
interface ChatSession {
  id: string;
  createdAt: Date;
  lastActivity: Date;
  
  // Session methods
  run(userInput: string, imageData?: ImageData): Promise<string>;
  getHistory(): Promise<ConversationHistory>;
  reset(): Promise<void>;
  getLLMService(): ILLMService;
}
```

### `SessionMetadata`

Metadata information about a session.

```typescript
interface SessionMetadata {
  id: string;
  createdAt: Date;
  lastActivity: Date;
  messageCount: number;
  tokenCount?: number;
}
```

### `ConversationHistory`

Complete conversation history for a session.

```typescript
interface ConversationHistory {
  sessionId: string;
  messages: ConversationMessage[];
  totalTokens?: number;
}

interface ConversationMessage {
  role: 'user' | 'assistant' | 'system' | 'tool';
  content: string;
  timestamp: Date;
  tokenCount?: number;
  toolCall?: ToolCall;
  toolResult?: ToolResult;
}
```

---

## Result Types

### `ValidatedLLMConfig`

Validated LLM configuration returned by `switchLLM`.

```typescript
type ValidatedLLMConfig = LLMConfig & {
  router: 'vercel' | 'in-built';
  maxInputTokens?: number;
};
```

---

## Event Types

### `AgentEventMap`

Type map for agent-level events.

```typescript
interface AgentEventMap {
  // Conversation events
  'dexto:conversationReset': {
    sessionId: string;
  };
  
  // MCP server events
  'dexto:mcpServerConnected': {
    name: string;
    success: boolean;
    error?: string;
  };
  
  'dexto:mcpServerAdded': {
    serverName: string;
    config: McpServerConfig;
  };
  
  'dexto:mcpServerRemoved': {
    serverName: string;
  };
  
  'dexto:mcpServerUpdated': {
    serverName: string;
    config: McpServerConfig;
  };
  
  'dexto:availableToolsUpdated': {
    tools: string[];
    source: 'mcp' | 'builtin';
  };
  
  // Configuration events
  'dexto:llmSwitched': {
    newConfig: ValidatedLLMConfig;
    router?: 'vercel' | 'in-built';
    historyRetained?: boolean;
    sessionIds: string[];
  };
  
  'dexto:stateChanged': {
    field: string;
    oldValue: any;
    newValue: any;
    sessionId?: string;
  };
  
  'dexto:stateExported': {
    config: AgentConfig;
  };
  
  'dexto:stateReset': {
    toConfig: AgentConfig;
  };
  
  // Session override events
  'dexto:sessionOverrideSet': {
    sessionId: string;
    override: SessionOverride;
  };
  
  'dexto:sessionOverrideCleared': {
    sessionId: string;
  };
  
  // Tool confirmation events
  'dexto:toolConfirmationRequest': {
    toolName: string;
    args: Record<string, any>;
    description?: string;
    executionId: string;
    timestamp: string; // ISO 8601 timestamp
    sessionId?: string;
  };
  
  'dexto:toolConfirmationResponse': {
    executionId: string;
    approved: boolean;
    rememberChoice?: boolean;
    sessionId?: string;
  };
  
  // LLM service events (forwarded from sessions)
  'llmservice:thinking': {
    sessionId: string;
  };
  
  'llmservice:response': {
    content: string;
    tokenCount?: number;
    model?: string;
    sessionId: string;
  };
  
  'llmservice:chunk': {
    content: string;
    isComplete?: boolean;
    sessionId: string;
  };
  
  'llmservice:toolCall': {
    toolName: string;
    args: Record<string, any>;
    callId?: string;
    sessionId: string;
  };
  
  'llmservice:toolResult': {
    toolName: string;
    result: any;
    callId?: string;
    success: boolean;
    sessionId: string;
  };
  
  'llmservice:error': {
    error: Error;
    context?: string;
    recoverable?: boolean;
    sessionId: string;
  };
  
  'llmservice:switched': {
    newConfig: ValidatedLLMConfig;
    router?: 'vercel' | 'in-built';
    historyRetained?: boolean;
    sessionId: string;
  };
}
```

### `SessionEventMap`

Type map for session-level events.

```typescript
interface SessionEventMap {
  'llmservice:thinking': void;
  
  'llmservice:response': {
    content: string;
    tokenCount?: number;
    model?: string;
  };
  
  'llmservice:chunk': {
    content: string;
    isComplete?: boolean;
  };
  
  'llmservice:toolCall': {
    toolName: string;
    args: Record<string, any>;
    callId?: string;
  };
  
  'llmservice:toolResult': {
    toolName: string;
    result: any;
    callId?: string;
    success: boolean;
  };
  
  'llmservice:error': {
    error: Error;
    context?: string;
    recoverable?: boolean;
  };
  
  'llmservice:switched': {
    newConfig: ValidatedLLMConfig;
    router?: 'vercel' | 'in-built';
    historyRetained?: boolean;
  };
}
```

---

## Storage Types

### `StorageBackends`

Container for storage backend instances.

```typescript
interface StorageBackends {
  cache: CacheBackend;
  database: DatabaseBackend;
}
```

### `CacheBackend`

Interface for cache storage operations.

```typescript
interface CacheBackend {
  get(key: string): Promise<any>;
  set(key: string, value: any, ttl?: number): Promise<void>;
  delete(key: string): Promise<void>;
  clear(): Promise<void>;
  disconnect?(): Promise<void>;
}
```

### `DatabaseBackend`

Interface for database storage operations.

```typescript
interface DatabaseBackend {
  get(key: string): Promise<any>;
  set(key: string, value: any): Promise<void>;
  delete(key: string): Promise<void>;
  append(key: string, value: any): Promise<void>;
  getRange(key: string, start: number, end: number): Promise<any[]>;
  disconnect?(): Promise<void>;
}
```

---

## Service Types

### `AgentServices`

Container for all agent service instances.

```typescript
interface AgentServices {
  mcpManager: MCPManager;
  promptManager: PromptManager;
  agentEventBus: AgentEventBus;
  stateManager: AgentStateManager;
  sessionManager: SessionManager;
  storage: StorageBackends;
}
```

---

## Tool Types

### `ToolSet`

Map of tool names to tool definitions.

```typescript
type ToolSet = Record<string, ToolDefinition>;

interface ToolDefinition {
  name: string;
  description: string;
  inputSchema: {
    type: 'object';
    properties: Record<string, any>;
    required?: string[];
  };
}
```

### `ToolCall`

Represents a tool execution request.

```typescript
interface ToolCall {
  id: string;
  name: string;
  arguments: Record<string, any>;
}
```

### `ToolResult`

Represents a tool execution result.

```typescript
interface ToolResult {
  callId: string;
  toolName: string;
  result: any;
  success: boolean;
  error?: string;
}
```

---

## Utility Types

### `ImageData`

Type for image data in conversations.

```typescript
interface ImageData {
  base64: string; // Base64 encoded image
  mimeType: string; // e.g., 'image/jpeg', 'image/png'
}
```

### `FileData`

Type for file data in conversations.

```typescript
interface FileData {
  base64: string; // Base64 encoded file data
  mimeType: string; // e.g., 'application/pdf', 'audio/wav'
  filename?: string; // Optional filename
}
```

**Supported File Types:**
- **PDF files** (`application/pdf`) - Most widely supported
- **Audio files** (`audio/mp3`, `audio/wav`) - With OpenAI `gpt-4o-audio-preview` and Google Gemini models

**Unsupported File Types:**
- Text files (`.txt`, `.md`)
- CSV files (`.csv`)
- Word documents (`.doc`, `.docx`)
- Excel files (`.xls`, `.xlsx`)
- PowerPoint files (`.ppt`, `.pptx`)
- JSON files (`.json`)
- XML files (`.xml`)
- HTML files (`.html`)

For unsupported file types, consider:
1. Converting to text and sending as regular messages
2. Using specialized MCP servers for file processing
3. Using dedicated file processing tools

### `LoggerOptions`

Configuration options for the Logger class.

```typescript
interface LoggerOptions {
  level?: 'error' | 'warn' | 'info' | 'http' | 'verbose' | 'debug' | 'silly';
  silent?: boolean;
}
```

### `ChalkColor`

Available colors for logger output.

```typescript
type ChalkColor = 
  | 'black' | 'red' | 'green' | 'yellow' | 'blue' | 'magenta' | 'cyan' | 'white'
  | 'gray' | 'grey' | 'blackBright' | 'redBright' | 'greenBright' | 'yellowBright'
  | 'blueBright' | 'magentaBright' | 'cyanBright' | 'whiteBright';
```

---

## Generic Types

### `EventListener`

Generic event listener function type.

```typescript
type EventListener<T> = (data: T) => void;
```

### `EventEmitterOptions`

Options for event emitter methods.

```typescript
interface EventEmitterOptions {
  signal?: AbortSignal;
} 


================================================
FILE: docs/api/websocket.md
================================================
---
sidebar_position: 2
---

# WebSocket API

The WebSocket API offers real-time, bidirectional communication with Dexto. Use this for building highly interactive applications.

### Connection URL
<p class="api-endpoint-header"><code>ws://localhost:3000/</code></p>
<small>_The port may vary based on your server configuration._</small>

---

## Client â†’ Server Messages
Send these messages to the server as JSON-formatted strings to control the agent.

### `message`
Instructs the agent to process a user prompt.
```json
{
  "type": "message",
  "content": "Your prompt here",
  "sessionId": "optional-session-id",
  "stream": true,
  "imageData": { "base64": "...", "mimeType": "image/jpeg" },
  "fileData": { "base64": "...", "mimeType": "application/pdf", "filename": "doc.pdf" }
}
```

### `reset`
Resets the conversation history for a given session.
```json
{
  "type": "reset",
  "sessionId": "optional-session-id"
}
```

---

## Server â†’ Client Events
Listen for these events from the server. All events follow the `{ "event": "EVENT_NAME", "data": { ... } }` structure.

| Event | Data Payload | Description |
| :--- | :--- | :--- |
| `thinking` | `{ sessionId }` | The agent has received the prompt and started processing. |
| `chunk` | `{ text, isComplete?, sessionId }` | A part of the agent's response when `stream` is `true`. |
| `response` | `{ text, tokenCount?, model?, sessionId }` | The final, complete response from the agent. |
| `toolCall` | `{ toolName, args, callId?, sessionId }` | Informs that the agent is about to execute a tool. |
| `toolResult` | `{ toolName, result, callId?, success, sessionId }` | Provides the result from a tool's execution. |
| `conversationReset` | `{ sessionId }` | Conversation history cleared for session. |
| `mcpServerConnected` | `{ name, success, error? }` | MCP server connection result. |
| `availableToolsUpdated` | `{ tools, source }` | Available tools changed. |
| `toolConfirmationRequest` | `{ ... }` | Request to confirm a tool execution. |
| `error` | `{ message, context?, recoverable?, sessionId }` | An error occurred during message processing. |


================================================
FILE: docs/api/rest/conversation.md
================================================
---
sidebar_position: 1
---

# Conversation

### Send Message (sync)
Sends a message and waits for the full response.

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/message-sync</code></p>

#### Request Body
- `message` (string, required): The user's message.
- `sessionId` (string, optional): The session to use for this message.
- `imageData` (object, optional):
    - `base64` (string): Base64-encoded image.
    - `mimeType` (string): The MIME type of the image (e.g., `image/png`).
- `fileData` (object, optional):
    - `base64` (string): Base64-encoded file data.
    - `mimeType` (string): The MIME type of the file (e.g., `application/pdf`).
    - `filename` (string, optional): The filename.

#### Responses

**Accepted (202)**
```json
{
  "status": "processing",
  "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
}
```

**Error (400)**
```json
{
  "error": "Missing message content"
}
```

### Send Message (async)
Sends a message and returns immediately. The full response will be sent over WebSocket.

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/message</code></p>

#### Request Body
- `message` (string, required): The user's message.
- `sessionId` (string, optional): The session to use for this message.
- `imageData` (object, optional):
    - `base64` (string): Base64-encoded image.
    - `mimeType` (string): The MIME type of the image (e.g., `image/png`).
- `fileData` (object, optional):
    - `base64` (string): Base64-encoded file data.
    - `mimeType` (string): The MIME type of the file (e.g., `application/pdf`).
    - `filename` (string, optional): The filename.
- `stream` (boolean, optional): Set to `true` to receive streaming chunks over WebSocket.

#### Responses

**Accepted (202)**
```json
{
  "status": "processing",
  "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
}
```

### Reset Conversation
*Resets the conversation history for a given session.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/reset</code></p>

#### Request Body
- `sessionId` (string, optional): The ID of the session to reset.

#### Responses

**Success (200)**
```json
{
  "status": "reset initiated",
  "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
}
```

## Supported File Types

File parts currently support:
- **PDF files** (`application/pdf`)
- **Audio files** (`audio/mp3`, `audio/wav`) - with OpenAI `gpt-4o-audio-preview` and Google Gemini models



================================================
FILE: docs/api/rest/llm.md
================================================
---
sidebar_position: 4
---

# LLM Configuration

### Get Current LLM Config
*Retrieves the current LLM configuration.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/llm/current</code></p>

#### Responses
**Success (200)**
```json
{
  "config": {
    "provider": "openai",
    "model": "gpt-4o",
    "displayName": "GPT-4o"
  }
}
```

### LLM Catalog
*Providers, models, capabilities, and API key status.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/llm/catalog</code></p>

#### Query Parameters
- `provider`: comma-separated providers (e.g., `openai,anthropic`).
- `hasKey`: filter by key presence (`true` | `false`).
- `router`: `vercel` | `in-built`.
- `fileType`: `audio` | `pdf`.
- `defaultOnly`: include only default models (`true` | `false`).
- `mode`: `grouped` (default) or `flat`.

#### Responses
**Success (200)**
```json
{
  "providers": {
    "openai": {
      "name": "Openai",
      "hasApiKey": false,
      "primaryEnvVar": "OPENAI_API_KEY",
      "supportedRouters": ["in-built", "vercel"],
      "supportsBaseURL": false,
      "models": [
        {"name":"gpt-4o","displayName":"GPT-4o","default":false,"maxInputTokens":128000,"supportedFileTypes":["pdf"]}
      ]
    }
  }
}
```

When `mode=flat`, response is:
```json
{
  "models": [
    {
      "provider": "openai",
      "name": "gpt-4o",
      "displayName": "GPT-4o",
      "default": false,
      "maxInputTokens": 128000,
      "supportedFileTypes": ["pdf"],
      "supportedRouters": ["vercel", "in-built"]
    }
  ]
}
```

### Save Provider API Key
*Stores an API key for a provider in .env and makes it available immediately.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/llm/key</code></p>

#### Request Body
```json
{"provider":"openai","apiKey":"sk-..."}
```

#### Responses
**Success (200)**
```json
{"ok":true,"provider":"openai","envVar":"OPENAI_API_KEY"}
```

Note: request body size is limited (4KB).

### Switch LLM
*Switches the LLM configuration.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/llm/switch</code></p>

#### Request Body
- `provider` (string, optional)
- `model` (string, optional)
- `router` ("vercel" | "in-built", optional)
- `apiKey` (string, optional)
- `baseURL` (string, optional)
- `maxInputTokens` (number, optional)
- `sessionId` (string, optional)

#### Responses

**Success (200)**
```json
{
  "ok": true,
  "data": {
    "provider": "openai",
    "model": "gpt-4o",
    "router": "vercel"
  },
  "issues": []
}
```

**Error (400)**
```json
{
  "ok": false,
  "issues": [
    {
      "code": "schema_validation",
      "message": "...",
      "path": ["provider"],
      "severity": "error",
      "context": {"field": "provider"}
    }
  ]
}
```



================================================
FILE: docs/api/rest/mcp.md
================================================
---
sidebar_position: 3
---

# MCP Management

### List MCP Servers
*Gets a list of all connected and failed MCP servers.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/mcp/servers</code></p>

#### Responses

**Success (200)**
```json
{
  "servers": [
    { "id": "filesystem", "name": "filesystem", "status": "connected" },
    { "id": "database", "name": "database", "status": "error" }
  ]
}
```

### Add MCP Server
*Connects a new MCP server dynamically.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/mcp/servers</code></p>

#### Request Body
- `name` (string, required): A unique name for the server.
- `config` (object, required): The server's configuration object, including optional `connectionMode`.

**Example Request Body:**
```json
{
  "name": "filesystem",
  "config": {
    "type": "stdio",
    "command": "npx",
    "args": ["-y", "@modelcontextprotocol/server-filesystem", "."],
    "timeout": 30000,
    "connectionMode": "strict"
  }
}
```

#### Responses
**Success (201)**
```json
{
  "status": "connected",
  "name": "new-server"
}
```

### List Server Tools
*Retrieves the list of tools available on a specific MCP server.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/mcp/servers/:serverId/tools</code></p>

#### Responses
**Success (200)**
```json
{
  "tools": [
    {
      "id": "readFile",
      "name": "readFile",
      "description": "Read the contents of a file",
      "inputSchema": {
          "type": "object",
          "properties": { "path": { "type": "string" } }
      }
    }
  ]
}
```

### Execute MCP Tool
*Executes a tool on an MCP server directly.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/mcp/servers/:serverId/tools/:toolName/execute</code></p>

#### Request Body
- An object containing the arguments required by the tool.

#### Responses

**Success (200)**
```json
{
  "success": true,
  "data": {
    "fileContent": "..."
  }
}
```

**Error (500)**
```json
{
  "success": false,
  "error": "Tool execution failed: ..."
}
```

### Remove MCP Server
*Disconnects and removes an MCP server.*

<p class="api-endpoint-header"><span class="api-method delete">DELETE</span><code>/api/mcp/servers/:serverId</code></p>

#### Responses
**Success (200)**
```json
{
  "status": "disconnected",
  "id": "server-to-remove"
}
```



================================================
FILE: docs/api/rest/search.md
================================================
---
sidebar_position: 6
---

# Search API

### Search Messages
*Searches for messages across all sessions or within a specific session.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/search/messages</code></p>

#### Query Parameters
- `q` (string, required): Search query string
- `sessionId` (string, optional): Limit search to a specific session
- `role` (string, optional): Filter by message role (`user`, `assistant`, `system`, `tool`)
- `limit` (number, optional): Maximum number of results to return (default: 20)
- `offset` (number, optional): Number of results to skip for pagination (default: 0)

#### Responses

**Success (200)**
```json
{
  "results": [
    {
      "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
      "message": {
        "role": "user",
        "content": "Hello, how are you?"
      },
      "matchedText": "Hello",
      "context": "Hello, how are you?",
      "messageIndex": 0
    }
  ],
  "total": 1,
  "hasMore": false,
  "query": "Hello",
  "options": {
    "limit": 20,
    "offset": 0
  }
}
```

**Error (400)**
```json
{
  "error": "Search query is required"
}
```

### Search Sessions
*Searches for sessions that contain the specified query.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/search/sessions</code></p>

#### Query Parameters
- `q` (string, required): Search query string

#### Responses

**Success (200)**
```json
{
  "results": [
    {
      "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
      "matchCount": 3,
      "firstMatch": {
        "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
        "message": {
          "role": "user",
          "content": "Hello, how are you?"
        },
        "matchedText": "Hello",
        "context": "Hello, how are you?",
        "messageIndex": 0
      },
      "metadata": {
        "createdAt": 1698408000000,
        "lastActivity": 1698408300000,
        "messageCount": 4
      }
    }
  ],
  "total": 1,
  "hasMore": false,
  "query": "Hello"
}
```

**Error (400)**
```json
{
  "error": "Search query is required"
}
```

## Example Usage

### Basic Message Search
```bash
curl "http://localhost:3001/api/search/messages?q=hello"
```

### Search with Filters
```bash
curl "http://localhost:3001/api/search/messages?q=error&role=assistant&limit=10"
```

### Search within Specific Session
```bash
curl "http://localhost:3001/api/search/messages?q=deploy&sessionId=b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
```

### Search Sessions
```bash
curl "http://localhost:3001/api/search/sessions?q=project"
```


================================================
FILE: docs/api/rest/sessions.md
================================================
---
sidebar_position: 2
---

# Session Management

### List Sessions
*Retrieves a list of all active sessions.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/sessions</code></p>

#### Responses

**Success (200)**
```json
{
  "sessions": [
    {
      "id": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
      "createdAt": "2023-10-27T10:00:00.000Z",
      "lastActivity": "2023-10-27T10:05:00.000Z",
      "messageCount": 4
    }
  ]
}
```

### Create Session
*Creates a new session.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/sessions</code></p>

#### Request Body
- `sessionId` (string, optional): A custom ID for the new session.

#### Responses

**Success (201)**
```json
{
  "session": {
    "id": "c5b3b4f9-83c2-5e11-b6d4-2b3d4e5f6a7b",
    "createdAt": "2023-10-27T11:00:00.000Z",
    "lastActivity": "2023-10-27T11:00:00.000Z",
    "messageCount": 0
  }
}
```

### Get Session Details
*Fetches details for a specific session.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/sessions/:sessionId</code></p>

#### Responses

**Success (200)**
```json
{
  "session": {
    "id": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
    "createdAt": "2023-10-27T10:00:00.000Z",
    "lastActivity": "2023-10-27T10:05:00.000Z",
    "messageCount": 4,
    "history": 8
  }
}
```

**Error (404)**
```json
{
  "error": "Session not found"
}
```

### Get Session History
*Retrieves the conversation history for a session.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/sessions/:sessionId/history</code></p>

#### Responses

**Success (200)**
```json
{
    "history": [
        { "role": "user", "content": "Hello" },
        { "role": "assistant", "content": "Hi! How can I help?" }
    ]
}
```

### Delete Session
*Permanently deletes a session and all its conversation history. This action cannot be undone.*

<p class="api-endpoint-header"><span class="api-method delete">DELETE</span><code>/api/sessions/:sessionId</code></p>

#### Responses

**Success (200)**
```json
{
  "status": "deleted",
  "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
}
```

### Load Session
*Sets a session as the current "active" session.*

<p class="api-endpoint-header"><span class="api-method post">POST</span><code>/api/sessions/:sessionId/load</code></p>

#### Responses

**Success (200)**
```json
{
    "status": "loaded",
    "sessionId": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a",
    "currentSession": "b4a2a3e8-72b1-4d00-a5c3-1a2c3d4e5f6a"
}
```



================================================
FILE: docs/api/rest/system.md
================================================
---
sidebar_position: 5
---

# System

### Health Check
*A simple endpoint to check if the server is running. Returns `OK` with status 200.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/health</code></p>

### Export Configuration
*Exports the agent's current configuration as a YAML file.*

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/api/config.yaml</code></p>

### Agent Card (A2A)
Provides the Agent Card for Agent-to-Agent discovery.

<p class="api-endpoint-header"><span class="api-method get">GET</span><code>/.well-known/agent.json</code></p>



================================================
FILE: docs/blog/2025-06-16-ai-agents-vs-llm-workflows/index.md
================================================
---
slug: ai-agents-vs-llm-workflows
title: AI Agents vs LLM Workflows â€“ Why Autonomy Matters
description: Learn what AI agents are, how they differ from traditional LLM workflows, and when to use each approach.
authors: rahul
tags: [ai-agents, llm-workflows, autonomous-ai, dexto]
keywords:
  - ai agents
  - llm workflows
  - autonomous ai
  - code review automation
  - dexto open-source runtime
---

If you have been remotely exposed to AI, you've probably heard the term AI agent. But what really is an AI agent?

`AI agent` has become a blanket term that is used in the industry for any automation or software that uses an LLM.

In this post, weâ€™ll break down what an **AI agent** is from first principles, then compare **AI agents vs LLM workflows**â€”when to use each and why autonomy matters.

<!--truncate-->

Let's first start with Large Language Models (LLMs), the backbone of AI agents.

## What Are LLMs?

LLMs are deep learning models, pre-trained on vast amounts of data, often more than what's available on the entire internet!

At their core, LLMs take in input and predict the most likely output.  
Here the input could be a chat message, an image, a voice message or even video.

LLMs predict the output token-by-token, which means that at each step of giving you a response, the LLM is predicting what the next token should be. More on this [here](https://x.com/cwolferesearch/status/1879995082285171081).

So when you ask an LLM something like `what is 5+10`, or [`how many r's are there in strawberry?`](https://techcrunch.com/2024/08/27/why-ai-cant-spell-strawberry/), the LLM tries to *guess* what the actual answer should be based on its training data.

LLMs have reached a point where their grammar and sentence structure are much better than a typical human, and also have knowledge of an extremely broad variety of topics.

ChatGPT is the most popular example of an LLM based application, which you've probably used, unless you're living under a rock.

Under the hood, ChatGPT uses LLMs built by OpenAI, like `gpt-4o` or `gpt-4.5` to answer your questions about almost anything.

This is why if you ask LLMs questions like `how many r's are there in the word strawberry`, you might see completely incorrect results - [the guessing doesn't always work well](https://www.reddit.com/r/singularity/comments/1enqk04/how_many_rs_in_strawberry_why_is_this_a_very/). This is called [*hallucination*](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)).

## System Prompts

Well we know that LLMs have an incredibly large knowledge base, but what if we wanted the LLM to specifically just do one thing - like give me food recipes.
LLMs allow you to customize their base instructions (aka system prompts).

This enables you to give the LLM custom roles/instructions based on your use-case

Here's what the recipe analogy might look like as a system prompt
```
You are an expert chef.
Your job is to suggest tasty recipes to me.
I don't eat beef, so keep that in mind
Only answer food related questions.
```


```
systemPrompt: |
    You are an expert chef.
    Your job is to suggest tasty recipes to me.
    I don't eat beef, so keep that in mind.
    Only answer food related questions.
```

Now when I chat with the LLM, it will talk to me only like a chef!


![Conversation 1](./sysprompt_1.webp)
![Conversation 2](./sysprompt_2.webp)



## Function Calling in LLMs
Now, we've already established that LLMs can accept input and give back output. But LLMs can do more than that - they can also **take actions**

This is done by giving the LLM access to `functions`, or `tools`.
These are defined methods with specific capabilities, implemented by developers.

This process of giving the LLM access to `functions` is called [function_calling](https://platform.openai.com/docs/guides/function-calling)

Let's revisit the previous case where we asked the LLM to add 2 numbers, this time with function calling.

Suppose you gave `gpt-4o` a function to add 2 numbers. 

The next time you ask it `What is 5+10` - instead of trying to guess what the answer is, it would use the function to generate a more reliable response.

This is an extremely basic example, but the key takeaway here is that by giving the LLM tools - **LLMs can now take actions on your behalf.**

This is where things get interesting - what if the LLM had a function to book a reservation for you at a restaurant? Or if the LLM had a function to make a payment for you? 

All the LLM would need to do in this case is use the right function based on the request, and you now have AI-powered bookings and payments. 
There are other complexities like ensuring the LLM uses the corerect function more accurately enough, and adding the appropriate guardrails and authentication, but we won't get into that for now.


## LLM Workflows and AI Agents

Now that we've explained how tools and system prompts work, let's dive into how LLMs can be used to automate tasks.

Let's look at one specific problem - automating code reviews, and 2 different approaches for how we can solve this problem using LLMs.

I've intentionally left out most of the complexity of actually building this system to primarily show 2 ways we can think about this problem.

### Approach 1

Ok I'm a software developer, so I have a pretty good idea of how code reviews work.

Here are 4 important things, among others that I look at when I review code:
1. **Functionality** - is the code functionally correct?
2. **Architecture** - does the code fit the codebase well and will it adapt well to changes we make in the future?
3. **Testing** - has the code been sufficiently tested? are there more test cases we can come up with?
4. **Documentation** - has the documentation been updated to account for the code changes?

If I wanted to use LLMs to automate this, I could maybe use 1 LLM for each of these sub-tasks? What if I had 4 LLMs - one for each problem? Then the flow could look something like this:

LLM-1 - instructed to ensure the code is functional for the problem.
LLM-2 - instructed to ensure the code fits the architecture and requirements
LLM-3 - ensures test coverage is sufficient and tries to come up with more edge-cases
LLM-4 - ensures documentation is up to date.

1. User submits pull request which triggers CI workflow
2. LLM-1 reads the code and examines it. If code is functional, move to next step.
3. LLM-2 reads the code and style guidelines and checks if it's good. Adds comments on the PR based on its analysis.
4. LLM-3 reads the code and tests and adds comments related to test cases
5. LLM-4 reads the code and documentation and adds comments

<!-- ![Code Review Workflow](./cr_workflow.png) -->

```mermaid
flowchart TD
    A[User submits pull request] --> B[CI workflow triggers LLM review]
    
    B --> LLM1[LLM-1: Check functionality]
    LLM1 -->|Functional| LLM2[LLM-2: Review architecture & style]
    LLM2 --> LLM3[LLM-3: Evaluate tests & suggest edge cases]
    LLM3 --> LLM4[LLM-4: Review documentation]

    LLM1 -->|Not functional| Stop1[âŒ Add comments & halt review]
    LLM2 -->|Issues found| Comment2[ğŸ“ Add architecture/style comments]
    LLM3 -->|Insufficient tests| Comment3[ğŸ“ Add test coverage comments]
    LLM4 -->|Missing/Outdated docs| Comment4[ğŸ“ Add documentation comments]
```

With this workflow mapped out, I just need to implement code that follows this logic tree.

### Approach 2

If I had a developer working for me, I'd just ask them to review the code right? What if I could leverage LLMs in a similar manner?

Let's give an LLM very detailed instructions, and all the tools necessary to complete this review, just like I would for a human. Let's also give it a way to reach back out to me if it needs any clarifying information.

LLM-1 - instructed to review the code and given all the necessary tools to do the task.

In this approach, LLM-1 is not just doing the steps, but it is also *figuring out* what steps to review the PR based on high level instructions.

<!-- ![Code Review Agent](./cr_workflow_2.png) -->

```mermaid
flowchart TD
    A[User submits pull request] --> B[CI workflow triggers LLM-1 review]
    B --> C[LLM-1: Reviews PR]
```


### So what's the difference between approach 1 and approach 2?

In Approach 1 - we broke down the high level task ourselves, decided exactly what steps were going to happen, and in what order, and then programmed that.

In Approach 2 - we gave the LLM some instructions and tools, and passed on the high level task to let the LLM do much more of the heavy-lifting to figure out how to do the task.

Let's look at the key differences in the approaches:

| Feature               | Approach 1 (LLM Workflow)      | Approach 2 (AI Agent)          |
| --------------------- | ------------------------------ | -------------------------------- |
| Autonomy              | Low â€“ follows set steps        | High â€“ makes decisions           |
| Adaptability          | Rigid, limited to defined flow | Handles unexpected situations    |
| Tool / Service usage  | Fixed call order               | Orchestrates multiple services   |
| User interaction      | None / minimal                 | Can ask clarifying questions     |


Now, we can replace `Approach 1` with the term `LLM Workflow`, and `Approach 2` with the term `AI Agent`

The key takeaway here is that workflows execute steps *we define*, while AI agents *figure out how to accomplish the goal* and can make decisions dynamically.

## Which Approach Is Better? {#which-approach-is-better}

Use an LLM Workflow when:

 - The problem is small, and requires a repeatable, well-defined sequence.
 - You want predictable, consistent output.
 - The process does not require dynamic decision-making.
 - Examples: AI recipe provider, AI task tracker

Use an AI Agent when:

 - The problem is vague and complex - requires decision-making, adaptation, or chaining multiple services.
 - The process may change based on context, user input, or something else.
 - Examples: Coding assistant, customer support assistant.

## Closing Thoughts

In the past few years, we have seen AI products emerge that have primarily been LLM workflows or lightweight wrappers around LLM APIs. The general trend is that these companies do well for a short while until the models natively get better, then the products fade away. 

My theory is that as AI models get natively better, there will be less need for these workflow driven paradigms for specific problems, and LLMs will be able to do more of the heavy lifting.

AI models will be able to handle more tools and more complex instructions - and more use-cases will shift towards using autonomous agents. We have already seen reinforcement learning cases where the AI is just given a high level goal, and is able to figure out unique ways of accomplishing the task that humans wouldn't have tried.

Google DeepMind recently launched [AlphaEvolve](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/), a coding agent designed to create new algorithms. AlphaEvolve has already discovered multiple new algorithms for matrix multiplication, a fundamental problem in computer science.

We're also seeing new AI agent products - IDEs like [Cursor](https://www.cursor.com/) and [Windsurf](https://windsurf.com/) allow users to build software applications by talking to an AI agent.

In a later blog post, we'll walk through how to use [Dexto, our open-source AI agent runtime](/docs/getting-started/intro) to build a real AI agent.



================================================
FILE: docs/docs/architecture/overview.md
================================================
# Overview

Dexto was built by the Truffle AI team.

We were trying to build useful AI agents in different domains, but we realized that we were re-building a lot of the same plumbing work each time. So we tried to use some existing AI agent frameworks.

Then we felt that we were getting stuck learning frameworks - each framework had different abstractions and levels of control, and we felt there had to be a simpler way to build AI agents.

So we built Dexto with the following tenets:
1. <ins>**Complete configurability**</ins>: We want users to be able to configure every part of Dexto with just a config file.
2. <ins>**MCP first**</ins>: Adopting MCP enables Dexto to interact with tooling in a standardized manner
3. <ins>**Powerful CLI**</ins>: We wanted a powerful CLI we could use for anything AI - just talking to LLMs, creating AI agents, deploying agents, testing out models/prompts/tools
4. <ins>**Re-usable Core primitives**</ins>: We want developers to be able to build all kinds of AI powered interfaces and applications using Dexto, without having to dive-deep into the code, but always having the option to. This allows us to re-use the same core layer to expose AI agents on telegram, discord, slack, etc.
5. <ins>**Simple deployments**</ins>: We want users to be able to play around with different config files of Dexto and simply save the configuration they liked to be able to re-use it anywhere. Docker helps make this happen.


Check out our generated deepwiki [here](https://deepwiki.truffle.ai/dexto) for more details.


================================================
FILE: docs/docs/concepts/agents-vs-workflows.md
================================================
---
sidebar_position: 2
---

# AI Agents vs. LLM Workflows

People often get confused between AI Agents and LLM workflows.

Understanding the distinction between **AI agents** and **LLM (Large Language Model) workflows** is key to choosing the right automation approach for your use-case.

## What is an AI Agent?

- An autonomous software entity that can perceive, reason, and act to achieve goals.
- Handles complex, multi-step tasks by making decisions and orchestrating tools/services.
- Can adapt to changing environments and user requests.

## What is an LLM Workflow?

- A predefined sequence of steps or prompts executed by a large language model (like GPT-4 or Claude).
- Typically linear and deterministic: each step follows the previous one.
- Great for repeatable, well-defined processes (e.g., data extraction, summarization, formatting).

## Key Differences

| Feature                | AI Agent                                 | LLM Workflow                         |
|------------------------|------------------------------------------|--------------------------------------|
| Autonomy               | High (makes decisions)                   | Low (follows set steps)              |
| Adaptability           | Can handle unexpected situations         | Rigid, limited to defined flow       |
| Use of Tools/Services  | Orchestrates multiple tools/services     | May call tools, but generally in fixed order   |
| User Interaction       | Can ask clarifying questions, replan     | Usually no dynamic interaction       |
| Example Use Case       | "Book a flight and notify me on Slack"  | "A button on a web page to summarize a document"           |

## When to Use Each

- **Use an AI Agent when:**
  - The problem is vague and complex - requires decision-making, adaptation, or chaining multiple services.
  - The process may change based on context, user input or something else.

- **Use an LLM Workflow when:**
  - The problem is small, and requires a repeatable, well-defined sequence.
  - You want predictable, consistent output.
  - The process does not require dynamic decision-making.


## In Dexto

Dexto CLI spins up a powerful AI Agent you can use for solving complex problems

Choosing the right tools for the job helps you get the most out of Dexto's automation capabilities. 


================================================
FILE: docs/docs/concepts/how-do-ai-agents-work.md
================================================
---
sidebar_position: 3
---

# How do AI Agents work?

AI agents operate by understanding your natural language instructions, reasoning about what needs to be done, and then taking actions to accomplish your goals. This process involves several key steps:

1. **Understanding:** The agent interprets your request using natural language processing.
2. **Planning:** It determines what actions or steps are needed to fulfill your request.
3. **Tool Selection:** The agent decides which tools or services are required to perform each step.
4. **Execution:** It invokes the selected tools, orchestrating them as needed to complete the task.

A key part of this process is the use of **tools** â€” external services, APIs, or modules that enable the agent to take real actions in the world. Tools are the bridge between the agent's reasoning and real-world effects.

Dexto CLI is an AI Agent that does all this for you - you just setup Dexto CLI the way you want to, and tell it what to do - Dexto CLI does the rest!

To learn more about tools and their role in Dexto, continue to the next section: [Tools](./tools.md). 


================================================
FILE: docs/docs/concepts/mcp.md
================================================
---
sidebar_position: 5
---

# What is MCP (Model Context Protocol)?

The **Model Context Protocol (MCP)** is an open protocol created and maintained by Anthropic - [MCP github organization](https://github.com/modelcontextprotocol)

MCP defines how AI agents (like Dexto agents) can discover, connect to, and interact with external tools, services, and APIs in a standardized way.

## Why MCP Matters

- **Interoperability:** MCP provides a common language for agents and tools, making it easy to connect new services without custom integration code for each one.
- **Extensibility:** Anyone can build and share MCP-compatible tools, expanding what agents can do.
- **Modularity:** Tools are decoupled from the agent's core logic, so you can add, remove, or swap tools as needed.

## How Dexto Agents Use MCP

Dexto agents use MCP to:
- **Discover available tools:** MCP servers advertise what actions they support (e.g., read a file, send an email, browse the web).
- **Connect to tools:** Dexto agents communicate with MCP servers using a standard protocol (often over stdio, HTTP, or sockets).
- **Invoke tool actions:** When you give a command, Dexto selects the right tool(s) via MCP and orchestrates their use to fulfill your request.
- **Read server resources:** Dexto agents can read resources from the server, like files, databases, etc., and use that to reason about what to do next.

## Example: Registering a Tool via MCP

Suppose you want to add a filesystem tool. In your Dexto agent configuration file, you might specify:

```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
    connectionMode: strict  # Ensure this tool is always available
```

This tells your Dexto agent to connect to the filesystem MCP server, which then advertises its capabilities to the agent.

## Learn More

- [Model Context Protocol documentation](https://modelcontextprotocol.io/introduction)
- [MCP reference servers on GitHub](https://github.com/modelcontextprotocol/reference-servers)

MCP is a key part of what makes Dexto flexible, extensible, and able to automate across a wide range of tools and services. 


================================================
FILE: docs/docs/concepts/tools.md
================================================
---
sidebar_position: 4
sidebar_label: "What are Tools?"
---

# Tools

## The Role of Tools

 **Tools** are external services, APIs, or modules that an AI agent can use to perform actions, retrieve information, or manipulate data.

### Why Tools Matter

AI agents are powerful because they can go beyond language understandingâ€”they can take real actions in the world. Tools are the bridge between the agent's reasoning and real-world effects.

### How do Dexto Agents use Tools?
Dexto agents use tools from MCP servers - MCP servers define the tools, dexto uses them.

### Examples of Tools in Dexto

- **Filesystem Tool:** Read, write, or search files on your computer.
- **Web Browser Tool:** Automate web browsing, scraping, or form submissions.
- **Email Tool:** Read, summarize, or send emails.
- **Slack Tool:** Post messages, retrieve channels, or automate notifications.
- **Custom Tools:** Any API or service you connect via the Model Context Protocol (MCP).

### How Tools Work

- Tools are registered with Dexto agents via MCP configuration (see the Configuration docs).
- When you give a natural language command, the agent decides which tools to use and in what order.
- The agent can chain multiple tools together to accomplish complex tasks.

**Example:**
> "Find all PDF files in my Downloads folder and email them to me."

- The Dexto agent uses the Filesystem Tool to search for PDFs.
- Then uses the Email Tool to send themâ€”all automatically.

### Extending with Your Own Tools

Dexto agents are extensible: you can add your own tools by implementing an MCP server or connecting to existing APIs. This lets you automate anything you can describe and connect. 


================================================
FILE: docs/docs/concepts/what-is-an-ai-agent.md
================================================
---
sidebar_position: 1
---

# What is an AI Agent?

An **AI Agent** is a program that can understand a goal, make a plan, and use a set of tools to execute that plan. Think of it as an autonomous worker that can operate digital tools on your behalf.

At a high level, most AI agents share a common structure:

1.  **Goal:** They are given a high-level objective in natural language (e.g., "summarize this report," "book a flight," "organize my files").
2.  **Reasoning:** The agent, typically powered by a Large Language Model (LLM), breaks down the goal into a sequence of steps.
3.  **Tools:** The agent has access to a set of tools (like APIs, web browsers, or file system commands) that it can use to execute the steps.
4.  **Observation:** After each action, the agent observes the result (e.g., the output of a command, the content of a webpage) and uses that information to decide the next step.
5.  **Execution:** The agent continues this loop of reasoning, tool use, and observation until the goal is achieved.

## Key Characteristics

- **Autonomy:** Agents can operate independently to achieve a goal without step-by-step human guidance.
- **Goal-Oriented:** Their actions are driven by the objective they are trying to achieve.
- **Tool-Using:** They don't just process information; they take action by using external tools.
- **Adaptive:** They can react to the results of their actions and adjust their plan accordingly.

AI agents represent a shift from simple instruction-following programs to more dynamic, goal-oriented systems that can navigate complex digital environments. Check out this blog post where we explore this in depth.


================================================
FILE: docs/docs/examples-demos/amazon-shopping.md
================================================
---
title: "Amazon shopping assistant"
hide_title: true

---

## ğŸ›’ Amazon shopping assistant 

```bash
# Uses default config which supports puppeteer for navigating the browser
dexto
```

**Task:**
> Can you go to amazon and add some snacks to my cart? I like trail mix, cheetos and maybe surprise me with something else?

**Output:**

[![Dexto: Amazon shopping agent demo](https://github.com/user-attachments/assets/3f5be5e2-7a55-4093-a071-8c52f1a83ba3)](https://youtu.be/C-Z0aVbl4Ik)




================================================
FILE: docs/docs/examples-demos/email-slack.md
================================================
---

title: "Email summaries in slack"
hide_title: true
---


## ğŸ“§ Email Summaries in Slack

```bash
dexto --agent ./agents/examples/email_slack.yml
```
**Task:**
> Summarize emails and send highlights to Slack

**Output:**
![Email to Slack Demo](/assets/email_slack_demo.gif)


================================================
FILE: docs/docs/examples-demos/website-designer.md
================================================
---
title: "Design a website with dexto"
hide_title: true
---

## Website Designer

```bash
dexto --agent ./agents/examples/website_designer.yml
```

**Task:**
> Design a landing page based on README.md

**Output:**
![Website Designer Demo](/assets/website_demo.gif)

---

For more examples and advanced use cases, see the [project README](https://github.com/truffle-ai/dexto#examples--demos). 


================================================
FILE: docs/docs/getting-started/first-agent-tutorial.md
================================================
---
sidebar_position: 3
---

# Build Your First Agent

Now that you have Dexto installed, let's build your first custom agent. This tutorial will guide you through creating an `agent.yml` file to define an agent with a unique personality and tools.

### 1. Create Your Agent Configuration
The heart of a Dexto agent is the `agent.yml` configuration file. This is where you declaratively define the agent's identity and capabilities.

Create a new directory for your project and add a basic configuration:

```bash
mkdir my-pirate-agent
cd my-pirate-agent
```

```yaml
# agent.yml
systemPrompt: |
  You are a helpful AI assistant.

llm:
  provider: openai
  model: gpt-4.1-mini
```

This basic configuration tells the runtime to use OpenAI's `gpt-4.1-mini` model with a simple system prompt.

### 2. Give Your Agent a Personality
Let's customize your agent by giving it a distinct personality. Modify the `systemPrompt` to create a pirate-themed agent:

```yaml
# agent.yml
systemPrompt: |
  Ahoy! Ye be chattin' with a pirate AI. Speak like a pirate in all yer responses, savvy?

llm:
  provider: openai
  model: gpt-4.1-mini
```

Now run your agent from inside the `my-pirate-agent` directory:

```bash
dexto --agent agent.yml "Who are you?"
```

Your agent should now respond like a pirate. You've just changed your agent's behavior through declarative configurationâ€”no code required.

### 3. Add Tool Integration
A core feature of Dexto is connecting agents to external tools through the Model Context Protocol (MCP). Let's give your pirate agent web browsing capabilities.

Add the `puppeteer` tool to your configuration:

```yaml
# agent.yml
systemPrompt: |
  Ahoy! Ye be chattin' with a pirate AI. Speak like a pirate in all yer responses, savvy?

llm:
  provider: openai
  model: gpt-4.1-mini

mcpServers:
  puppeteer:
    type: stdio
    command: npx
    args: ["-y", "@truffle-ai/puppeteer-server"]
```

The runtime will automatically handle tool installation and integration when you first run the agent.

### 4. Test Your Enhanced Agent
Start an interactive session with your enhanced agent:

```bash
dexto --agent agent.yml
```

Now ask it to use its new web browsing capability:
> `summarize the main points of the article at https://en.wikipedia.org/wiki/Piracy`

Your agent will use the puppeteer tool to visit the webpage, read the content, and provide a summary (in pirate voice, of course).

## Congratulations!
You've just built and customized your first AI agent using declarative configuration. You've learned how to:

- âœ… Define an agent with `agent.yml` configuration
- âœ… Customize agent behavior through system prompts  
- âœ… Integrate external tools via MCP servers
- âœ… Run and interact with your agent using the runtime

This is the fundamental development workflow with Dexto: configure declaratively, let the runtime handle orchestration, and focus on your agent's purpose rather than implementation details.

**Next Steps**: Explore adding more [tools](../concepts/tools.md) or building [multi-agent systems](../tutorials/multi-agent-systems.md).



================================================
FILE: docs/docs/getting-started/installation.md
================================================
---
sidebar_position: 2
---

# Installation

This guide will walk you through installing the Dexto CLI and setting up your environment so you can start running agents.

### Prerequisites
- [Node.js](https://nodejs.org/en/download) >= 20.0.0
- An [OpenAI API Key](https://platform.openai.com/api-keys)

### 1. Install Dexto
Install Dexto globally using npm:

```bash
npm install -g dexto
```
This adds the `dexto` command to your system, giving you access to the agent runtime.

### 2. Set Your API Key
Dexto agents use Large Language Models. Set the API key(s) for your chosen provider(s):

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."

# Anthropic
export ANTHROPIC_API_KEY="sk-ant-..."

# Google Gemini
export GOOGLE_GENERATIVE_AI_API_KEY="AIza..."

# Groq
export GROQ_API_KEY="gsk_..."

# XAI
export XAI_API_KEY="xai_..."

# Cohere
export COHERE_API_KEY="cohere_..."
```

Dexto auto-detects keys based on provider selection (CLI flag `--model` can infer provider).

### 3. Verify Your Installation
Test your installation with a simple command:

```bash
dexto "What is the meaning of life?"
```

If you receive a response, your installation is successful and the runtime is working correctly.

## Next Step: Build Your First Agent
Now that Dexto is installed, you're ready to create your first custom agent with its own configuration and capabilities.

Continue to the **[First Agent Tutorial](./first-agent-tutorial.md)** to learn how to build agents using declarative configuration. 


================================================
FILE: docs/docs/getting-started/intro.md
================================================
---
sidebar_position: 1
---

# Introduction

Dexto is an **AI Agent Runtime** that orchestrates intelligent, stateful agents capable of reasoning, executing tools, and completing complex tasks. Instead of building agents from scratchâ€”setting up LLM clients, managing state, implementing tool calling, handling sessionsâ€”you simply configure them declaratively and let Dexto handle the orchestration.

## Why Dexto?

Traditional AI applications are stateless and limited to single interactions. Your agent forgets context, loses track of ongoing tasks, and can't coordinate multiple tools effectively.

**Dexto changes this** by providing a runtime that maintains persistent agent state, handles complex reasoning loops, and manages tool executionâ€”giving you agents that can:

- ğŸ§  **Remember everything** across conversations and sessions  
- ğŸ”„ **Work on long-running tasks** without losing progress
- ğŸ› ï¸ **Orchestrate multiple tools** to complete complex objectives
- âš¡ **Scale intelligently** with persistent state management

Think of it as the difference between a stateless chatbot vs. a **persistent AI assistant** that grows smarter with each interaction.

```mermaid
flowchart TD
    subgraph Config ["Configuration Layer"]
        A[LLM Config<br/><i>Provider, Model, Prompts</i>]
        B[MCP Servers<br/><i>Tool Connections</i>]
        C[Storage<br/><i>Cache & Database</i>]
        D[Sessions<br/><i>Limits & TTL</i>]
    end
    
    subgraph Runtime ["Runtime Layer"]
        E[<i>Orchestrates Services<br/>for<br/>Stateful Agent Behavior</i>]
    end
    
    subgraph Interactive ["Interactive Layer"]
        F[CLI]
        G[Web UI]
        H[API Server]
        I[SDK/Library]
    end
    
    Config --> Runtime
    Runtime --> Interactive

    classDef configNode fill:#1a202c,stroke:#4fd1c7,stroke-width:2px,color:#f7fafc
    classDef runtimeNode fill:#2d3748,stroke:#68d391,stroke-width:2px,color:#f7fafc
    classDef interactiveNode fill:#2c5282,stroke:#63b3ed,stroke-width:2px,color:#f7fafc
    
    class A,B,C,D configNode
    class E runtimeNode
    class F,G,H,I interactiveNode
```

## What You Get

Dexto provides everything you need to build sophisticated AI agents:

- **Persistent Conversations** - Maintain context across sessions with configurable storage backends (Redis, PostgreSQL, SQLite, in-memory)
- **Multi-Session Support** - Run concurrent conversations with isolation, limits, and automatic cleanup
- **Model Flexibility** - Use any LLM provider (OpenAI, Anthropic, Google, local) and switch models dynamically
- **Tool Integration** - Connect to external APIs through Model Context Protocol (MCP) without writing integration code
- **Multi-Agent Systems** - Run specialized agents that communicate, delegate tasks, and coordinate through emerging protocols like MCP, A2A, etc.
- **Clean Deployment** - Single-command Docker deployment with built-in health checks and production-ready configuration
- **Event System** - Real-time events for agent state, tool executions, and LLM interactions
- **Multiple Interfaces** - Access via CLI, Web UI, REST API, or embed using the SDK/library

## How It Works

:::tip Quick Start
1. **ğŸ“ Configure Your Agent**: Create an `agent.yml` file defining your agent's purpose and capabilities
2. **ğŸš€ Start the Runtime**: Launch Dexto to orchestrate your agent with persistent state and tool access  
3. **ğŸ’¬ Interact**: Use CLI, Web UI, API, or embed directly using the SDK
:::

## Ready to Build Your First Agent?

**[Install Dexto â†’](./installation.md)**

---

*Dexto is built by the team at Truffle AI. Join our community and help shape the future of intelligent agent orchestration!* 


================================================
FILE: docs/docs/guides/cli.md
================================================
---
sidebar_position: 2

---

# CLI Guide

This guide helps you get started with the Dexto CLI and includes a comprehensive list of commands you can run with Dexto CLI.

Dexto CLI is the easiest way to get started with AI agents.

Some of the cool things you can do with Dexto CLI:

- Talk to any LLM in your terminal
- Create long-lived AI agents with tools, knowledge and memories. Example: a productivity agent that integrates with your linear and github.
- Deploy these agents either locally or on the cloud
- Talk to these agents on any application - discord, telegram, slack, cursor, claude desktop, etc.
- Start building your own AI applications - get started with building your own Cursor! `dexto create-app`


More CLI commands coming soon! 

Request a CLI command by creating an issue [here](https://github.com/truffle-ai/dexto/issues).


#### **See all available options and flags:**

```bash
dexto -h
```

#### **Launch the interactive CLI:**
```bash
dexto
```

#### **Start dexto CLI with a different LLM**
```bash
# openai
dexto -m gpt-4o

# anthropic
dexto -m claude-4-sonnet-20250514

# google
dexto -m gemini-2.0-flash
```


#### **Start dexto with a different config file**

This allows you to configure dexto CLI to use a different AI agent
```bash
dexto --agent <path_to_agent_config_file>
```

Check [Configuration Guide](./configuring-dexto/overview) to understand more about dexto config files

#### **Require all MCP servers to connect successfully**

By default, Dexto uses "lenient" mode where individual servers can fail to connect without preventing startup. Use the `--strict` flag to require all servers to connect successfully:

```bash
dexto --strict
```

This overrides any individual `connectionMode` settings in your MCP server configurations. See [MCP Configuration](../mcp/connecting-servers) for more details on connection modes.

#### **Run a specific command with Dexto CLI:**

```bash
dexto "find all .sh files in this directory"
# or use explicit -p flag
dexto -p "find all .sh files in this directory"
```

or do the same with gemini:

```bash
dexto -m gemini-2.0-flash "find all files in this directory"
# or with explicit -p flag
dexto -m gemini-2.0-flash -p "find all files in this directory"
```

Dexto CLI can accept __any__ command - if it doesn't see it as an in-built command, it will fire a single run CLI with that request

For instance, in the above command, the query "find all .sh files in this directory" will start Dexto Agent, send it this query, process the response, and then exit.


#### **Start a telegram bot**

```bash
dexto --mode telegram
```
To use a specific agent config file for the telegram bot:
```bash
dexto --mode telegram --agent ./telegram-agent-config.yml
```

<!-- Todo: add telegram demo -->

#### **Start a discord bot**
```bash
dexto --mode discord
```
To use a specific agent config file for the discord bot:
```bash
dexto --mode discord --agent ./discord-agent-config.yml
```

<!-- Todo: add discord demo -->

#### **Start dexto as an MCP server**
```bash
dexto --mode mcp
```

With this, you can now connect this agent to Cursor, claude desktop, or even other Dexto agents!

Check [Using dexto as an MCP Server](../mcp/dexto-as-mcp-server) to understand more about MCP servers.

#### **Group MCP servers with dexto**
```bash
dexto mcp --group-servers
```

This starts Dexto as an MCP server that aggregates and re-exposes tools from multiple configured MCP servers. This is useful when you want to access tools from multiple MCP servers through a single connection.

To use a specific config file:
```bash
dexto mcp --group-servers -a ./dexto-tools.yml
```

Check [Using Dexto to group MCP servers](../mcp/grouping-servers) to understand more about MCP server aggregation.


#### **Change log level for dexto CLI**

To change the logging level, set environment variable `DEXTO_LOG_LEVEL` to 'info', 'debug', or 'silly'. Default is 'info'.

ex: for debug logs:
```bash
DEXTO_LOG_LEVEL=debug
dexto what is the time
```


## Project setup commands

These commands will help you get started creating your own AI application using Dexto

Setup a fresh typescript project using dexto-core
```bash
dexto create-app
```

Add dexto into an existing typescript project
```bash
dexto init-app
```

Check [Building with Dexto Guide](../tutorials/index.md) for more information!

## Coming soon!

Some of the CLI commands we're working on!

#### Load pre-built templates for dexto CLI

#### Deploy config files as AI agents with dexto CLI



================================================
FILE: docs/docs/guides/deployment.md
================================================
---
sidebar_position: 3
---

# Deployment Guide

Deploy Dexto agents using Docker for local or production environments.

## Docker Deployment

### Quick Start

1. **Build the Docker image**
   ```bash
   docker build -t dexto .
   ```

2. **Create environment file**
   ```bash
   # .env
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   # Add other API keys as needed
   ```

3. **Run the container**
   ```bash
   docker run --env-file .env -p 3001:3001 dexto
   ```

Your Dexto server will be available at `http://localhost:3001` with:
- âœ… SQLite database connected
- âœ… MCP servers (filesystem & puppeteer) connected  
- âœ… REST API + WebSocket endpoints available

### Background Mode

Run Dexto in detached mode:

```bash
# Start in background
docker run -d --name dexto-server --env-file .env -p 3001:3001 dexto

# View logs
docker logs -f dexto-server

# Stop server
docker stop dexto-server
```

### Docker Compose

For easier management:

```yaml
# docker-compose.yml
version: '3.8'
services:
  dexto:
    build: .
    ports:
      - "3001:3001"
    env_file:
      - .env
    volumes:
      - dexto_data:/app/.dexto
    restart: unless-stopped

volumes:
  dexto_data:
```

Run with:
```bash
docker compose up --build
```

## Production Setup

### Environment Variables

```bash
# Production environment variables
NODE_ENV=production
PORT=3001
CONFIG_FILE=/app/configuration/dexto.yml
```

### Persistent Storage

Mount a volume for persistent data:

```bash
docker run -d \
  --name dexto-server \
  --env-file .env \
  -p 3001:3001 \
  -v dexto_data:/app/.dexto \
  dexto
```

### Resource Limits

Set memory and CPU limits:

```bash
docker run -d \
  --name dexto-server \
  --env-file .env \
  --memory=1g \
  --cpus=1 \
  -p 3001:3001 \
  dexto
```

## API Endpoints

Once deployed, your Dexto server provides:

### REST API
- `POST /api/message` - Send async message
- `POST /api/message-sync` - Send sync message  
- `POST /api/reset` - Reset conversation
- `GET /api/mcp/servers` - List MCP servers
- `GET /health` - Health check

### WebSocket
- Real-time events and streaming responses
- Connect to `ws://localhost:3001/ws`


## Next Steps

- **[Dexto SDK Guide](./dexto-sdk)** - Integrate Dexto into your application's codebase
- **[API Reference](/api)** - Complete API documentation

For more detailed information on configuring agents, refer to the [Dexto Configuration Guide](./configuring-dexto/overview).

### Building with the Dexto SDK for TypeScript

For custom builds and advanced integration, you can use the [Dexto SDK Guide](./dexto-sdk) to bundle Dexto into your own applications.

For a complete technical reference, see the [API Reference](/api).

## Hosting Options


================================================
FILE: docs/docs/guides/dexto-as-mcp-server.md
================================================
---
sidebar_position: 7
title: "Using Dexto as an MCP Server"
sidebar_label: "Using Dexto as an MCP Server"
---

# Using Dexto as an MCP Server

Dexto agents can act as Model Context Protocol (MCP) server, enabling external tools like Cursor/Claude Desktop or any MCP client to connect and interact with your Dexto agent.

This means you can even connect one Dexto agent to another Dexto agent!

The default Dexto agent has tools to access files and browse the web, but you can configure this too by changing the config file!

Check out our [Configuration guide](./configuring-dexto/overview)

## Local MCP Server Guide

### Setup in Cursor

1. **Create or edit your `.cursor/mcp.json` file:**

Use the default Dexto configuration
```json
{
  "mcpServers": {
    "dexto": {
      "command": "npx",
      "args": ["-y", "dexto", "--mode", "mcp"],
      "env": {
        "OPENAI_API_KEY": "your_openai_api_key"
      }
    }
  }
}
```

Using a custom Dexto configuration:
Note: if you use a different LLM in your config file, you will need to pass the appropriate environment variable for that provider.

```json
{
  "mcpServers": {
    "dexto": {
      "command": "npx",
      "args": ["-y", "dexto", "--mode", "mcp", "--agent", "path/to/your/agent.yml"],
      "env": {
        "OPENAI_API_KEY": "your_openai_api_key"
      }
    }
  }
}
```


2. **Restart Cursor**

### Using Dexto in Cursor

**Available Tools in Cursor:**
- `chat_with_agent`: Interact with Dexto AI agent

**Available Dexto tools:**

By default, Dexto CLI loads an AI agent that has tools to:
- browse the web
- search files on your local system

But you can customize the tools by using a custom Dexto agent configuration file. Check out our [Configuration guide](./configuring-dexto/overview).

**Example Usage in Cursor:**

1. **Refactor a function:**
   ```bash
   Ask Dexto agent to help me refactor this function to be more efficient
   ```

2. **Get file analysis:**
   ```bash
   Ask Dexto agent to analyze the architecture of this project
   ```

3. **Browse the web:**
   ```bash
   Ask Dexto agent to search the web for soccer shoes under $100
   ```

4. **Any custom functionality:**
    You can configure your Dexto agent to have any other custom functionality by setting up your own config file and using it here. Check out our [Configuration guide](./configuring-dexto/overview)

## Remote MCP Server Setup

### Step 1: Start Dexto in Server Mode

```bash
# If installed globally
dexto --mode server

# Or via npx
npx dexto --mode server
```

**Options:**
```bash
# Custom port using environment variable
API_PORT=8080 dexto --mode server
# Or via npx
API_PORT=8080 npx dexto --mode server

# Custom port for network access
API_PORT=3001 dexto --mode server
# Or via npx
API_PORT=3001 npx dexto --mode server

# Enable debug logging
dexto --mode server --debug
# Or via npx
npx dexto --mode server --debug
```

### Step 2: Configure the Connection URL

**HTTP MCP Endpoint:**
```bash
http://localhost:3001/mcp
```

**For network access:**
```bash
http://YOUR_SERVER_IP:3001/mcp
```

### Remote Server in Cursor (WIP)
Cursor/Claude desktop don't support streamable http yet

## Troubleshooting

**Cursor not detecting MCP server:**
- Verify `.cursor/mcp.json` syntax is correct
- Restart Cursor after configuration changes
- Ensure dexto is installed and accessible
- Verify environment variables are set correctly

**Debug mode:**
```bash
# If installed globally
dexto --mode mcp --debug

# Or via npx
npx dexto --mode mcp --debug
``` 


================================================
FILE: docs/docs/guides/dexto-group-mcp-servers.md
================================================
---
sidebar_position: 8
sidebar_label: "Using Dexto to group MCP servers"
---

# Using Dexto CLI to group MCP servers together

Dexto can operate in **MCP Tools Mode**, where it acts as a local tool aggregation server that groups MCP servers and re-exposes them all under 1 common MCP server. 

Unlike the regular MCP server mode where you interact with a Dexto AI agent, this mode provides direct access to the underlying tools without an AI intermediary.

This is useful when you want to:
- Access tools from multiple MCP servers through a single connection
- Group tools directly without AI agent processing
- Create a centralized tool hub for your development environment

## How It Works

In MCP Tools Mode, Dexto:
1. Connects to multiple MCP servers as configured
2. Aggregates all available tools from these servers
3. Exposes them directly as its own local MCP server
4. Acts as a pass-through for tool execution

## Configuration

### Step 1: Create a Dexto Configuration File

Create a `dexto-tools.yml` configuration file with the MCP servers you want to aggregate:

```yaml
# dexto-tools.yml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - "."
  
  puppeteer:
    type: stdio
    command: npx
    args:
      - -y
      - "@truffle-ai/puppeteer-server"
```

 - You don't need LLM configuration for tools mode
 - Only the mcpServers section is used

### Step 2: Setup in Cursor

Add the following to your `.cursor/mcp.json` file:

```json
{
  "mcpServers": {
    "dexto-tools": {
      "command": "npx",
      "args": [
        "-y", 
        "dexto", 
        "mcp",
        "--group-servers",
        "-a",
        "path/to/your/dexto-tools.yml"
      ]
    }
  }
}
```

Or use the default Dexto configuration

```json
{
  "mcpServers": {
    "dexto-tools": {
      "command": "npx",
      "args": [
        "-y", 
        "dexto", 
        "mcp",
        "--group-servers"
      ]
    }
  }
}
```

### Step 3: Restart Cursor

After adding the configuration, restart Cursor to load the new MCP server. 


================================================
FILE: docs/docs/guides/dexto-sdk.md
================================================
---
sidebar_position: 1
title: "Dexto SDK Guide"
---

# Dexto SDK Guide

Welcome to the Dexto SDK guide for TypeScript. This guide provides everything you need to build high-quality AI applications with Dexto.

Whether you're creating standalone agents, integrating with existing applications, or building custom AI workflows, the SDK offers a flexible and robust set of tools.

## Key Features

- **Full TypeScript Support**: Strong typing for better development.

## Core Concepts

The SDK is built around a few core concepts:

- **DextoAgent**: The main class for creating and managing agents.
- **MCPManager**: A utility for managing MCP server connections.
- **LLMService**: A service for interacting with large language models.
- **StorageBackends**: A set of backends for persisting agent data.

## Example Usage

Here's a quick example of how to create a simple agent that uses the OpenAI API:

```typescript
import { DextoAgent } from 'dexto';

const agent = new DextoAgent({
  llm: {
    provider: 'openai',
    model: 'gpt-4',
    apiKey: process.env.OPENAI_API_KEY,
  },
});

await agent.start();

const response = await agent.run('Hello, world!');
console.log(response);

await agent.stop();
```

For more detailed examples, see the [Examples & Demos](/docs/category/examples--demos) section.

## Overview

The Dexto SDK provides a complete TypeScript library for building AI agents with MCP (Model Context Protocol) integration. It offers both high-level agent abstractions and low-level utilities for maximum flexibility.

### When to Use the SDK vs REST API

**Use the Dexto SDK when:**
- Building TypeScript applications
- Need real-time event handling
- Want type safety and IDE support
- Require complex session management
- Building long-running applications

**Use the REST API when:**
- Working in other languages
- Building simple integrations
- Prefer stateless interactions
- Working with webhooks or serverless functions

## Installation

```bash
npm install dexto
```

## Quick Start

### Basic Agent Setup

```typescript
import { DextoAgent } from 'dexto';

// Create agent with minimal configuration
const agent = new DextoAgent({
  llm: {
    provider: 'openai',
    model: 'gpt-4o',
    apiKey: process.env.OPENAI_API_KEY
  }
});
await agent.start();

// Start a conversation
const response = await agent.run('Hello! What can you help me with?');
console.log(response);
```

### Adding MCP Tools

```typescript
const agent = new DextoAgent({
  llm: {
    provider: 'openai',
    model: 'gpt-4o',
    apiKey: process.env.OPENAI_API_KEY
  },
  mcpServers: {
    filesystem: {
      type: 'stdio',
      command: 'npx',
      args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
    },
    web: {
      type: 'stdio', 
      command: 'npx',
      args: ['-y', '@modelcontextprotocol/server-brave-search']
    }
  }
});
await agent.start();

// Now the agent can use filesystem and web search tools
const response = await agent.run('List the files in this directory and search for recent AI news');
```

## Core Concepts

### Agents vs Sessions

- **Agent**: The main AI system with configuration, tools, and state management
- **Session**: Individual conversation threads within an agent

```typescript
// Create an agent (one per application typically)
const agent = new DextoAgent(config);
await agent.start();

// Create multiple sessions for different conversations
const userSession = await agent.createSession('user-123');
const adminSession = await agent.createSession('admin-456');

// Each session maintains separate conversation history
await userSession.run('Help me with my account');
await adminSession.run('Show me system metrics');
```

### Event-Driven Architecture

The SDK provides real-time events for monitoring and integration:

```typescript
// Listen to agent-wide events
agent.agentEventBus.on('dexto:mcpServerConnected', (data) => {
  console.log(`âœ… Connected to ${data.name}`);
});

// Listen to conversation events
agent.agentEventBus.on('llmservice:thinking', (data) => {
  console.log(`ğŸ¤” Agent thinking... (session: ${data.sessionId})`);
});

agent.agentEventBus.on('llmservice:toolCall', (data) => {
  console.log(`ğŸ”§ Using tool: ${data.toolName}`);
});
```

## Common Patterns

### Multi-User Chat Application

```typescript
import { DextoAgent } from 'dexto';

class ChatApplication {
  private agent: DextoAgent;
  private userSessions = new Map<string, string>();

  async initialize() {
    this.agent = new DextoAgent({
      llm: { provider: 'openai', model: 'gpt-4o', apiKey: process.env.OPENAI_API_KEY },
      mcpServers: { /* your tools */ }
    });
    await this.agent.start();

    // Set up event monitoring
    this.agent.agentEventBus.on('llmservice:response', (data) => {
      this.broadcastToUser(data.sessionId, data.content);
    });
  }

  async handleUserMessage(userId: string, message: string) {
    // Get or create session for user
    let sessionId = this.userSessions.get(userId);
    if (!sessionId) {
      const session = await this.agent.createSession(`user-${userId}`);
      sessionId = session.id;
      this.userSessions.set(userId, sessionId);
    }

    // Process message
    return await this.agent.run(message, undefined, sessionId);
  }

  private broadcastToUser(sessionId: string, message: string) {
    // Find user and send response via WebSocket, etc.
  }
}
```

### Dynamic Tool Management

```typescript
class AdaptiveAgent {
  private agent: DextoAgent;

  async initialize() {
    this.agent = new DextoAgent(baseConfig);
    await this.agent.start();
  }

  async addCapability(name: string, serverConfig: McpServerConfig) {
    try {
      await this.agent.connectMcpServer(name, serverConfig);
      console.log(`âœ… Added ${name} capability`);
    } catch (error) {
      console.error(`âŒ Failed to add ${name}:`, error);
    }
  }

  async removeCapability(name: string) {
    await this.agent.removeMcpServer(name);
    console.log(`ğŸ—‘ï¸ Removed ${name} capability`);
  }

  async listCapabilities() {
    const tools = await this.agent.getAllMcpTools();
    return Object.keys(tools);
  }
}
```

### Session Management with Persistence

```typescript
class PersistentChatBot {
  private agent: DextoAgent;

  async initialize() {
    this.agent = new DextoAgent({
      llm: { /* config */ },
      storage: {
        cache: { type: 'redis', url: 'redis://localhost:6379' },
        database: { type: 'postgresql', url: process.env.DATABASE_URL }
      }
    });
    await this.agent.start();
  }

  async resumeConversation(userId: string) {
    const sessionId = `user-${userId}`;
    
    // Check if session exists
    const sessions = await this.agent.listSessions();
    if (sessions.includes(sessionId)) {
      // Load existing session
      await this.agent.loadSession(sessionId);
      const history = await this.agent.getSessionHistory(sessionId);
      return history;
    } else {
      // Create new session
      await this.agent.createSession(sessionId);
      return null;
    }
  }
}
```

## Configuration Options

### LLM Providers

```typescript
// OpenAI
const openaiConfig = {
  provider: 'openai',
  model: 'gpt-4o',
  apiKey: process.env.OPENAI_API_KEY,
  temperature: 0.7,
  maxOutputTokens: 4000
};

// Anthropic
const anthropicConfig = {
  provider: 'anthropic', 
  model: 'claude-3-opus-20240229',
  apiKey: process.env.ANTHROPIC_API_KEY,
  maxIterations: 5
};

// Cohere
const cohereConfig = {
  provider: 'cohere',
  model: 'command-a-03-2025',
  apiKey: process.env.COHERE_API_KEY,
  temperature: 0.3
};

// Local/Custom OpenAI-compatible
const localConfig = {
  provider: 'openai',
  model: 'llama-3.1-70b',
  apiKey: 'not-needed',
  baseURL: 'http://localhost:8080/v1'
};
```

### Storage Backends

```typescript
// In-memory (development)
const memoryStorage = {
  cache: { type: 'in-memory' },
  database: { type: 'in-memory' }
};

// Production with Redis + PostgreSQL
const productionStorage = {
  cache: { 
    type: 'redis',
    url: 'redis://localhost:6379'
  },
  database: {
    type: 'postgresql', 
    url: process.env.DATABASE_URL
  }
};
```

## Error Handling

### Graceful Degradation

```typescript
const agent = new DextoAgent(config);
await agent.start();

// Handle MCP connection failures
agent.agentEventBus.on('dexto:mcpServerConnected', (data) => {
  if (!data.success) {
    console.warn(`âš ï¸ ${data.name} unavailable: ${data.error}`);
    // Continue without this capability
  }
});

// Handle LLM errors
agent.agentEventBus.on('llmservice:error', (data) => {
  if (data.recoverable) {
    console.log('ğŸ”„ Retrying request...');
  } else {
    console.error('ğŸ’¥ Fatal error:', data.error);
    // Implement fallback or user notification
  }
});
```

### Validation and Fallbacks

```typescript
try {
  const agent = new DextoAgent({
    llm: primaryLLMConfig,
    mcpServers: allServers
  });
  await agent.start();
} catch (error) {
  console.warn('âš ï¸ Full setup failed, using minimal config');
  
  // Fallback to basic configuration
  const agent = new DextoAgent({
    llm: fallbackLLMConfig,
    mcpServers: {} // No external tools
  });
  await agent.start();
}
```

## Best Practices

### 1. Resource Management

```typescript
// Proper cleanup
const agent = new DextoAgent(config);
await agent.start();

process.on('SIGTERM', async () => {
  await agent.stop();
  process.exit(0);
});
```

### 2. Session Lifecycle

```typescript
// Set session TTL to manage memory usage (chat history preserved in storage)
const agent = new DextoAgent({
  // ... other config
  sessions: {
    maxSessions: 1000,
    sessionTTL: 24 * 60 * 60 * 1000 // 24 hours
  }
});
await agent.start();
```

### 3. Monitoring and Observability

```typescript
// Log all tool executions
agent.agentEventBus.on('llmservice:toolCall', (data) => {
  console.log(`[${data.sessionId}] Tool: ${data.toolName}`, data.args);
});

agent.agentEventBus.on('llmservice:toolResult', (data) => {
  if (data.success) {
    console.log(`[${data.sessionId}] âœ… ${data.toolName} completed`);
  } else {
    console.error(`[${data.sessionId}] âŒ ${data.toolName} failed:`, data.result);
  }
});
```

## Next Steps

- **[DextoAgent API](/api/dexto-agent)** - Detailed method documentation
- **[MCP Guide](/docs/mcp/overview)** - Learn about Model Context Protocol
- **[Deployment Guide](/docs/guides/deployment)** - Production deployment strategies
- **[Examples](/docs/category/examples--demos)** - Complete example applications


================================================
FILE: docs/docs/guides/mcp-manager.md
================================================
---
sidebar_position: 6
---

# MCP Manager

The MCPManager is Dexto's powerful standalone utility for managing Model Context Protocol (MCP) servers. Use it in your own applications to connect, manage, and interact with multiple MCP servers without needing the full Dexto agent framework.

## Overview

The MCPManager provides:
- **Multi-server management**: Connect to multiple MCP servers simultaneously
- **Unified tool interface**: Access tools from all connected servers
- **Resource management**: Handle MCP resources and prompts
- **Connection pooling**: Automatic connection management and error handling
- **Type safety**: Full TypeScript support with comprehensive types

## Installation

```bash
npm install dexto
```

## Quick Start

```typescript
import { MCPManager } from 'dexto';

// Create manager instance
const manager = new MCPManager();

// Connect to an MCP server
await manager.connectServer('filesystem', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Get available tools
const tools = await manager.getAllTools();
console.log('Available tools:', Object.keys(tools));

// Execute a tool
const result = await manager.executeTool('readFile', { path: './README.md' });
console.log(result);
```

## Core Concepts

### MCP Servers

MCP servers are external processes that provide tools, resources, and prompts. Common types include:

- **File system servers**: Read/write files and directories
- **Web search servers**: Search the internet for information
- **Database servers**: Query and manage databases
- **API servers**: Interact with external APIs
- **Custom servers**: Your own domain-specific tools

### Connection Types

MCPManager supports three connection types:

- **`stdio`**: Most common, spawns a child process (e.g., Node.js packages)
- **`http`**: Connect to HTTP-based MCP servers
- **`sse`**: Server-sent events for real-time communication

### Tool Execution

Tools are functions provided by MCP servers. The manager:
1. Discovers all available tools from connected servers
2. Routes tool calls to the appropriate server
3. Handles confirmation prompts for sensitive operations
4. Returns structured results

## Common Usage Patterns

### File Operations

Perfect for automating file system tasks:

```typescript
const manager = new MCPManager();

await manager.connectServer('fs', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Read files
const packageJson = await manager.executeTool('readFile', { 
  path: './package.json' 
});

// List directory contents
const files = await manager.executeTool('listFiles', { 
  path: './src' 
});

// Write files
await manager.executeTool('writeFile', {
  path: './output.md',
  content: '# Generated Report\n\nSome content here...'
});
```

### Web Research

Integrate web search capabilities:

```typescript
await manager.connectServer('search', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', 'tavily-mcp@0.1.2'],
  env: { TAVILY_API_KEY: process.env.TAVILY_API_KEY }
});

const results = await manager.executeTool('search', {
  query: 'Model Context Protocol specifications',
  max_results: 10
});
```

### Multi-Server Workflows

Combine multiple servers for complex tasks:

```typescript
// Initialize multiple servers at once
await manager.initializeFromConfig({
  filesystem: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  },
  search: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', 'tavily-mcp@0.1.2'],
    env: { TAVILY_API_KEY: process.env.TAVILY_API_KEY }
  },
  git: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@cyanheads/git-mcp-server'],
    env: {
        MCP_LOG_LEVEL: "info",
        GIT_SIGN_COMMITS: "false"
  }
});

// Complex workflow using multiple tools
async function generateProjectReport() {
  const files = await manager.executeTool('listFiles', { path: './src' });
  const commits = await manager.executeTool('git_log', { limit: 10 });
  const research = await manager.executeTool('search', {
    query: 'project documentation best practices'
  });
  
  const report = `# Project Report
Files: ${files.length}
Recent commits: ${commits.length}
Research findings: ${research.length}`;
  
  await manager.executeTool('writeFile', {
    path: './PROJECT_REPORT.md',
    content: report
  });
}
```

## Integration Examples

### Express.js API

Create an API that exposes MCP tools:

```typescript
import express from 'express';
import { MCPManager } from 'dexto';

const app = express();
app.use(express.json());

const manager = new MCPManager();
await manager.initializeFromConfig({
  filesystem: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  }
});

app.get('/api/tools', async (req, res) => {
  const tools = await manager.getAllTools();
  res.json({ tools: Object.keys(tools) });
});

app.post('/api/execute/:toolName', async (req, res) => {
  try {
    const { toolName } = req.params;
    const { args } = req.body;
    
    const result = await manager.executeTool(toolName, args);
    res.json({ success: true, result });
  } catch (error) {
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

app.listen(3000);
```

For detailed API reference, see the [MCPManager API documentation](/api/mcp-manager). ğŸ› ï¸

**Tool execution failures**
- Validate tool arguments match expected schema
- Check server logs for detailed error information 


================================================
FILE: docs/docs/guides/web-playground.md
================================================
---
sidebar_position: 2
---

# Web playground 

## Overview

Dexto web playground is the easiest way to test out different LLMs, MCP servers, prompts, and more!

Once you're satisfied with a specific combination, save it as a **Re-usable** AI agent built with Dexto, and deploy the agent anywhere.

All this is possible because Dexto sees any valid config file as a re-usable AI agent.

Dexto web playground also stores your conversation history locally so it remembers your past conversations!

## Get started
**Start dexto web playground:**

```bash
dexto --mode web
```
Then open [http://localhost:3000](http://localhost:3000) in your browser.

Or open dexto web playground in a different port:

```bash
dexto --mode web --web-port 3333
```

## Conversation storage

When installed as a global CLI, dexto stores conversation history in `~/.dexto` folder by default

In development mode, storage location defaults to`<path_to_dexto_project_dir>/.dexto`


================================================
FILE: docs/docs/guides/configuring-dexto/agent-yml.md
================================================
---
sidebar_position: 9
sidebar_label: "Annotated agent.yml"
---
# agent.yml â€“ Annotated Example

Below is a **canonical** configuration file with inline comments.  Adjust paths and credentials for your environment.

```yaml
systemPrompt: |
  You are a helpful AI assistant.

llm:                         # LLM configuration block
  provider: anthropic        # openai | anthropic | â€¦
  model: claude-3-opus-20240229
  apiKey: $ANTHROPIC_API_KEY # env references expanded on load
  router: in-built           # message router strategy
  maxInputTokens: 100000     # optional override

mcpServers:                  # zero or more MCP servers
  filesystem:
    command: mcp-filesystem
    args: [ "/tmp" ]

internalTools:
  - search_history           # enable built-in tools

storage:
  database:
    type: sqlite
    path: .dexto/dexto.db
```

For advanced scenarios (multi-environment overrides, hot-reload) see `docs/guides/configuring-dexto/dynamic-changes.md`.


================================================
FILE: docs/docs/guides/configuring-dexto/agentCard.md
================================================
---
sidebar_position: 8
sidebar_label: "Agent Card (A2A)"
---

# Agent Card Configuration

Configure your agent's public metadata for Agent-to-Agent (A2A) communication and service discovery.

## Overview

The agent card provides standardized metadata about your agent's capabilities, allowing other agents and services to discover and interact with your agent programmatically.

Learn more about Agent-to-Agent communication: [A2A: A new era of agent interoperability](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/)

## Configuration

```yaml
agentCard:
  name: "My Dexto Agent"
  description: "A helpful AI assistant with specialized capabilities"
  url: "https://my-agent.example.com"
  version: "1.0.0"
  documentationUrl: "https://docs.example.com/my-agent"
  provider:
    organization: "My Company"
    url: "https://mycompany.com"
  capabilities:
    streaming: true
    pushNotifications: false
    stateTransitionHistory: false
  authentication:
    schemes: ["bearer", "apiKey"]
    credentials: "optional"
  defaultInputModes: ["application/json", "text/plain"]
  defaultOutputModes: ["application/json", "text/plain"]
  skills:
    - id: "data_analysis"
      name: "Data Analysis"
      description: "Analyze and visualize data from various sources"
      tags: ["analytics", "data", "visualization"]
      examples: ["Analyze sales data", "Create charts from CSV"]
```

## Required Fields

### `name`
- **Type:** String
- **Description:** Display name for your agent

### `url`
- **Type:** String (URL)
- **Description:** Public endpoint where your agent can be accessed

### `version`
- **Type:** String
- **Description:** Version identifier for your agent

## Optional Fields

### `description`
- **Type:** String
- **Default:** "Dexto is an AI assistant capable of chat and task delegation, accessible via multiple protocols."
- **Description:** Brief description of your agent's capabilities

### `documentationUrl`
- **Type:** String (URL)
- **Description:** Link to your agent's documentation

### `provider`
- **Type:** Object
- **Description:** Information about the organization providing this agent

```yaml
provider:
  organization: "Your Organization Name"
  url: "https://yourorganization.com"
```

### `capabilities`
- **Type:** Object
- **Description:** Technical capabilities your agent supports

```yaml
capabilities:
  streaming: true                    # Supports real-time streaming responses
  pushNotifications: false           # Can send push notifications
  stateTransitionHistory: false      # Maintains state transition history
```

### `authentication`
- **Type:** Object
- **Description:** Supported authentication methods

```yaml
authentication:
  schemes: ["bearer", "apiKey"]      # Supported auth schemes
  credentials: "optional"            # Credential requirements
```

### `defaultInputModes`
- **Type:** Array of strings
- **Default:** `["application/json", "text/plain"]`
- **Description:** Content types your agent accepts

### `defaultOutputModes`
- **Type:** Array of strings  
- **Default:** `["application/json", "text/event-stream", "text/plain"]`
- **Description:** Content types your agent can produce

### `skills`
- **Type:** Array of skill objects
- **Description:** Specific capabilities your agent provides

```yaml
skills:
  - id: "unique_skill_id"
    name: "Human-readable skill name"
    description: "What this skill does"
    tags: ["category", "keywords"]
    examples: ["Example usage 1", "Example usage 2"]
    inputModes: ["text/plain"]        # Optional, defaults to ["text/plain"]
    outputModes: ["application/json"] # Optional, defaults to ["text/plain"]
```

## Examples

### Basic Agent Card
```yaml
agentCard:
  name: "Support Bot"
  description: "Customer support assistant"
  url: "https://support.mycompany.com/agent"
  version: "2.1.0"
```

### Full-Featured Agent Card
```yaml
agentCard:
  name: "Analytics Assistant"
  description: "Advanced data analysis and visualization agent"
  url: "https://analytics.mycompany.com"
  version: "3.0.0"
  documentationUrl: "https://docs.mycompany.com/analytics-agent"
  provider:
    organization: "Data Insights Corp"
    url: "https://datainsights.com"
  capabilities:
    streaming: true
    pushNotifications: true
    stateTransitionHistory: true
  authentication:
    schemes: ["bearer", "oauth2"]
    credentials: "required"
  defaultInputModes: ["application/json", "text/csv", "application/xml"]
  defaultOutputModes: ["application/json", "image/png", "text/html"]
  skills:
    - id: "csv_analysis"
      name: "CSV Analysis"
      description: "Parse and analyze CSV data files"
      tags: ["data", "csv", "analysis"]
      examples: ["Analyze sales data CSV", "Generate summary statistics"]
      inputModes: ["text/csv", "text/plain"]
      outputModes: ["application/json", "text/html"]
    - id: "chart_generation"
      name: "Chart Generation"
      description: "Create visualizations from data"
      tags: ["visualization", "charts", "graphs"]
      examples: ["Create bar chart", "Generate trend analysis"]
      inputModes: ["application/json"]
      outputModes: ["image/png", "image/svg+xml"]
```

## Agent-to-Agent Communication

The agent card enables:

- **Service Discovery:** Other agents can find and understand your agent's capabilities
- **Protocol Negotiation:** Automatic selection of compatible input/output formats
- **Capability Matching:** Agents can determine if your agent can help with specific tasks
- **Authentication:** Proper setup of secure agent-to-agent communication

## Default Behavior

If no agent card is specified, Dexto will generate basic metadata based on your configuration. For A2A communication, it's recommended to configure your agent card explicitly.




================================================
FILE: docs/docs/guides/configuring-dexto/dynamic-changes.md
================================================
---
sidebar_position: 10
sidebar_label: "Dynamic Changes"
---
# Runtime / Dynamic Configuration Changes

`AgentStateManager` allows safe, validated modifications to the running configuration.

## Example â€“ per-session LLM override

```typescript
stateManager.updateLLM(
  { provider: 'openai', model: 'gpt-4o', maxInputTokens: 50_000 },
  'user-123'
);
```

Internally the manager:

1. Validates the patch against `LLMConfigSchema`.
2. Stores the override under `sessionOverrides`.
3. Emits `dexto:stateChanged` and `dexto:sessionOverrideSet` events.

## Example â€“ add MCP server at runtime

```typescript
await stateManager.addMcpServer('git', {
  command: 'mcp-git',
  args: ['--repo', process.cwd()]
});
```

This triggers `dexto:mcpServerAdded`, after which `MCPManager` connects and refreshes its capability cache.


================================================
FILE: docs/docs/guides/configuring-dexto/mcp.md
================================================
---
title: MCP Configuration
sidebar_position: 4
sidebar_label: "MCP Configuration"
description: How to configure MCP servers in agent.yml and via runtime updates, with links to the full MCP docs for deeper guidance.
---

This page focuses on configuration tasks in `agent.yml` and runtime overrides. For concepts, transports, manager APIs, and advanced patterns, see the MCP section.

## agent.yml

Add servers under `mcpServers`:

```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - @modelcontextprotocol/server-filesystem
    env:
      ROOT: ./
  puppeteer:
    type: stdio
    command: npx
    args:
      - @modelcontextprotocol/server-puppeteer
```

See: [MCP â€º Configure Connections](../../mcp/connecting-servers)

## Runtime changes

- Add/update/remove servers dynamically via the SDK or REST APIs
- Events: `dexto:mcpServerAdded`, `dexto:mcpServerUpdated`, `dexto:mcpServerRemoved`

See: [MCP â€º MCP Manager](../../mcp/mcp-manager)

## Next steps

- [MCP â€º Overview](../../mcp/overview)
- [MCP â€º Configure Connections](../../mcp/connecting-servers)
- [MCP â€º Dexto as an MCP Server](../../mcp/dexto-as-mcp-server)





================================================
FILE: docs/docs/guides/configuring-dexto/overview.md
================================================
---
sidebar_position: 1
sidebar_label: "Overview"
---

# Configuring Dexto

Dexto's power comes from its customizability. You can customize every part of your Dexto agent with one `yml` config file. 

This guide walks through all the different features you can customize, and the expected format.

We chose `yml` instead of the more popular `json` because of its support for comments (which we find super useful!), and better parsing libraries.

## Where to Place Your Config

By default, Dexto uses a configuration file named `agents/default-agent.yml`. You can also specify a custom config path using the CLI:

```bash
dexto --agent path/to/your-config.yml
```

## Example Configuration File

```yaml
# agent.yml - Basic agent configuration
systemPrompt: |
  You are a helpful AI assistant with access to tools.
  Use these tools when appropriate to answer user queries.
  You can use multiple tools in sequence to solve complex problems.
  After each tool result, determine if you need more information or can provide a final answer.

llm:
  provider: openai
  model: gpt-4.1-mini
  # you can update the system prompt to change the behavior of the llm
  apiKey: $OPENAI_API_KEY

# Optional default greeting shown when a chat starts (for UI consumption)
greeting: "Hello! Iâ€™m your Dexto agent."

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]

```

## Key Sections Explained

- **mcpServers:**
  - This section represents the different MCP servers that you want to connect to your agent
  - Each key represents a different MCP server
  - [Complete Reference](../../mcp/connecting-servers)
- **llm:**
  - This section defines the configuration for the LLM that your agent will use as its brain.
  - [Complete Reference](./llm)
- **storage:**
  - This section defines where the agent will store conversation history, settings, and other data. 
  - [Complete Reference](./storage)
- **toolConfirmation:**
  - This section controls how and when users are prompted to approve tool execution
  - Configure confirmation modes, timeouts, and approval storage
  - [Complete Reference](./toolConfirmation)
- **greeting:**
  - Simple string used by UI layers to show an initial chat message or welcome text
  - Optional; omit it if your UI handles welcome state differently

## Best Practices

- **Use environment variables** for secrets and API keys. Reference them in YML as `$VARNAME`.
- **Keep your config in version control** (but never commit secrets!). Use `.env` files or CI secrets for sensitive values.
- **Document your config** for your team. Add comments to your YML files. We chose YML for this reason.
- **Validate your config** before running Dexto in production.
- **See the `agents/examples/` folder for more templates and advanced use cases.**


================================================
FILE: docs/docs/guides/configuring-dexto/sessions.md
================================================
---
sidebar_position: 7
sidebar_label: "Sessions"
---

# Sessions Configuration

Configure session management for your Dexto agent, including maximum concurrent sessions and session timeouts.

## Overview

Sessions in Dexto represent individual conversation contexts or user interactions. Each session maintains its own message history, tool approvals, and state.

## Configuration

```yaml
sessions:
  maxSessions: 100        # Maximum concurrent sessions
  sessionTTL: 3600000     # Session timeout in milliseconds (1 hour)
```

## Options

### `maxSessions`
- **Type:** Number (positive integer)
- **Default:** 100
- **Description:** Maximum number of concurrent sessions the agent can handle

### `sessionTTL`
- **Type:** Number (milliseconds)
- **Default:** 3600000 (1 hour)
- **Description:** How long sessions remain in memory without activity before being removed from memory (chat history is preserved in storage)

## Examples

### High-Traffic Environment
```yaml
sessions:
  maxSessions: 1000
  sessionTTL: 1800000     # 30 minutes
```

### Low-Resource Environment
```yaml
sessions:
  maxSessions: 20
  sessionTTL: 7200000     # 2 hours
```

### Development Environment
```yaml
sessions:
  maxSessions: 10
  sessionTTL: 86400000    # 24 hours (for debugging)
```

## Session Behavior

- **Automatic cleanup:** Expired sessions are automatically removed from memory (chat history preserved in storage)
- **Session isolation:** Each session has independent conversation history and tool approvals
- **Memory management:** Limiting sessions prevents memory exhaustion in long-running deployments
- **Chat persistence:** Conversation history is always preserved in storage and can be restored when sessions are accessed again

## Default Configuration

If not specified, Dexto uses:
```yaml
sessions:
  maxSessions: 100
  sessionTTL: 3600000
```

This provides a good balance for most use cases.


================================================
FILE: docs/docs/guides/configuring-dexto/storage.md
================================================
---
sidebar_position: 5
sidebar_label: "Storage Configuration"
---

# Storage Configuration

The `storage` section in your configuration file defines how your agent stores data. It's composed of two main components: a `cache` for temporary, high-speed data access, and a `database` for persistent, long-term storage.

You can configure different backends for both the cache and the database, allowing you to tailor your agent's storage to your specific needs, from simple in-memory setups to robust production environments using Redis and PostgreSQL.

```yaml
storage:
  cache:
    # Cache backend configuration
  database:
    # Database backend configuration
```

## Supported Backends

Dexto supports the following storage backends, which can be used for either `cache` or `database`:

| Backend    | Type         | Use Case                                                    |
|------------|--------------|-------------------------------------------------------------|
| **In-Memory** | `in-memory`     | Default, simple, no-dependency setup for quick-start & dev. |
| **Redis**  | `redis`      | High-performance caching and ephemeral data storage.        |
| **SQLite** | `sqlite`     | Simple, file-based persistent database.                     |
| **Postgres** | `postgres` | Robust, scalable, and feature-rich persistent database.     |


## Common Backend Options

These options can be applied to any backend type (`in-memory`, `redis`, `sqlite`, `postgres`) to configure connection pooling behavior.

```typescript
export interface BaseBackendConfig {
    maxConnections?: number;
    idleTimeoutMillis?: number;
    connectionTimeoutMillis?: number;
    options?: Record<string, any>;
}
```

-   `maxConnections`: Maximum number of connections in the pool.
-   `idleTimeoutMillis`: Time in milliseconds that a connection can be idle before being closed.
-   `connectionTimeoutMillis`: Time in milliseconds to wait for a connection to be established.
-   `options`: A key-value map for any other backend-specific options.

---

## Backend-Specific Configuration

### In-Memory (`in-memory`)

The simplest backend, storing all data in memory. Data is lost when the Dexto process terminates. It's the default for both `cache` and `database` if not otherwise specified.

**TypeScript Interface:**
```typescript
export interface InMemoryBackendConfig {
    type: 'in-memory';
    // Inherits common backend options
}
```

**Example:**
```yaml
storage:
  cache:
    type: in-memory
  database:
    type: in-memory
```

---

### Redis (`redis`)

A high-performance in-memory data store, ideal for caching.

**TypeScript Interface:**
```typescript
export interface RedisBackendConfig {
    type: 'redis';
    url?: string;      // e.g., "redis://user:pass@host:port"
    host?: string;
    port?: number;
    password?: string;
    database?: number; // DB index
    // Inherits common backend options
}
```
**Field Explanations:**
- `type`: Must be `'redis'`.
- `url`: A full Redis connection string. If provided, `host`, `port`, etc., are ignored.
- `host`, `port`, `password`, `database`: Individual connection parameters. `host` is required if `url` is not provided.

**Example:**
```yaml
storage:
  cache:
    type: redis
    host: localhost
    port: 6379
    maxConnections: 50
```

---

### SQLite (`sqlite`)

A serverless, file-based SQL database engine, great for simple, persistent storage without needing a separate database server.

**TypeScript Interface:**
```typescript
export interface SqliteBackendConfig {
    type: 'sqlite';
    path?: string;     // Directory to store the DB file
    database?: string; // Filename for the database (e.g., "dexto.db")
    // Inherits common backend options
}
```

**Field Explanations:**
- `type`: Must be `'sqlite'`.
- `path`: The directory where the database file will be stored. If omitted, Dexto will use a default location.
- `database`: The name of the database file. Defaults to `dexto.db`.

**Example:**
```yaml
storage:
  database:
    type: sqlite
    database: my-agent.db
    path: /var/data/dexto
```

---

### PostgreSQL (`postgres`)

A powerful, open-source object-relational database system, suitable for production and large-scale deployments.

**TypeScript Interface:**
```typescript
export interface PostgresBackendConfig {
    type: 'postgres';
    url?: string; // e.g., "postgresql://user:pass@host:port/dbname"
    connectionString?: string; // Alternative to URL
    host?: string;
    port?: number;
    database?: string;
    password?: string;
    // Inherits common backend options
}
```
**Field Explanations:**
- `type`: Must be `'postgres'`.
- `url` or `connectionString`: A full PostgreSQL connection string.
- `host`, `port`, `database`, `password`: Individual connection parameters. `host` is required if a URL is not provided.

**Example:**
```yaml
storage:
  database:
    type: postgres
    host: db.example.com
    port: 5432
    database: dexto_prod
    user: dexto_user
    password: $DB_PASSWORD
    maxConnections: 20
    idleTimeoutMillis: 30000
```

## Configuration Examples

### Default: In-Memory Only
If you provide no storage configuration, Dexto defaults to using the `in-memory` backend for both cache and database.

```yaml
# No storage section needed for this default behavior
```
This is equivalent to:
```yaml
storage:
  cache:
    type: in-memory
  database:
    type: in-memory
```

### Production: Redis and PostgreSQL
A common production setup uses Redis for its speed as a cache and PostgreSQL for its reliability as a database.

```yaml
storage:
  cache:
    type: redis
    url: $REDIS_URL
    maxConnections: 100
    idleTimeoutMillis: 10000
  database:
    type: postgres
    connectionString: $POSTGRES_CONNECTION_STRING
    maxConnections: 25
    idleTimeoutMillis: 30000
```

### Simple Persistent: SQLite
For a simple setup that persists data across restarts without a full database server, use SQLite.

```yaml
storage:
  cache:
    type: in-memory # Keep cache in-memory for speed
  database:
    type: sqlite
    database: my-dexto-agent.sqlite
```

### Hybrid: Redis Cache with SQLite DB
For a single-instance production setup, this combines a fast Redis cache with a simple, persistent SQLite database.

```yaml
storage:
  cache:
    type: redis
    host: localhost
    port: 6379
  database:
    type: sqlite
    path: ./data/dexto.db
```

### Advanced Configuration
You can pass backend-specific parameters through the `options` field.

**Advanced Redis Example:**
```yaml
storage:
  cache:
    type: redis
    host: localhost
    port: 6379
    options:
      commandTimeout: 5000
      maxRetriesPerRequest: 3
```

**Advanced PostgreSQL Example:**
```yaml
storage:
  database:
    type: postgres
    connectionString: $POSTGRES_CONNECTION_STRING
    options:
      ssl: true
      application_name: dexto-agent
      statement_timeout: 30000
```

## Best Practices
- **Use Environment Variables:** Store sensitive information like passwords and connection strings in environment variables (`$VAR_NAME`).
- **Match Backend to Use Case:** Use `redis` or `in-memory` for caching and `postgres` or `sqlite` for persistent data.
- **Tune Connection Pools:** Adjust `maxConnections` and timeouts based on your expected load and database capacity.

For more information on how these storage layers are used within Dexto, see the [Storage Pattern Examples](https://github.com/truffle-ai/dexto/blob/main/feature-plans/settings-storage/storage-examples.md). 


================================================
FILE: docs/docs/guides/configuring-dexto/systemPrompt.md
================================================
---
sidebar_position: 2
sidebar_label: "System Prompt"
---

# System Prompt Configuration

Configure how your Dexto agent behaves and responds to users through system prompts.

## Overview

System prompts define your agent's personality, behavior, and capabilities. They can be simple strings for basic use cases or advanced configurations with multiple contributors for complex scenarios.

## Configuration Types

### Simple String Prompt

The simplest way to configure a system prompt:

```yaml
systemPrompt: |
  You are a helpful AI assistant with access to tools.
  Use these tools when appropriate to answer user queries.
  You can use multiple tools in sequence to solve complex problems.
  After each tool result, determine if you need more information or can provide a final answer.
```

### Advanced SystemPromptConfig

For more complex scenarios using structured contributors:

```yaml
systemPrompt:
  contributors:
    - id: default
      type: static
      priority: 1
      content: |
        You are a helpful AI assistant with access to tools.
        Use these tools when appropriate to answer user queries.
    - id: date-time
      type: dynamic
      priority: 2
      source: dateTime
    - id: custom-instructions
      type: static
      priority: 3
      enabled: true
      content: |
        Additional custom instructions for this specific agent.
```

## Contributors

### Static Contributors
- **Type:** `static`
- **Required:** `content` field
- **Use case:** Fixed text and consistent agent behavior instructions
- **Priority:** Contibutors are concatenated in ascending-piority order. `priority: 1` text appears before `priority:2` in the system prompt

```yaml
systemPrompt:
  contributors:
    - id: core-behavior
      type: static
      priority: 1
      content: |
        You are a professional assistant that provides accurate information.
        Always be helpful, respectful, and thorough in your responses.
```

### Dynamic Contributors
- **Type:** `dynamic`  
- **Required:** `source` field
- **Use case:** Dynamically generated content
- **Control:** Enable/disable with `enabled` field

```yaml
systemPrompt:
  contributors:
    - id: timestamp
      type: dynamic
      priority: 2
      source: dateTime
      enabled: true
```

#### Available Dynamic Sources
- **`dateTime`:** Automatically adds current date/time context
- **`resources`:** Automatically includes resources from connected MCP servers (disabled by default)

##### MCP Resources Contributor

The `resources` dynamic contributor automatically fetches and includes resources from all connected MCP servers. This is particularly useful when you have MCP servers that provide contextual information like documentation, database schemas, or configuration files.

**Key Features:**
- Automatically discovers all available resources from connected MCP servers
- Fetches and includes resource content in the system prompt
- Wraps each resource in XML tags with the resource URI for clear identification
- Handles errors gracefully (shows error message if resource can't be loaded)
- **Disabled by default** to avoid performance impact

**Example Usage:**
```yaml
systemPrompt:
  contributors:
    - id: main-prompt
      type: static
      priority: 1
      content: |
        You are a helpful assistant with access to project resources.
    
    - id: resources
      type: dynamic
      priority: 10
      source: resources
      enabled: true  # Enable MCP resources
```

**Output Format:**
The resources contributor wraps all resources in XML tags:
```xml
<resources>
<resource uri="file:///project/schema.sql">CREATE TABLE users...</resource>
<resource uri="config://app-settings">{"debug": true, ...}</resource>
</resources>
```

### File Contributors
- **Type:** `file`
- **Required:** `files` field
- **Use case:** Include content from external files in your system prompt
- **Supported formats:** Only `.md` and `.txt` files are supported
- **Control:** Enable/disable with `enabled` field

```yaml
systemPrompt:
  contributors:
    - id: project-context
      type: file
      priority: 10
      files:
        - ./README.md
        - ./docs/guidelines.md
        - ./CONTRIBUTING.txt
      options:
        includeFilenames: true
        separator: "\n\n---\n\n"
        errorHandling: "skip"
        maxFileSize: 50000
        includeMetadata: false
```

#### File Contributor Options
- **`files`** (array): List of file paths to include (only `.md` and `.txt` files)
- **`options.includeFilenames`** (boolean): Whether to include filename headers (default: `true`)
- **`options.separator`** (string): Text to separate multiple files (default: `"\n\n---\n\n"`)
- **`options.errorHandling`** (string): How to handle missing/invalid files - `"skip"`, `"error"` (default: `"skip"`)
- **`options.maxFileSize`** (number): Maximum file size in bytes (default: `100000`)
- **`options.includeMetadata`** (boolean): Include file size and modification time (default: `false`)

**Note:** Files are always read using UTF-8 encoding.

#### File Path Resolution

**Important:** File paths in file contributors are resolved **relative to the config filepath**, not the current working directory.

**Examples:**

If your config file is at `/project/agents/billing-agent.yml`:
- `docs/policies.md` â†’ `/project/agents/docs/policies.md`
- `./README.md` â†’ `/project/agents/README.md`
- `../README.md` â†’ `/project/README.md` (parent directory)
- `/absolute/path/file.md` â†’ `/absolute/path/file.md` (absolute paths unchanged)

**Best Practices:**
- Use relative paths for files near your config: `docs/guidelines.md`, `./README.md`
- Use parent directory paths for project root files: `../README.md`
- Use absolute paths for system-wide files: `/etc/project/config.md`
- Organize your documentation files in a predictable structure relative to your config file

**Example Directory Structure:**
```
project/
â”œâ”€â”€ README.md
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ support-agent.yml
â”‚   â””â”€â”€ docs/
â”‚       â”œâ”€â”€ guidelines.md
â”‚       â””â”€â”€ policies.md
â””â”€â”€ shared/
    â””â”€â”€ common-instructions.md
```

**Config file paths:**
```yaml
# In agents/support-agent.yml
systemPrompt:
  contributors:
    - id: project-readme
      type: file
      files:
        - ../README.md                    # Project root README
    - id: local-docs
      type: file
      files:
        - docs/guidelines.md              # Local to agent directory
        - docs/policies.md                # Local to agent directory
    - id: shared-instructions
      type: file
      files:
        - ../shared/common-instructions.md # Shared across agents
```

#### File Contributor Use Cases
- Include project documentation and guidelines
- Add code style guides and best practices
- Provide domain-specific knowledge from markdown files
- Include API documentation or specification files
- Add context-specific instructions for different projects

**Note:** File contributors only support `.md` and `.txt` files. Other file types will be skipped (or cause an error if `errorHandling: "error"` is set).

### Contributor Fields

- **`id`** (string): Unique identifier for the contributor
- **`type`** (`static` | `dynamic` | `file`): Type of contributor
- **`priority`** (number): Execution order (lower numbers first)
- **`enabled`** (boolean, optional): Whether contributor is active (default: true)
- **`content`** (string): Static content (required for `static` type)
- **`source`** (string): Dynamic source identifier (required for `dynamic` type)
- **`files`** (array): List of file paths to include (required for `file` type)
- **`options`** (object, optional): Configuration options for `file` type contributors

## Examples

### Production Agent
```yaml
systemPrompt:
  contributors:
    - id: core
      type: static
      priority: 1
      content: |
        You are a helpful AI assistant designed to work with tools and data.
        Always use available tools when they can help answer user questions.
        Provide clear, accurate, and helpful responses.
    - id: timestamp
      type: dynamic
      priority: 2
      source: dateTime
```

### Development Agent
```yaml
systemPrompt: |
  You are a helpful AI assistant running in development mode.
  Use the available tools to help users with their tasks.
  Be verbose in your explanations for debugging purposes.
```

### Customer Support Agent
```yaml
systemPrompt:
  contributors:
    - id: role
      type: static
      priority: 1
      content: |
        You are a customer support assistant for our software platform.
        Always be polite, professional, and solution-oriented.
    - id: context
      type: dynamic
      priority: 2
      source: dateTime
    - id: guidelines
      type: static
      priority: 3
      content: |
        - Always acknowledge the customer's concern
        - Provide step-by-step solutions when possible
        - Escalate complex technical issues to engineering team
```

### Complete Multi-Contributor Example
```yaml
systemPrompt:
  contributors:
    - id: core-behavior
      type: static
      priority: 1
      content: |
        You are a professional software development assistant.
        You help with coding, documentation, and project management.
        You have access to project files and MCP resources.
    
    - id: project-context
      type: file
      priority: 5
      files:
        - ./README.md
        - ./CONTRIBUTING.md
        - ./docs/architecture.md
      options:
        includeFilenames: true
        separator: "\n\n---\n\n"
        errorHandling: "skip"
        maxFileSize: 50000
    
    - id: current-time
      type: dynamic
      priority: 10
      source: dateTime
    
    - id: mcp-resources
      type: dynamic
      priority: 12
      source: resources
      enabled: true
    
    - id: additional-instructions
      type: static
      priority: 15
      content: |
        Always provide code examples when relevant.
        Reference the project documentation and available resources when making suggestions.
```

## Best Practices

1. **Keep it focused:** Clear, specific instructions work better than lengthy prompts
2. **Use priority ordering:** Structure contributors logically from general to specific
3. **Test behavior:** Validate that your prompt produces the desired agent behavior
4. **Dynamic content:** Use dynamic sources for time-sensitive or contextual information
5. **Modular approach:** Break complex prompts into separate contributors for easier management
6. **File contributors:** Use File contributors to include project-specific documentation and guidelines
7. **File format restrictions:** Remember that File contributors only support `.md` and `.txt` files
8. **Error handling:** Use `"skip"` error handling for optional files, `"error"` for required files
9. **File size limits:** Set appropriate `maxFileSize` limits to prevent memory issues with large files
10. **Path organization:** Organize documentation files relative to your config file for cleaner, more maintainable paths
11. **MCP resources:** Enable the `resources` contributor when you want to include context from MCP servers
12. **Performance considerations:** Be mindful that the `resources` contributor fetches all MCP resources on each prompt build




================================================
FILE: docs/docs/guides/configuring-dexto/toolConfirmation.md
================================================
---
sidebar_position: 6
sidebar_label: "Tool Confirmation"
---

# Tool Confirmation Configuration

Dexto's tool confirmation system controls how and when users are prompted to approve tool execution. This security feature ensures you maintain control over which tools your agent can execute and when.

## Overview

The `toolConfirmation` section in your `agent.yml` file configures:
- **Confirmation mode** - How tools are approved (interactive, auto-approve, auto-deny)
- **Timeout duration** - How long to wait for user response
- **Storage type** - Where to remember user approvals (persistent vs session-only)

## Configuration Schema

```yaml
toolConfirmation:
  mode: "event-based"           # Confirmation mode
  timeout: 30000               # Timeout in milliseconds (30 seconds)
  allowedToolsStorage: "storage" # Storage type for remembered approvals
```

All fields are optional with sensible defaults.

## Confirmation Modes

### `event-based` (Default)
Interactive confirmation via CLI prompts or WebUI dialogs.

```yaml
toolConfirmation:
  mode: "event-based"
  timeout: 30000               # Wait 30 seconds for user response
  allowedToolsStorage: "storage" # Remember approvals across sessions
```

**When to use:**
- Production environments where you want oversight
- Development with tool approval oversight
- Multi-user environments where different users need different permissions

#### Event Flow for Tool Confirmation

In event-based mode, Dexto uses an event-driven architecture where your UI layer must listen for confirmation requests and send back approval responses.

```mermaid
sequenceDiagram
    participant User as User
    participant UI as UI Layer (CLI/WebUI)
    participant Bus as AgentEventBus
    participant Provider as ConfirmationProvider
    participant LLM as LLM Service
    participant Tool as MCP Tool

    User->>LLM: "Run git status command"
    LLM->>Provider: requestConfirmation({toolName: "git_status", sessionId: "123"})
    Provider->>Bus: emit('dexto:toolConfirmationRequest', {executionId, toolName, args, sessionId})
    Bus->>UI: forward confirmation request
    
    UI->>User: Show confirmation dialog/prompt
    User->>UI: Approve/Deny + Remember choice
    UI->>Bus: emit('dexto:toolConfirmationResponse', {executionId, approved, rememberChoice, sessionId})
    Bus->>Provider: forward response
    
    alt Tool Approved
        Provider->>LLM: resolve(true)
        LLM->>Tool: execute git_status
        Tool->>LLM: return results
        LLM->>User: Display results
    else Tool Denied
        Provider->>LLM: resolve(false) or throw ToolExecutionDeniedError
        LLM->>User: "Tool execution was denied"
    end
```

#### Backend Event Expectations

When implementing a custom UI layer, your code needs to:

1. **Listen for confirmation requests:**
```typescript
agentEventBus.on('dexto:toolConfirmationRequest', (event: ToolConfirmationEvent) => {
  // event contains: toolName, args, executionId, sessionId, timestamp
  // Show UI confirmation to user
});
```

2. **Send confirmation responses:**
```typescript
// User approved - remember globally
agentEventBus.emit('dexto:toolConfirmationResponse', {
  executionId: event.executionId,
  approved: true,
  rememberChoice: true,    // Store approval for future use
  sessionId: event.sessionId  // Optional: scope to session
});

// User denied - don't remember
agentEventBus.emit('dexto:toolConfirmationResponse', {
  executionId: event.executionId,
  approved: false,
  rememberChoice: false
});
```

#### Event Interface Types

```typescript
interface ToolConfirmationEvent {
  toolName: string;          // e.g., "git_status"
  args: any;                // Tool arguments object
  description?: string;      // Tool description if available
  executionId: string;       // Unique ID for this request
  timestamp: Date;          // When request was made
  sessionId?: string;       // Session scope (optional)
}

interface ToolConfirmationResponse {
  executionId: string;       // Must match request executionId
  approved: boolean;         // true = approve, false = deny
  rememberChoice?: boolean;  // Store approval for future use
  sessionId?: string;       // Session scope (optional)
}
```

#### Timeout Behavior

- If no response is received within the configured timeout, the tool is automatically **denied**
- The timeout countdown is visible to users in supported UI layers
- Default timeout is 30 seconds, configurable via `timeout` field

### `auto-approve`
Automatically approve all tool executions without prompting.

```yaml
toolConfirmation:
  mode: "auto-approve"
  allowedToolsStorage: "memory" # Don't persist approvals
```

**When to use:**
- Development environments where speed is important
- Trusted automation scripts
- Testing scenarios where manual approval isn't practical

### `auto-deny`
Automatically deny all tool execution attempts.

```yaml
toolConfirmation:
  mode: "auto-deny"
```

**When to use:**
- High-security environments
- Read-only agent deployments
- Environments where tool execution should be completely disabled

## Storage Options

### `storage` (Default)
Approvals are stored persistently and remembered across sessions.

```yaml
toolConfirmation:
  allowedToolsStorage: "storage"
```

- **Pros:** Convenient - approve once, use across sessions
- **Cons:** Less secure - approvals persist until manually cleared
- **Best for:** Development and trusted environments

### `memory`
Approvals are stored only in memory and cleared when the session ends.

```yaml
toolConfirmation:
  allowedToolsStorage: "memory"
```

- **Pros:** More secure - approvals don't persist
- **Cons:** Need to re-approve tools in each session
- **Best for:** Security-sensitive environments

## Session-Aware Approvals

Tool approvals can be scoped to specific sessions or applied globally:

### **Session-Scoped Approvals**
Approvals stored with a specific `sessionId` only apply to that conversation session:

```typescript
// Session-scoped approval - only for session-123
allowedToolsProvider.allowTool('git_commit', 'session-123');
```

### **Global Approvals** 
Approvals stored without a `sessionId` apply to all sessions:

```typescript
// Global approval - applies everywhere
allowedToolsProvider.allowTool('git_status');
```

### **Approval Lookup Logic**
The system checks approvals in this order:
1. **Session-specific approvals** - Check if tool is approved for this specific session
2. **Global approvals** - Check if tool is approved globally
3. **Deny** - If not found in either scope, deny the tool

### **Implementation in Custom UIs**
When implementing tool confirmation in your UI, you can control the scope:

```typescript
// Store approval for current session only
agentEventBus.emit('dexto:toolConfirmationResponse', {
  executionId: event.executionId,
  approved: true,
  rememberChoice: true,
  sessionId: event.sessionId  // Scoped to this session
});

// Store approval globally (all sessions)
agentEventBus.emit('dexto:toolConfirmationResponse', {
  executionId: event.executionId,
  approved: true,
  rememberChoice: true
  // No sessionId = global scope
});
```

## Configuration Examples

### Development Environment
Fast development with minimal interruptions:

```yaml
toolConfirmation:
  mode: "auto-approve"
  allowedToolsStorage: "memory"
```

### Production Environment
Secure with persistent approvals for convenience:

```yaml
toolConfirmation:
  mode: "event-based"
  timeout: 60000               # 1 minute timeout
  allowedToolsStorage: "storage"
```

### High-Security Environment
No tool execution allowed:

```yaml
toolConfirmation:
  mode: "auto-deny"
```

### CI/CD Environment
Deny all tools in automated environments:

```yaml
toolConfirmation:
  mode: "auto-deny"
```

### Custom Timeout
Longer timeout for complex decisions:

```yaml
toolConfirmation:
  mode: "event-based"
  timeout: 120000              # 2 minute timeout
  allowedToolsStorage: "storage"
```

## Default Behavior

If you don't specify a `toolConfirmation` section, Dexto uses these defaults:

```yaml
toolConfirmation:
  mode: "event-based"           # Interactive confirmation
  timeout: 120000               # 2 minute timeout
  allowedToolsStorage: "storage" # Persistent storage
```

This provides a good balance of security and usability for most use cases.

## Integration for Custom UIs

When building custom applications with Dexto, you'll need to implement tool confirmation handling in your own UI layer. The core system provides the event infrastructure - you provide the user interface.

## Security Considerations

1. **Default to Secure**: The default mode requires explicit approval
2. **Timeout Protection**: Requests auto-deny after timeout to prevent hanging
3. **Session Isolation**: Session-scoped approvals don't affect other users
4. **Audit Trail**: All approval decisions are logged for review
5. **Granular Control**: Approve specific tools rather than blanket permissions

## Troubleshooting

### Tool Confirmations Not Working
- Check that your mode is set to `"event-based"`
- Verify timeout is reasonable (not too short)
- Ensure you have a UI layer (CLI or WebUI) to handle confirmations

### Approvals Not Persisting
- Check `allowedToolsStorage` is set to `"storage"`
- Verify your storage configuration is working
- Check that you're using "Remember globally" not "Remember for session"

### Tools Auto-Denying
- Check if mode is set to `"auto-deny"`
- Verify timeout isn't too short for your response time
- Check for session isolation issues if using session-scoped approvals

## Custom UI Integration Examples

### Direct AgentEventBus Integration
For custom applications using Dexto:

```typescript
import { DextoAgent, AgentEventBus } from 'dexto';

class CustomToolConfirmationHandler {
  constructor(private agentEventBus: AgentEventBus) {
    this.agentEventBus.on('dexto:toolConfirmationRequest', this.handleRequest.bind(this));
  }

  private async handleRequest(event: ToolConfirmationEvent) {
    // Implement your custom UI logic here
    const approved = await this.showYourCustomConfirmationUI(event);
    
    // Send response back to the framework
    this.agentEventBus.emit('dexto:toolConfirmationResponse', {
      executionId: event.executionId,
      approved,
      rememberChoice: approved, // Your logic for remembering choices
      sessionId: event.sessionId
    });
  }
  
  private async showYourCustomConfirmationUI(event: ToolConfirmationEvent): Promise<boolean> {
    // Your custom UI implementation:
    // - Mobile app confirmation dialog
    // - Voice confirmation system  
    // - Slack bot approval workflow
    // - Custom web interface
    // - etc.
    return true; // placeholder
  }
}

// In your application setup:
const agent = new DextoAgent(config);
await agent.start();

const confirmationHandler = new CustomToolConfirmationHandler(agent.agentEventBus);
```

### WebSocket Server Integration
For remote UIs communicating via WebSocket:

```typescript
import { WebSocketServer } from 'ws';

class ToolConfirmationWebSocketBridge {
  constructor(private agentEventBus: AgentEventBus, private wss: WebSocketServer) {
    // Forward framework events to WebSocket clients
    this.agentEventBus.on('dexto:toolConfirmationRequest', (event) => {
      this.broadcastToClients({
        type: 'toolConfirmationRequest',
        data: event
      });
    });

    // Handle responses from WebSocket clients
    this.wss.on('connection', (ws) => {
      ws.on('message', (data) => {
        const message = JSON.parse(data.toString());
        if (message.type === 'toolConfirmationResponse') {
          this.agentEventBus.emit('dexto:toolConfirmationResponse', message.data);
        }
      });
    });
  }
}
```

### REST API Integration
For HTTP-based confirmation workflows:

```typescript
import express from 'express';

class ToolConfirmationAPIHandler {
  private pendingConfirmations = new Map<string, {resolve: Function, reject: Function}>();

  constructor(private agentEventBus: AgentEventBus, private app: express.Application) {
    this.agentEventBus.on('dexto:toolConfirmationRequest', this.handleRequest.bind(this));
    this.setupRoutes();
  }

  private async handleRequest(event: ToolConfirmationEvent) {
    // Store pending confirmation
    const promise = new Promise<boolean>((resolve, reject) => {
      this.pendingConfirmations.set(event.executionId, { resolve, reject });
      
      // Auto-timeout
      setTimeout(() => {
        if (this.pendingConfirmations.has(event.executionId)) {
          this.pendingConfirmations.delete(event.executionId);
          reject(new Error('Confirmation timeout'));
        }
      }, 30000);
    });

    try {
      const approved = await promise;
      this.agentEventBus.emit('dexto:toolConfirmationResponse', {
        executionId: event.executionId,
        approved,
        sessionId: event.sessionId
      });
    } catch (error) {
      // Handle timeout or rejection
      this.agentEventBus.emit('dexto:toolConfirmationResponse', {
        executionId: event.executionId,
        approved: false,
        sessionId: event.sessionId
      });
    }
  }

  private setupRoutes() {
    // Endpoint for your custom UI to respond
    this.app.post('/api/tool-confirmation/:executionId', (req, res) => {
      const { executionId } = req.params;
      const { approved } = req.body;
      
      const pending = this.pendingConfirmations.get(executionId);
      if (pending) {
        this.pendingConfirmations.delete(executionId);
        pending.resolve(approved);
        res.json({ success: true });
      } else {
        res.status(404).json({ error: 'Confirmation not found or expired' });
      }
    });
  }
}
```

## Built-in Dexto UI Implementations

Dexto includes two built-in UI implementations for reference and immediate use:

### Tool Confirmation in Dexto CLI
The built-in CLI mode provides:
- Interactive arrow-key navigation (â†/â†’ to select, Enter to confirm)
- Visual confirmation with colored output
- Auto-timeout with denial for security
- Boxed confirmation dialogs with clear tool information

### Tool Confirmation in Dexto WebUI  
The built-in WebUI mode provides:
- Modal dialogs with approve/deny buttons
- "Remember my choice" checkbox with scope selection (session/global)
- Visual timeout countdown
- Security warnings for sensitive operations
- WebSocket-based real-time communication

These implementations serve as reference examples for building your own custom UIs.

## Related Configuration

Tool confirmation works with these other configuration sections:
- **[Storage](./storage)** - Required for persistent approval storage
- **[MCP Servers](../../mcp/connecting-servers)** - Defines which tools are available for confirmation
- **[Sessions](./sessions)** - Affects session-scoped approval behavior


================================================
FILE: docs/docs/guides/configuring-dexto/llm/configuration.md
================================================
---
sidebar_position: 1
---

# Configuration Reference

This page covers all the technical details of configuring LLMs in Dexto.

## Type Definition

```typescript
export type LLMConfig = {
    provider: string;
    model: string;
    apiKey: string;
    baseURL?: string;
    maxInputTokens?: number;
    maxOutputTokens?: number;
    temperature?: number;
    router?: 'vercel' | 'in-built';
    maxIterations?: number;
};

export type AgentConfig = {
    llm: LLMConfig;
    // ... other agent fields
};
```

## LLM Configuration Fields

### Required Fields

- **provider** (string): The LLM provider to use (e.g., `openai`, `anthropic`, `google`, `groq`, `cohere`)
- **model** (string): The model name (see [Providers Guide](./providers) for full list)
- **apiKey** (string): API key or environment variable (e.g., `$OPENAI_API_KEY`)

### Optional Fields

- **baseURL** (string): Custom API endpoint for OpenAI-compatible providers
- **maxInputTokens** (number): Maximum tokens for input context (when this is crossed, messages are compressed)
- **maxOutputTokens** (number): Maximum tokens for AI response generation
- **temperature** (number): Controls randomness in AI responses (0 = deterministic, 1 = very creative)
- **router** (string): Choose between `vercel` (default) or `in-built` routers
- **maxIterations** (number): Maximum number of tool execution iterations before stopping (prevents infinite loops)

## System Prompts

âš ï¸ **Important**: The `systemPrompt` field is configured at the agent level, not within the LLM configuration.

For detailed system prompt configuration, including simple strings and advanced contributor patterns, see the dedicated [System Prompt Configuration](../systemPrompt) guide.

## LLM Response Control

### Temperature Setting
Control the creativity/randomness of AI responses:

```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  temperature: 0.7  # 0 = deterministic, 1 = very creative
```

### Token Limits

**Input Token Control (maxInputTokens)**
- Controls when conversation history gets compressed/truncated
- Useful for managing long conversations
- Defaults to model's maximum context window

**Output Token Control (maxOutputTokens)**
- Limits how long the AI's responses can be
- Prevents excessively long responses
- Provider-specific limits may apply

```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  maxInputTokens: 100000   # Compress history when exceeding this
  maxOutputTokens: 4000    # Limit response length
  temperature: 0.7
```

## Provider Examples

### OpenAI Configuration
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  temperature: 0.7
  maxOutputTokens: 4000
```

### Anthropic Configuration
```yaml
llm:
  provider: anthropic
  model: claude-3-5-sonnet-20240620
  apiKey: $ANTHROPIC_API_KEY
  temperature: 0.7
  maxOutputTokens: 8000
```

### Cohere Configuration
```yaml
llm:
  provider: cohere
  model: command-r-plus
  apiKey: $COHERE_API_KEY
  temperature: 0.7
  maxOutputTokens: 4096
```

### Google Configuration
```yaml
llm:
  provider: google
  model: gemini-2.0-flash
  apiKey: $GOOGLE_GENERATIVE_AI_API_KEY
  temperature: 0.7
  maxOutputTokens: 8192
```

## Custom Providers

For OpenAI-compatible providers, you'll need additional configuration:

```yaml
llm:
  provider: openai
  model: your-custom-model
  apiKey: $YOUR_API_KEY
  baseURL: https://api.your-provider.com/v1
  maxInputTokens: 100000   # Required for custom providers
  maxOutputTokens: 4000
  temperature: 0.7
```

**Important Notes for Custom Providers:**
- Always set `provider: openai` for OpenAI-compatible APIs
- The `maxInputTokens` field is required when using `baseURL`
- Use `baseURL` to point to the custom endpoint

## Router Configuration

Dexto offers two router options:

### Vercel Router (Default)
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  router: vercel  # This is the default
```

**Benefits:**
- Optimized for performance and reliability
- Built-in error handling and retries
- Better streaming support

### In-built Router
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  router: in-built
```

**When to use:**
- Direct control over LLM communication
- Custom provider configurations
- Debugging provider issues
- **Required for GPT-5 models** (gpt-5, gpt-5-mini, gpt-5-nano)

> **Model-Specific Restrictions**: Some models have router restrictions. For example, GPT-5 models only support the `in-built` router. The system will automatically validate router compatibility and provide clear error messages if an incompatible router is selected.

## Complete Configuration Examples

### Production-Ready Configuration
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
  temperature: 0.3
  maxOutputTokens: 4000
```

### Local Development Configuration
```yaml
llm:
  provider: openai
  model: llama3.2
  apiKey: dummy
  baseURL: http://localhost:11434/v1
  maxInputTokens: 8000
  maxOutputTokens: 4000
  temperature: 0.7
  router: in-built
```

## Next Steps

- **Learn about providers**: Check the [Providers Guide](./providers) for specific setup instructions
- **Start building**: Head to [Building with Dexto](../../../tutorials/index.md) to put this configuration to use
- **Explore MCP**: Learn about [MCP Server Configuration](../../../mcp/connecting-servers) to add tools to your agents



================================================
FILE: docs/docs/guides/configuring-dexto/llm/index.md
================================================
---
sidebar_position: 2
---

# LLM Configuration

Large Language Models (LLMs) are the brain of your Dexto agents. This section covers everything you need to know about configuring LLMs for your agents.

## Overview

Dexto supports multiple LLM providers out-of-the-box via the Vercel AI SDK. You can also use any OpenAI SDK-compatible provider. You can easily switch between different models and providers without changing your application code.

## Quick Start

### Basic Configuration
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
```

### Environment Variables
Set API keys in your `.env` file:
```bash
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_GENERATIVE_AI_API_KEY=your_google_key
GROQ_API_KEY=your_groq_key
```

## What's in This Section

### [Configuration Reference](./configuration)
Complete guide to all LLM configuration options including:
- Required and optional fields
- Provider-specific options
- Advanced settings

### [Supported Providers](./providers)
Detailed guide to all supported LLM providers:
- **Built-in providers**: OpenAI, Anthropic, Google, Groq, Cohere
- **Custom providers**: Azure OpenAI, OpenRouter, Together.ai, local models
- **Setup instructions** for each provider
- **Supported models** and their capabilities

## Key Concepts

### Providers vs Models
- **Provider**: The service hosting the LLM (e.g., OpenAI, Anthropic)
- **Model**: The specific AI model to use (e.g., gpt-4.1-mini, claude-3-5-sonnet)

### System Prompts
System prompts define how your agent behaves. See the [System Prompt Configuration](../systemPrompt) guide for details on simple strings and advanced contributor configurations.

### Routers
Dexto uses routers to handle LLM requests:
- **Vercel router** (default): Optimized for performance and reliability
- **In-built router**: Direct communication with providers

## Next Steps

1. **New to LLMs?** Start with the [Configuration Reference](./configuration) to understand the basics
2. **Looking for a specific provider?** Check the [Providers Guide](./providers) for setup instructions
3. **Building an agent?** Head to [Building with Dexto](../../../tutorials/index.md) for implementation patterns 


================================================
FILE: docs/docs/guides/configuring-dexto/llm/providers.md
================================================
---
sidebar_position: 3
---

# Supported Providers

Dexto supports multiple LLM providers out-of-the-box, plus the ability to use any OpenAI SDK-compatible provider.

## Default Providers

### **OpenAI**
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini  # Default
  apiKey: $OPENAI_API_KEY
```

**Supported models**: `gpt-5`, `gpt-5-mini`, `gpt-5-nano`, `gpt-4.1`, `gpt-4.1-mini`, `gpt-4.1-nano`, `gpt-4o`, `gpt-4o-mini`, `o4-mini`, `o3`, `o3-mini`, `o1`

### **Anthropic**
```yaml
llm:
  provider: anthropic
  model: claude-4-sonnet-20250514 # Default
  apiKey: $ANTHROPIC_API_KEY
```

**Supported models**: `claude-4-opus-20250514`, `claude-4-sonnet-20250514`, `claude-3-7-sonnet-20250219`, `claude-3-5-sonnet-20240620`, `claude-3-haiku-20240307`, `claude-3-opus-20240229`, `claude-3-sonnet-20240229`

### **Google**
```yaml
llm:
  provider: google
  model: gemini-2.5-pro  # Default
  apiKey: $GOOGLE_GENERATIVE_AI_API_KEY
```

**Supported models**: `gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-2.0-flash`, `gemini-2.0-flash-lite`, `gemini-1.5-pro-latest`, `gemini-1.5-flash-latest`


### **xAI**
```yaml
llm:
  provider: xai
  model: grok-4  # Default
  apiKey: $XAI_API_KEY
```

**Supported models**: `grok-4`, `grok-3`, `grok-3-mini`

### **Groq**
```yaml
llm:
  provider: groq
  model: llama-3.3-70b-versatile  # Default
  apiKey: $GROQ_API_KEY
```

**Supported models**: `gemma-2-9b-it`, `llama-3.3-70b-versatile`

### **Cohere**
```yaml
llm:
  provider: cohere
  model: command-a-03-2025  # Default
  apiKey: $COHERE_API_KEY
```

**Supported models**: `command-a-03-2025, command-r-plus`, `command-r`, `command`, `command-light`


## OpenAI-Compatible Providers

You can use any provider that implements the OpenAI SDK interface by setting `provider: openai-compatible` and providing a custom `baseURL`:

```yaml
llm:
  provider: openai-compatible
  model: your-custom-model
  apiKey: $YOUR_API_KEY
  baseURL: https://api.your-provider.com/v1
  maxInputTokens: 100000  # Required for custom providers
```

### Popular Compatible Providers

#### **Local Models**
Run models locally using Ollama, LM Studio, or similar:

```yaml
llm:
  provider: openai-compatible
  model: gemma3n:e2b
  apiKey: dummy  # Required but ignored for local
  baseURL: http://localhost:11434/v1  # Ollama default
  maxInputTokens: 8000
```

**Popular local model options:**
- **Ollama**: Easy local model hosting
- **LM Studio**: User-friendly local interface
- **vLLM**: High-performance serving
- **TGI (Text Generation Inference)**: Hugging Face's serving solution

#### **Azure OpenAI**
```yaml
llm:
  provider: openai-compatible
  model: gpt-4
  apiKey: $AZURE_OPENAI_API_KEY
  baseURL: https://your-resource.openai.azure.com/openai/deployments/gpt-4
  maxInputTokens: 128000
```

**Setup notes:**
- Replace `your-resource` with your Azure resource name
- The model name should match your deployment name
- Supports all OpenAI models available in Azure

#### **OpenRouter**
Access 100+ models through one API:

```yaml
llm:
  provider: openai-compatible
  model: anthropic/claude-3.5-sonnet
  apiKey: $OPENROUTER_API_KEY
  baseURL: https://openrouter.ai/api/v1
  maxInputTokens: 200000
```

**Popular OpenRouter models:**
- `anthropic/claude-3.5-sonnet`
- `meta-llama/llama-3.1-405b-instruct`
- `google/gemini-pro-1.5`
- `mistralai/mistral-large`

#### **Together.ai**
```yaml
llm:
  provider: openai-compatible
  model: meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo
  apiKey: $TOGETHER_API_KEY
  baseURL: https://api.together.xyz/v1
  maxInputTokens: 8000
```

**Popular Together.ai models:**
- `meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo`
- `mistralai/Mixtral-8x7B-Instruct-v0.1`
- `NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO`

#### **Anyscale**
```yaml
llm:
  provider: openai-compatible
  model: meta-llama/Llama-2-70b-chat-hf
  apiKey: $ANYSCALE_API_KEY
  baseURL: https://api.endpoints.anyscale.com/v1
  maxInputTokens: 4000
```

#### **Perplexity**
```yaml
llm:
  provider: openai-compatible
  model: llama-3.1-sonar-huge-128k-online
  apiKey: $PERPLEXITY_API_KEY
  baseURL: https://api.perplexity.ai
  maxInputTokens: 128000
```

**Special feature**: Online models that can search the web in real-time.

## Environment Variables

Set API keys in your `.env` file:

```bash
# Built-in providers
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_GENERATIVE_AI_API_KEY=your_google_key
GROQ_API_KEY=your_groq_key
XAI_API_KEY=your_xai_key
COHERE_API_KEY=your_cohere_key

# Custom providers
OPENROUTER_API_KEY=your_openrouter_key
TOGETHER_API_KEY=your_together_key
AZURE_OPENAI_API_KEY=your_azure_key
ANYSCALE_API_KEY=your_anyscale_key
PERPLEXITY_API_KEY=your_perplexity_key
```

## Provider-Specific Features

### OpenAI
- **Function calling**: Excellent tool use capabilities
- **Streaming**: Real-time response streaming
- **Vision**: GPT-4o models support image inputs
- **JSON mode**: Structured output generation

### Anthropic
- **Large context**: Up to 200K tokens
- **Tool use**: Advanced function calling
- **Safety**: Built-in content filtering
- **Constitutional AI**: Helpful, harmless, honest responses

### Google
- **Multimodal**: Text, image, video, and audio inputs
- **Large context**: Up to 2M tokens
- **Fast inference**: Optimized for speed
- **Code generation**: Excellent programming capabilities

### Groq
- **Ultra-fast inference**: Fastest API responses
- **Cost-effective**: Competitive pricing
- **Open source models**: Access to Llama and other OSS models

### xAI
- **Grok models**: Access to xAI's Grok language models
- **State of the art**: Grok 4 is the leader in all benchmarks!
- **Real-time knowledge**: Trained on real-time data
- **Reasoning**: Strong performance on complex reasoning tasks

### Cohere
- **State-of-the-Art Performance**: Models like `Command A` (`command-a-03-2025`) excel at complex workflows, including Retrieval-Augmented Generation (RAG), tool use, and multilingual tasks. It is Cohere's most performant model with a 256k context window.
- **Optimized for Conversation**: Strong instruction-following and conversational capabilities suitable for chat applications.
- **Flexible and Scalable**: Offers a range of models, from the powerful `Command A` and `Command R+` to the fast and efficient `command-light`.

## Choosing the Right Provider

### For Development
- **OpenAI**: Best overall developer experience and documentation
- **Local models**: Free, private, and great for experimentation

### For Production
- **OpenAI**: Reliable, well-documented, extensive model selection
- **Anthropic**: Excellent for safety-critical applications
- **Google**: Best for multimodal and large context applications

### For Cost Optimization
- **Groq**: Fastest and often cheapest for compatible models
- **OpenRouter**: Compare prices across providers
- **Local hosting**: No per-token costs after setup

### For Privacy
- **Local models**: Complete data privacy
- **Azure OpenAI**: Enterprise-grade security and compliance

## Troubleshooting

### Common Issues

**Invalid API Key**
```yaml
# Make sure environment variable is set correctly
apiKey: $OPENAI_API_KEY  # Not: OPENAI_API_KEY
```

**Model Not Found**
- Check the model name exactly matches provider documentation
- Verify your API key has access to the requested model

**Rate Limiting**
- Built-in providers have automatic retry logic
- For custom providers, consider implementing retry logic

**Timeout Issues**
- Consider using a different model or provider
- Check your network connection and provider status

### Getting Help

1. **Check the model name**: Ensure it exactly matches the provider's documentation
2. **Verify API keys**: Make sure environment variables are properly set
3. **Test with curl**: Verify your API key works with direct API calls
4. **Check quotas**: Ensure you haven't exceeded rate limits or billing quotas

## Next Steps

- **Configure your chosen provider**: Use the [Configuration Reference](./configuration) for detailed setup
- **Start building**: Head to [Building with Dexto](../../../tutorials/index.md) to create your first agent
- **Add tools**: Learn about [MCP Server Configuration](../../../mcp/connecting-servers) to give your agent capabilities


================================================
FILE: docs/docs/mcp/connecting-servers.md
================================================
---
sidebar_position: 2
title: Configure MCP Connections
sidebar_label: "Configure Connections"
description: How to connect Dexto to MCP servers via stdio, http, and sse, with examples and best practices.
---

# Configuring MCP Connections

The `mcpServers` section defines the Model Context Protocol (MCP) servers that your Dexto Agent can use for tool execution.

Dexto supports three types of MCP server connections:
- **Local servers** (`stdio`) - Launch processes on your machine
- **Remote servers** (`sse`) - Connect via Server-Sent Events over HTTP
- **HTTP servers** (`http`) - Connect via streamable HTTP transport

## Local MCP Server (stdio)

Local MCP servers use the `stdio` type to launch a process on your machine. This is useful for integrating with local tools or scripts.

**TypeScript interface:**
```typescript
export interface StdioServerConfig {
    type: 'stdio';
    command: string;
    args: string[];
    env?: Record<string, string>;
    timeout?: number; // in milliseconds
    connectionMode?: 'strict' | 'lenient'; // defaults to 'lenient'
}
```

**Field explanations:**
- `type`: Must be `'stdio'` for local servers
- `command`: The shell command to launch the server (e.g., `node`, `npx`)
- `args`: Array of arguments for the command
- `env` (optional): Environment variables for the server process
- `timeout` (optional): Timeout in milliseconds for server startup or communication
- `connectionMode` (optional): Connection requirement mode - `'strict'` requires successful connection, `'lenient'` allows failures (defaults to `'lenient'`)

**Example:**
```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
    connectionMode: strict  # This server must connect successfully
  puppeteer:
    type: stdio
    command: node
    args:
      - dist/src/servers/puppeteerServer.js
    timeout: 30000
    connectionMode: lenient  # This server is optional
```

## Remote MCP Server (sse)

:::note
SSE is on the deprecation path. We recommend using the [`http`](#http-mcp-server-http) type instead.
:::

Remote MCP servers use the `sse` type to connect to a server over HTTP using Server-Sent Events. This is useful for cloud-hosted or remote tool integrations.

**TypeScript interface:**
```typescript
export interface SSEServerConfig {
    type: 'sse';
    url: string;
    headers?: Record<string, string>;
    timeout?: number; // in milliseconds
    connectionMode?: 'strict' | 'lenient'; // defaults to 'lenient'
}
```

**Field explanations:**
- `type`: Must be `'sse'` for Server-Sent Events servers
- `url`: The URL of the remote MCP server
- `headers` (optional): HTTP headers to send with the connection (e.g., for authentication)
- `timeout` (optional): Timeout in milliseconds for server communication
- `connectionMode` (optional): Connection requirement mode - `'strict'` requires successful connection, `'lenient'` allows failures (defaults to `'lenient'`)

**Example:**
```yaml
mcpServers:
  remote-llm:
    type: sse
    url: https://api.example.com/mcp-server
    headers:
      Authorization: Bearer $REMOTE_LLM_TOKEN
      User-Agent: Dexto/1.0
    timeout: 60000
```

## HTTP MCP Server (http)

HTTP MCP servers use the `http` type to connect via streamable HTTP transport. This provides a reliable HTTP-based connection for MCP servers that support this protocol.

**TypeScript interface:**
```typescript
export interface HttpServerConfig {
    type: 'http';
    baseUrl: string;
    headers?: Record<string, string>;
    timeout?: number; // in milliseconds
    connectionMode?: 'strict' | 'lenient'; // defaults to 'lenient'
}
```

**Field explanations:**
- `type`: Must be `'http'` for HTTP transport servers
- `baseUrl`: The base URL of the HTTP MCP server
- `headers` (optional): HTTP headers to send with requests (e.g., for authentication)
- `timeout` (optional): Timeout in milliseconds for server communication
- `connectionMode` (optional): Connection requirement mode - `'strict'` requires successful connection, `'lenient'` allows failures (defaults to `'lenient'`)

**Example:**
```yaml
mcpServers:
  api-server:
    type: http
    baseUrl: https://mcp.api.example.com
    headers:
      Authorization: Bearer $API_TOKEN
      Content-Type: application/json
    timeout: 45000
```

## Mixed Configuration Examples

### Example with all server types

```yaml
mcpServers:
  # Local filesystem access
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
    timeout: 30000

  # Remote SSE server
  remote-analytics:
    type: sse
    url: https://analytics.example.com/mcp-sse
    headers:
      Authorization: Bearer $ANALYTICS_TOKEN
    timeout: 60000

  # HTTP-based API server
  external-api:
    type: http
    baseUrl: https://api.external-service.com/mcp
    headers:
      Authorization: Bearer $EXTERNAL_API_TOKEN
      X-Client-Version: "1.0"
    timeout: 45000
```

### Example with environment variables

```yaml
mcpServers:
  database:
    type: stdio
    command: npx
    args:
      - -y
      - "@truffle-ai/database-server"
    env:
      DATABASE_URL: $DATABASE_URL
      LOG_LEVEL: info
    timeout: 30000

  cloud-service:
    type: http
    baseUrl: $CLOUD_SERVICE_URL
    headers:
      Authorization: Bearer $CLOUD_SERVICE_TOKEN
    timeout: 60000
```

## Server Selection Guidelines

| Server Type | Use Case | Pros | Cons |
|-------------|----------|------|------|
| **stdio** | Local tools, development, file operations | Fast, secure, full control | Requires local installation |
| **sse** | Real-time events, streaming data | Efficient for live updates | Limited to SSE-compatible servers |
| **http** | RESTful APIs, reliable connections | Widely supported, robust | May have higher latency |

## Connection Modes

Each MCP server can be configured with a `connectionMode` that determines how Dexto handles connection failures:

- **`strict`**: The server must connect successfully or Dexto will fail to start
- **`lenient`** (default): The server can fail to connect and Dexto will continue running

### Per-Server Configuration

```yaml
mcpServers:
  critical-database:
    type: stdio
    command: npx
    args: ["-y", "@truffle-ai/database-server"]
    connectionMode: strict  # Must connect or fail startup
  
  optional-analytics:
    type: http
    baseUrl: https://analytics.example.com/mcp
    connectionMode: lenient  # Can fail without breaking startup
```

### Global --strict Flag

You can override all server connection modes using the `--strict` CLI flag:

```bash
dexto --strict  # Makes ALL servers strict, regardless of config
```

This is useful for production environments where you want to ensure all configured servers are available.

## Best Practices

1. **Use environment variables** for sensitive data like API keys and tokens
2. **Set appropriate timeouts** based on expected server response times
3. **Group related servers** logically in your configuration
4. **Test server connections** during development with appropriate fallbacks
5. **Document server purposes** in comments for team collaboration
6. **Use `strict` mode for critical servers** that your agent depends on
7. **Use `lenient` mode for optional enhancements** like analytics or debugging tools

## Troubleshooting

### Common Issues

| Problem | Solution |
|---------|----------|
| `stdio` server fails to start | Check if command and args are correct, verify file paths |
| `sse` connection drops | Verify URL accessibility, check network/firewall settings |
| `http` server timeouts | Increase timeout value, verify server availability |
| Authentication failures | Verify tokens/credentials, check header format |

### Debug Tips

- Enable debug logging to see detailed connection attempts
- Test server URLs independently before adding to configuration
- Use shorter timeouts during development to fail fast
- Verify environment variables are properly set and accessible

## Additional Resources

- [Dexto GitHub repository examples](https://github.com/truffle-ai/dexto/tree/main/agents/examples) - More configuration examples
- [Model Context Protocol specification](https://spec.modelcontextprotocol.io/) - Official MCP documentation
- [Available MCP servers](https://github.com/modelcontextprotocol/servers) - Community-maintained server list

## Notes

- You can define as many servers as needed, each with a unique name
- Server names should be descriptive and follow consistent naming conventions
- Mixed server types can be used simultaneously in the same configuration
- All server types support optional timeout configuration for reliable operation 


================================================
FILE: docs/docs/mcp/dexto-as-mcp-server.md
================================================
---
sidebar_position: 3
title: Expose Dexto as an MCP Server
sidebar_label: "Expose Dexto as MCP Server"
description: Run Dexto as a local or remote MCP server for use in clients like Cursor or other MCP-compatible agents.
---

# Expose Dexto as an MCP Server

Dexto agents can act as Model Context Protocol (MCP) server, enabling external tools like Cursor/Claude Desktop or any MCP client to connect and interact with your Dexto agent.

This means you can even connect one Dexto agent to another Dexto agent!

The default Dexto agent has tools to access files and browse the web, but you can configure this too by changing the config file!

Check out our [Configuration guide](../guides/configuring-dexto/overview)

## Local MCP Server

### Setup in Cursor

1. **Create or edit your `.cursor/mcp.json` file:**

Use the default Dexto configuration
```json
{
  "mcpServers": {
    "dexto": {
      "command": "npx",
      "args": ["-y", "dexto", "--mode", "mcp"],
      "env": {
        "OPENAI_API_KEY": "your_openai_api_key"
      }
    }
  }
}
```

Using a custom Dexto configuration:
Note: if you use a different LLM in your config file, you will need to pass the appropriate environment variable for that provider.

```json
{
  "mcpServers": {
    "dexto": {
      "command": "npx",
      "args": ["-y", "dexto", "--mode", "mcp", "--agent", "path/to/your/agent.yml"],
      "env": {
        "OPENAI_API_KEY": "your_openai_api_key"
      }
    }
  }
}
```


2. **Restart Cursor**

### Using Dexto in Cursor

**Available Tools in Cursor:**
- `chat_with_agent`: Interact with Dexto AI agent

**Available Dexto tools:**

By default, Dexto CLI loads an AI agent that has tools to:
- browse the web
- search files on your local system

But you can customize the tools by using a custom Dexto agent configuration file. Check out our [Configuration guide](../guides/configuring-dexto/overview).

**Example Usage in Cursor:**

1. **Refactor a function:**
   ```bash
   Ask Dexto agent to help me refactor this function to be more efficient
   ```

2. **Get file analysis:**
   ```bash
   Ask Dexto agent to analyze the architecture of this project
   ```

3. **Browse the web:**
   ```bash
   Ask Dexto agent to search the web for soccer shoes under $100
   ```

4. **Any custom functionality:**
    You can configure your Dexto agent to have any other custom functionality by setting up your own config file and using it here. Check out our [Configuration guide](../guides/configuring-dexto/overview)

## Remote MCP Server

### Step 1: Start Dexto in Server Mode

```bash
# If installed globally
dexto --mode server

# Or via npx
npx dexto --mode server
```

**Options:**
```bash
# Custom port using environment variable
API_PORT=8080 dexto --mode server
# Or via npx
API_PORT=8080 npx dexto --mode server

# Custom port for network access
API_PORT=3001 dexto --mode server
# Or via npx
API_PORT=3001 npx dexto --mode server

# Enable debug logging
dexto --mode server --debug
# Or via npx
npx dexto --mode server --debug
```

### Step 2: Configure the Connection URL

**HTTP MCP Endpoint:**
```bash
http://localhost:3001/mcp
```

**For network access:**
```bash
http://YOUR_SERVER_IP:3001/mcp
```

### Remote Server in Cursor (WIP)
Cursor/Claude desktop don't support streamable http yet

## Troubleshooting

**Cursor not detecting MCP server:**
- Verify `.cursor/mcp.json` syntax is correct
- Restart Cursor after configuration changes
- Ensure dexto is installed and accessible
- Verify environment variables are set correctly

**Debug mode:**
```bash
# If installed globally
dexto --mode mcp --debug

# Or via npx
npx dexto --mode mcp --debug
``` 


================================================
FILE: docs/docs/mcp/grouping-servers.md
================================================
---
sidebar_position: 5
title: Aggregate Multiple MCP Servers
sidebar_label: "Aggregate Multiple Servers"
description: Use Dexto in MCP Tools Mode to aggregate tools from multiple MCP servers and expose them via a single local MCP endpoint.
---

# Aggregate Multiple MCP Servers

Dexto can operate in **MCP Tools Mode**, where it acts as a local tool aggregation server that groups MCP servers and re-exposes them all under 1 common MCP server. 

Unlike the regular MCP server mode where you interact with a Dexto AI agent, this mode provides direct access to the underlying tools without an AI intermediary.

This is useful when you want to:
- Access tools from multiple MCP servers through a single connection
- Group tools directly without AI agent processing
- Create a centralized tool hub for your development environment

## How It Works

In MCP Tools Mode, Dexto:
1. Connects to multiple MCP servers as configured
2. Aggregates all available tools from these servers
3. Exposes them directly as its own local MCP server
4. Acts as a pass-through for tool execution

## Configuration

### Step 1: Create a Dexto Configuration File

Create a `dexto-tools.yml` configuration file with the MCP servers you want to aggregate:

```yaml
# dexto-tools.yml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - "."
  
  puppeteer:
    type: stdio
    command: npx
    args:
      - -y
      - "@truffle-ai/puppeteer-server"
```

 - You don't need LLM configuration for tools mode
 - Only the mcpServers section is used

### Step 2: Setup in Cursor

Add the following to your `.cursor/mcp.json` file:

```json
{
  "mcpServers": {
    "dexto-tools": {
      "command": "npx",
      "args": [
        "-y", 
        "dexto", 
        "mcp",
        "--group-servers",
        "-a",
        "path/to/your/dexto-tools.yml"
      ]
    }
  }
}
```

Or use the default Dexto configuration

```json
{
  "mcpServers": {
    "dexto-tools": {
      "command": "npx",
      "args": [
        "-y", 
        "dexto", 
        "mcp",
        "--group-servers"
      ]
    }
  }
}
```

### Step 3: Restart Cursor

After adding the configuration, restart Cursor to load the new MCP server. 


================================================
FILE: docs/docs/mcp/mcp-manager.md
================================================
---
sidebar_position: 4
title: MCP Manager
description: Programmatic control for connecting to, aggregating, and executing tools across multiple MCP servers using the Dexto SDK.
---

# MCP Manager

The MCPManager is Dexto's powerful standalone utility for managing Model Context Protocol (MCP) servers. Use it in your own applications to connect, manage, and interact with multiple MCP servers without needing the full Dexto agent framework.

## Overview

The MCPManager provides:
- **Multi-server management**: Connect to multiple MCP servers simultaneously
- **Unified tool interface**: Access tools from all connected servers
- **Resource management**: Handle MCP resources and prompts
- **Connection pooling**: Automatic connection management and error handling
- **Type safety**: Full TypeScript support with comprehensive types

## Installation

```bash
npm install dexto
```

## Quick Start

```typescript
import { MCPManager } from 'dexto';

// Create manager instance
const manager = new MCPManager();

// Connect to an MCP server
await manager.connectServer('filesystem', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Get available tools
const tools = await manager.getAllTools();
console.log('Available tools:', Object.keys(tools));

// Execute a tool
const result = await manager.executeTool('readFile', { path: './README.md' });
console.log(result);
```

## Core Concepts

### MCP Servers

MCP servers are external processes that provide tools, resources, and prompts. Common types include:

- **File system servers**: Read/write files and directories
- **Web search servers**: Search the internet for information
- **Database servers**: Query and manage databases
- **API servers**: Interact with external APIs
- **Custom servers**: Your own domain-specific tools

### Connection Types

MCPManager supports three connection types:

- **`stdio`**: Most common, spawns a child process (e.g., Node.js packages)
- **`http`**: Connect to HTTP-based MCP servers
- **`sse`**: Server-sent events for real-time communication

### Tool Execution

Tools are functions provided by MCP servers. The manager:
1. Discovers all available tools from connected servers
2. Routes tool calls to the appropriate server
3. Handles confirmation prompts for sensitive operations
4. Returns structured results

## Common Usage Patterns

### File Operations

Perfect for automating file system tasks:

```typescript
const manager = new MCPManager();

await manager.connectServer('fs', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
});

// Read files
const packageJson = await manager.executeTool('readFile', { 
  path: './package.json' 
});

// List directory contents
const files = await manager.executeTool('listFiles', { 
  path: './src' 
});

// Write files
await manager.executeTool('writeFile', {
  path: './output.md',
  content: '# Generated Report\n\nSome content here...'
});
```

### Web Research

Integrate web search capabilities:

```typescript
await manager.connectServer('search', {
  type: 'stdio',
  command: 'npx',
  args: ['-y', 'tavily-mcp@0.1.3'],
  env: { TAVILY_API_KEY: process.env.TAVILY_API_KEY }
});

const results = await manager.executeTool('search', {
  query: 'Model Context Protocol specifications',
  max_results: 10
});
```

### Multi-Server Workflows

Combine multiple servers for complex tasks:

```typescript
// Initialize multiple servers at once
await manager.initializeFromConfig({
  filesystem: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
  },
  search: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', 'tavily-mcp@0.1.3'],
    env: { TAVILY_API_KEY: process.env.TAVILY_API_KEY }
  },
  git: {
    type: 'stdio',
    command: 'npx',
    args: ['-y', '@cyanheads/git-mcp-server'],
    env: {
        MCP_LOG_LEVEL: "info",
        GIT_SIGN_COMMITS: "false"
    }
  }
});

// Complex workflow using multiple tools
async function generateProjectReport() {
  const files = await manager.executeTool('listFiles', { path: './src' });
  const commits = await manager.executeTool('git_log', { limit: 10 });
  const research = await manager.executeTool('search', {
    query: 'project documentation best practices'
  });
  
  const report = `# Project Report
Files: ${files.length}
Recent commits: ${commits.length}
Research findings: ${research.length}`;
  
  await manager.executeTool('writeFile', {
    path: './PROJECT_REPORT.md',
    content: report
  });
}
```

## Integration Examples

### Express.js API

Create an API that exposes MCP tools:

```typescript
import express from 'express';
import { MCPManager } from 'dexto';

const app = express();
app.use(express.json());

const manager = new MCPManager();

// Wrap initialization and server start in an async IIFE
(async () => {
  try {
    await manager.initializeFromConfig({
      filesystem: {
        type: 'stdio',
        command: 'npx',
        args: ['-y', '@modelcontextprotocol/server-filesystem', '.']
      }
    });

    app.get('/api/tools', async (req, res) => {
      const tools = await manager.getAllTools();
      res.json({ tools: Object.keys(tools) });
    });

    app.post('/api/execute/:toolName', async (req, res) => {
      try {
        const { toolName } = req.params;
        const { args } = req.body;
        
        const result = await manager.executeTool(toolName, args);
        res.json({ success: true, result });
      } catch (error) {
        res.status(500).json({ 
          success: false, 
          error: error instanceof Error ? error.message : String(error)
        });
      }
    });

    // Only start the server after successful initialization
    app.listen(3000, () => {
      console.log('MCP API server running on port 3000');
    });
  } catch (error) {
    console.error(`Failed to initialize MCP manager: ${error instanceof Error ? error.message : String(error)}`);
    process.exit(1);
  }
})();
```

For detailed API reference, see the [MCPManager API documentation](/api/mcp-manager). ğŸ› ï¸

**Tool execution failures**
- Validate tool arguments match expected schema
- Check server logs for detailed error information 


================================================
FILE: docs/docs/mcp/overview.md
================================================
---
sidebar_position: 1
title: MCP Overview
description: Understand the Model Context Protocol (MCP), why it matters, and how Dexto integrates with MCP servers and tools.
---

# What is MCP?

The **Model Context Protocol (MCP)** is an open protocol created and maintained by Anthropic - [MCP github organization](https://github.com/modelcontextprotocol)

MCP defines how AI agents (like Dexto agents) can discover, connect to, and interact with external tools, services, and APIs in a standardized way.

## Why MCP Matters

- **Interoperability:** MCP provides a common language for agents and tools, making it easy to connect new services without custom integration code for each one.
- **Extensibility:** Anyone can build and share MCP-compatible tools, expanding what agents can do.
- **Modularity:** Tools are decoupled from the agent's core logic, so you can add, remove, or swap tools as needed.

## How Dexto Agents Use MCP

Dexto agents use MCP to:
- **Discover available tools:** MCP servers advertise what actions they support (e.g., read a file, send an email, browse the web).
- **Connect to tools:** Dexto agents communicate with MCP servers using a standard protocol (often over stdio, HTTP, or sockets).
- **Invoke tool actions:** When you give a command, Dexto selects the right tool(s) via MCP and orchestrates their use to fulfill your request.
- **Read server resources:** Dexto agents can read resources from the server, like files, databases, etc., and use that to reason about what to do next.

## Example: Registering a Tool via MCP

Suppose you want to add a filesystem tool. In your Dexto agent configuration file, you might specify:

```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
    connectionMode: strict  # Ensure this tool is always available
```

This tells your Dexto agent to connect to the filesystem MCP server, which then advertises its capabilities to the agent.

## Learn More

- [Model Context Protocol documentation](https://modelcontextprotocol.io/introduction)
- [MCP reference servers on GitHub](https://github.com/modelcontextprotocol/reference-servers)

MCP is a key part of what makes Dexto flexible, extensible, and able to automate across a wide range of tools and services. 

## Next steps

- [Configure Connections](./connecting-servers)
- [MCP Manager](./mcp-manager)
- [Aggregate Multiple Servers](./grouping-servers)
- [Expose Dexto as MCP Server](./dexto-as-mcp-server)


================================================
FILE: docs/docs/tutorials/advanced-patterns.md
================================================
---
sidebar_position: 4
---

# Advanced Patterns and Best Practices

Once you're comfortable with the basics, these patterns will help you build production-ready applications.

## Pattern 1: Specialized Agents

Instead of one do-everything agent, create specialized ones:

### Code Reviewer Agent
```yaml
# agents/code-reviewer.yml
systemPrompt: |
  You are a senior code reviewer. Focus on:
  - Code quality and best practices
  - Security vulnerabilities
  - Performance optimizations
  - Clear, actionable feedback
  
  When reviewing code:
  1. Read the entire file or section first
  2. Identify specific issues with line numbers
  3. Suggest concrete improvements
  4. Explain the reasoning behind your recommendations
  5. Prioritize security and maintainability

llm:
  provider: anthropic
  model: claude-3-5-sonnet-20240620
  apiKey: $ANTHROPIC_API_KEY

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
```

### Documentation Writer Agent
```yaml
# agents/documentation-writer.yml
systemPrompt: |
  You are a technical writer. Create clear, comprehensive documentation.
  
  Your documentation should:
  - Always include practical examples
  - Explain complex concepts simply
  - Use proper formatting and structure
  - Include troubleshooting sections
  - Consider different skill levels
  
  When writing docs:
  1. Start with a clear overview
  2. Provide step-by-step instructions
  3. Include code examples that work
  4. Add common pitfalls and solutions
  5. End with next steps or related topics

llm:
  provider: openai
  model: gpt-4.1
  apiKey: $OPENAI_API_KEY

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
```

### Using Specialized Agents
```typescript
// specialized-agents.ts
import { loadConfigFile, DextoAgent } from 'dexto';

class AgentOrchestrator {
  private codeReviewer: any;
  private docWriter: any;
  
  async initialize() {
    this.codeReviewer = new DextoAgent(
      await loadConfigFile('./agents/code-reviewer.yml')
    );
    await this.codeReviewer.start();
    
    this.docWriter = new DextoAgent(
      await loadConfigFile('./agents/documentation-writer.yml')
    );
    await this.docWriter.start();
  }
  
  async reviewCode(filePath: string) {
    return await this.codeReviewer.run(
      `Review the code in ${filePath}. Focus on security, performance, and best practices.`
    );
  }
  
  async generateDocs(filePath: string) {
    return await this.docWriter.run(
      `Create comprehensive documentation for the code in ${filePath}.`
    );
  }
  
  async fullCodeAudit(directory: string) {
    // First, review the code
    const review = await this.codeReviewer.run(
      `Perform a comprehensive code review of all files in ${directory}.`
    );
    
    // Then, generate updated documentation
    const docs = await this.docWriter.run(
      `Based on this code review: ${review}\n\nUpdate the documentation for ${directory}.`
    );
    
    return { review, docs };
  }
  
  async cleanup() {
    await this.codeReviewer.stop();
    await this.docWriter.stop();
  }
}
```

**Why this works:** Specialized agents give better results than generalists.

## Pattern 2: Smart Error Handling

### Retry Logic with Exponential Backoff
```typescript
async function safeAgentCall(agent: any, message: string, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const result = await agent.run(message);
      return result;
    } catch (error) {
      console.log(`Attempt ${attempt} failed: ${error.message}`);
      
      if (attempt === retries) {
        throw new Error(`Failed after ${retries} attempts: ${error.message}`);
      }
      
      // Exponential backoff: 1s, 2s, 4s
      const delay = 1000 * Math.pow(2, attempt - 1);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Circuit Breaker Pattern
```typescript
class CircuitBreaker {
  private failures = 0;
  private lastFailureTime = 0;
  private isOpen = false;
  
  constructor(
    private maxFailures = 5,
    private resetTimeout = 60000 // 1 minute
  ) {}
  
  async execute(fn: () => Promise<any>) {
    if (this.isOpen) {
      if (Date.now() - this.lastFailureTime > this.resetTimeout) {
        this.reset();
      } else {
        throw new Error('Circuit breaker is open');
      }
    }
    
    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  private onSuccess() {
    this.failures = 0;
    this.isOpen = false;
  }
  
  private onFailure() {
    this.failures++;
    this.lastFailureTime = Date.now();
    
    if (this.failures >= this.maxFailures) {
      this.isOpen = true;
    }
  }
  
  private reset() {
    this.failures = 0;
    this.isOpen = false;
  }
}

// Usage
const breaker = new CircuitBreaker();

async function callAgent(agent: any, message: string) {
  return await breaker.execute(async () => {
    return await agent.run(message);
  });
}
```

### Graceful Degradation
```typescript
class RobustAgent {
  constructor(
    private primaryAgent: any,
    private fallbackAgent?: any
  ) {}
  
  async run(message: string, options: { timeout?: number } = {}) {
    const timeout = options.timeout || 30000; // 30 seconds
    
    try {
      // Try primary agent with timeout
      const result = await Promise.race([
        this.primaryAgent.run(message),
        new Promise((_, reject) => 
          setTimeout(() => reject(new Error('Timeout')), timeout)
        )
      ]);
      
      return result;
    } catch (error) {
      console.warn(`Primary agent failed: ${error.message}`);
      
      // Fall back to simpler agent or cached response
      if (this.fallbackAgent) {
        console.log('Trying fallback agent...');
        return await this.fallbackAgent.run(message);
      }
      
      // Return helpful error message
      return "I'm experiencing technical difficulties. Please try again later or rephrase your request.";
    }
  }
}
```

**Why this matters:** LLM APIs can be unreliable. Graceful handling keeps your apps running.

## Pattern 3: Event-Driven Architecture

### Agent Event System
```typescript
import { EventEmitter } from 'events';

class SmartAgent extends EventEmitter {
  constructor(private agent: any) {
    super();
    this.setupEventHandlers();
  }
  
  setupEventHandlers() {
    // Track when tools are used
    this.agent.agentEventBus.on('llmservice:toolCall', (toolInfo: any) => {
      console.log(`ğŸ”§ Used tool: ${toolInfo.toolName}`);
      this.emit('toolUsed', toolInfo);
    });
    
    // Handle conversation resets
    this.agent.agentEventBus.on('dexto:conversationReset', () => {
      console.log('ğŸ”„ Conversation reset');
      this.emit('conversationReset');
    });
    
    // Track token usage
    this.agent.agentEventBus.on('llmservice:completion', (data: any) => {
      this.emit('tokensUsed', {
        inputTokens: data.usage?.prompt_tokens || 0,
        outputTokens: data.usage?.completion_tokens || 0,
        totalTokens: data.usage?.total_tokens || 0
      });
    });
  }
  
  async processTask(task: string) {
    console.log(`ğŸ“‹ Processing: ${task}`);
    this.emit('taskStarted', { task });
    
    try {
      const result = await this.agent.run(task);
      console.log(`âœ… Completed: ${task}`);
      this.emit('taskCompleted', { task, result });
      return result;
    } catch (error) {
      console.log(`âŒ Failed: ${task}`);
      this.emit('taskFailed', { task, error });
      throw error;
    }
  }
}
```

### Analytics and Monitoring
```typescript
class AgentAnalytics {
  private metrics = {
    totalRequests: 0,
    successfulRequests: 0,
    failedRequests: 0,
    totalTokens: 0,
    averageResponseTime: 0,
    toolUsage: new Map<string, number>()
  };
  
  constructor(agent: SmartAgent) {
    this.setupListeners(agent);
  }
  
  private setupListeners(agent: SmartAgent) {
    agent.on('taskStarted', ({ task }) => {
      this.metrics.totalRequests++;
    });
    
    agent.on('taskCompleted', ({ task, result }) => {
      this.metrics.successfulRequests++;
    });
    
    agent.on('taskFailed', ({ task, error }) => {
      this.metrics.failedRequests++;
    });
    
    agent.on('tokensUsed', ({ totalTokens }) => {
      this.metrics.totalTokens += totalTokens;
    });
    
    agent.on('toolUsed', ({ toolName }) => {
      const current = this.toolUsage.get(toolName) || 0;
      this.toolUsage.set(toolName, current + 1);
    });
  }
  
  getMetrics() {
    return {
      ...this.metrics,
      successRate: this.metrics.totalRequests > 0 
        ? this.metrics.successfulRequests / this.metrics.totalRequests 
        : 0,
      toolUsage: Object.fromEntries(this.metrics.toolUsage)
    };
  }
  
  reset() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalTokens: 0,
      averageResponseTime: 0,
      toolUsage: new Map()
    };
  }
}
```

**Why this helps:** Events let you build reactive applications that respond to what's happening.

## Pattern 4: Performance Optimization

### Request Batching
```typescript
class BatchedAgent {
  private pendingRequests: Array<{
    message: string;
    resolve: (value: any) => void;
    reject: (error: any) => void;
  }> = [];
  
  private batchTimer: NodeJS.Timeout | null = null;
  
  constructor(
    private agent: any,
    private batchSize = 5,
    private batchDelay = 100 // milliseconds
  ) {}
  
  async run(message: string): Promise<string> {
    return new Promise((resolve, reject) => {
      this.pendingRequests.push({ message, resolve, reject });
      
      if (this.pendingRequests.length >= this.batchSize) {
        this.processBatch();
      } else if (!this.batchTimer) {
        this.batchTimer = setTimeout(() => this.processBatch(), this.batchDelay);
      }
    });
  }
  
  private async processBatch() {
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
      this.batchTimer = null;
    }
    
    const batch = this.pendingRequests.splice(0);
    if (batch.length === 0) return;
    
    try {
      // Process requests in parallel
      const results = await Promise.allSettled(
        batch.map(({ message }) => this.agent.run(message))
      );
      
      // Resolve/reject individual promises
      results.forEach((result, index) => {
        if (result.status === 'fulfilled') {
          batch[index].resolve(result.value);
        } else {
          batch[index].reject(result.reason);
        }
      });
    } catch (error) {
      // Reject all if batch processing fails
      batch.forEach(({ reject }) => reject(error));
    }
  }
}
```

### Caching
```typescript
class CachedAgent {
  private cache = new Map<string, { result: any; timestamp: number }>();
  
  constructor(
    private agent: any,
    private cacheTTL = 5 * 60 * 1000 // 5 minutes
  ) {}
  
  async run(message: string): Promise<string> {
    const key = this.generateCacheKey(message);
    const cached = this.cache.get(key);
    
    if (cached && Date.now() - cached.timestamp < this.cacheTTL) {
      console.log('Cache hit');
      return cached.result;
    }
    
    const result = await this.agent.run(message);
    
    this.cache.set(key, {
      result,
      timestamp: Date.now()
    });
    
    return result;
  }
  
  private generateCacheKey(message: string): string {
    // Simple hash function for cache key
    return Buffer.from(message).toString('base64');
  }
  
  clearCache() {
    this.cache.clear();
  }
}
```

## Pattern 5: Multi-Agent Coordination

```typescript
class AgentWorkflow {
  private agents = new Map<string, any>();
  
  async addAgent(name: string, configPath: string) {
    const config = await loadConfigFile(configPath);
    const agent = new DextoAgent(config);
    await agent.start();
    this.agents.set(name, agent);
  }
  
  async executeWorkflow(steps: Array<{
    agent: string;
    task: string;
    dependencies?: string[];
  }>) {
    const results = new Map<string, any>();
    
    for (const step of steps) {
      // Wait for dependencies
      if (step.dependencies) {
        await this.waitForDependencies(step.dependencies, results);
      }
      
      const agent = this.agents.get(step.agent);
      if (!agent) {
        throw new Error(`Agent ${step.agent} not found`);
      }
      
      // Include dependency results in task
      let task = step.task;
      if (step.dependencies) {
        const depResults = step.dependencies.map(dep => results.get(dep)).join('\n\n');
        task = `${task}\n\nPrevious results:\n${depResults}`;
      }
      
      const result = await agent.run(task);
      results.set(step.agent, result);
    }
    
    return results;
  }
  
  private async waitForDependencies(dependencies: string[], results: Map<string, any>) {
    // In a real implementation, this would handle async dependencies
    for (const dep of dependencies) {
      if (!results.has(dep)) {
        throw new Error(`Dependency ${dep} not satisfied`);
      }
    }
  }
  
  async cleanup() {
    for (const [name, agent] of this.agents) {
      await agent.stop();
    }
    this.agents.clear();
  }
}

// Usage
const workflow = new AgentWorkflow();
await workflow.addAgent('analyzer', './agents/code-analyzer.yml');
await workflow.addAgent('reviewer', './agents/code-reviewer.yml');
await workflow.addAgent('documenter', './agents/documentation-writer.yml');

const results = await workflow.executeWorkflow([
  {
    agent: 'analyzer',
    task: 'Analyze the codebase structure and identify key components.'
  },
  {
    agent: 'reviewer',
    task: 'Review the code for quality and security issues.',
    dependencies: ['analyzer']
  },
  {
    agent: 'documenter',
    task: 'Create comprehensive documentation based on the analysis and review.',
    dependencies: ['analyzer', 'reviewer']
  }
]);

// Clean up when done
await workflow.cleanup();
```

## What You've Learned

These advanced patterns give you:
- âœ… **Specialized agents** for better results
- âœ… **Robust error handling** for production reliability
- âœ… **Event-driven architecture** for reactive applications
- âœ… **Performance optimization** for scale
- âœ… **Multi-agent coordination** for complex workflows

## Next Steps

You're now equipped with production-ready patterns! Here's what to explore next:

- **Deploy your application**: Check out the [Deployment Guide](../guides/deployment.md) for deployment and scaling guidance
- **Join the community**: Share your patterns and learn from others in our [Discord](https://discord.gg/GFzWFAAZcm)
- **Contribute back**: Help improve Dexto by sharing your experiences and patterns

You're ready to build enterprise-grade AI applications! ğŸš€ 


================================================
FILE: docs/docs/tutorials/backend-server.md
================================================
---
sidebar_position: 2
---

# React Chat App using Dexto

When you run `dexto --mode web`, you get a powerful backend server with REST APIs and WebSocket support. Let's build a React chat application step by step, introducing each API capability as we go.

## Available Dexto Server APIs

When Dexto runs in web mode, it provides these endpoints:

- **`POST /api/message-sync`** - Send message and get complete response
- **`POST /api/message`** - Send message asynchronously (use WebSocket for response)
- **`POST /api/reset`** - Reset conversation history
- **`POST /api/connect-server`** - Dynamically add new MCP servers
- **`GET /api/mcp/servers`** - List connected servers
- **`GET /api/mcp/servers/:id/tools`** - List tools for a server
- **`POST /api/mcp/servers/:id/tools/:tool/execute`** - Execute specific tools
- **WebSocket at `/`** - Real-time streaming responses

Let's start simple and build up our React app layer by layer.

## Layer 1: Basic Synchronous Chat

Start with the simplest possible chat interface using the synchronous API:

```typescript
// components/BasicChat.tsx
import React, { useState } from 'react';

interface Message {
  id: string;
  content: string;
  sender: 'user' | 'agent';
  timestamp: Date;
}

export const BasicChat: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentInput, setCurrentInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  const sendMessage = async () => {
    if (!currentInput.trim()) return;

    // Add user message
    const userMessage: Message = {
      id: Date.now().toString(),
      content: currentInput,
      sender: 'user',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);
    setCurrentInput('');
    setIsLoading(true);

    try {
      // Call Dexto's synchronous API
      const response = await fetch('http://localhost:3001/api/message-sync', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: currentInput })
      });

      if (response.ok) {
        const result = await response.json();
        
        // Add agent response
        const agentMessage: Message = {
          id: (Date.now() + 1).toString(),
          content: result.response,
          sender: 'agent',
          timestamp: new Date()
        };
        setMessages(prev => [...prev, agentMessage]);
      } else {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
    } catch (error) {
      console.error('Error sending message:', error);
      // Add error message
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        content: `Error: ${error.message}`,
        sender: 'agent',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-screen max-w-2xl mx-auto p-4">
      {/* Header */}
      <div className="mb-4 p-4 bg-blue-50 rounded">
        <h1 className="text-2xl font-bold">Dexto Chat - Basic Version</h1>
        <p className="text-sm text-gray-600">Using synchronous API</p>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto space-y-4 mb-4">
        {messages.map(message => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                message.sender === 'user'
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-200 text-gray-800'
              }`}
            >
              <p className="whitespace-pre-wrap">{message.content}</p>
              <div className="text-xs opacity-70 mt-1">
                {message.timestamp.toLocaleTimeString()}
              </div>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="flex justify-start">
            <div className="bg-gray-200 text-gray-800 px-4 py-2 rounded-lg animate-pulse">
              ğŸ¤” Thinking...
            </div>
          </div>
        )}
      </div>

      {/* Input */}
      <div className="flex gap-2">
        <input
          type="text"
          value={currentInput}
          onChange={(e) => setCurrentInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && !isLoading && sendMessage()}
          placeholder="Type your message..."
          className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
          disabled={isLoading}
        />
        <button
          onClick={sendMessage}
          disabled={isLoading || !currentInput.trim()}
          className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
        >
          {isLoading ? '...' : 'Send'}
        </button>
      </div>
    </div>
  );
};
```

**What we've learned:**
- Basic API communication with Dexto
- Simple request/response pattern
- Error handling basics

## Layer 2: Add Real-time Streaming

Now let's add WebSocket support for real-time streaming responses:

```typescript
// components/StreamingChat.tsx
import React, { useState, useEffect, useRef } from 'react';

interface Message {
  id: string;
  content: string;
  sender: 'user' | 'agent';
  timestamp: Date;
  isStreaming?: boolean;
}

export const StreamingChat: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentInput, setCurrentInput] = useState('');
  const [isConnected, setIsConnected] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);

  // WebSocket connection
  useEffect(() => {
    const connectWebSocket = () => {
      const ws = new WebSocket('ws://localhost:3001/');
      wsRef.current = ws;

      ws.onopen = () => {
        setIsConnected(true);
        console.log('ğŸŸ¢ Connected to Dexto');
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleDextoEvent(data);
      };

      ws.onclose = () => {
        setIsConnected(false);
        console.log('ğŸ”´ Disconnected from Dexto');
        // Auto-reconnect after 3 seconds
        setTimeout(connectWebSocket, 3000);
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
      };
    };

    connectWebSocket();

    return () => {
      wsRef.current?.close();
    };
  }, []);

  const handleDextoEvent = (data: any) => {
    switch (data.event) {
      case 'thinking':
        // Agent started thinking
        setMessages(prev => [
          ...prev,
          {
            id: Date.now().toString(),
            content: 'ğŸ¤” Thinking...',
            sender: 'agent',
            timestamp: new Date(),
            isStreaming: true
          }
        ]);
        break;

      case 'chunk':
        // Streaming content chunk
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          
          if (lastMessage && lastMessage.sender === 'agent' && lastMessage.isStreaming) {
            // Replace "Thinking..." with actual content or append to existing content
            if (lastMessage.content === 'ğŸ¤” Thinking...') {
              lastMessage.content = data.data.content;
            } else {
              lastMessage.content += data.data.content;
            }
          } else {
            // Create new streaming message
            newMessages.push({
              id: Date.now().toString(),
              content: data.data.content,
              sender: 'agent',
              timestamp: new Date(),
              isStreaming: true
            });
          }
          
          return newMessages;
        });
        break;

      case 'response':
        // Streaming complete
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          
          if (lastMessage && lastMessage.sender === 'agent' && lastMessage.isStreaming) {
            lastMessage.isStreaming = false;
            lastMessage.content = data.data.content;
          }
          
          return newMessages;
        });
        break;

      case 'error':
        setMessages(prev => [
          ...prev,
          {
            id: Date.now().toString(),
            content: `âŒ Error: ${data.data.message}`,
            sender: 'agent',
            timestamp: new Date()
          }
        ]);
        break;
    }
  };

  const sendMessage = async () => {
    if (!currentInput.trim() || !isConnected) return;

    // Add user message
    const userMessage: Message = {
      id: Date.now().toString(),
      content: currentInput,
      sender: 'user',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);

    // Send via WebSocket for streaming response
    wsRef.current?.send(JSON.stringify({
      type: 'message',
      content: currentInput
    }));

    setCurrentInput('');
  };

  return (
    <div className="flex flex-col h-screen max-w-2xl mx-auto p-4">
      {/* Header */}
      <div className="mb-4 p-4 bg-blue-50 rounded">
        <h1 className="text-2xl font-bold">Dexto Chat - Streaming Version</h1>
        <div className="flex items-center gap-2">
          <span className={`w-3 h-3 rounded-full ${isConnected ? 'bg-green-500' : 'bg-red-500'}`}></span>
          <span className="text-sm text-gray-600">
            {isConnected ? 'Connected to Dexto' : 'Connecting...'}
          </span>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto space-y-4 mb-4">
        {messages.map(message => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                message.sender === 'user'
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-200 text-gray-800'
              } ${message.isStreaming ? 'animate-pulse border-2 border-blue-300' : ''}`}
            >
              <p className="whitespace-pre-wrap">{message.content}</p>
              <div className="text-xs opacity-70 mt-1">
                {message.timestamp.toLocaleTimeString()}
                {message.isStreaming && ' â€¢ Streaming...'}
              </div>
            </div>
          </div>
        ))}
      </div>

      {/* Input */}
      <div className="flex gap-2">
        <input
          type="text"
          value={currentInput}
          onChange={(e) => setCurrentInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="Type your message..."
          className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
          disabled={!isConnected}
        />
        <button
          onClick={sendMessage}
          disabled={!isConnected || !currentInput.trim()}
          className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
        >
          Send
        </button>
      </div>
    </div>
  );
};
```

**What we've added:**
- WebSocket connection management
- Real-time streaming responses
- Connection status indicator
- Auto-reconnection logic

## Layer 3: Add Server Management

Now let's add the ability to see and manage MCP servers:

```typescript
// components/ServerManagementChat.tsx
import React, { useState, useEffect, useRef } from 'react';

interface Message {
  id: string;
  content: string;
  sender: 'user' | 'agent';
  timestamp: Date;
  isStreaming?: boolean;
}

interface Server {
  id: string;
  name: string;
  status: string;
}

export const ServerManagementChat: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentInput, setCurrentInput] = useState('');
  const [isConnected, setIsConnected] = useState(false);
  const [servers, setServers] = useState<Server[]>([]);
  const [showServerPanel, setShowServerPanel] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);

  // WebSocket connection (same as Layer 2)
  useEffect(() => {
    const connectWebSocket = () => {
      const ws = new WebSocket('ws://localhost:3001/');
      wsRef.current = ws;

      ws.onopen = () => {
        setIsConnected(true);
        fetchServers(); // Fetch servers when connected
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleDextoEvent(data);
      };

      ws.onclose = () => {
        setIsConnected(false);
        setTimeout(connectWebSocket, 3000);
      };
    };

    connectWebSocket();
    return () => wsRef.current?.close();
  }, []);

  // Fetch available servers
  const fetchServers = async () => {
    try {
      const response = await fetch('http://localhost:3001/api/mcp/servers');
      if (response.ok) {
        const data = await response.json();
        setServers(data.servers);
      }
    } catch (error) {
      console.error('Failed to fetch servers:', error);
    }
  };

  // Add a new server
  const addServer = async () => {
    const name = prompt('Server name (e.g., "my-tool"):');
    const command = prompt('Command (e.g., "npx"):');
    const argsInput = prompt('Arguments (comma-separated, e.g., "-y, @company/tool-server"):');
    
    if (!name || !command) return;

    const args = argsInput ? argsInput.split(',').map(s => s.trim()) : [];

    try {
      const response = await fetch('http://localhost:3001/api/connect-server', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          name,
          config: {
            type: 'stdio',
            command,
            args
          }
        })
      });

      if (response.ok) {
        await fetchServers(); // Refresh server list
        alert(`âœ… Successfully connected ${name}!`);
      } else {
        const error = await response.text();
        alert(`âŒ Failed to connect server: ${error}`);
      }
    } catch (error) {
      console.error('Error connecting server:', error);
      alert(`âŒ Error: ${error.message}`);
    }
  };

  const handleDextoEvent = (data: any) => {
    switch (data.event) {
      case 'thinking':
        setMessages(prev => [...prev, {
          id: Date.now().toString(),
          content: 'ğŸ¤” Thinking...',
          sender: 'agent',
          timestamp: new Date(),
          isStreaming: true
        }]);
        break;

      case 'chunk':
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          
          if (lastMessage && lastMessage.sender === 'agent' && lastMessage.isStreaming) {
            if (lastMessage.content === 'ğŸ¤” Thinking...') {
              lastMessage.content = data.data.content;
            } else {
              lastMessage.content += data.data.content;
            }
          }
          return newMessages;
        });
        break;

      case 'toolCall':
        // Show when agent uses a tool
        setMessages(prev => [...prev, {
          id: Date.now().toString(),
          content: `ğŸ”§ Using tool: ${data.data.toolName}`,
          sender: 'agent',
          timestamp: new Date()
        }]);
        break;

      case 'response':
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          
          if (lastMessage && lastMessage.sender === 'agent' && lastMessage.isStreaming) {
            lastMessage.isStreaming = false;
            lastMessage.content = data.data.content;
          }
          return newMessages;
        });
        break;
    }
  };

  const sendMessage = async () => {
    if (!currentInput.trim() || !isConnected) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      content: currentInput,
      sender: 'user',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);

    wsRef.current?.send(JSON.stringify({
      type: 'message',
      content: currentInput
    }));

    setCurrentInput('');
  };

  return (
    <div className="flex flex-col h-screen max-w-4xl mx-auto p-4">
      {/* Header */}
      <div className="mb-4 p-4 bg-blue-50 rounded">
        <div className="flex justify-between items-center">
          <div>
            <h1 className="text-2xl font-bold">Dexto Chat - With Server Management</h1>
            <div className="flex items-center gap-2">
              <span className={`w-3 h-3 rounded-full ${isConnected ? 'bg-green-500' : 'bg-red-500'}`}></span>
              <span className="text-sm text-gray-600">
                {isConnected ? 'Connected to Dexto' : 'Connecting...'}
              </span>
            </div>
          </div>
          <div className="flex gap-2">
            <button
              onClick={() => setShowServerPanel(!showServerPanel)}
              className="px-3 py-1 bg-gray-500 text-white rounded hover:bg-gray-600"
            >
              {showServerPanel ? 'Hide' : 'Show'} Servers
            </button>
            <button
              onClick={addServer}
              className="px-3 py-1 bg-green-500 text-white rounded hover:bg-green-600"
            >
              Add Server
            </button>
          </div>
        </div>
      </div>

      {/* Server Panel */}
      {showServerPanel && (
        <div className="mb-4 p-3 bg-gray-50 rounded">
          <h3 className="font-semibold mb-2">Connected Servers ({servers.length}):</h3>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
            {servers.map(server => (
              <div key={server.id} className="flex justify-between items-center p-2 bg-white rounded border">
                <span className="font-medium">{server.name}</span>
                <span className={`px-2 py-1 rounded text-xs ${
                  server.status === 'connected' 
                    ? 'bg-green-100 text-green-800' 
                    : 'bg-red-100 text-red-800'
                }`}>
                  {server.status}
                </span>
              </div>
            ))}
            {servers.length === 0 && (
              <div className="col-span-2 text-gray-500 text-center py-4">
                No servers connected. Click "Add Server" to connect one!
              </div>
            )}
          </div>
        </div>
      )}

      {/* Messages */}
      <div className="flex-1 overflow-y-auto space-y-4 mb-4">
        {messages.map(message => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                message.sender === 'user'
                  ? 'bg-blue-500 text-white'
                  : message.content.startsWith('ğŸ”§')
                  ? 'bg-purple-100 text-purple-800'
                  : 'bg-gray-200 text-gray-800'
              } ${message.isStreaming ? 'animate-pulse border-2 border-blue-300' : ''}`}
            >
              <p className="whitespace-pre-wrap">{message.content}</p>
              <div className="text-xs opacity-70 mt-1">
                {message.timestamp.toLocaleTimeString()}
                {message.isStreaming && ' â€¢ Streaming...'}
              </div>
            </div>
          </div>
        ))}
      </div>

      {/* Input */}
      <div className="flex gap-2">
        <input
          type="text"
          value={currentInput}
          onChange={(e) => setCurrentInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="Type your message..."
          className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
          disabled={!isConnected}
        />
        <button
          onClick={sendMessage}
          disabled={!isConnected || !currentInput.trim()}
          className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
        >
          Send
        </button>
      </div>
    </div>
  );
};
```

**What we've added:**
- Server listing and management
- Dynamic server connection
- Tool usage indicators
- Collapsible server panel

## Layer 4: Add Direct Tool Execution

Finally, let's add the ability to execute tools directly:

```typescript
// Add this to the previous component or create AdvancedChat.tsx

const [availableTools, setAvailableTools] = useState<Record<string, any[]>>({});
const [showToolPanel, setShowToolPanel] = useState(false);

// Fetch tools for each server
const fetchServerTools = async (serverId: string) => {
  try {
    const response = await fetch(`http://localhost:3001/api/mcp/servers/${serverId}/tools`);
    if (response.ok) {
      const data = await response.json();
      setAvailableTools(prev => ({
        ...prev,
        [serverId]: data.tools
      }));
    }
  } catch (error) {
    console.error(`Failed to fetch tools for ${serverId}:`, error);
  }
};

// Execute a tool directly
const executeTool = async (serverId: string, toolName: string) => {
  const args = prompt(`Enter arguments for ${toolName} (JSON format):`);
  let parsedArgs = {};
  
  if (args) {
    try {
      parsedArgs = JSON.parse(args);
    } catch {
      alert('Invalid JSON format');
      return;
    }
  }

  try {
    const response = await fetch(
      `http://localhost:3001/api/mcp/servers/${serverId}/tools/${toolName}/execute`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(parsedArgs)
      }
    );

    if (response.ok) {
      const result = await response.json();
      
      // Add tool result as a message
      setMessages(prev => [...prev, {
        id: Date.now().toString(),
        content: `ğŸ”§ Tool Result (${toolName}):\n${JSON.stringify(result.data, null, 2)}`,
        sender: 'agent',
        timestamp: new Date()
      }]);
    } else {
      alert('Tool execution failed');
    }
  } catch (error) {
    console.error('Error executing tool:', error);
    alert(`Error: ${error.message}`);
  }
};

// Update fetchServers to also fetch tools
const fetchServers = async () => {
  try {
    const response = await fetch('http://localhost:3001/api/mcp/servers');
    if (response.ok) {
      const data = await response.json();
      setServers(data.servers);
      
      // Fetch tools for each connected server
      data.servers.forEach((server: Server) => {
        if (server.status === 'connected') {
          fetchServerTools(server.id);
        }
      });
    }
  } catch (error) {
    console.error('Failed to fetch servers:', error);
  }
};

// Add this to your JSX after the server panel:
{showToolPanel && (
  <div className="mb-4 p-3 bg-yellow-50 rounded">
    <h3 className="font-semibold mb-2">Available Tools:</h3>
    <div className="space-y-2">
      {Object.entries(availableTools).map(([serverId, tools]) => (
        <div key={serverId} className="border rounded p-2">
          <h4 className="font-medium text-sm text-gray-700 mb-1">{serverId}:</h4>
          <div className="flex flex-wrap gap-1">
            {tools.map((tool: any) => (
              <button
                key={tool.name}
                onClick={() => executeTool(serverId, tool.name)}
                className="px-2 py-1 bg-yellow-200 hover:bg-yellow-300 rounded text-xs"
                title={tool.description}
              >
                {tool.name}
              </button>
            ))}
          </div>
        </div>
      ))}
    </div>
  </div>
)}

// Add tool panel toggle to your header buttons:
<button
  onClick={() => setShowToolPanel(!showToolPanel)}
  className="px-3 py-1 bg-yellow-500 text-white rounded hover:bg-yellow-600"
>
  {showToolPanel ? 'Hide' : 'Show'} Tools
</button>
```

## Summary: Progressive API Usage

We've built up our React app layer by layer:

1. **Layer 1**: Basic synchronous messaging (`/api/message-sync`)
2. **Layer 2**: Real-time streaming (WebSocket events)
3. **Layer 3**: Server management (`/api/mcp/servers`, `/api/connect-server`)
4. **Layer 4**: Direct tool execution (`/api/mcp/servers/:id/tools/:tool/execute`)

## Key Takeaways

### ğŸ¯ **Start Simple**
- Begin with synchronous API calls
- Add complexity gradually
- Each layer builds on the previous

### ğŸ”— **API Progression**
- **Synchronous** â†’ **Streaming** â†’ **Management** â†’ **Direct Control**
- Each API serves different use cases
- Mix and match based on your needs

### ğŸ›  **Real-world Usage**
- Most apps start with layers 1-2
- Server management (layer 3) is for power users
- Direct tool execution (layer 4) is for advanced integrations

### ğŸ“ˆ **Scaling Considerations**
- Cache server/tool information
- Handle connection states gracefully
- Implement proper error boundaries
- Consider user permission levels

Start with Layer 1 for your first integration, then add layers as your application grows!

---

**Next Steps**: Try building the basic version first, then gradually add each layer. For production patterns, see [Advanced Patterns](./advanced-patterns). 


================================================
FILE: docs/docs/tutorials/building-triage-system.md
================================================
---
sidebar_position: 5
---

# Customer Support Triage System

Learn how to build an intelligent customer support triage system using multiple specialized agents that work together through MCP connections.

## Overview

We'll build a system where:
1. **Triage Agent** receives customer requests and routes them
2. **Specialist Agents** handle specific domains (technical, billing, etc.)
3. **MCP Tools** enable seamless agent-to-agent communication
4. **Auto-approval** provides smooth customer experience

```
Customer Request â†’ Triage Agent â†’ Specialist Agent â†’ Complete Response
```

## Step 1: Create Specialist Agents

### Technical Support Agent

```yaml
# technical-support-agent.yml
systemPrompt: |
  You are a Technical Support Specialist with expertise in:
  - API troubleshooting and integration issues
  - Application bugs and system diagnostics
  - Performance optimization and monitoring
  
  Provide detailed, step-by-step solutions with clear explanations.

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]

llm:
  provider: openai
  model: gpt-4o
  apiKey: $OPENAI_API_KEY
```

### Billing Support Agent

```yaml
# billing-agent.yml
systemPrompt: |
  You are a Billing Support Specialist handling:
  - Payment processing and subscription management
  - Plan upgrades, downgrades, and pricing questions
  - Refunds and billing disputes
  
  Always provide specific timelines and next steps.

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

## Step 2: Create the Triage Agent

The triage agent coordinates everything and connects to specialists:

```yaml
# triage-agent.yml
systemPrompt: |
  You are a Customer Support Triage Agent. Your process:
  
  1. Analyze the customer request
  2. Identify the best specialist (technical, billing, etc.)
  3. Call the chat_with_agent tool with the customer message
  4. Provide a complete response combining your routing decision with the specialist's answer
  
  After routing, you MUST:
  - Use chat_with_agent tool to get the specialist's response
  - Include the specialist's complete answer in your response
  
  Response format: "I've connected you with [specialist]. [Complete specialist answer]"

# Auto-approve tools for seamless delegation
toolConfirmation:
  mode: auto-approve
  allowedToolsStorage: memory

mcpServers:
  # Connect to specialist agents as MCP servers
  technical_support:
    type: stdio
    command: npx
    args: [dexto, --mode, mcp, --agent, technical-support-agent.yml]
    connectionMode: lenient
  
  billing_support:
    type: stdio
    command: npx
    args: [dexto, --mode, mcp, --agent, billing-agent.yml]
    connectionMode: lenient

llm:
  provider: openai
  model: gpt-4o
  apiKey: $OPENAI_API_KEY
```

## Step 3: Test the System

### Start the Triage System

```bash
npx dexto --agent triage-agent.yml
```

This automatically:
- Starts the triage agent
- Connects to specialist agents as MCP servers
- Loads the `chat_with_agent` tool for delegation

### Test Scenarios

**Technical Issue:**
```
My API keeps returning 500 errors when uploading files.
```

**Expected Flow:**
1. Triage identifies â†’ Technical Support
2. Calls `chat_with_agent` â†’ Technical specialist responds
3. Customer gets complete troubleshooting guide

**Billing Issue:**
```
I want to upgrade my plan but confused about pricing.
```

**Expected Flow:**
1. Triage identifies â†’ Billing Support  
2. Calls `chat_with_agent` â†’ Billing specialist responds
3. Customer gets complete pricing explanation

## Step 4: Add More Specialists

### Product Information Agent

```yaml
# product-info-agent.yml
systemPrompt: |
  You are a Product Information Specialist covering:
  - Feature descriptions and plan comparisons
  - Integration capabilities and setup guides
  - How-to questions and best practices

mcpServers:
  web_search:
    type: stdio
    command: npx
    args: ["-y", "tavily-mcp@0.1.3"]
    env:
      TAVILY_API_KEY: $TAVILY_API_KEY

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

### Update Triage Agent

Add the new specialist to your triage configuration:

```yaml
# Add to mcpServers section
product_info:
  type: stdio
  command: npx
  args: [dexto, --mode, mcp, --agent, product-info-agent.yml]
  connectionMode: lenient
```

Update the system prompt to include routing to Product Info Agent:

```yaml
systemPrompt: |
  Available specialists:
  - Technical Support: API errors, bugs, performance issues
  - Billing Support: payments, subscriptions, pricing  
  - Product Info: features, plans, integrations, how-to guides
  
  # ... rest of prompt
```

## Step 5: Advanced Features

### Add Business Context

Create documentation files that agents can access:

```markdown
<!-- company-info.md -->
# Company Plans

- Basic Plan: $9/month, 10 users, 5GB storage
- Pro Plan: $19/month, 100 users, 100GB storage  
- Enterprise Plan: $39/month, unlimited users, 1TB storage
```

Reference in agent configurations:

```yaml
systemPrompt:
  contributors:
    - id: base-prompt
      type: static
      content: |
        Your main system prompt here...
    
    - id: company-info
      type: file
      files: [company-info.md]  # Relative to config file location
```

### Production Deployment

For production, run specialists as separate servers:

```bash
# Terminal 1: Technical Support
npx dexto --agent technical-support-agent.yml --mode server --port 3001

# Terminal 2: Billing Support  
npx dexto --agent billing-agent.yml --mode server --port 3002

# Terminal 3: Triage Coordinator
npx dexto --agent triage-agent.yml --mode server --port 3000
```

Update triage agent to use HTTP connections:

```yaml
mcpServers:
  technical_support:
    type: sse
    url: "http://localhost:3001/mcp"
  
  billing_support:
    type: sse  
    url: "http://localhost:3002/mcp"
```

## Key Concepts

### MCP Tool Delegation

The `chat_with_agent` tool enables one agent to execute another:

```yaml
# When triage agent connects to specialist as MCP server
# It gets access to chat_with_agent tool automatically
# Tool calls specialist with customer message
# Returns specialist's complete response
```

### Auto-Approval Configuration

Essential for smooth delegation:

```yaml
toolConfirmation:
  mode: auto-approve        # No manual confirmation
  allowedToolsStorage: memory  # Session-only approvals
```

### Stdio vs SSE Connections

**Development (stdio):**
- Agents start automatically
- Simple configuration
- Single machine deployment

**Production (sse):**
- Agents run as separate servers
- Distributed deployment
- Better scalability

## Complete Example

Your final file structure:

```
triage-system/
â”œâ”€â”€ triage-agent.yml
â”œâ”€â”€ technical-support-agent.yml  
â”œâ”€â”€ billing-agent.yml
â”œâ”€â”€ product-info-agent.yml
â””â”€â”€ docs/
    â””â”€â”€ company-info.md
```

**Test the complete system:**

```bash
npx dexto --agent triage-agent.yml "I need help with API integration and want to upgrade my billing plan"
```

The triage agent will:
1. Identify this as a technical issue (primary)
2. Route to Technical Support specialist
3. Execute the specialist via `chat_with_agent`
4. Provide complete API integration guidance
5. Optionally route billing question to Billing specialist

## Next Steps

- Add more specialists (Sales, Escalation, etc.)
- Include external tools (CRM, knowledge base)
- Implement logging and analytics
- Deploy with authentication and scaling

This pattern works for any domain where you need intelligent routing and specialized expertise! 


================================================
FILE: docs/docs/tutorials/database-agent.md
================================================
---
sidebar_position: 3
---

# Database Agent Tutorial

Learn how to build an AI agent that provides natural language access to database operations and analytics. This tutorial shows how to create an agent that can query databases, manage data, and generate insights through conversation.

## What You'll Build

A database agent that can:
- Execute natural language queries
- Create and manage database records
- Generate reports and analytics
- Handle data validation and errors
- Provide context-aware responses

## Prerequisites

- Node.js 18+ installed
- SQLite3 installed on your system
- OpenAI API key (or other LLM provider)
- Basic understanding of SQL and databases

> **Note**: This tutorial uses the [MCP Database Server](https://github.com/executeautomation/mcp-database-server) for database connectivity. This MCP server provides database access capabilities supporting SQLite, SQL Server, PostgreSQL, and MySQL databases.

## Step 1: Setup the Database Agent

First, let's set up the database agent with sample data:

```bash
# Navigate to the database agent directory
cd agents/database-agent

# Run the setup script to initialize the database
./setup-database.sh
```

This creates a sample database with:
- Users table (id, name, email, created_at, last_login, is_active)
- Products table (id, name, description, price, category, stock_quantity)
- Orders table (id, user_id, total_amount, status, created_at)
- Order items table (id, order_id, product_id, quantity, unit_price)

## Step 2: Configure the Agent

The database agent uses this configuration:

```yaml
# database-agent.yml
mcpServers:
  sqlite:
    type: stdio
    command: npx
    args:
      - -y
      - "@executeautomation/database-server"
      - "./agents/database-agent/data/example.db"
    timeout: 30000
    connectionMode: strict

systemPrompt:
  contributors:
    - id: primary
      type: static
      priority: 0
      content: |
        You are a Database Interaction Agent that provides natural language access to database operations
        and analytics. You orchestrate database operations through intelligent conversation and tool usage.

        ## Your Core Capabilities

        **Database Operations:**
        - Execute SQL queries and return formatted results
        - Create, modify, and drop database tables
        - Insert, update, and delete records
        - Analyze database schema and structure
        - Generate reports and data insights
        - Perform data validation and integrity checks

        **Intelligent Orchestration:**
        - Understand user intent from natural language
        - Break down complex requests into sequential operations
        - Validate data before operations
        - Provide clear explanations of what you're doing
        - Handle errors gracefully with helpful suggestions

        ## Best Practices

        - Always explain what you're doing before doing it
        - Show sample data when creating tables
        - Validate user input before database operations
        - Provide helpful error messages and suggestions
        - Use transactions for multi-step operations
        - Keep responses concise but informative

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
  temperature: 0.1  # Lower temperature for more consistent database operations
```

## Step 3: Start the Agent

```bash
# Set your OpenAI API key
export OPENAI_API_KEY="your-openai-api-key"

# Start the database agent
dexto --agent database-agent.yml
```

## Step 4: Basic Database Operations

### Querying Data

Start with simple queries:

```
User: Show me all users
Agent: I'll query the users table to show you all the user records...

User: Find products under $100
Agent: I'll search for products with prices below $100...
```

### Creating Records

Add new data to the database:

```
User: Create a new user named Sarah Johnson with email sarah@example.com
Agent: I'll insert a new user record for Sarah Johnson...

User: Add a new product called "Wireless Headphones" for $89.99
Agent: I'll add the new product to the database...
```

### Complex Queries

Ask for insights and analytics:

```
User: Show me total sales by category
Agent: I'll aggregate the sales data by product category...

User: Find users who haven't logged in for more than 5 days
Agent: I'll query for users whose last_login is older than 5 days...
```

## Step 5: Advanced Features

### Data Analysis

The agent can perform complex analysis:

```
User: Generate a monthly sales report for the last 6 months
User: Find products with declining sales trends
User: Calculate customer lifetime value for each user
User: Identify the most popular product categories
```

### Data Management

Handle data operations:

```
User: Update the price of the Laptop to $849.99
User: Mark all orders older than 30 days as completed
User: Delete all inactive users who haven't logged in for 90 days
```

### Schema Operations

Manage database structure:

```
User: Show me the current database schema
User: Add a new column to the products table
User: Create an index on the email field for better performance
```

## Next Steps

Now that you have a working database agent, you can:

1. **Extend the Schema**: Add more tables and relationships
2. **Add Business Logic**: Implement domain-specific operations
3. **Integrate with APIs**: Connect to external services
4. **Build Web Interface**: Create a web UI for your agent
5. **Scale Up**: Move to production databases like PostgreSQL

The database agent demonstrates how AI can make data operations accessible through natural conversation, changing how we think about database interaction and business intelligence. 


================================================
FILE: docs/docs/tutorials/image-editor-agent.md
================================================
---
sidebar_position: 7
---

# Image Editor Agent

Learn how to build an AI agent that provides intelligent image processing and editing capabilities. This tutorial shows how to create an agent that can analyze, transform, and enhance images through natural language commands.

## ğŸ¥ Demo Video

Watch the Image Editor Agent in action:

<iframe
  width="100%"
  height="400"
  src="https://www.youtube.com/embed/A0j61EIgWdI"
  title="Image Editor Agent Demo"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; fullscreen"
  allowfullscreen="true"
></iframe>

## What You'll Build

An image editor agent that can:
- Analyze image metadata and properties
- Resize and crop images with intelligent aspect ratio handling
- Convert between image formats with quality control
- Apply filters and effects (blur, sharpen, grayscale, sepia, etc.)
- Adjust brightness, contrast, and color properties
- Add text overlays and annotations
- Detect objects, faces, and visual features
- Create image collages and compositions

## Understanding the Architecture

The image editor agent follows Dexto's framework design with clear separation of responsibilities:

1. **MCP Server**: Sets up the server and exposes image processing tools to the agent
2. **Agent**: Orchestrates workflows and handles user interaction
3. **Tools**: Contain the actual image processing logic

This architecture allows the agent to focus on understanding user intent while the tools handle the technical image processing.

## MCP Server Code

The core functionality is provided by the **Image Editor MCP Server**, a Python-based server built with FastMCP. To understand the complete MCP server implementation, refer to the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/tree/main):

- **Image Editor Server**: [src/image-editor](https://github.com/truffle-ai/mcp-servers/tree/main/src/image-editor) - Image processing, filters, computer vision, and analysis tools

## Step 1: Setting Up the Project

First, let's understand the project structure:

```
agents/image-editor-agent/
â”œâ”€â”€ image-editor-agent.yml  # Agent configuration
â”œâ”€â”€ Lenna.webp              # Sample image for testing
â””â”€â”€ README.md               # Documentation
```

## Step 2: Quick Setup

The image editor agent uses a published MCP server that's automatically installed:

```bash
# From the dexto project root
dexto --agent agents/image-editor-agent/image-editor-agent.yml
```

That's it! The MCP server (`truffle-ai-image-editor-mcp`) will be automatically downloaded and installed via `uvx` on first run.

### What's Happening Behind the Scenes

The published MCP server includes these key dependencies:
- **OpenCV**: Computer vision and image processing operations
- **Pillow**: Python Imaging Library for image manipulation
- **NumPy**: Numerical computing for image data
- **NumPy**: Numerical computing for image data

## Step 3: Understanding the Agent Configuration

The agent is configured in `image-editor-agent.yml`:

```yaml
systemPrompt: |
  You are an AI assistant specialized in image editing and processing. You have access to a comprehensive set of tools for manipulating images including:
  
  - **Basic Operations**: Resize, crop, convert formats
  - **Filters & Effects**: Blur, sharpen, grayscale, sepia, invert, edge detection, emboss, vintage
  - **Adjustments**: Brightness, contrast, color adjustments
  - **Text & Overlays**: Add text to images with customizable fonts and colors
  - **Computer Vision**: Face detection, edge detection, contour analysis, circle detection, line detection
  - **Analysis**: Detailed image statistics, color analysis, histogram data

mcpServers:
  image_editor:
    type: stdio
    command: uvx
    args:
      - truffle-ai-image-editor-mcp
    connectionMode: strict

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

### Key Components Explained

1. **systemPrompt**: Defines the agent's capabilities and behavior
2. **mcpServers**: Connects to the Python MCP server
3. **llm**: Configures the language model for intelligent interaction

## Step 4: Available Tools

The image editor agent provides 20+ powerful tools organized into categories:

### Image Analysis
- `get_image_info` - Get detailed image metadata (dimensions, format, file size)
- `preview_image` - Get a base64 preview for UI display
- `analyze_image` - Comprehensive image analysis with statistics
- `show_image_details` - Display detailed image information

### Basic Operations
- `resize_image` - Resize images with aspect ratio preservation
- `crop_image` - Crop images to specific dimensions
- `convert_format` - Convert between image formats
- `create_thumbnail` - Create small preview images

### Filters & Effects
- `apply_filter` - Apply various filters (blur, sharpen, grayscale, sepia, etc.)
- `adjust_brightness_contrast` - Adjust brightness and contrast levels

### Drawing & Annotations
- `add_text_to_image` - Add text overlays with custom fonts and colors
- `draw_rectangle` - Draw rectangles on images
- `draw_circle` - Draw circles on images
- `draw_line` - Draw lines on images
- `draw_arrow` - Draw arrows on images
- `add_annotation` - Add text annotations with backgrounds

### Computer Vision
- `detect_objects` - Detect faces, edges, contours, circles, lines

### Advanced Features
- `create_collage` - Create image collages with various layouts
- `create_collage_template` - Use predefined collage templates
- `batch_process` - Process multiple images with the same operation
- `compare_images` - Compare two images side by side

### Utility
- `list_available_filters` - List all available filter options
- `list_collage_templates` - List available collage templates

## Step 5: Running the Agent

Start the image editor agent:

```bash
# From the project root
dexto --agent agents/image-editor-agent/image-editor-agent.yml
```

## Step 6: Testing with Example Prompts

Let's test the agent with some example prompts to understand how it works:

### Basic Image Analysis
```
"Get information about the image at /path/to/image.jpg"
```
**What happens**: The agent calls `get_image_info` to retrieve dimensions, format, and file size.

### Image Transformation
```
"Resize the image to 800x600 pixels while maintaining aspect ratio"
```
**What happens**: The agent calls `resize_image` with `maintainAspectRatio: true` to preserve proportions.

### Applying Filters
```
"Apply a sepia filter to make the image look vintage"
```
**What happens**: The agent calls `apply_filter` with `filter: "sepia"` to create a vintage effect.

### Adding Text
```
"Add the text 'Hello World' at coordinates (50, 50) with white color"
```
**What happens**: The agent calls `add_text_to_image` with the specified text, position, and color.

### Computer Vision
```
"Detect faces in the image"
```
**What happens**: The agent calls `detect_objects` with `detectionType: "faces"` to find faces.

### Creating Collages
```
"Create a collage of these three images in a grid layout"
```
**What happens**: The agent calls `create_collage` with the image paths and grid layout.

## Step 7: Understanding the Workflow

Here's how the three components work together in a typical interaction:

1. **User Request**: "Make this image brighter and add a watermark"
2. **Agent**: Interprets the request and orchestrates the workflow
3. **Tools**: Agent calls the processing functions:
   - `adjust_brightness_contrast()` - increases image brightness
   - `add_text_to_image()` - adds watermark text
4. **Response**: Agent provides the result with image context

### Example Workflow
```
User: "Take this image, resize it to 500x500, apply a blur filter, and add the text 'SAMPLE' at the bottom"

Agent Response:
"I'll help you process that image. Let me break this down into steps:
1. First, I'll resize the image to 500x500 pixels
2. Then I'll apply a blur filter
3. Finally, I'll add the text 'SAMPLE' at the bottom

[Executes tools and provides results]"
```

## Supported Formats

### Input Formats
- **JPG/JPEG**: Most common compressed format
- **PNG**: Lossless format with transparency support
- **BMP**: Uncompressed bitmap format
- **TIFF**: High-quality format for professional use
- **WebP**: Modern format with excellent compression

### Output Formats
- **JPG/JPEG**: Configurable quality settings
- **PNG**: Lossless with transparency
- **WebP**: Configurable quality with small file sizes
- **BMP**: Uncompressed format
- **TIFF**: High-quality professional format

## Common Use Cases

- **Web Development**: Optimize images, create thumbnails, convert formats
- **Content Creation**: Apply filters, add text overlays, create compositions
- **Professional Work**: Batch processing, color adjustments, quality enhancement

---

**Ready to start?** Run the setup script and begin creating intelligent image processing workflows! 


================================================
FILE: docs/docs/tutorials/index.md
================================================
---
sidebar_position: 1
---

# Building Applications

Now let's build something useful. We'll create three types of applications, each building on what you've learned.

## Application 1: Smart File Organizer

Let's build an agent that can organize messy directories:

```typescript
// file-organizer.ts
import 'dotenv/config';
import { loadConfigFile, DextoAgent } from 'dexto';

const config = await loadConfigFile('./agents/default-agent.yml');
const agent = new DextoAgent(config);

// Start the agent
await agent.start();

console.log("ğŸ—‚ï¸ Smart File Organizer");
console.log("I can help organize your files by type, date, or project.\n");

const task = "Look at the current directory and suggest how to organize these files. Create folders if needed.";
const response = await agent.run(task);
console.log(response);

// Clean shutdown
await agent.stop();
```

**What you're learning:** Single-purpose agents with clear objectives work best.

### Making it Interactive

Let's add some user input:

```typescript
// interactive-organizer.ts
import 'dotenv/config';
import { loadConfigFile, DextoAgent } from 'dexto';
import readline from 'readline';

const config = await loadConfigFile('./agents/default-agent.yml');
const agent = new DextoAgent(config);
await agent.start();

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

console.log("ğŸ—‚ï¸ Smart File Organizer");
console.log("Commands: 'analyze', 'organize by type', 'organize by date', 'exit'\n");

function askQuestion() {
  rl.question("What would you like to do? ", async (input) => {
    if (input.toLowerCase() === 'exit') {
      rl.close();
      return;
    }
    
    let task;
    switch (input.toLowerCase()) {
      case 'analyze':
        task = "Analyze the current directory and tell me what files are here.";
        break;
      case 'organize by type':
        task = "Organize files by type (documents, images, code, etc.). Create folders and move files.";
        break;
      case 'organize by date':
        task = "Organize files by creation date. Create year/month folders and move files.";
        break;
      default:
        task = input;
    }
    
    try {
      const response = await agent.run(task);
      console.log(`\nğŸ¤– ${response}\n`);
    } catch (error) {
      console.log(`âŒ Error: ${error.message}\n`);
    }
    
    askQuestion();
  });
}

askQuestion();

// Cleanup on exit
process.on('SIGINT', async () => {
  console.log('\nShutting down...');
  await agent.stop();
  rl.close();
  process.exit(0);
});
```

## Application 2: Interactive Code Helper

Now let's build something interactive for developers:

```typescript
// code-helper.ts
import 'dotenv/config';
import { loadConfigFile, DextoAgent } from 'dexto';
import readline from 'readline';

const agent = new DextoAgent(
  await loadConfigFile('./agents/default-agent.yml')
);
await agent.start();

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

console.log("ğŸ’» Your Code Helper is ready!");
console.log("Ask me about code, files, or type 'exit' to quit.\n");

function askQuestion() {
  rl.question("You: ", async (input) => {
    if (input.toLowerCase() === 'exit') {
      rl.close();
      return;
    }
    
    try {
      const response = await agent.run(input);
      console.log(`\nğŸ¤– ${response}\n`);
    } catch (error) {
      console.log(`âŒ Error: ${error.message}\n`);
    }
    
    askQuestion();
  });
}

askQuestion();

// Cleanup on exit
process.on('SIGINT', async () => {
  console.log('\nShutting down...');
  await agent.stop();
  rl.close();
  process.exit(0);
});
```

**What you're learning:** Adding interaction is just a few lines of code. The agent handles the complexity.

### Specialized Code Helper Configuration

Create a specialized configuration for code assistance:

```yaml
# agents/code-helper.yml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
  
systemPrompt: |
  You are a senior software engineer and code reviewer.
  
  Your expertise includes:
  - Code review and best practices
  - Debugging and troubleshooting
  - Architecture and design patterns
  - Security considerations
  - Performance optimization
  
  When helping with code:
  1. Read and understand the codebase structure first
  2. Provide specific, actionable feedback
  3. Explain your reasoning
  4. Suggest improvements with examples
  5. Consider security and performance implications
  
  Use the filesystem tools to examine code files when needed.

llm:
  provider: anthropic
  model: claude-4-sonnet-20250514
  apiKey: $ANTHROPIC_API_KEY
```

## Application 3: Web API Service

Ready for something more advanced? Let's create a web service:

```typescript
// web-service.ts
import express from 'express';
import { loadConfigFile, DextoAgent } from 'dexto';

const app = express();
app.use(express.json());

// Initialize our agent once
const agent = new DextoAgent(
  await loadConfigFile('./agents/default-agent.yml')
);
await agent.start();

// Simple chat endpoint
app.post('/chat', async (req, res) => {
  try {
    const { message } = req.body;
    const response = await agent.run(message);
    
    res.json({ 
      success: true, 
      response,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'healthy', agent: 'ready' });
});

// File analysis endpoint
app.post('/analyze', async (req, res) => {
  try {
    const { path = '.' } = req.body;
    const response = await agent.run(`Analyze the files in ${path} and provide a summary.`);
    
    res.json({
      success: true,
      analysis: response,
      path,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

const server = app.listen(3000, () => {
  console.log('ğŸš€ Dexto web service running on http://localhost:3000');
  console.log('Endpoints:');
  console.log('  POST /chat - Chat with the agent');
  console.log('  POST /analyze - Analyze files');
  console.log('  GET /health - Health check');
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  console.log('Shutting down gracefully...');
  server.close(async () => {
    await agent.stop();
    process.exit(0);
  });
});
```

**What you're learning:** The same agent works everywhereâ€”CLI, web, mobileâ€”anywhere TypeScript runs.

### Testing Your Web Service

Test it with curl:

```bash
# Health check
curl http://localhost:3000/health

# Chat with the agent
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What files are in the current directory?"}'

# Analyze files
curl -X POST http://localhost:3000/analyze \
  -H "Content-Type: application/json" \
  -d '{"path": "."}'
```

## Key Patterns You've Learned

### 1. Single Purpose Agents
Each application has a clear, focused purpose:
- **File Organizer**: Manages file organization
- **Code Helper**: Assists with development tasks
- **Web Service**: Provides API access to agent capabilities

### 2. Configuration Over Code
Notice how we didn't write complex AI integration code. Instead:
- **Configure capabilities** in YAML
- **Use simple API calls** to interact
- **Let Dexto handle** the complexity

### 3. Consistent API
The same `agent.run()` call works in:
- **Command line tools**
- **Interactive applications**
- **Web services**
- **Any TypeScript/JavaScript environment**

### 4. Error Handling
Always wrap agent calls in try-catch blocks:
```typescript
try {
  const response = await agent.run(message);
  // Handle success
} catch (error) {
  // Handle errors gracefully
}
```

## Customizing for Your Use Case

### Environment-Specific Configurations

**Development**
```yaml
llm:
  provider: openai
  model: gpt-4.1-mini  # Faster, cheaper for dev
  apiKey: $OPENAI_API_KEY
```

**Production**
```yaml
llm:
  provider: openai
  model: gpt-4.1  # More capable for production
  apiKey: $OPENAI_API_KEY
  temperature: 0.3  # More consistent responses
```

### Adding More Capabilities

Add new tools by including more MCP servers:

```yaml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
  
  puppeteer:
    type: stdio
    command: npx
    args: ["-y", "@truffle-ai/puppeteer-server"]
    
  # Add more servers for additional capabilities
```

## What You've Built

You now have three working applications that demonstrate:
- âœ… **File management** with AI assistance
- âœ… **Interactive development** tools
- âœ… **Web API** integration
- âœ… **Error handling** and user experience
- âœ… **Flexible configuration** for different environments

## Next Steps

Ready to take it to the next level?

- **Learn advanced patterns**: Check out [Advanced Patterns](./advanced-patterns) for production-ready techniques
- **Add more tools**: Explore [MCP servers](../mcp/connecting-servers) for additional capabilities
- **Deploy your service**: See the [deployment guide](../guides/deployment) for production hosting
- **Join the community**: Share your creations in our [Discord](https://discord.gg/GFzWFAAZcm)

You're well on your way to building amazing AI applications! ğŸ‰ 


================================================
FILE: docs/docs/tutorials/langchain-integration.md
================================================
# Integrating Existing Agents: Dexto + LangChain

This tutorial shows you how to integrate an existing LangChain agent with Dexto to create a multi-agent system. Instead of rebuilding your agent, you'll learn to wrap it with MCP and let Dexto orchestrate between it and other tools.

## The Integration Pattern

Here's what we're building - a single system where Dexto coordinates between different tools:

```mermaid
graph TD
    A[Dexto Orchestrator] --> B[Filesystem Tools]
    A --> C[Puppeteer Tools]
    A --> D[LangChain Agent]
    
    style A fill:#4f46e5,stroke:#312e81,stroke-width:2px,color:#fff
    style B fill:#10b981,stroke:#065f46,stroke-width:1px,color:#fff
    style C fill:#f59e0b,stroke:#92400e,stroke-width:1px,color:#fff
    style D fill:#8b5cf6,stroke:#5b21b6,stroke-width:1px,color:#fff
```

Your existing LangChain agent becomes just another tool in Dexto's toolkit, working alongside file operations and web browsing.

## How the Integration Works

The integration happens in three simple steps. Let's walk through each piece of code to see exactly what's happening.

### Step 1: Your Existing LangChain Agent

Here's a typical LangChain agent you might already have:

```javascript
// agent.js
import { ChatOpenAI } from '@langchain/openai';
import { PromptTemplate } from '@langchain/core/prompts';

class LangChainAgent {
    constructor() {
        this.llm = new ChatOpenAI({ model: 'gpt-4o-mini' });
        this.tools = {
            summarize: this.summarize.bind(this),
            translate: this.translate.bind(this),
            analyze: this.analyze.bind(this)
        };
    }

    async run(input) {
        const prompt = PromptTemplate.fromTemplate(`
            You have three tools: summarize, translate, analyze.
            User input: {user_input}
            Determine which tool to use and provide a helpful response.
        `);
        
        const chain = prompt.pipe(this.llm);
        const result = await chain.invoke({ user_input: input });
        return result.content;
    }
}
```

This is your standard LangChain agent - it stays exactly as it is. No modifications needed.

### Step 2: Wrap It in MCP

Now we create a thin MCP wrapper that exposes your agent:

```javascript
// mcp-server.js
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { z } from 'zod';
import { LangChainAgent } from './agent.js';

class LangChainMCPServer {
    constructor() {
        this.server = new McpServer({ name: 'langchain-agent', version: '1.0.0' });
        this.agent = new LangChainAgent();
        this.registerTools();
    }

    registerTools() {
        this.server.registerTool(
            'chat_with_langchain_agent',
            {
                description: 'Chat with a LangChain agent for text processing',
                inputSchema: {
                    message: z.string().describe('Message to send to the agent')
                }
            },
            async ({ message }) => {
                const response = await this.agent.run(message);
                return { content: [{ type: 'text', text: response }] };
            }
        );
    }
}
```

This wrapper does one thing: it takes MCP tool calls and forwards them to your existing agent.

### Step 3: Configure Dexto

Finally, tell Dexto about all your tools in the configuration:

```yaml
# dexto-agent-with-langchain.yml
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    
  puppeteer:
    type: stdio
    command: npx
    args: ["-y", "@truffle-ai/puppeteer-server"]
    
  langchain:
    type: stdio
    command: node
    args: ["./langchain-agent/dist/mcp-server.js"]
    env:
      OPENAI_API_KEY: $OPENAI_API_KEY
```

Now Dexto can coordinate between file operations, web browsing, and your LangChain agent.

## See It in Action

```bash
# Setup
cd examples/dexto-langchain-integration/langchain-agent && npm install && npm run build
export OPENAI_API_KEY="your_key_here"
cd ../../../  # Return to repo root

# Run a multi-agent workflow
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Read README.md, analyze its sentiment, and save the analysis"
```

What happens when you run this:

1. **Dexto receives** the natural language request
2. **Breaks it down** into subtasks: read file â†’ analyze sentiment â†’ save result
3. **Routes each task** to the appropriate tool:
   - File reading â†’ filesystem MCP server
   - Sentiment analysis â†’ LangChain MCP server  
   - File saving â†’ filesystem MCP server
4. **Coordinates the workflow** and returns the final result

## Extending the Pattern

Want to add more agents? Just follow the same three-step pattern:

```yaml
mcpServers:
  # Your existing setup
  langchain:
    type: stdio
    command: node
    args: ["./langchain-agent/dist/mcp-server.js"]
    
  # Add more agents
  autogen-research:
    type: stdio
    command: python
    args: ["./autogen-agent/mcp_server.py"]
    
  custom-analyzer:
    type: stdio
    command: "./custom-agent/target/release/mcp-server"
```

Each agent runs independently, but Dexto can orchestrate between all of them based on the task at hand.

## Benefits of using Dexto

Instead of building custom orchestration logic, Dexto gives you:

- **Intelligent routing**: Automatically determines which tools to use and in what order
- **State management**: Shares context and results between different systems seamlessly  
- **Workflow coordination**: Handles dependencies, retries, and error handling across steps
- **Natural language interface**: Describe complex multi-step workflows in plain English

Without Dexto, you'd manually chain API calls and manage coordination between your LangChain agent, file operations, and web browsing. With Dexto, you just describe what you want.

## Key Takeaways

- **Your existing agents don't change** - they keep working exactly as before
- **MCP provides the bridge** - a simple wrapper makes any agent Dexto-compatible
- **Dexto handles orchestration** - it figures out which tool to use when
- **The pattern scales** - add as many agents and frameworks as you need

This approach lets you build sophisticated multi-agent systems by composing existing pieces, rather than rebuilding everything from scratch.


================================================
FILE: docs/docs/tutorials/multi-agent-systems.md
================================================
---
sidebar_position: 3
---

# Building Multi-Agent Systems

Learn how to build multi-agent systems where Dexto agents can communicate with each other using the Model Context Protocol (MCP). This powerful pattern enables specialized agents to collaborate and delegate tasks to each other.

## Overview

In this guide, you'll learn how to:
- Set up multiple Dexto agents running on different ports
- Configure one agent to use another as an MCP server
- Enable inter-agent communication through tool calls
- Build collaborative agent workflows

## What We're Building

We'll create two specialized agents:
- **Researcher Agent** (Port 3001): Specializes in gathering and analyzing information
- **Writer Agent** (Port 3002): Specializes in content creation, can call the Researcher for help

The Writer agent will be able to delegate research tasks to the Researcher agent using MCP tool calls.

### Mode Selection Strategy
- **`--mode mcp`**: Use for agents that primarily serve as MCP servers for other agents (like our Researcher)
- **`--mode web`**: Use for agents that need web UI access for user interaction (like our Writer)

Both modes expose the `/mcp` endpoint, but `mcp` mode is optimized for API-only usage.

## Step 1: Create the Project Structure

```bash
mkdir multi-agent-example
cd multi-agent-example

# Create config files for each agent
touch researcher.yml writer.yml .env
```

Your project structure should look like:
```
multi-agent-example/
â”œâ”€â”€ researcher.yml
â”œâ”€â”€ writer.yml
â””â”€â”€ .env
```

## Step 2: Set Up the Researcher Agent

### Create Researcher Configuration

Create `researcher.yml`:

```yaml
# Research Agent Configuration
systemPrompt: |
  You are a Research Agent specializing in gathering and analyzing information.
  
  Your capabilities include:
  - Reading and analyzing files using the filesystem tool
  - Searching the web for current information using tavily-search
  - Synthesizing research findings into clear summaries
  
  When responding to research requests:
  1. Use your tools to gather relevant information
  2. Analyze and synthesize the findings
  3. Provide well-structured, factual responses
  4. Include sources and evidence when possible
  
  Be thorough but concise in your research summaries.

llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - "."
  
  tavily-search:
    type: stdio
    command: npx
    args:
      - -y
      - "tavily-mcp@0.1.2"
    env:
      TAVILY_API_KEY: $TAVILY_API_KEY
```

## Step 3: Set Up the Writer Agent

### Create Writer Configuration

Create `writer.yml`:

```yaml
# Writer Agent - Specializes in content creation
systemPrompt: |
  You are a Content Writer Agent specializing in creating high-quality written content.
  
  Your capabilities include:
  - Writing articles, blog posts, and documentation
  - Reading and editing files using the filesystem tool
  - Collaborating with the Researcher Agent for information gathering
  
  When you need research or factual information:
  1. Use the "researcher" tool to delegate research tasks
  2. Provide clear, specific research requests
  3. Incorporate the research findings into your writing
  
  Example researcher tool usage:
  - "Research the latest trends in AI agents"
  - "Find information about the Model Context Protocol"
  - "Analyze the contents of the project files for context"
  
  Always create well-structured, engaging content that incorporates research findings naturally.

mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - "."
  
  # Connect to the Researcher Agent as an MCP server
  researcher:
    type: http
    baseUrl: http://localhost:3001/mcp
    timeout: 30000

llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
```

## Step 4: Set Up Environment Variables

Create `.env`:

```bash
# Add your OpenAI API key
OPENAI_API_KEY=your_openai_key_here

# Add Tavily API key for web search (get free key at tavily.com)
TAVILY_API_KEY=your_tavily_key_here

# Optional: Add other provider keys if using different models
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_GENERATIVE_AI_API_KEY=your_google_key
COHERE_API_KEY=your_cohere_key
```

## Step 5: Run the Multi-Agent System

That's it! No custom code needed. Just run Dexto with different configs and ports:

### Terminal 1: Start the Researcher Agent
```bash
dexto --mode mcp --web-port 3001 --agent researcher.yml
```

### Terminal 2: Start the Writer Agent  
```bash
dexto --mode web --web-port 3002 --agent writer.yml
```

### Terminal 3: Test the System
```bash
# Test the researcher directly
curl -X POST http://localhost:3001/api/message-sync \
  -H "Content-Type: application/json" \
  -d '{"message": "Research the latest developments in AI agents"}'

# Test the writer (which can call the researcher)
curl -X POST http://localhost:3002/api/message-sync \
  -H "Content-Type: application/json" \
  -d '{"message": "Write a blog post about AI agent collaboration. Research current trends first."}'
```

You can also open the web interfaces:
- **Researcher**: http://localhost:3001 (API endpoints only)
- **Writer**: http://localhost:3002 (Full web UI)

## How It Works

### Inter-Agent Communication Flow

1. **User Request**: "Write a blog post about AI agents"
2. **Writer Agent**: Recognizes it needs research
3. **Tool Call**: Writer calls the `researcher` tool via HTTP MCP
4. **Research Execution**: Researcher agent processes the research request
5. **Response**: Researcher returns findings to Writer
6. **Content Creation**: Writer incorporates research into the blog post
7. **Final Output**: User receives a well-researched blog post

### MCP Configuration Explained

In the Writer's configuration, this section connects to the Researcher:

```yaml
researcher:
  type: http                           # Use HTTP MCP connection
  baseUrl: http://localhost:3001/mcp   # Researcher's MCP endpoint (auto-available in mcp mode)
  timeout: 30000                       # 30-second timeout
```

When Dexto runs in `mcp` or `web` mode, it automatically exposes an MCP endpoint at `/mcp` that other agents can connect to. The `mcp` mode is specifically designed for agents that primarily serve as MCP servers for other agents.

### The Power of Configuration-First

This example demonstrates Dexto's core philosophy:
- **No custom code** - just YAML configuration
- **Built-in web server** - automatic API and UI
- **Automatic MCP endpoints** - no need to implement protocols
- **Simple scaling** - add more agents by adding more configs

## Advanced Usage Patterns

### 1. Multiple Specialized Agents

```yaml
# Writer agent with multiple specialist agents
mcpServers:
  researcher:
    type: http
    baseUrl: http://localhost:3001/mcp
  
  fact-checker:
    type: http
    baseUrl: http://localhost:3003/mcp
  
  editor:
    type: http
    baseUrl: http://localhost:3004/mcp
```

Then run:
```bash
# Terminal 1: Researcher (MCP server mode)
dexto --mode mcp --web-port 3001 --agent researcher.yml

# Terminal 2: Fact-checker (MCP server mode)
dexto --mode mcp --web-port 3003 --agent fact-checker.yml

# Terminal 3: Editor (MCP server mode)
dexto --mode mcp --web-port 3004 --agent editor.yml

# Terminal 4: Writer (Web UI for user interaction)
dexto --mode web --web-port 3002 --agent writer.yml
```

### 2. Bidirectional Communication

Configure agents to call each other:

```yaml
# In researcher.yml - Researcher can also call Writer for help with summaries
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
  
  writer:
    type: http
    baseUrl: http://localhost:3002/mcp
```

### 3. Agent Orchestration

Create a coordinator agent that manages multiple specialized agents:

```yaml
# coordinator.yml
mcpServers:
  researcher:
    type: http
    baseUrl: http://localhost:3001/mcp
  
  writer:
    type: http
    baseUrl: http://localhost:3002/mcp
  
  reviewer:
    type: http
    baseUrl: http://localhost:3003/mcp

# Coordinator Agent Configuration
systemPrompt: |
    You are a Coordinator Agent that orchestrates work between specialized agents.
    
    Your team includes:
    - researcher: For gathering information and analysis
    - writer: For content creation
    - reviewer: For quality assurance and editing
    
  When given a task, break it down and delegate to the appropriate agents.

llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY
```

Run the system:
```bash
# Start specialized agents (MCP servers)
dexto --mode mcp --web-port 3001 --agent researcher.yml
dexto --mode mcp --web-port 3002 --agent writer.yml  
dexto --mode mcp --web-port 3003 --agent reviewer.yml

# Start coordinator (Web UI for user interaction)
dexto --mode web --web-port 3000 --agent coordinator.yml
```

## Production Considerations

### 1. Process Management
Use a process manager like PM2 for production:

```bash
# Install PM2
npm install -g pm2

# Create ecosystem file
cat > ecosystem.config.js << EOF
module.exports = {
  apps: [
    {
      name: 'researcher-agent',
      script: 'dexto',
      args: '--mode mcp --web-port 3001 --agent researcher.yml'
    },
    {
      name: 'writer-agent', 
      script: 'dexto',
      args: '--mode web --web-port 3002 --agent writer.yml'
    }
  ]
};
EOF

# Start all agents
pm2 start ecosystem.config.js
```

### 2. Docker Deployment

```dockerfile
# Dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install -g dexto
COPY . .
CMD ["dexto", "--mode", "web", "--web-port", "3000"]
```

```yaml
# docker-compose.yml
version: '3.8'
services:
  researcher:
    build: .
    ports:
      - "3001:3000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
    command: dexto --mode mcp --web-port 3000 --agent researcher.yml
    
  writer:
    build: .
    ports:
      - "3002:3000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    command: dexto --mode web --web-port 3000 --agent writer.yml
    depends_on:
      - researcher
```

### 3. Load Balancing
Use nginx to load balance multiple instances:

```nginx
upstream researcher_agents {
    server localhost:3001;
    server localhost:3011;
    server localhost:3021;
}

server {
    listen 80;
    location /researcher/ {
        proxy_pass http://researcher_agents/;
    }
}
```

## Troubleshooting

### Common Issues

**"Connection refused" errors**
- Ensure the researcher agent is started before the writer
- Check that ports are not already in use: `netstat -tulpn | grep :3001`
- Verify the MCP endpoint URLs in configurations

**Timeout errors**
- Increase timeout values in MCP server configurations
- Check agent response times in the web UI
- Consider splitting complex tasks

**Tool not found errors**
- Verify agent names match the MCP server names
- Check that target agents are running
- Ensure MCP endpoints return proper responses

**Environment variable issues**
- Verify `.env` file is in the working directory
- Check API key validity and credits
- Use `--no-verbose` flag to reduce debug output

## Next Steps

- **Scale Up**: Add more specialized agents to your system
- **Production**: Use PM2, Docker, or Kubernetes for deployment
- **Integration**: Connect to external services and APIs
- **Monitoring**: Add health checks and logging

The beauty of Dexto's multi-agent systems is their simplicity - just configuration files and command-line arguments. No custom code, no complex deployments, just pure agent collaboration! ğŸ¤–âœ¨ 


================================================
FILE: docs/docs/tutorials/music-agent.md
================================================
---
sidebar_position: 8
---

# Music Creator Agent

Learn how to build an AI agent that provides comprehensive music creation and audio processing capabilities. This tutorial shows how to create an agent that can generate music, analyze audio, and process sound files through natural language commands.

## ğŸ¥ Demo Video

Watch the Music Creator Agent in action:

<iframe
  width="100%"
  height="400"
  src="https://www.youtube.com/embed/wEnQy1zEVZw"
  title="Music Creator Agent Demo"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; fullscreen"
  allowfullscreen="true"
></iframe>

> **âš ï¸ Experimental Status**: This agent is currently in experimental development. The tools have not been extensively tested in production environments and may have limitations or bugs. We're actively seeking feedback and improvements from users.

## What You'll Build

A music creator agent that can:
- Generate melodies, chord progressions, and drum patterns
- Analyze audio for tempo, key, and musical features
- Convert between audio formats with quality control
- Apply audio effects and processing
- Mix multiple audio tracks with volume control
- Play audio and MIDI files with precise control
- Process both audio and MIDI files seamlessly

## Understanding the Architecture

The music creator agent follows Dexto's framework design with clear separation of responsibilities:

1. **MCP Server**: Sets up the server and exposes audio processing tools to the agent
2. **Agent**: Orchestrates workflows and handles user interaction
3. **Tools**: Contain the actual audio processing logic

This architecture allows the agent to focus on understanding musical intent while the tools handle the technical audio processing.

## MCP Server Code

The core functionality is provided by the **Music Agent MCP Server**, a Python-based server built with FastMCP. To understand the complete MCP server implementation, refer to the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/tree/main):

- **Music Server**: [src/music](https://github.com/truffle-ai/mcp-servers/tree/main/src/music) - Audio generation, processing, effects, and MIDI handling

## Step 1: Setting Up the Project

First, let's understand the project structure:

```
agents/music-agent/
â”œâ”€â”€ music-agent.yml         # Agent configuration
â””â”€â”€ README.md               # Documentation
```

## Step 2: Quick Setup

The music creator agent uses a published MCP server that's automatically installed:

```bash
# From the dexto project root
dexto --agent agents/music-agent/music-agent.yml
```

That's it! The MCP server (`truffle-ai-music-creator-mcp`) will be automatically downloaded and installed via `uvx` on first run.

### What's Happening Behind the Scenes

The published MCP server includes these key dependencies:
- **librosa**: Audio analysis and music information retrieval
- **pydub**: Audio file manipulation and processing
- **music21**: Music notation and analysis
- **pretty_midi**: MIDI file handling
- **FastMCP**: Model Context Protocol server framework
- **NumPy & SciPy**: Numerical computing for audio processing

## Step 3: Understanding the Agent Configuration

The agent is configured in `music-agent.yml`:

```yaml
systemPrompt: |
  You are an AI assistant specialized in music creation, editing, and production. You have access to a comprehensive set of tools for working with audio and music including:
  
  - **Audio Analysis**: Analyze audio files for tempo, key, BPM, frequency spectrum, and audio characteristics
  - **Audio Processing**: Convert formats, adjust volume, normalize, apply effects (reverb, echo, distortion, etc.)
  - **Music Generation**: Create melodies, chord progressions, drum patterns, and complete compositions
  - **Audio Manipulation**: Trim, cut, splice, loop, and arrange audio segments
  - **Effects & Filters**: Apply various audio effects and filters for creative sound design
  - **Mixing & Mastering**: Balance levels, apply compression, EQ, and mastering effects
  - **File Management**: Organize, convert, and manage audio files in various formats

mcpServers:
  music_creator:
    type: stdio
    command: uvx
    args:
      - truffle-ai-music-creator-mcp
    connectionMode: strict

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

### Key Components Explained

1. **systemPrompt**: Defines the agent's capabilities and behavior
2. **mcpServers**: Connects to the Python MCP server
3. **llm**: Configures the language model for intelligent interaction

## Step 4: Available Tools

The music creator agent provides 20+ powerful tools organized into categories:

### Music Generation
- `create_melody` - Generate melodies in any key and scale
- `create_chord_progression` - Create chord progressions using Roman numerals
- `create_drum_pattern` - Generate drum patterns for different styles

### Audio Analysis
- `analyze_audio` - Comprehensive audio analysis with spectral features
- `detect_tempo` - Detect BPM and beat positions
- `detect_key` - Identify musical key and mode
- `get_audio_info` - Get detailed audio file information
- `get_midi_info` - Get detailed MIDI file information

### Audio Processing
- `convert_audio_format` - Convert between audio formats
- `convert_midi_to_audio` - Convert MIDI files to high-quality audio (WAV, 44.1kHz, 16-bit)
- `adjust_volume` - Adjust audio levels in dB
- `normalize_audio` - Normalize audio to target levels
- `trim_audio` - Cut audio to specific time ranges
- `apply_audio_effect` - Apply reverb, echo, distortion, filters

### Mixing & Arrangement
- `merge_audio_files` - Combine multiple audio files
- `mix_audio_files` - Mix tracks with individual volume control (supports both audio and MIDI)

### Playback
- `play_audio` - Play audio files with optional start time and duration
- `play_midi` - Play MIDI files with optional start time and duration

### Utility
- `list_available_effects` - List all audio effects
- `list_drum_patterns` - List available drum patterns

## Step 5: Running the Agent

Start the music creator agent:

```bash
# From the project root
dexto --agent agents/music-agent/music-agent.yml
```

## Step 6: Testing with Example Prompts

Let's test the agent with some example prompts to understand how it works:

### Music Generation
```
"Create a melody in G major at 140 BPM for 15 seconds"
```
**What happens**: The agent calls `create_melody` with the specified key, tempo, and duration.

```
"Create a I-IV-V-I chord progression in D major"
```
**What happens**: The agent calls `create_chord_progression` with the Roman numeral progression and key.

### Audio Analysis
```
"Analyze the tempo and key of my song.mp3"
```
**What happens**: The agent calls `analyze_audio` to get comprehensive audio information.

```
"What's the BPM of this track?"
```
**What happens**: The agent calls `detect_tempo` to find the beat per minute.

### Audio Processing
```
"Convert my song.wav to MP3 format"
```
**What happens**: The agent calls `convert_audio_format` to change the file format.

```
"Convert my MIDI melody to WAV format"
```
**What happens**: The agent calls `convert_midi_to_audio` to synthesize the MIDI file.

### Audio Effects
```
"Add reverb to my guitar with 200ms reverb time"
```
**What happens**: The agent calls `apply_audio_effect` with reverb parameters.

### Mixing & Playback
```
"Mix my vocals, guitar, and drums together with the vocals at +3dB"
```
**What happens**: The agent calls `mix_audio_files` with volume levels for each track.

```
"Create a melody in G major and play it for 5 seconds"
```
**What happens**: The agent calls `create_melody` followed by `play_midi` to generate and preview.

## Step 7: Understanding the Workflow

Here's how the three components work together in a typical interaction:

1. **User Request**: "Create a rock song with drums and a melody in C major"
2. **Agent**: Interprets the request and orchestrates the workflow
3. **Tools**: Agent calls the processing functions:
   - `create_drum_pattern()` - generates rock drum pattern
   - `create_melody()` - creates C major melody
   - `mix_audio_files()` - combines the tracks
4. **Response**: Agent provides the result with musical context

### Example Workflow
```
User: "Create a jazz melody in B minor, add some reverb, and play it for 10 seconds"

Agent Response:
"I'll help you create a jazz melody with reverb. Let me break this down:
1. First, I'll create a jazz melody in B minor
2. Then I'll add reverb to give it some space
3. Finally, I'll play it for you to hear

[Executes tools and provides results]"
```

## Supported Formats

- **Audio**: MP3, WAV, FLAC, OGG, M4A, AIFF, WMA
- **MIDI**: MID, MIDI

## Experimental Features

This agent is in active development. We encourage feedback on real-world usage, different genres, and various file sizes.

## Common Use Cases

- **Music Production**: Create backing tracks, generate drum patterns, compose melodies
- **Audio Editing**: Clean up recordings, normalize levels, apply effects
- **Music Analysis**: Analyze tempo, key, and musical features
- **Educational**: Learn music theory through generation and experimentation

---

**Ready to start?** Run the setup script and begin creating intelligent music workflows!

> **ğŸ’¡ Tip**: This is an experimental agent, so we encourage you to try different use cases and provide feedback to help improve the tools! 


================================================
FILE: docs/docs/tutorials/product-name-scout-agent.md
================================================
---
sidebar_position: 8
---

# Product Name Scout Agent

Learn how to build an AI agent that provides comprehensive product name research and brand validation capabilities. This tutorial shows how to create an agent that can analyze potential product names through search engine analysis, developer platform collision detection, and automated scoring algorithms.

## ğŸ¥ Demo Video

Watch the Product Name Scout Agent in action:

<iframe
  width="100%"
  height="400"
  src="https://www.youtube.com/embed/oReKtfZuHYY"
  title="Product Name Scout Agent Demo"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; fullscreen"
  allowfullscreen="true"
></iframe>

## What You'll Build

A product name research agent that can:
- Check for domain availability (.com, .ai, .dev, .io, etc.) for your product name
- Analyze search engine results for brand competition across Google, DuckDuckGo, and Brave
- Check autocomplete suggestions to identify spelling and recognition issues
- Detect conflicts on developer platforms (GitHub, npm, PyPI)
- Conduct competitive research and trademark conflict assessment
- Provide a final 1-100 scoring based on all of these factors

## Understanding the Architecture

The product name scout agent follows Dexto's framework design with clear separation of responsibilities:

1. **MCP Servers with tools**: Multiple specialized servers for different aspects of name research. These handle specific research tasks (SERP analysis, domain checking, etc.)
2. **Agent**: Orchestrates complex research workflows and synthesizes findings

This architecture allows the agent to conduct thorough research while maintaining clear, actionable insights.

## MCP Server Code

The core functionality is provided by three MCP servers. To understand the complete MCP server implementations, refer to the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/tree/main):

- **Product Name Scout Server**: [src/product-name-scout](https://github.com/truffle-ai/mcp-servers/tree/main/src/product-name-scout) - SERP analysis, autocomplete, dev collisions, and scoring
- **Domain Checker Server**: [src/domain-checker](https://github.com/truffle-ai/mcp-servers/tree/main/src/domain-checker) - Domain availability checking via WHOIS and DNS
- **DuckDuckGo Server**: External third-party server for web search capabilities

## Step 1: Setting Up the Project

The product name research agent uses multiple MCP servers for comprehensive analysis:

```
agents/product-name-researcher/
â”œâ”€â”€ product-name-researcher.yml  # Agent configuration
â””â”€â”€ README.md                   # Documentation
```

## Step 2: Quick Setup

The agent uses published MCP servers that are automatically installed:

```bash
# From the dexto project root
dexto --agent agents/product-name-researcher/product-name-researcher.yml
```

The agent will automatically download and install all required MCP servers:
- `truffle-ai-domain-checker-mcp` - Domain availability checking
- `duckduckgo-mcp-server` - Web search and competitive research
- `@truffle-ai/product-name-scout-mcp` - Advanced name analysis tools

## Step 3: Understanding the Agent Configuration

The agent is configured in `product-name-researcher.yml`:

```yaml
systemPrompt: |
  You are a specialized Product Name Research Agent focused on helping entrepreneurs, 
  product managers, and marketing teams validate potential product names through 
  comprehensive research. Your expertise combines domain availability checking with 
  competitive landscape analysis and advanced searchability assessment.

mcpServers:
  # Domain availability checking
  domain-checker:
    type: stdio
    command: uvx
    args:
      - truffle-ai-domain-checker-mcp
  
  # Web search for competitive research
  duckduckgo:
    type: stdio
    command: uvx
    args:
      - duckduckgo-mcp-server
  
  # Advanced product name analysis
  product-name-scout:
    type: stdio
    command: npx
    args:
      - "@truffle-ai/product-name-scout-mcp"

llm:
  provider: anthropic
  model: claude-4-sonnet-20250514
  apiKey: $ANTHROPIC_API_KEY

toolConfirmation:
  mode: auto-approve
```

### Key Components Explained

1. **systemPrompt**: Defines specialized product name research expertise
2. **mcpServers**: Connects to three complementary research tools
3. **toolConfirmation**: Auto-approves tools for seamless research workflow
4. **llm**: Configures the language model for intelligent analysis

## Step 4: Available Tools

The product name scout agent provides 9 specialized research tools across three categories:

### Domain Research Tools (3)
- `check_domain` - Check availability of a single domain
- `check_multiple_domains` - Check multiple domains simultaneously
- `check_domain_variations` - Check a base name across multiple TLD extensions

### Advanced Name Analysis Tools (4)
- `check_brand_serp` - Analyze search engine results for brand competition
- `get_autocomplete` - Get search engine autocomplete suggestions
- `check_dev_collisions` - Check for existing projects on GitHub, npm, PyPI
- `score_name` - Comprehensive scoring across multiple brand viability factors

### Competitive Research Tools (2)
- `search` - DuckDuckGo search for competitive analysis and market research
- `get_content` - Extract and analyze content from specific web pages

## Step 5: Research Methodology

The agent follows a systematic approach to product name validation:

### For Single Name Research:
1. **Domain Availability Check**: Verify availability across key TLDs (.com, .io, .app, etc.)
2. **SERP Competition Analysis**: Assess existing brand presence in search results
3. **Autocomplete Pattern Analysis**: Understand search behavior and spelling issues
4. **Developer Platform Conflicts**: Check for existing projects on GitHub, npm, PyPI
5. **Competitive Research**: Search for existing companies/products with similar names
6. **Trademark Assessment**: Search for trademark conflicts and legal issues
7. **Comprehensive Scoring**: Generate overall viability score with detailed breakdown

### For Multiple Name Comparison:
1. **Batch Domain Analysis**: Check all names across key TLD extensions
2. **Parallel Research**: Conduct SERP and collision analysis for each name
3. **Comparison Matrix**: Create comprehensive comparison including all factors
4. **Scoring & Ranking**: Rank names based on availability, conflicts, and strategic value
5. **Final Recommendation**: Provide clear recommendation with detailed reasoning

## Step 6: Running the Agent

Start the product name research agent:

```bash
# From the project root
dexto --agent agents/product-name-researcher/product-name-researcher.yml
```

## Step 7: Testing with Example Prompts

Let's test the agent with realistic product name research scenarios:

### Basic Name Validation
```
"I'm considering 'ZenFlow' as a product name for a productivity app. Can you research this name?"
```

**What happens**: The agent orchestrates a complete research workflow:
1. Checks domain availability for zenflow.com, zenflow.io, etc.
2. Analyzes search competition for "ZenFlow"
3. Checks autocomplete suggestions
4. Searches GitHub, npm, and PyPI for conflicts
5. Provides comprehensive scoring and recommendations

### Domain-Focused Research
```
"Check domain availability for 'CodeCraft' across all major extensions"
```

**What happens**: The agent calls `check_domain_variations` to check .com, .net, .org, .io, .app, .dev, and .tech extensions simultaneously.

### Competitive Analysis
```
"Research existing companies using the name 'DataFlow' and assess trademark risks"
```

**What happens**: The agent combines multiple tools:
- `search` for competitive landscape analysis
- `check_brand_serp` for search presence assessment
- `get_content` to analyze competitor websites
- Synthesizes findings into trademark risk assessment

### Multiple Name Comparison
```
"Compare these three product names for a fintech startup: 'PayEase', 'CashFlow', and 'MoneyBridge'"
```

**What happens**: The agent conducts parallel research on all three names and provides a ranked comparison with detailed scoring breakdown.

### Developer-Focused Research
```
"I'm launching a new JavaScript library. Check if 'ReactFlow' conflicts with existing packages"
```

**What happens**: The agent focuses on `check_dev_collisions` for GitHub and npm, plus domain research for library website.

## Step 8: Understanding the Scoring System

The `score_name` tool uses weighted scoring across multiple factors:

### Scoring Factors (with weights):
- **SERP Emptiness (3x)**: Lower search competition = higher score
- **Spellability (2x)**: Easy to spell and remember names score higher  
- **Autocomplete Behavior (2x)**: Clean autocomplete patterns score higher
- **Developer Collisions (2x)**: Fewer conflicts on dev platforms = higher score
- **Domain Availability (3x)**: More available domains = higher score
- **Trademark Conflicts (2x)**: Lower trademark risk = higher score
- **International Considerations (1x)**: Global usability assessment

### Score Interpretation:
- **80-100**: Excellent name with strong availability and low conflicts
- **60-79**: Good name with minor issues to consider
- **40-59**: Moderate concerns requiring careful evaluation
- **20-39**: Significant conflicts or availability issues
- **0-19**: High-risk name with major obstacles

## Step 9: Example Research Workflow

Here's a complete workflow for researching a product name:

```
User: "Research 'CloudSync' for a file synchronization service"

Agent Response:
"I'll conduct comprehensive research on 'CloudSync' for your file synchronization service. Let me analyze multiple factors:

ğŸ” DOMAIN AVAILABILITY
[Checks cloudsync.com, cloudsync.io, cloudsync.app, etc.]
- cloudsync.com: âŒ NOT AVAILABLE 
- cloudsync.io: âœ… AVAILABLE
- cloudsync.app: âœ… AVAILABLE

ğŸ” SEARCH COMPETITION ANALYSIS  
[Analyzes Google search results for 'CloudSync']
- Found ~45,000 results
- Existing competitors in cloud storage space
- Mixed signals on brand conflicts

ğŸ” DEVELOPER PLATFORM CHECK
[Searches GitHub, npm, PyPI for conflicts]
- GitHub: 12 repositories with 'cloudsync' 
- npm: 3 packages with similar names
- PyPI: 1 existing package

ğŸ” AUTOCOMPLETE ANALYSIS
[Checks search suggestions]
- Google suggests: 'cloudsync app', 'cloudsync software'
- Shows some existing recognition

ğŸ“Š COMPREHENSIVE SCORE: 67/100
- Moderate availability with some conflicts
- Strong domain options available (.io, .app)
- Consider alternative: 'SyncCloud' or 'CloudFlow'

ğŸ’¡ RECOMMENDATION: Proceed with caution. While .io and .app domains are available, existing competition suggests trademark research needed. Consider variants like 'SyncStream' or 'CloudVault' for cleaner positioning."
```

## Research Best Practices

### Competitive Research Guidelines:
- Search for exact name matches and close variations
- Research across different industries and markets
- Look for existing trademarks and brand registrations
- Check social media presence and brand mentions
- Consider international markets and global brand presence

### Search Strategy Guidelines:
- Use specific queries: "[name] company", "[name] trademark", "[name] brand"
- Search industry-specific usage: "[name] [industry]", "[name] product"
- Look for legal conflicts: "[name] lawsuit", "[name] trademark dispute"
- Research naming trends in the target industry

## Common Use Cases

- **Startup Name Validation**: Complete due diligence for new company names
- **Product Launch Research**: Validate product names before market entry  
- **Brand Extension Analysis**: Research names for new product lines
- **Trademark Risk Assessment**: Identify potential legal conflicts early
- **Domain Strategy Planning**: Optimize domain portfolio decisions
- **Competitive Intelligence**: Understand market landscape and positioning

---

**Ready for comprehensive name research?** Start the agent and begin validating your product names with professional-grade analysis tools!


================================================
FILE: docs/docs/tutorials/talk2pdf-agent.md
================================================
---
sidebar_position: 6
---

# Talk2PDF Agent

In this tutorial, we'll build a custom AI agent that can parse PDF documents and make them consumable by LLMs. We'll walk through the process step by step, explaining what we're doing and why.

## What We're Building

We want to create an agent that can:
- Parse PDF files and extract text content
- Search for specific terms within documents  
- Provide intelligent analysis and summaries
- Handle errors gracefully

The key insight is that we'll separate concerns: a custom MCP server handles the low-level PDF parsing, while the agent provides intelligent interaction.

## Step 1: Understanding the Architecture

Our agent will have two main components:
1. **MCP Server**: Handles PDF parsing operations (tools)
2. **Agent**: Provides intelligent analysis and user interaction

This separation allows the agent to focus on understanding and analysis while the MCP server handles the technical PDF processing.

## Step 2: Quick Setup

The talk2pdf agent uses a published MCP server that's automatically installed:

```bash
# From the dexto project root
dexto --agent agents/talk2pdf-agent/talk2pdf-agent.yml
```

That's it! The MCP server (`@truffle-ai/talk2pdf-mcp`) will be automatically downloaded and installed via `npx` on first run.

## Step 3: Understanding the MCP Server

The core functionality is provided by the **Talk2PDF MCP Server**, a TypeScript-based server built with the Model Context Protocol SDK. To understand the complete MCP server implementation, refer to the [mcp-servers repository](https://github.com/truffle-ai/mcp-servers/tree/main):

- **Talk2PDF Server**: [src/talk2pdf](https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf) - PDF parsing, text extraction, and content analysis tools

### What's Happening Behind the Scenes

The published MCP server includes these key dependencies:
- **@modelcontextprotocol/sdk**: The MCP framework for server communication
- **pdf-parse-debugging-disabled**: PDF parsing without debug console output
- **zod**: Runtime type validation for tool parameters
- **TypeScript**: Compiled to JavaScript for reliable execution

## Step 4: Available Tools

The talk2pdf MCP server provides two main tools:

1. **`parse_pdf`**: Extract all text and metadata from a PDF
2. **`extract_section`**: Search for specific content within a PDF

Here's how the MCP server is structured (you can view the full implementation at [https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf](https://github.com/truffle-ai/mcp-servers/tree/main/src/talk2pdf)):

```typescript
// Core server structure
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { z } from 'zod';
import { readFileSync, existsSync } from 'fs';
import { extname } from 'path';
import pdf from 'pdf-parse-debugging-disabled';

class Talk2PDFMCPServer {
  private server: McpServer;

  constructor() {
    this.server = new McpServer(
      { name: 'talk2pdf', version: '1.0.0' },
      { capabilities: { tools: {}, resources: {} } }
    );
    this.registerTools();
  }

  private registerTools(): void {
    // Tools are registered here
  }

  async start(): Promise<void> {
    const transport = new StdioServerTransport();
    await this.server.connect(transport);
    console.log('Talk2PDF MCP Server started');
  }
}
```

**What's happening here?**
- We create an MCP server with the name 'talk2pdf'
- The server registers tools that the agent can call
- The server communicates via stdio (standard input/output)

## Step 5: Adding the Parse Tool

The `parse_pdf` tool is our main workhorse. It needs to:
1. Validate the file exists and is a PDF
2. Extract text content
3. Extract metadata (page count, title, author, etc.)
4. Return structured data

```typescript
this.server.tool(
  'parse_pdf',
  'Parse a PDF file and extract its text content and metadata',
  {
    filePath: z.string().describe('Path to the PDF file'),
    includeMetadata: z.boolean().optional().default(true),
    maxPages: z.number().optional(),
  },
  async ({ filePath, includeMetadata = true, maxPages }) => {
    // Validate file exists and is PDF
    if (!existsSync(filePath)) {
      throw new Error(`File not found: ${filePath}`);
    }
    
    // Parse PDF and extract content
    const dataBuffer = readFileSync(filePath);
    const pdfData = await pdf(dataBuffer, { max: maxPages });
    
    // Extract metadata
    const metadata = {
      pageCount: pdfData.numpages,
      title: pdfData.info?.Title,
      author: pdfData.info?.Author,
      fileSize: dataBuffer.length,
      fileName: filePath.split('/').pop() || filePath,
    };
    
    // Return structured result
    const result = {
      content: pdfData.text,
      metadata: includeMetadata ? metadata : {
        pageCount: metadata.pageCount,
        fileSize: metadata.fileSize,
        fileName: metadata.fileName,
      },
    };
    
    return {
      content: [{ type: 'text', text: JSON.stringify(result, null, 2) }],
    };
  }
);
```

**Key points:**
- We validate the file first (safety)
- We use `pdf-parse-debugging-disabled` to avoid common issues
- We return JSON so the agent can easily parse the result

## Step 6: Adding the Search Tool

The `extract_section` tool allows searching within PDFs:

```typescript
this.server.tool(
  'extract_section',
  'Extract specific content from a PDF document',
  {
    filePath: z.string().describe('Path to the PDF file'),
    searchTerm: z.string().optional().describe('Search term to find'),
  },
  async ({ filePath, searchTerm }) => {
    // Validate file exists and is PDF
    if (!existsSync(filePath)) {
      throw new Error(`File not found: ${filePath}`);
    }
    
    const fileExtension = extname(filePath).toLowerCase();
    if (fileExtension !== '.pdf') {
      throw new Error(`File is not a PDF: ${filePath}`);
    }
    
    // Parse the PDF
    const pdfData = await pdf(readFileSync(filePath));
    
    let extractedContent = pdfData.text;
    
    // If search term provided, filter content
    if (searchTerm) {
      const lines = extractedContent.split('\n');
      const matchingLines = lines.filter(line => 
        line.toLowerCase().includes(searchTerm.toLowerCase())
      );
      extractedContent = matchingLines.join('\n');
    }
    
    const result = {
      fileName: filePath.split('/').pop() || filePath,
      totalPages: pdfData.numpages,
      extractedContent,
      searchTerm: searchTerm || null,
      contentLength: extractedContent.length,
    };
    
    return { content: [{ type: 'text', text: JSON.stringify(result, null, 2) }] };
  }
);
```

**What this does:**
- Parses the PDF to get all text
- If a search term is provided, filters lines containing that term
- Returns the filtered content

## Step 7: Understanding the Agent Configuration

The agent configuration connects to the published MCP server:

```yaml
# agents/talk2pdf-agent/talk2pdf-agent.yml
mcpServers:
  talk2pdf:
    type: stdio
    command: npx
    args:
      - "@truffle-ai/talk2pdf-mcp"
    timeout: 30000
    connectionMode: strict

systemPrompt:
  contributors:
    - id: primary
      type: static
      priority: 0
      content: |
        You are a Talk2PDF Agent. You can parse PDF files, extract their text, metadata, and provide summaries or extract specific sections for LLM consumption.
        
        ## Your Capabilities
        - Parse PDF files and extract all text content and metadata
        - Extract specific sections or search for terms within a PDF
        - Provide intelligent analysis, summarization, and insights based on the extracted content
        - Handle errors gracefully and provide clear feedback
        
        Always ask for the file path if not provided. If a file is not a PDF or does not exist, inform the user.

llm:
  provider: openai
  model: gpt-4o-mini
  apiKey: $OPENAI_API_KEY
```

**Key configuration points:**
- The agent connects to the published MCP server via stdio
- We use `npx @truffle-ai/talk2pdf-mcp` to run the compiled server
- The system prompt tells the agent what it can do and how to behave

## Step 8: Testing the Agent

Now we can test our agent:

```bash
# From the project root
dexto --agent ./agents/talk2pdf-agent/talk2pdf-agent.yml
```

Once started, try these interactions:

**Parse and summarize:**
```
Parse the PDF at /path/to/document.pdf and summarize the key points
```

**Search for content:**
```
Find all mentions of "budget" in the financial report at /path/to/report.pdf
```

## How It All Works Together

1. **User asks a question** about a PDF
2. **Agent understands** what the user wants
3. **Agent calls the appropriate tool** (`parse_pdf` or `extract_section`)
4. **MCP server processes** the PDF and returns structured data
5. **Agent analyzes** the returned data and provides intelligent response
6. **User gets** a helpful, contextual answer

## What We've Accomplished

We've created a complete PDF parsing agent that demonstrates:

- **Separation of concerns**: Tools handle technical operations, agent handles intelligence
- **Error handling**: Proper validation and graceful error messages
- **Flexible architecture**: Easy to extend with more tools
- **Distributed architecture**: Published MCP server for easy deployment and updates

The agent can now parse PDFs, extract content, search for terms, and provide intelligent analysis - all through natural language interaction, using a published MCP server that's automatically installed.

## Next Steps

This pattern can be extended to:
- Add more document formats (DOCX, TXT)
- Implement document comparison
- Add OCR for scanned PDFs
- Create document classification

The key insight is that by separating the technical operations (published MCP server) from the intelligence (agent), we create a flexible, maintainable system that's easy to extend and debug. The published server approach means updates and improvements can be distributed automatically without requiring changes to the agent configuration. 


================================================
FILE: docs/src/pages/markdown-page.md
================================================
---
title: Markdown page example
---

# Markdown page example

You don't need React to write simple standalone pages.



================================================
FILE: examples/dexto-langchain-integration/README.md
================================================
# Dexto + LangChain Example

This example demonstrates how Dexto's orchestration layer can integrate existing agents from other frameworks (like LangChain, LangGraph, etc.) via the Model Context Protocol (MCP), enabling seamless multi-agent workflows.

## Architecture

```mermaid
graph TD
    A[Dexto Orchestrator] --> B[Filesystem Tools]
    A --> C[Puppeteer Tools]
    A --> D[LangChain Agent]
    
    style A fill:#4f46e5,stroke:#312e81,stroke-width:2px,color:#fff
    style B fill:#10b981,stroke:#065f46,stroke-width:1px,color:#fff
    style C fill:#f59e0b,stroke:#92400e,stroke-width:1px,color:#fff
    style D fill:#8b5cf6,stroke:#5b21b6,stroke-width:1px,color:#fff
```

## How to Think About Multi-Agent Integration

When building multi-agent systems, you often have agents built in different frameworks. Here's how to approach this with Dexto:

1. **Start with what you have**: You may already have agents in LangChain, LangGraph, AutoGen, or other frameworks
2. **Use MCP as the bridge**: Instead of rebuilding or creating custom adapters, wrap your existing agents with MCP as a tool
3. **Let Dexto orchestrate**: Dexto can then coordinate between your existing agents and other tools/subsystems
4. **Build incrementally**: Add more agents and frameworks as needed - MCP makes it straightforward

## Quick Setup

```bash
# Install dependencies
cd examples/dexto-langchain-integration/langchain-agent
npm install
npm run build

# Set API key
export OPENAI_API_KEY="your_openai_api_key_here"

# Test integration (run from repository root)
cd ../../..
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Analyze the sentiment of this review: 'I absolutely love this product! The quality is amazing and the customer service was outstanding. Best purchase I've made this year.'"

# Note: Agent file paths in the YAML config are resolved relative to the current working directory
```

## What You Can Do

**Dexto orchestrates between:**
- **Filesystem**: Read/write files
- **Puppeteer**: Web browsing and interaction
- **LangChain Agent**: Text summarization, translation, sentiment analysis

**Example workflows:**
```bash
# Text summarization
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Summarize this article: Artificial intelligence has transformed how we work, with tools like ChatGPT and GitHub Copilot becoming essential for developers. These AI assistants help write code, debug issues, and even design entire applications. The impact extends beyond coding - AI is reshaping customer service, content creation, and decision-making processes across industries."

# Translation
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Translate this text to Spanish: The weather is beautiful today and I'm going to the park to enjoy the sunshine."

# Sentiment Analysis
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Analyze the sentiment of this customer review: 'I absolutely love this product! The quality is amazing and the customer service was outstanding. Best purchase I've made this year.'"

# Multi-step: Read file â†’ Summarize â†’ Save
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Read README.md, summarize it, save the summary"

# Complex: Web scrape â†’ Sentiment Analysis â†’ Save
dexto --agent ./examples/dexto-langchain-integration/dexto-agent-with-langchain.yml "Search for customer reviews about our product, analyze the sentiment, save as sentiment_report.md"
```

## How It Works

1. **Dexto Orchestrator**: Manages & supervises all subsystems and workflows
2. **LangChain MCP Agent**: Wraps existing LangChain agent as a Dexto subsystem
3. **Configuration**: Registers LangChain alongside filesystem and puppeteer tools

## Extending

**Add agents from other frameworks:**
1. Wrap more agents into an MCP Server
2. Add to Dexto configuration
3. Dexto orchestrates between all agents and subsystems

**Add capabilities to existing agents:**
1. Extend your external agent capabilities
2. Register new tools/methods
3. Dexto accesses via MCP integration

This demonstrates how to think about Dexto as your orchestration layer for multi-agent systems - start with your existing agents, use MCP to connect them, and let Dexto handle the coordination.



================================================
FILE: postman/README.md
================================================
# Postman Collections

This folder contains Postman collections for testing Dexto APIs.

## Available Collections

### `dexto-webhooks.postman_collection.json`
Complete API collection for testing Dexto webhook functionality including:
- Webhook management (register, list, get, test, remove)
- Event triggers (send message, reset conversation)
- Other API endpoints (health, sessions, LLM config)

## Setup Instructions

1. **Import Collection**
   - Open Postman
   - Click "Import" â†’ "File"
   - Select the collection JSON file
   - Click "Import"

2. **Configure Variables**
   - Click collection name â†’ "Variables" tab
   - Update `webhookUrl` with your webhook.site URL
   - Update `baseUrl` if server runs on different port
   - Save changes

3. **Start Dexto Server**
   ```bash
   npm run build
   node dist/src/app/index.js --mode server --agent test-config.yml
   ```

4. **Test Workflow**
   - Health Check â†’ Register Webhook â†’ Test Webhook â†’ Send Message
   - Check webhook.site to see received events

## Variables Used

| Variable | Description | Default |
|----------|-------------|---------|
| `baseUrl` | Dexto server URL | `http://localhost:3000` |
| `webhookUrl` | Test webhook endpoint | `https://webhook.site/your-unique-id` |
| `webhookSecret` | HMAC verification secret | `test_secret_123` |
| `sessionId` | Session ID for events | `test-session-123` |
| `webhookId` | Auto-set from registration | *(empty)* |

## Features

- âœ… Parametric URLs with variables
- âœ… Auto-capture webhook ID from registration
- âœ… Pretty printing enabled (`?pretty=true`)
- âœ… Pre-configured request bodies
- âœ… Complete webhook testing workflow


================================================
FILE: src/TESTING.md
================================================
This doc describes how to test the dexto exported files and dexto CLI after making changes in 

### Testing library exports
This part tests the functions/classes/types that we export from dexto for usage in programs.

1.  In the dexto root directory, pack the build into a local tarball  
    ```bash
    npm run build
    npm pack
    ```  
    This produces something like  
    ```
    dexto-0.2.1.tgz
    ```

2.  Spin up a fresh, disposable test project  
    ```bash
    mkdir ~/tmp/dexto-test && cd ~/tmp/dexto-test
    npm init -y
    ```

3.  Install your packaged tarball  
    ```bash
    npm install /full/path/to/dexto/dexto*.tgz
    ```

4.  Verify CJS import resolution  
    â€¢ Create a file `test-cjs.js`:
    ```js
    // test-cjs.js
    const pkg = require('dexto');
    console.log('CJS import â†’', pkg);
    ```  
    â€¢ Run it:
    ```bash
    node test-cjs.js
    ```
    You should see your exported object (and no "cannot find module" errors).

5.  Verify ESM import resolution  
    â€¢ Create `test-esm.mjs`:
    ```js
    // test-esm.mjs
    import pkg from 'dexto';
    console.log('ESM import â†’', pkg);
    ```  
    â€¢ Run it:
    ```bash
    node test-esm.mjs
    ```
    Again, you should see your package namespace.

6.  Check TypeScript typings  
    â€¢ Install TS (if you haven't):  
      ```bash
      npm install typescript --save-dev
      ```  
    â€¢ Create `test.d.ts`:
    ```ts
    import pkg from 'dexto';
    ```
    â€¢ Add a minimal `tsconfig.json`:
    ```jsonc
    {
      "compilerOptions": {
        "module": "NodeNext",
        "moduleResolution": "NodeNext",
        "noEmit": true,
        "esModuleInterop": true
      }
    }
    ```  
    â€¢ Run:
    ```bash
    npx tsc
    ```  
    No errors means your `"types"` export is wired up correctly.

### Testing the CLI

Clean up old install
```
npm uninstall -g dexto
cd <location of dexto root directory>
```

Install again
```
npm run build && npm pack
# this will create a tarball dexto.<>.tgz
npm install -g dexto.*.tgz
```

Now go to another directory and test
```
cd ~
dexto --help 
dexto "what is the current time"
dexto "list files in current directory"

# Test other model override in CLI
dexto -m gpt-4o-mini "what is the current date"

# Test web mode
dexto --mode web

# Test discord bot mode (requires additional setup)
dexto --mode discord

# Test telegram bot mode (requires additional setup)
dexto --mode telegram

# try the same in a few other directories
```


================================================
FILE: src/app/api/webhooks.md
================================================
# Webhook API Documentation

The Dexto webhook system provides HTTP-based event delivery for agent events, offering an alternative to WebSocket subscriptions for cloud integrations.

## Overview

Webhooks allow you to receive real-time notifications about agent events by registering HTTP endpoints that will receive POST requests when events occur. This is similar to how Stripe webhooks work - when something happens in your Dexto agent, we'll send a POST request to your configured webhook URL.

## Event Structure

All webhook events follow a consistent structure inspired by Stripe's webhook events:

```typescript
interface DextoWebhookEvent<T extends AgentEventName = AgentEventName> {
    id: string;              // Unique event ID (e.g., "evt_1234567890_abc123def")
    type: T;                 // Event type with TypeScript autocomplete
    data: AgentEventMap[T];  // Event-specific payload
    created: string;         // ISO-8601 timestamp of when the event occurred
    apiVersion: string;      // API version (currently "2025-07-03")
}
```

## TypeScript Autocomplete Support

The webhook system provides full TypeScript autocomplete support for event types, similar to Stripe's implementation:

```typescript
// Your IDE will autocomplete available event types
if (event.type === "llmservice:response") {
    // TypeScript knows event.data has response-specific fields
    console.log(event.data.content);
    console.log(event.data.tokenUsage?.totalTokens);
}
```

## Available Event Types

The webhook system supports all agent events:

- `llmservice:thinking` - AI model is processing
- `llmservice:chunk` - Streaming response chunk received
- `llmservice:toolCall` - Tool execution requested
- `llmservice:toolResult` - Tool execution completed
- `llmservice:response` - Final AI response received
- `llmservice:error` - Error during AI processing
- `llmservice:unsupportedInput` - Input type not supported by selected model
- `dexto:conversationReset` - Conversation history cleared
- `dexto:mcpServerConnected` - MCP server connection established
- `dexto:availableToolsUpdated` - Available tools changed
- `dexto:toolConfirmationRequest` - Tool execution requires confirmation
- `dexto:llmSwitched` - LLM model switched
- `dexto:stateChanged` - Agent state updated

## Webhook Management API

### Register a Webhook

```bash
POST /api/webhooks
Content-Type: application/json

{
    "url": "https://your-app.com/webhooks/dexto",
    "secret": "whsec_your_secret_key",  // Optional for signature verification
    "description": "Production webhook"  // Optional description
}
```

Response:
```json
{
    "webhook": {
        "id": "wh_1703123456_abc123def",
        "url": "https://your-app.com/webhooks/dexto",
        "description": "Production webhook",
        "createdAt": "2025-01-01T12:00:00.000Z"
    }
}
```

### List Webhooks

```bash
GET /api/webhooks
```

### Get Specific Webhook

```bash
GET /api/webhooks/{webhook_id}
```

### Remove Webhook

```bash
DELETE /api/webhooks/{webhook_id}
```

### Test Webhook

```bash
POST /api/webhooks/{webhook_id}/test
```

This sends a test `dexto:availableToolsUpdated` event to verify your endpoint is working.

## Security & Signature Verification

When you provide a `secret` during webhook registration, Dexto will include an HMAC signature in the `X-Dexto-Signature-256` header for verification:

```
X-Dexto-Signature-256: sha256=a1b2c3d4e5f6...
```

### Verifying Signatures (Node.js Example)

```javascript
const crypto = require('crypto');

function verifyWebhookSignature(payload, signature, secret) {
    const expectedSignature = crypto
        .createHmac('sha256', secret)
        .update(payload, 'utf8')
        .digest('hex');
    
    const expected = `sha256=${expectedSignature}`;
    return crypto.timingSafeEqual(
        Buffer.from(signature, 'utf8'),
        Buffer.from(expected, 'utf8')
    );
}

// In your webhook handler
app.post('/webhooks/dexto', (req, res) => {
    const signature = req.headers['x-dexto-signature-256'];
    const payload = req.body.toString('utf8'); // `req.body` is a Buffer here
    
    if (!verifyWebhookSignature(payload, signature, 'your_secret')) {
        return res.status(401).send('Unauthorized');
    }
    
    // Parse only *after* signature verification
    const event = JSON.parse(payload);
    console.log(`Received ${event.type} event:`, event.data);
    
    res.status(200).send('OK');
});
```

## HTTP Headers

Each webhook request includes these headers:

- `Content-Type: application/json`
- `User-Agent: DextoAgent/1.0`
- `X-Dexto-Event-Type: {event_type}`
- `X-Dexto-Event-Id: {event_id}`
- `X-Dexto-Delivery-Attempt: {attempt_number}`
- `X-Dexto-Signature-256: sha256={signature}` (if secret provided)

## Delivery & Retry Logic

- **Delivery**: Webhooks are delivered asynchronously and don't block agent operations
- **Timeout**: 10 second timeout per request
- **Retries**: Up to 3 attempts with exponential backoff (1s, 2s, 4s)
- **Success**: HTTP 2xx status codes are considered successful
- **Failure**: Non-2xx responses or network errors trigger retries

## Best Practices

1. **Respond Quickly**: Return a 2xx status code as fast as possible. Process events asynchronously if needed.

2. **Handle Duplicates**: Due to retries, you might receive the same event multiple times. Use the `event.id` for deduplication.

3. **Verify Signatures**: Always verify webhook signatures in production to ensure requests are from Dexto.

4. **Use HTTPS**: Always use HTTPS URLs for webhook endpoints to ensure secure delivery.

5. **Handle All Event Types**: Your webhook should handle unknown event types gracefully as new events may be added.

## Example Webhook Handler

```typescript
import express from 'express';
import type { DextoWebhookEvent } from './webhook-types';

const app = express();
// Use raw body middleware for signature verification
app.use(express.raw({ type: 'application/json' }));

app.post('/webhooks/dexto', (req, res) => {
    // Parse JSON from raw buffer
    const event: DextoWebhookEvent = JSON.parse(req.body.toString('utf8'));
    
    try {
        switch (event.type) {
            case 'llmservice:response':
                console.log('AI Response:', event.data.content);
                break;
                
            case 'llmservice:toolCall':
                console.log('Tool Called:', event.data.toolName);
                break;
                
            case 'dexto:conversationReset':
                console.log('Conversation reset for session:', event.data.sessionId);
                break;
                
            default:
                console.log('Unknown event type:', event.type);
        }
        
        res.status(200).send('OK');
    } catch (error) {
        console.error('Webhook error:', error);
        res.status(500).send('Internal Server Error');
    }
});
```

## Differences from WebSockets

| Feature | WebSockets | Webhooks |
|---------|------------|----------|
| Connection | Persistent connection required | Stateless HTTP requests |
| Delivery | Real-time | Near real-time with retries |
| Scalability | Limited by connection count | Scales with HTTP infrastructure |
| Reliability | Connection can drop | Built-in retry mechanism |
| Development | Requires WebSocket client | Standard HTTP endpoint |
| Cloud-friendly | Requires persistent connections | Works with serverless functions |

## Server Mode Requirement

Webhooks are only available when Dexto is running in server mode (`dexto --mode server` command). They are not available in CLI or other modes since webhooks require the HTTP API server to be running.



================================================
FILE: src/app/cli/commands/interactive-commands/README.md
================================================
# Interactive CLI Commands

This directory contains the modular CLI command system for Dexto. The architecture has been designed to be maintainable, extensible, and well-organized.

## Architecture Overview

The CLI system is built with a modular approach where commands are organized by functionality and category. This makes it easy to add new commands, modify existing ones, and maintain the codebase.

### Core Components

#### `commands.ts` - Main Aggregator
- **Purpose**: Combines all modular commands into a single `CLI_COMMANDS` array
- **Exports**: `CLI_COMMANDS`, `executeCommand()`, `getAllCommands()`
- **Pattern**: Uses both direct imports and spread operators for different command types

#### `command-parser.ts` - Core Infrastructure
- **Purpose**: Provides parsing, formatting, and help display utilities
- **Key Functions**:
  - `parseInput()` - Distinguishes between commands and prompts
  - `displayAllCommands()` - Shows categorized help display
  - `formatCommandHelp()` - Formats individual command help
  - `getCommandSuggestions()` - Command completion support

### Command Organization

Commands are organized into logical modules based on functionality:

#### Simple Commands (Array Exports)
These export arrays of individual `CommandDefinition` objects:

- **`general-commands.ts`** - Basic CLI functionality
  - `/help` - Command help system (special factory pattern)
  - `/exit` - CLI termination  
  - `/clear` - Reset conversation

- **`system/system-commands.ts`** - System configuration
  - `/log` - Log level management
  - `/config` - Configuration display
  - `/stats` - System statistics

- **`tool-commands.ts`** - Tool management
  - `/tools` - List available MCP tools

- **`prompt-commands.ts`** - System prompt
  - `/prompt` - Display current system prompt

- **`documentation-commands.ts`** - Help resources
  - `/docs` - Open documentation in browser

- **`session/`** - Session management (folder)
  - `/session` - Session management (parent command with subcommands)
  - `/history` - Standalone history command
  - `/search` - Standalone search command

#### Hierarchical Commands (Single Object Exports)
These export single `CommandDefinition` objects with subcommands:

- **`model/model-commands.ts`** - Model management
  - `/model list` - List available models
  - `/model current` - Show current model
  - `/model switch` - Switch models
  - `/model help` - Model help

- **`mcp/mcp-commands.ts`** - MCP server management
  - `/mcp list` - List MCP servers
  - `/mcp add` - Add MCP servers (with sub-subcommands for stdio/http/sse)
  - `/mcp remove` - Remove MCP servers
  - `/mcp help` - MCP help

### File Structure

```
src/app/cli/interactive-commands/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ commands.ts                        # Main command aggregator
â”œâ”€â”€ command-parser.ts                  # Core parsing and formatting utilities
â”œâ”€â”€ general-commands.ts                # Basic CLI commands
â”œâ”€â”€ tool-commands.ts                   # Tool management
â”œâ”€â”€ prompt-commands.ts                 # System prompt display
â”œâ”€â”€ documentation-commands.ts          # Documentation access
â”œâ”€â”€ session/                           # Session management
â”‚   â”œâ”€â”€ index.ts                      # Session module exports
â”‚   â”œâ”€â”€ session-commands.ts           # Session command implementations
â”‚   â””â”€â”€ helpers/
â”‚       â””â”€â”€ formatters.ts             # Session formatting utilities
â”œâ”€â”€ model/                            # Model management
â”‚   â”œâ”€â”€ index.ts                      # Model module exports
â”‚   â””â”€â”€ model-commands.ts             # Model command implementations
â”œâ”€â”€ mcp/                              # MCP server management
â”‚   â”œâ”€â”€ index.ts                      # MCP module exports
â”‚   â”œâ”€â”€ mcp-commands.ts               # MCP command implementations
â”‚   â””â”€â”€ mcp-add-utils.ts              # MCP add command utilities
â””â”€â”€ system/                           # System commands
    â”œâ”€â”€ index.ts                      # System module exports
    â””â”€â”€ system-commands.ts            # System command implementations
```

## Command Categories

The help system displays commands in these categories:

1. **General** - Basic CLI functionality
2. **Session Management** - Session, history, and search
3. **Model Management** - AI model configuration
4. **MCP Management** - MCP server management
5. **Tool Management** - Available tools
6. **Prompt Management** - System prompt
7. **System** - Configuration and statistics
8. **Documentation** - Help resources

## Design Patterns

### Help Command Factory Pattern
The `/help` command uses a factory pattern to access all commands:
```typescript
export function createHelpCommand(getAllCommands: () => CommandDefinition[]): CommandDefinition
```

### Consistent Export Patterns
- **Arrays**: `export const commandName: CommandDefinition[] = [...]`
- **Single Objects**: `export const commandName: CommandDefinition = {...}`

### Module Index Pattern
Each folder has an `index.ts` that re-exports the main command definitions for clean imports.

### Command Handler Pattern
All command handlers follow the same signature:
```typescript
handler: async (args: string[], agent: DextoAgent) => Promise<boolean>
```

## Adding New Commands

### Simple Command (Individual)
1. Add to appropriate `*-commands.ts` file or create new file
2. Export as array: `export const newCommands: CommandDefinition[] = [...]`
3. Import and spread in `commands.ts`: `...newCommands`

### Hierarchical Command (With Subcommands)
1. Create new folder with `index.ts` and `*-commands.ts`
2. Export as single object: `export const newCommand: CommandDefinition = {...}`
3. Import directly in `commands.ts`: `newCommand`

### Folder Structure Command
1. Create folder: `mkdir new-category/`
2. Add `index.ts`, `*-commands.ts`, and any utilities
3. Update `commands.ts` imports and exports
4. Update category order in `command-parser.ts`

## Best Practices

### Code Organization
- Keep related commands in the same module
- Use helper files for complex utilities
- Follow consistent naming conventions

### Type Safety
- Always use proper TypeScript types
- Import types from `@core/index.js`
- Use `CommandDefinition` interface consistently

### Error Handling
- Always wrap async operations in try/catch
- Use `logger.error()` for error reporting
- Return `true` to continue CLI, `false` to exit

### Help Documentation
- Provide clear descriptions and usage examples
- Use real examples from `agents/` directory
- Include tips and best practices in help text

### Import Standards
- All imports must end with `.js` for ES module compatibility
- Use relative imports within the same module
- Import types separately when possible

## Dependencies

The CLI system depends on:
- `@core/index.js` - Core Dexto agent functionality
- `chalk` - Terminal color formatting
- Various MCP and session management utilities

## Testing

Commands should be tested by:
1. Unit tests for individual command logic
2. Integration tests for agent interactions
3. Manual testing of CLI user experience

The modular architecture makes it easy to test individual command modules in isolation.


================================================
FILE: src/app/discord/README.md
================================================
# Discord Bot Setup

To run Dexto as a Discord bot, you need to configure the following environment variable:

1.  **`DISCORD_BOT_TOKEN` (Required)**
    *   This is the authentication token for your Discord bot application. It allows your Dexto instance to connect to Discord as your bot.
    *   **How to get your token:**
        1.  Go to the [Discord Developer Portal](https://discord.com/developers/applications).
        2.  Select your application, or create a new one if you haven't already.
        3.  In the sidebar, navigate to **Bot**.
        4.  Under the "Token" section, click **Reset Token** (or **Copy Token** if one is already generated and visible).
        5.  Confirm the reset if prompted (this will invalidate the old token if one existed).
        6.  Copy the newly revealed token. This is your `DISCORD_BOT_TOKEN`.
            *   **Important:** Treat this token like a password. Do not share it publicly or commit it to your repository.
    *   Example (in your `.env` file):
        `DISCORD_BOT_TOKEN=YOUR_DISCORD_BOT_TOKEN_HERE`

## Running the Bot

Once the `DISCORD_BOT_TOKEN` is set (e.g., in a `.env` file at the project root), you can start the Discord bot.

To use the default Dexto configuration (`agents/default-agent.yml`):
```bash
dexto --mode discord
# With a custom config path:
# dexto --mode discord --agent ./agents/discord_bot_config.yml
```

Or, if you are running directly from the source without a global installation:
```bash
npm start -- --mode discord
# With a custom config path:
# npm start -- --mode discord --agent ./agents/discord_bot_config.yml
```

Refer to the main project [README.md](../../../README.md) for more details on general Dexto setup and configuration.

## Technical Details

*   **Message Handling:** The bot connects to Discord using a WebSocket and processes messages as they arrive based on `discord.js` library events. It does not use explicit short polling for messages.
*   **Service Initialization:** When started, the Discord bot initializes its own instance of Dexto's core services (LLM service, client manager for MCP tools, event bus) by calling `createAgentServices`. It uses `runMode: 'web'` for this initialization. This means that, by default, tool confirmations use the `NoOpConfirmationProvider`, which automatically approves all tool executions initiated by the bot.
*   **Configuration:** The Dexto configuration file (specified by `DISCORD_CONFIG_PATH`, the global `--agent` option, or the default `agents/default-agent.yml`) is loaded by the bot to configure its internal services, such as the LLM provider, model, and any MCP server connections.
*   **Tool Call Notifications:** The bot subscribes to `llmservice:toolCall` events on its `agentEventBus`. When a tool is about to be executed by the LLM service, a notification message (âš™ï¸ Calling tool...) is sent to the Discord channel where the command originated.
*   **Image Attachments:** If a message includes an image attachment, the bot downloads the image, converts it to a base64 string, and passes it along with any text content to the LLM service for processing. This allows for multimodal interactions.
*   **Command Trigger:** The bot responds to messages in Direct Messages (DMs) or messages in servers/guilds that start with the `!ask ` prefix. 


================================================
FILE: src/app/telegram/README.md
================================================
# Telegram Bot Setup

To run Dexto as a Telegram bot, you need to configure the following environment variable:

1.  **`TELEGRAM_BOT_TOKEN` (Required)**
    *   This is the authentication token for your Telegram bot. It allows your Dexto instance to connect to Telegram as your bot.
    *   **How to get your token:**
        1.  Open Telegram and search for "BotFather" (it's an official bot from Telegram with a verified checkmark).
        2.  Start a chat with BotFather by sending `/start`.
        3.  To create a new bot, send `/newbot`. Follow the prompts to choose a name and username for your bot. The username must end in "bot" (e.g., `YourDextoBot`).
        4.  Alternatively, if you already have a bot, you can generate/regenerate a token by sending `/token` and selecting your bot.
        5.  Once your bot is created or selected, BotFather will provide you with an API token. This is your `TELEGRAM_BOT_TOKEN`.
            *   **Important:** Treat this token like a password. Do not share it publicly or commit it to your repository.
    *   Example (in your `.env` file):
        `TELEGRAM_BOT_TOKEN=YOUR_TELEGRAM_BOT_TOKEN_HERE`

## Running the Bot

Once the `TELEGRAM_BOT_TOKEN` is set (e.g., in a `.env` file at the project root), you can start the Telegram bot.

To use the default Dexto configuration (`agents/default-agent.yml`):
```bash
dexto --mode telegram
# With a custom config path:
# dexto --mode telegram --agent ./agents/telegram_bot_config.yml
```

Or, if you are running directly from the source without a global installation:
```bash
npm start -- --mode telegram
# With a custom config path:
# npm start -- --mode telegram --agent ./agents/telegram_bot_config.yml
```

Refer to the main project [README.md](../../../README.md) for more details on general Dexto setup and configuration.

## Technical Details

*   **Framework:** The bot now uses [grammY](https://grammy.dev), a modern, secure, and lightweight Telegram Bot framework with excellent TypeScript support.
*   **Message Handling:** The bot uses long polling to receive updates from Telegram. grammY handles this automatically when `bot.start()` is called.
*   **Tool Call Notifications:** The bot subscribes to `llmservice:toolCall` events on its `agentEventBus`. When a tool is about to be executed by the LLM service, a notification message (âš™ï¸ Calling tool...) is sent to the Telegram chat where the command originated.
*   **Image Attachments:** If a message includes a photo, the bot downloads the highest resolution version of the image, converts it to a base64 string, and passes it along with any caption text to the LLM service for processing.
*   **Command Triggers & Interaction:**
    *   `/start`: Displays a welcome message and inline buttons (e.g., for resetting conversation).
    *   Button Callbacks: Handles actions from inline buttons (e.g., `reset`, `help`).
    *   `/ask <question>`: Specifically for group chats to direct a question to the bot.
    *   General Messages: In direct messages (DMs) or if no other command handler matches, the bot processes the text (and any attached image) as input for the LLM.
    *   Inline Queries (@YourBotName): Supports Telegram inline queries, allowing users to get AI responses directly in any chat by typing the bot's username and their query.

## Migration Notes

This bot was recently migrated from `node-telegram-bot-api` to grammY to:
- Fix security vulnerabilities in the deprecated `request` package
- Improve performance and reduce dependencies
- Provide better TypeScript support
- Enable access to modern Telegram Bot API features

All functionality remains the same, but the underlying implementation is now more secure and maintainable. 


================================================
FILE: src/app/webui/README.md
================================================
# Dexto Playground

This project is an interactive playground for testing MCP tools/servers tools and building your own AI agents.

[MCP - Model Context Protocol]

## Features

- **Tool Testing Playground**: Connect and test MCP servers and their tools interactively
- **Simple Chat Interface**: Clean, focused conversation with AI agents
- **Server Management**: Easy connection and management of MCP servers
- **Tool Discovery**: Explore available tools and their capabilities
- **Configuration Export**: Export your tool setup for use with Claude Desktop or other MCP clients

## What is MCP?

The Model Context Protocol (MCP) allows AI models to securely connect to external tools and data sources. Dexto provides a simple interface to:

- Connect to MCP servers
- Test tool functionality
- Chat with AI agents that have access to your tools
- Export configurations for other clients

## Quick Start

1. Connect a MCP server using the "Tools" panel
2. Test individual tools in the playground (`/playground`)
3. Chat with AI agents that can use your connected tools
4. Export your configuration when ready

This project is built with [Next.js](https://nextjs.org) and uses modern web technologies for a smooth development experience.

## Developer guide

Clear out ports 3000 (linux):
```bash
lsof -ti:3000-3001 | xargs kill -9   
```

Start one server for the API at the root directory of this project [port 3001]:
```bash
[  2:29PM ]  [ ~/Projects/dexto(storageâœ—) ]
 $ npm run build && npm link && dexto --mode server
 ```

then start the npm dev server [port 3000]

```bash
[  2:31PM ]  [ karaj@MacBook-Pro:~/Projects/dexto/src/app/webui(storageâœ—) ]
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to start testing your tools.

This is temporary because the application functionality uses Dexto APIs built in the same project



================================================
FILE: src/app/webui/lib/README.md
================================================
# MCP Server Registry

This directory contains the MCP (Model Context Protocol) server registry system for Dexto.

## Structure

- `serverRegistry.ts` - The main registry service that manages MCP server entries
- `server-registry-data.json` - External JSON file containing all built-in server definitions

## Adding New MCP Servers

To add a new MCP server to the registry, simply edit the `server-registry-data.json` file. No code changes are required!

### Server Entry Format

Each server entry should follow this structure:

```json
{
  "id": "unique-server-id",
  "name": "Display Name",
  "description": "Brief description of what this server does",
  "category": "productivity|research|creative|development",
  "icon": "ğŸ“",
  "config": {
    "type": "stdio|http|sse",
    "command": "npx|uvx|python",
    "args": ["-y", "package-name"],
    "env": {
      "API_KEY": ""
    },
    "timeout": 30000
  },
  "tags": ["tag1", "tag2"],
  "isOfficial": true,
  "isInstalled": false,
  "requirements": {
    "platform": "all|windows|mac|linux",
    "node": ">=18.0.0",
    "python": ">=3.10"
  },
  "author": "Author Name",
  "homepage": "https://github.com/author/repo",
  "matchIds": ["server-id", "alternative-id"]
}
```

### Configuration Types

#### Stdio (Node.js/npm)
```json
{
  "type": "stdio",
  "command": "npx",
  "args": ["-y", "package-name"],
  "env": {
    "API_KEY": ""
  }
}
```

#### Stdio (Python/uvx)
```json
{
  "type": "stdio",
  "command": "uvx",
  "args": ["package-name"]
}
```

#### HTTP/SSE
```json
{
  "type": "http",
  "url": "https://api.example.com/mcp",
  "headers": {
    "Authorization": "Bearer $API_KEY"
  }
}
```

### Categories

- **productivity** - File operations, task management, workflow tools
- **research** - Search, data analysis, information gathering
- **creative** - Image editing, music creation, content generation
- **development** - Code analysis, debugging, development tools

### Icons

Use appropriate emojis for each server type:
- ğŸ“ File operations
- ğŸ” Search/research
- ğŸ–¼ï¸ Image/media
- ğŸµ Audio/music
- ğŸŒ Web/browser
- ğŸ“‹ Task management
- ğŸ¤— AI/ML models

## Benefits of External JSON

1. **No rebuilds required** - Add servers by editing JSON only
2. **Easy maintenance** - All server data in one place
3. **Version control friendly** - Track server additions in git
4. **Non-developer friendly** - Anyone can add servers without touching code
5. **Consistent structure** - Enforced schema for all entries

## Example: Adding Tavily Search

```json
{
  "id": "tavily",
  "name": "Tavily Search",
  "description": "Web search and research using Tavily AI search engine",
  "category": "research",
  "icon": "ğŸ”",
  "config": {
    "type": "stdio",
    "command": "npx",
    "args": ["-y", "tavily-mcp@0.1.3"],
    "env": {
      "TAVILY_API_KEY": ""
    },
    "timeout": 30000
  },
  "tags": ["search", "web", "research", "ai"],
  "isOfficial": false,
  "isInstalled": false,
  "requirements": { "platform": "all", "node": ">=18.0.0" },
  "author": "Tavily AI",
  "homepage": "https://www.npmjs.com/package/tavily-mcp",
  "matchIds": ["tavily"]
}
```

## Testing

After adding a new server to the JSON file:

1. Restart the Dexto WebUI
2. Navigate to the server registry
3. Verify the new server appears in the list
4. Test adding it to an agent

## Troubleshooting

- **Server not appearing**: Check JSON syntax and restart WebUI
- **Import errors**: Ensure the JSON file is valid and accessible
- **Type errors**: Verify the server entry matches the expected schema



================================================
FILE: src/core/llm/services/README.md
================================================
# Adding a New LLM Service

This guide explains how to add support for a new Large Language Model (LLM) provider to Dexto. For an architectural overview of the LLM system see `../README.md`. The LLM service architecture is designed to be extensible, allowing you to integrate with different AI providers while maintaining consistent behavior.

## LLM Architecture Overview

Dexto uses an abstraction layer to interact with different LLM providers:

```
+-----------------+      +---------------------+      +---------------------+
|  Client Manager |----->|     LLM Factory     |<-----|       Config        |
| (Tool Execution)|      +----------+----------+      +---------------------+
+--------+--------+                 |
         |                         â–¼
         |        +----------------------------------+
         |        |         LLM Interface            |
         +------->|       (ILLMService type)         |
                  +-----------------+----------------+
                                    |
                      +-------------+-------------+
                      |                           |
            +---------â–¼----------+     +----------â–¼---------+
            |   OpenAIService    |     |  AnthropicService  |  ... (Other Providers)
            | (Uses MessageMgr)  |     | (Uses MessageMgr)  |
            +--------------------+     +--------------------+
```

The main components are:

1.  **LLM Interface (`ILLMService`)** - Defines the contract that all LLM implementations must follow. It handles task completion, context updates, conversation state, and event emission.
2.  **Provider Implementations** - Each provider (e.g., OpenAI, Anthropic) has its own implementation of `ILLMService`. These services interact with the provider's specific API.
3.  **Factory (`factory.ts`)** - Creates the appropriate service (`OpenAIService`, `AnthropicService`, etc.) based on configuration (`LLMConfig`). It also handles API key extraction and can optionally create services compatible with the Vercel AI SDK.
4.  **Client Manager (`client/manager.ts`)** - Manages the available tools (getting definitions, executing them). LLM services use the `McpManager` to get tool information and execute tool calls requested by the LLM.
5.  **Message Manager (`messages/manager.ts`)** - Manages the conversation history, formats messages according to the provider's requirements (using specific formatters), handles system prompts, applies compression strategies, and manages token limits. Each LLM service instance typically has its own `ContextManager`.
6.  **Event Emitter (`EventEmitter`)** - Used by LLM services to emit events during the task completion lifecycle (e.g., `thinking`, `toolCall`, `toolResult`, `response`, `error`). This allows other parts of the application to react to the LLM's progress.


## Overview of Implementation Steps

Adding a new LLM provider involves these main steps:

1.  **Choose LLM & Install SDK:** Select the provider and install its Node.js/TypeScript SDK.
2.  **Implement/Select Formatter:** Ensure a message formatter (`IMessageFormatter`) exists for the provider's API structure.
3.  **Implement/Select Tokenizer & Utilities:** Ensure a tokenizer (`ITokenizer`) and token limit information (`getMaxTokens`) are available for the chosen model(s).
4.  **Choose/Implement Compression Strategy(ies):** Decide which context compression strategies (`ICompressionStrategy`) the `ContextManager` should use if the token limit is exceeded.
5.  **Create `ILLMService` Implementation:** Build the core service class, integrating the SDK, `ContextManager`, `McpManager`, and handling the API interaction logic.
6.  **Update Factory:** Modify the `factory.ts` to recognize and instantiate your new service.
7.  **Test:** Configure and run Dexto to test your new provider integration.

Let's look at each step in more detail.

## Step 1: Choose LLM & Install SDK

*   Select the Large Language Model provider you want to integrate (e.g., Google Gemini, Cohere, Mistral).
*   Find and install their official Node.js/TypeScript SDK:
    ```bash
    npm install @provider/sdk-library
    ```

## Step 2: Implement/Select Message Formatter (`IMessageFormatter`)

*   **Role:** Translates Dexto's internal message history (`InternalMessage[]`) into the specific array format required by your chosen LLM provider's API.
*   **Location:** `src/core/llm/messages/formatters/`
*   **Action:**
    *   Check if a suitable formatter already exists (e.g., `OpenAIMessageFormatter`, `AnthropicMessageFormatter`).
    *   If not, create a new class (e.g., `YourProviderMessageFormatter.ts`) that implements the `IMessageFormatter` interface from `./types.ts`.
    *   Implement the `formatMessages` method to perform the required transformation based on the provider's API documentation (e.g., mapping roles, handling content types).
    *   Implement `formatSystemPrompt` if the provider handles system prompts separately from the main message list.

## Step 3: Implement/Select Tokenizer (`ITokenizer`) & Utilities

*   **Role:** Counts tokens in text according to the specific model's tokenization scheme. This is crucial for the `ContextManager` to manage the context window and apply compression strategies when the token limit is exceeded.
*   **Location:** `src/core/llm/tokenizer/`
*   **Action:**
    1.  **Check/Add Tokenizer Logic:** Find a library or method (often part of the provider's SDK) to count tokens for your model. Integrate this into the `createTokenizer` function in `factory.ts` if possible, associating it with your provider name (e.g., `'your-provider-name'`). Alternatively, you can directly instantiate the tokenizer within your service constructor.
    2.  **Update `getMaxTokens`:** Add your model's maximum context window size (token limit) to the `getMaxTokens` function in `utils.ts`. This allows the system to calculate appropriate limits for `ContextManager`.
    *   Ensure your tokenizer implementation conforms to the `ITokenizer` interface from `./types.ts` (primarily the `countTokens(text: string): number` method).

## Step 4: Choose/Implement Compression Strategy(ies) (`ICompressionStrategy`)

*   **Role:** Defines how the `ContextManager` should reduce the token count of the conversation history when it exceeds the `maxTokens` limit. Strategies are applied sequentially until the history fits.
*   **Location:** `src/core/llm/messages/compression/`
*   **Action:**
    *   Review the existing strategies: `OldestRemovalStrategy.ts` (removes oldest messages) and `MiddleRemovalStrategy.ts` (attempts to remove messages between the first user message and the latest messages).
    *   Decide which strategy or sequence of strategies is appropriate for your provider/use case. The default sequence used by `ContextManager` is `[MiddleRemovalStrategy, OldestRemovalStrategy]`.
    *   If necessary, implement a custom strategy by creating a class that implements the `ICompressionStrategy` interface from `./types.ts`, defining the `compress(messages: InternalMessage[], maxTokens: number, tokenizer: ITokenizer): InternalMessage[]` method.
    *   You will pass your chosen strategy instance(s) to the `ContextManager` constructor in the next step.

## Step 5: Create `ILLMService` Implementation

This is the core step where you tie everything together.

1.  **Create the Service File:** Create `src/core/llm/services/your-provider.ts`.
2.  **Implement the Class:** The factory (`factory.ts`) typically handles the instantiation of the `ContextManager` and the provider's SDK client, passing them to your service's constructor along with the `MCPManager` and an `EventEmitter`.

```typescript
import YourProviderSDK from '@provider/sdk-library'; // Your provider's SDK
import { MCPManager } from '../../../client/manager.js'; // Use MCPManager
import { ILLMService, LLMServiceConfig } from './types.js';
import { ToolSet } from '../../types.js';
import { logger } from '../../../utils/logger.js';
import { EventEmitter } from 'events';
import { ContextManager } from '../messages/manager.js';
import { getMaxTokens } from '../tokenizer/utils.js';
import { ImageData } from '../messages/types.js'; // For potential image support

export class YourProviderService implements ILLMService {
    private providerClient: YourProviderSDK; // Provider SDK instance (passed in)
    private model: string;                  // Model identifier (passed in)
    private mcpManager: MCPManager; // Passed in from factory
    private contextManager: ContextManager;  // Passed in from factory
    private eventEmitter: EventEmitter;      // Passed in from factory
    private maxIterations: number;           // Max tool call loops

    constructor(
        mcpManager: MCPManager,     // Provided by factory
        providerClient: YourProviderSDK,   // Provided by factory
        agentEventBus: EventEmitter,       // Provided by factory
        contextManager: ContextManager,    // Provided by factory
        model: string,                     // Provided by factory
        maxIterations: number = 10         // Or a default suitable for the provider
    ) {
        this.model = model;
        this.providerClient = providerClient;
        this.mcpManager = mcpManager;
        this.eventEmitter = agentEventBus;   // Use the passed-in emitter
        this.contextManager = contextManager; // Use the passed-in message manager
        this.maxIterations = maxIterations;

        // Initialization logic simplified as ContextManager, etc. are pre-configured
        logger.info(`Initialized YourProviderService with model ${this.model}`);
    }


    getAllTools(): Promise<ToolSet> {
        return this.mcpManager.getAllTools();
    }

    getConfig(): LLMServiceConfig {
        const configuredMaxTokens = this.contextManager.getMaxTokens();
        return {
            // Use the provider name registered in the factory
            provider: 'your-provider-name', 
            model: this.model,
            configuredMaxTokens: configuredMaxTokens,
            // Ensure getMaxTokens uses the same provider name and model
            modelMaxTokens: getMaxTokens('your-provider-name', this.model)
        };
    }

    async completeTask(userInput: string, imageData?: ImageData): Promise<string> {
        // Add user message (potentially with image data) via ContextManager
        this.contextManager.addUserMessage(userInput, imageData);

        const rawTools = await this.mcpManager.getAllTools();
        // Provider-specific formatting is still needed
        const formattedTools = this.formatToolsForProvider(rawTools); 
        
        // Emit standardized event
        this.eventEmitter.emit('llmservice:thinking'); 
        logger.debug('Starting completeTask loop');

        let iterationCount = 0;
        let finalResponseText = ''; // Store final text across iterations if needed

        try {
            while (iterationCount < this.maxIterations) {
                iterationCount++;
                logger.debug(`LLM Iteration ${iterationCount}`);

                // Get formatted messages from ContextManager (handles history, compression, formatting)
                const messages = await this.contextManager.getFormattedMessages({ 
                    mcpManager: this.mcpManager // May be needed for certain formatters
                }); 
                
                // Estimate and log token count (optional but useful)
                const currentTokens = this.contextManager.getTokenCount();
                logger.debug(`Estimated tokens being sent: ${currentTokens}`);

                logger.silly("Messages sent to provider:", messages);
                logger.silly("Formatted tools:", formattedTools);

                // --- Call Provider API ---
                // Adapt based on provider SDK (e.g., chat completions, generateText)
                const response = await this.providerClient.someApiCall({ 
                    model: this.model,
                    messages: messages, // Use messages from ContextManager
                    tools: formattedTools, // Send formatted tools
                    tool_choice: 'auto', // Or provider-specific equivalent
                    // ... other provider options
                });
                logger.silly("Raw response from provider:", response);

                // --- Process Response --- 
                // Provider-specific parsing is required
                const { textContent, toolCalls } = this.parseProviderResponse(response); 
                logger.silly("Parsed response:", { textContent, toolCalls });

                // Add assistant message via ContextManager (handles text and/or tool calls)
                this.contextManager.addAssistantMessage(textContent, toolCalls);

                // --- Handle Tool Calls (if any) --- 
                if (!toolCalls || toolCalls.length === 0) {
                    logger.debug('No tool calls. Task complete.');
                    finalResponseText = textContent || ''; 
                    this.eventEmitter.emit('llmservice:response', finalResponseText); // Emit final response
                    return finalResponseText; // Exit loop and return
                }
                
                // Optional: Accumulate intermediate text if needed
                // if (textContent) { finalResponseText += textContent + '\\n'; }

                logger.debug(`Processing ${toolCalls.length} tool calls.`);
                for (const toolCall of toolCalls) { 
                    // Extract provider-specific details (ID, function name, arguments)
                    const toolName = toolCall.function.name; 
                    const toolCallId = toolCall.id; // Provider-specific ID
                    let args: any = {};
                    
                    try {
                        // Arguments might already be objects or need parsing
                        args = typeof toolCall.function.arguments === 'string' 
                            ? JSON.parse(toolCall.function.arguments) 
                            : toolCall.function.arguments;
                    } catch (e) {
                        const errorMsg = `Invalid arguments format: ${e instanceof Error ? e.message : String(e)}`;
                        logger.error(`Failed to parse arguments for tool ${toolName}: ${toolCall.function.arguments}`, e);
                        // Add error result via ContextManager
                        this.contextManager.addToolResult(toolCallId, toolName, { error: errorMsg });
                        this.eventEmitter.emit('llmservice:toolResult', toolName, { error: errorMsg });
                        continue; // Skip execution
                    }

                    this.eventEmitter.emit('llmservice:toolCall', toolName, args);
                    let result: any;
                    try {
                        result = await this.mcpManager.executeTool(toolName, args);
                        logger.debug(`Tool ${toolName} executed successfully.`);
                        // Add success result via ContextManager
                        this.contextManager.addToolResult(toolCallId, toolName, result);
                        this.eventEmitter.emit('llmservice:toolResult', toolName, result);
                    } catch (error) {
                        const errorMessage = error instanceof Error ? error.message : String(error);
                        logger.error(`Tool execution error for ${toolName}: ${errorMessage}`);
                        result = { error: errorMessage }; 
                        // Add error result via ContextManager
                        this.contextManager.addToolResult(toolCallId, toolName, result);
                        this.eventEmitter.emit('llmservice:toolResult', toolName, result);
                    }
                }
                
                // Prepare for next iteration
                this.eventEmitter.emit('llmservice:thinking'); 

            } // End while loop

            // Max iterations reached
            logger.warn(`Reached maximum iterations (${this.maxIterations}).`);
            const maxIterResponse = finalResponseText || 'Reached maximum tool call iterations without a final answer.';
            // Add final assistant message if loop ended due to iterations
            if (!finalResponseText) {
                 this.contextManager.addAssistantMessage(maxIterResponse);
            }
            this.eventEmitter.emit('llmservice:response', maxIterResponse);
            return maxIterResponse;

        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            logger.error(`Error during completeTask execution: ${errorMessage}`, { error });
            this.eventEmitter.emit('llmservice:error', error instanceof Error ? error : new Error(errorMessage));
            // Optionally add an error message to history via ContextManager if desired
            // this.contextManager.addAssistantMessage(`Error processing request: ${errorMessage}`);
            return `Error processing request: ${errorMessage}`;
        }
    }

    // --- Private Helper Methods (Still Provider-Specific) --- 

    // Translates Dexto's internal ToolSet into the provider's specific format
    private formatToolsForProvider(tools: ToolSet): any[] { // Return type depends on provider SDK
        logger.debug(`Formatting ${Object.keys(tools).length} tools for provider.`);
        // *** Provider-Specific Transformation Logic Here ***
        // Example (adapt based on provider's requirements, e.g., OpenAI, Vercel AI SDK):
        return Object.entries(tools).map(([toolName, toolDefinition]) => ({
            type: 'function', // Or appropriate type for the provider
            function: {
                name: toolName,
                description: toolDefinition.description,
                parameters: toolDefinition.parameters || { type: 'object', properties: {} } 
            }
        }));
    }

    // Parses the raw response from the provider's API 
    private parseProviderResponse(response: any): { textContent: string | null; toolCalls: any[] | null } {
         // *** Provider-Specific Parsing Logic Here ***
         // Needs to extract:
         // 1. The main textual response content.
         // 2. Tool call requests, formatted into the structure ContextManager expects:
         //    { id: string, type: 'function', function: { name: string, arguments: string | object } }[]
         //    (Note: ContextManager's addAssistantMessage handles the internal conversion)
         
         // Example structure (adapt heavily based on provider response structure):
         const message = response?.choices?.[0]?.message; // Example for OpenAI-like structure
         let textContent: string | null = message?.content || null;
         let toolCalls: any[] | null = message?.tool_calls || null; 

         // Handle providers that might mix text and tool calls differently (e.g., Anthropic).
         // Ensure tool call 'arguments' are accessible (stringified JSON or object).

         return { textContent, toolCalls };
       }
   }
   ```

## Step 6: Update the Factory (`factory.ts`)

The factory (`src/core/llm/services/factory.ts`) creates the correct LLM service based on the configuration.

1.  **Import Your Service:** Add `import { YourProviderService } from './your-provider.js';` at the top.
2.  **Add to `_createLLMService`:** Add a `case` for your provider name in the `switch` statement within the `_createLLMService` function:
    ```typescript
    case 'your-provider-name':
        return new YourProviderService(mcpManager, config.systemPrompt, apiKey, config.model);
    ```
3.  **Update API Key Env Var (If Needed):** If your provider uses a standard environment variable name different from `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`, update the `switch` statement within the `extractApiKey` function (or the `getApiKeyEnvVarName` helper if used) to include your provider's key name.
    ```typescript
    case 'your-provider-name': apiKeyEnvVar = 'YOUR_PROVIDER_API_KEY'; break;
    ```
4.  **Update `createContextManager`:** Modify the `createContextManager` function in `factory.ts` to handle your provider:
    *   Ensure `getMaxTokens` is updated for your model(s).
    *   Import and instantiate your `YourProviderMessageFormatter`.
    *   Select appropriate `ICompressionStrategy` instances (or use defaults).
    *   Create the `ITokenizer` for your provider (often via `createTokenizer`).
    *   Add a `case` for your provider name to return a correctly configured `ContextManager`.
        ```typescript
         case 'your-provider-name': {
             const tokenizer = createTokenizer('your-provider-name', config.model);
             const formatter = new YourProviderMessageFormatter(); // Your formatter
             const rawMaxTokens = getMaxTokens('your-provider-name', config.model);
             // Calculate margin, potentially based on provider specifics
             const maxTokensWithMargin = Math.floor(rawMaxTokens * 0.9); 
             // Choose compression strategies
             const compressionStrategies: ICompressionStrategy[] = [
                 new MiddleRemovalStrategy(), // Example default
                 new OldestRemovalStrategy()
             ]; 
             return new ContextManager(
                 formatter,
                 config.systemPrompt,
                 maxTokensWithMargin,
                 tokenizer,
                 compressionStrategies
             );
         }
        ```
5.  **Optional: Add Vercel AI SDK Support:** If your provider is supported by `@ai-sdk` and you want to enable Vercel mode:
    *   Import its SDK model creation function (e.g., `import { yourProvider } from '@ai-sdk/your-provider';`).
    *   Add a `case` to the `switch` statement in `_createVercelModel` within `factory.ts`:
        ```typescript
         case 'your-provider-name': 
              modelInstance = yourProvider(modelId, { apiKey }); // Pass API key if needed
              provider = 'your-provider-name'; // Set provider name for ContextManager lookup
              break; // Don't forget break!
        ```
    *   Ensure `createContextManager` can handle the Vercel provider name derived (e.g., using `getProviderFromModel`).

## Step 7: Test Your Implementation

1.  **Configure `agent.yml`:** Update your configuration file to use your new provider:
   ```yaml
   systemPrompt: |
     You are a helpful AI assistant.

   llm:
     provider: your-provider-name
     model: your-model-name
     # you can update the system prompt to change the behavior of the llm
     apiKey: $YOUR_PROVIDER_API_KEY
   ```
2.  **Set API Key:** Ensure the API key is available either directly in the config (not recommended for production) or in your environment variables (e.g., in a `.env` file loaded by your application).
3.  **Run Dexto:** Start the application (`npm start` or similar).
4.  **Test Thoroughly:**
    *   Send simple prompts.
    *   Send prompts designed to trigger tool usage.
    *   Send long conversations to test context window limits and compression.
    *   Monitor the logs (set log level to `debug` or `silly` for detailed info during development).
    *   Check for expected events from the `EventEmitter` if applicable.

By following these steps, you should be able to successfully integrate a new LLM provider into Dexto's extensible architecture. Remember to adapt the provider-specific logic (`formatToolsForProvider`, `parseProviderResponse`, API calls) based on the chosen provider's SDK and API documentation. 

## Related Modules

- [`llm`](../README.md) - Core LLM system
- [`config`](../config/README.md) - Configuration
- [`tools`](../../tools/README.md) - Tool management 


================================================
FILE: .claude/commands/get-gh-comments.md
================================================
---
description: "Extract GitHub review comments from Dexto PRs with powerful filtering options"
allowed-tools: ["bash", "read"]
---

# GitHub Review Comment Extractor

Extract and filter GitHub review comments from Dexto pull requests with support for any reviewer.

I'll parse your request and call the appropriate script with the right parameters. You can use natural language like:
- "for PR 293 from rahulkarajgikar" 
- "get unresolved comments from latest CodeRabbit review on PR 456"
- "show all comments from PR 123"

The script I'll use: `./scripts/extract-review-comments.sh truffle-ai/dexto [PR_NUMBER] [OPTIONS]`

## Natural Language Examples

```bash
# Use natural language - Claude will parse these intelligently!
/get-gh-comments for PR 293 from rahulkarajgikar
/get-gh-comments unresolved comments from latest CodeRabbit review on PR 456  
/get-gh-comments show all comments from PR 123
/get-gh-comments latest actionable review from PR 789
/get-gh-comments get PR 555 comments from coderabbitai that are unresolved
```

## Traditional Flag Examples

```bash
# Get all review comments from PR #123
/get-gh-comments 123

# Get CodeRabbit comments only - uses quotes to avoid parsing issues in shell
/get-gh-comments 123 --reviewer "coderabbitai[bot]"

# Get human reviewer comments  
/get-gh-comments 123 --reviewer rahulkarajgikar

# Get latest actionable review from CodeRabbit (substantial feedback) - quotes to avoid issues in shell
/get-gh-comments 123 --reviewer "coderabbitai[bot]" --latest-actionable

# Get all unresolved comments from any reviewer
/get-gh-comments 123 --unresolved-only

# Get unresolved comments from latest actionable review (most useful for CodeRabbit)
/get-gh-comments 123 --reviewer "coderabbitai[bot]" --latest-actionable --unresolved-only

# Get unresolved comments from latest actionable human review
/get-gh-comments 123 --reviewer rahulkarajgikar --latest-actionable --unresolved-only

# Show help
/get-gh-comments 123 --help
```

## Pagination Examples

```bash
# Get first 10 unresolved comments (recommended to avoid output truncation)
/get-gh-comments 123 --unresolved-only --limit 10

# Get next 10 comments (page 2)
/get-gh-comments 123 --unresolved-only --limit 10 --offset 10

# Get comments 21-25 (page 3 of 5-comment pages)
/get-gh-comments 123 --unresolved-only --limit 5 --offset 20

# Browse CodeRabbit feedback in small chunks
/get-gh-comments 123 --reviewer "coderabbitai[bot]" --unresolved-only --limit 5
```

## Defaults

If user doesn't specify, prefer unresolved only. No point in looking at resolved comments generally
If user doesn't specify to use the latest only, run script with both --latest-actionable and without, and consolidate the two to give a meaningful response

## âš ï¸ Important: Use Pagination to Avoid Truncation

**Always use `--limit` when there are many comments!** Large PRs with 20+ comments will be truncated in Claude Code's output, causing you to miss important issues. 

Recommended approach:
1. Start with `--limit 10` to see the first batch
2. Use the pagination hints provided by the script to navigate
3. For CodeRabbit reviews, `--limit 5` works well since comments are detailed

## Available Options

### Reviewer Filter
- `--reviewer LOGIN_ID`: Filter by specific reviewer (e.g., `coderabbitai[bot]`, `rahulkarajgikar`, `shaunak99`)

### Pagination Options
- `--limit NUMBER`: Maximum number of comments to display (default: all)
- `--offset NUMBER`: Number of comments to skip (default: 0, for pagination)

### Flags (combinable)
- `--latest-only`: Latest review by timestamp (most recent)
- `--latest-actionable`: Latest review with substantial feedback (has top-level summary)  
- `--unresolved-only`: Only comments that haven't been resolved

*Note*: `--latest-only` and `--latest-actionable` are mutually exclusive. The script uses an `elif` structure where `--latest-actionable` takes precedence if both are provided.

## Common Workflows

**Focus on CodeRabbit's current feedback (paginated):**
```bash
/get-gh-comments 456 --reviewer "coderabbitai[bot]" --latest-actionable --unresolved-only --limit 5
```

**Check all unresolved issues in manageable chunks:**
```bash  
/get-gh-comments 456 --unresolved-only --limit 10
```

**Review human feedback:**
```bash
/get-gh-comments 456 --reviewer username --latest-actionable --limit 10
```

**Browse all feedback from a specific reviewer:**
```bash
/get-gh-comments 456 --reviewer "coderabbitai[bot]" --limit 10
```

## Requirements

- GitHub CLI (`gh`) must be installed and authenticated
- `jq` must be installed for JSON processing
- Access to the target repository
- PR must have review comments

## Notes

- **Actionable Reviews**: Reviews with top-level summaries (body content), typically containing substantial feedback
- **Resolution Status**: Uses GitHub's review thread resolution system
- **Reviewer IDs**: Use GitHub login names (bot accounts include `[bot]` suffix)
- **Comment Sorting**: Comments are automatically sorted by file path and line number for systematic review
- **Pagination Navigation**: The script provides ready-to-use commands for next/previous pages


## âš ï¸ Important: Review Before Acting

**ALWAYS review the comments and current code before making changes!**

1. **Read the comments carefully** - CodeRabbit suggestions may be based on outdated code analysis
2. **Check if the issue actually exists** - Test current functionality before "fixing" it
3. **Verify the suggested change is beneficial** - Some suggestions may break working code
4. **Ask the user for confirmation** if you're unsure about a suggested change

## Responding back to user

While responding back to the user, mention the following information:
- Number of total comments (would be at the bottom of the script response)

Then for each comment, mention:
- The number of the comment
- The line number of the comment  
- **The GitHub link** (for easy navigation to the actual comment)
- High level information about what the comment is
- Potential fix: keep this short about what needs to be done to fix it
- Your assessment: whether the fix is actually needed or if current code is correct

This keeps the response concise for the user while also informing them of the essentials

## Handling Incorrect CodeRabbit Comments

When CodeRabbit comments are **incorrect** or based on outdated analysis:

1. **Provide the GitHub links** for manual resolution as invalid
2. **Explain why the comment is wrong** briefly  
3. **Group them clearly**:

```
## Comments to Manually Resolve (CodeRabbit was wrong)

1. **Total count output** - https://github.com/truffle-ai/dexto/pull/293#discussion_r2288992034
   INCORRECT: Script already displays total counts properly

2. **GraphQL -F flag** - https://github.com/truffle-ai/dexto/pull/293#discussion_r2289006182
   INCORRECT: -F is correct for integer parameters, -f is for strings

## Valid Comments Still Needing Fixes
[List the legitimate issues with their links]
```



================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.md
================================================
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: ''
assignees: ''

---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.



================================================
FILE: .github/ISSUE_TEMPLATE/feature_request.md
================================================
---
name: Feature request
about: Suggest an idea for this project
title: ''
labels: ''
assignees: ''

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.


