Directory structure:
└── ag-ui-protocol-ag-ui/
    ├── README.md
    ├── CLAUDE.md
    ├── CONTRIBUTING.md
    ├── LICENSE
    ├── python-sdk/
    │   ├── README.md
    │   ├── LICENSE
    │   ├── pyproject.toml
    │   ├── ag_ui/
    │   │   ├── py.typed
    │   │   ├── core/
    │   │   │   ├── __init__.py
    │   │   │   ├── events.py
    │   │   │   └── types.py
    │   │   └── encoder/
    │   │       ├── __init__.py
    │   │       └── encoder.py
    │   └── tests/
    │       ├── __init__.py
    │       ├── test_encoder.py
    │       ├── test_events.py
    │       ├── test_text_roles.py
    │       └── test_types.py
    ├── typescript-sdk/
    │   ├── README.md
    │   ├── LICENSE
    │   ├── package.json
    │   ├── pnpm-workspace.yaml
    │   ├── tsconfig.json
    │   ├── turbo.json
    │   ├── .npmrc
    │   ├── .prettierrc
    │   ├── apps/
    │   │   ├── client-cli-example/
    │   │   │   ├── README.md
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   └── src/
    │   │   │       ├── agent.ts
    │   │   │       ├── index.ts
    │   │   │       └── tools/
    │   │   │           ├── browser.tool.ts
    │   │   │           └── weather.tool.ts
    │   │   └── dojo/
    │   │       ├── README.md
    │   │       ├── eslint.config.mjs
    │   │       ├── LICENSE
    │   │       ├── next.config.ts
    │   │       ├── package.json
    │   │       ├── postcss.config.mjs
    │   │       ├── tailwind.config.ts
    │   │       ├── tsconfig.json
    │   │       ├── e2e/
    │   │       │   ├── README.md
    │   │       │   ├── clean-reporter.js
    │   │       │   ├── package.json
    │   │       │   ├── playwright.config.ts
    │   │       │   ├── pnpm-workspace.yaml
    │   │       │   ├── setup-aws.sh
    │   │       │   ├── slack-layout-simple.ts
    │   │       │   ├── slack-layout.ts
    │   │       │   ├── test-isolation-helper.ts
    │   │       │   ├── test-isolation-setup.ts
    │   │       │   ├── VIDEO_SETUP.md
    │   │       │   ├── featurePages/
    │   │       │   │   ├── AgenticChatPage.ts
    │   │       │   │   ├── SharedStatePage.ts
    │   │       │   │   └── ToolBaseGenUIPage.ts
    │   │       │   ├── lib/
    │   │       │   │   └── upload-video.ts
    │   │       │   ├── pages/
    │   │       │   │   ├── crewAIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   └── PredictiveStateUpdatesPage.ts
    │   │       │   │   ├── langGraphFastAPIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   ├── PredictiveStateUpdatesPage.ts
    │   │       │   │   │   └── SubgraphsPage.ts
    │   │       │   │   ├── langGraphPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   ├── PredictiveStateUpdatesPage.ts
    │   │       │   │   │   └── SubgraphsPage.ts
    │   │       │   │   ├── llamaIndexPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   └── HumanInLoopPage.ts
    │   │       │   │   ├── pydanticAIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   └── PredictiveStateUpdatesPage.ts
    │   │       │   │   └── serverStarterAllFeaturesPages/
    │   │       │   │       ├── AgenticUIGenPage.ts
    │   │       │   │       ├── HumanInLoopPage.ts
    │   │       │   │       └── PredictiveStateUpdatesPage.ts
    │   │       │   ├── reporters/
    │   │       │   │   └── s3-video-reporter.ts
    │   │       │   ├── tests/
    │   │       │   │   ├── copilotkit-home.spec.ts
    │   │       │   │   ├── agnoTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── crewAITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── integration/
    │   │       │   │   │   └── ai-features.spec.ts
    │   │       │   │   ├── langgraphFastAPITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   ├── subgraphsPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── langgraphTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   ├── subgraphsPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── llamaIndexTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   └── sharedStatePage.spec.ts
    │   │       │   │   ├── mastraAgentLocalTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── mastraTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── middlewareStarterTests/
    │   │       │   │   │   └── agenticChatPage.spec.ts
    │   │       │   │   ├── pydanticAITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── serverStarterAllFeaturesTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── serverStarterTests/
    │   │       │   │   │   └── agenticChatPage.spec.ts
    │   │       │   │   ├── smoke-only/
    │   │       │   │   │   └── basic-loading.spec.ts
    │   │       │   │   └── vercelAISdkTests/
    │   │       │   │       └── agenticChatPage.spec.ts
    │   │       │   └── utils/
    │   │       │       └── aiWaitHelpers.ts
    │   │       ├── public/
    │   │       │   ├── logo_dark.webp
    │   │       │   └── logo_light.webp
    │   │       ├── scripts/
    │   │       │   ├── generate-content-json.ts
    │   │       │   ├── link-cpk.js
    │   │       │   ├── prep-dojo-everything.js
    │   │       │   └── run-dojo-everything.js
    │   │       └── src/
    │   │           ├── agents.ts
    │   │           ├── config.ts
    │   │           ├── env.ts
    │   │           ├── menu.ts
    │   │           ├── app/
    │   │           │   ├── globals.css
    │   │           │   ├── layout.tsx
    │   │           │   ├── page.tsx
    │   │           │   ├── [integrationId]/
    │   │           │   │   ├── not-found.tsx
    │   │           │   │   ├── page.tsx
    │   │           │   │   └── feature/
    │   │           │   │       ├── layout.tsx
    │   │           │   │       ├── agentic_chat/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── agentic_chat_reasoning/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── agentic_generative_ui/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── human_in_the_loop/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── predictive_state_updates/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── shared_state/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── subgraphs/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       └── tool_based_generative_ui/
    │   │           │   │           ├── README.mdx
    │   │           │   │           ├── page.tsx
    │   │           │   │           └── style.css
    │   │           │   └── api/
    │   │           │       └── copilotkit/
    │   │           │           └── [integrationId]/
    │   │           │               └── route.ts
    │   │           ├── components/
    │   │           │   ├── theme-provider.tsx
    │   │           │   ├── code-viewer/
    │   │           │   │   ├── code-editor.tsx
    │   │           │   │   └── code-viewer.tsx
    │   │           │   ├── demo-list/
    │   │           │   │   └── demo-list.tsx
    │   │           │   ├── file-tree/
    │   │           │   │   ├── file-tree-nav.tsx
    │   │           │   │   └── file-tree.tsx
    │   │           │   ├── layout/
    │   │           │   │   ├── main-layout.tsx
    │   │           │   │   └── viewer-layout.tsx
    │   │           │   ├── readme/
    │   │           │   │   └── readme.tsx
    │   │           │   ├── sidebar/
    │   │           │   │   └── sidebar.tsx
    │   │           │   └── ui/
    │   │           │       ├── badge.tsx
    │   │           │       ├── button.tsx
    │   │           │       ├── dropdown-menu.tsx
    │   │           │       ├── markdown-components.tsx
    │   │           │       ├── mdx-components.tsx
    │   │           │       ├── tabs.tsx
    │   │           │       └── theme-toggle.tsx
    │   │           ├── contexts/
    │   │           │   └── url-params-context.tsx
    │   │           ├── lib/
    │   │           │   └── utils.ts
    │   │           ├── mastra/
    │   │           │   └── index.ts
    │   │           ├── styles/
    │   │           │   └── typography.css
    │   │           ├── types/
    │   │           │   ├── feature.ts
    │   │           │   ├── integration.ts
    │   │           │   └── interface.ts
    │   │           └── utils/
    │   │               ├── domain-config.ts
    │   │               ├── mdx-utils.tsx
    │   │               ├── use-mobile-chat.ts
    │   │               └── use-mobile-view.ts
    │   ├── integrations/
    │   │   ├── agno/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── requirements.txt
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── api/
    │   │   │   │           ├── __init__.py
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           └── tool_based_generative_ui.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── crewai/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── python/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── ag_ui_crewai/
    │   │   │   │   │   ├── __init__.py
    │   │   │   │   │   ├── context.py
    │   │   │   │   │   ├── crews.py
    │   │   │   │   │   ├── dojo.py
    │   │   │   │   │   ├── endpoint.py
    │   │   │   │   │   ├── enterprise.py
    │   │   │   │   │   ├── events.py
    │   │   │   │   │   ├── sdk.py
    │   │   │   │   │   ├── utils.py
    │   │   │   │   │   └── examples/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       ├── agentic_chat.py
    │   │   │   │   │       ├── agentic_generative_ui.py
    │   │   │   │   │       ├── human_in_the_loop.py
    │   │   │   │   │       ├── predictive_state_updates.py
    │   │   │   │   │       ├── shared_state.py
    │   │   │   │   │       └── tool_based_generative_ui.py
    │   │   │   │   └── tests/
    │   │   │   │       └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── langgraph/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── python/
    │   │   │   │   │   ├── README.md
    │   │   │   │   │   ├── langgraph.json
    │   │   │   │   │   ├── pyproject.toml
    │   │   │   │   │   ├── .env.example
    │   │   │   │   │   └── agents/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       ├── dojo.py
    │   │   │   │   │       ├── agentic_chat/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── agentic_chat_reasoning/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── agentic_generative_ui/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── human_in_the_loop/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── predictive_state_updates/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── shared_state/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── subgraphs/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       └── tool_based_generative_ui/
    │   │   │   │   │           ├── __init__.py
    │   │   │   │   │           └── agent.py
    │   │   │   │   └── typescript/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── langgraph.json
    │   │   │   │       ├── package.json
    │   │   │   │       ├── pnpm-lock.yaml
    │   │   │   │       ├── pnpm-workspace.yaml
    │   │   │   │       ├── tsconfig.json
    │   │   │   │       ├── .env.example
    │   │   │   │       └── src/
    │   │   │   │           └── agents/
    │   │   │   │               ├── agentic_chat/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── agentic_generative_ui/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── human_in_the_loop/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── predictive_state_updates/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── shared_state/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── subgraphs/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               └── tool_based_generative_ui/
    │   │   │   │                   └── agent.ts
    │   │   │   ├── python/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── ag_ui_langgraph/
    │   │   │   │   │   ├── __init__.py
    │   │   │   │   │   ├── agent.py
    │   │   │   │   │   ├── endpoint.py
    │   │   │   │   │   ├── types.py
    │   │   │   │   │   └── utils.py
    │   │   │   │   └── tests/
    │   │   │   │       └── __init__.py
    │   │   │   └── src/
    │   │   │       ├── agent.ts
    │   │   │       ├── index.ts
    │   │   │       ├── types.ts
    │   │   │       └── utils.ts
    │   │   ├── llamaindex/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server-py/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── routers/
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           ├── agentic_generative_ui.py
    │   │   │   │           ├── human_in_the_loop.py
    │   │   │   │           └── shared_state.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── mastra/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── example/
    │   │   │   │   ├── package.json
    │   │   │   │   ├── tsconfig.json
    │   │   │   │   └── src/
    │   │   │   │       └── mastra/
    │   │   │   │           ├── index.ts
    │   │   │   │           ├── agents/
    │   │   │   │           │   ├── agentic-chat.ts
    │   │   │   │           │   └── tool-based-generative-ui.ts
    │   │   │   │           └── tools/
    │   │   │   │               └── weather-tool.ts
    │   │   │   └── src/
    │   │   │       ├── index.ts
    │   │   │       ├── mastra.ts
    │   │   │       └── utils.ts
    │   │   ├── middleware-starter/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── pydantic-ai/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── api/
    │   │   │   │           ├── __init__.py
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           ├── agentic_generative_ui.py
    │   │   │   │           ├── human_in_the_loop.py
    │   │   │   │           ├── predictive_state_updates.py
    │   │   │   │           ├── shared_state.py
    │   │   │   │           └── tool_based_generative_ui.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── server-starter/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server/
    │   │   │   │   └── python/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── pyproject.toml
    │   │   │   │       ├── example_server/
    │   │   │   │       │   └── __init__.py
    │   │   │   │       └── tests/
    │   │   │   │           └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── server-starter-all-features/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server/
    │   │   │   │   └── python/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── pyproject.toml
    │   │   │   │       ├── example_server/
    │   │   │   │       │   ├── __init__.py
    │   │   │   │       │   ├── agentic_chat.py
    │   │   │   │       │   ├── agentic_generative_ui.py
    │   │   │   │       │   ├── human_in_the_loop.py
    │   │   │   │       │   ├── predictive_state_updates.py
    │   │   │   │       │   ├── shared_state.py
    │   │   │   │       │   └── tool_based_generative_ui.py
    │   │   │   │       └── tests/
    │   │   │   │           └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   └── vercel-ai-sdk/
    │   │       ├── README.md
    │   │       ├── jest.config.js
    │   │       ├── package.json
    │   │       ├── tsconfig.json
    │   │       ├── tsup.config.ts
    │   │       ├── .npmignore
    │   │       └── src/
    │   │           └── index.ts
    │   ├── packages/
    │   │   ├── cli/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── client/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── index.ts
    │   │   │       ├── utils.ts
    │   │   │       ├── agent/
    │   │   │       │   ├── agent.ts
    │   │   │       │   ├── http.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── subscriber.ts
    │   │   │       │   ├── types.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── agent-concurrent.test.ts
    │   │   │       │       ├── agent-multiple-runs.test.ts
    │   │   │       │       ├── agent-mutations.test.ts
    │   │   │       │       ├── agent-result.test.ts
    │   │   │       │       ├── agent-text-roles.test.ts
    │   │   │       │       ├── http.test.ts
    │   │   │       │       ├── legacy-bridged.test.ts
    │   │   │       │       └── subscriber.test.ts
    │   │   │       ├── apply/
    │   │   │       │   ├── default.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── default.concurrent.test.ts
    │   │   │       │       ├── default.state.test.ts
    │   │   │       │       ├── default.text-message.test.ts
    │   │   │       │       └── default.tool-calls.test.ts
    │   │   │       ├── chunks/
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── transform.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── transform-roles.test.ts
    │   │   │       │       └── transform.test.ts
    │   │   │       ├── legacy/
    │   │   │       │   ├── convert.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── types.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── convert.concurrent.test.ts
    │   │   │       │       ├── convert.predictive.test.ts
    │   │   │       │       ├── convert.state.test.ts
    │   │   │       │       └── convert.tool-calls.test.ts
    │   │   │       ├── run/
    │   │   │       │   ├── http-request.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       └── http-request.test.ts
    │   │   │       ├── transform/
    │   │   │       │   ├── http.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── proto.ts
    │   │   │       │   ├── sse.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── http.test.ts
    │   │   │       │       ├── proto.test.ts
    │   │   │       │       └── sse.test.ts
    │   │   │       └── verify/
    │   │   │           ├── index.ts
    │   │   │           ├── verify.ts
    │   │   │           └── __tests__/
    │   │   │               ├── verify.concurrent.test.ts
    │   │   │               ├── verify.events.test.ts
    │   │   │               ├── verify.lifecycle.test.ts
    │   │   │               ├── verify.multiple-runs.test.ts
    │   │   │               ├── verify.steps.test.ts
    │   │   │               ├── verify.text-messages.test.ts
    │   │   │               └── verify.tool-calls.test.ts
    │   │   ├── core/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── events.ts
    │   │   │       ├── index.ts
    │   │   │       ├── types.ts
    │   │   │       └── __tests__/
    │   │   │           ├── events-role-defaults.test.ts
    │   │   │           └── index.test.ts
    │   │   ├── encoder/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── encoder.ts
    │   │   │       ├── index.ts
    │   │   │       ├── media-type.ts
    │   │   │       └── __tests__/
    │   │   │           └── encoder.test.ts
    │   │   └── proto/
    │   │       ├── README.md
    │   │       ├── jest.config.js
    │   │       ├── package.json
    │   │       ├── tsconfig.json
    │   │       ├── tsup.config.ts
    │   │       ├── .npmignore
    │   │       ├── __tests__/
    │   │       │   ├── message-events.test.ts
    │   │       │   ├── proto.test.ts
    │   │       │   ├── run-events.test.ts
    │   │       │   ├── state-events.test.ts
    │   │       │   ├── test-utils.ts
    │   │       │   └── tool-call-events.test.ts
    │   │       └── src/
    │   │           ├── index.ts
    │   │           ├── proto.ts
    │   │           └── proto/
    │   │               ├── events.proto
    │   │               ├── patch.proto
    │   │               └── types.proto
    │   └── .cursor/
    │       └── rules/
    │           └── project-rules.mdc
    └── .github/
        ├── CODEOWNERS
        └── workflows/
            ├── check-generated-files.yml
            ├── dojo-e2e.yml
            └── test.yml

================================================
FILE: README.md
================================================

# <img src="https://github.com/user-attachments/assets/ebc0dd08-8732-4519-9b6c-452ce54d8058" alt="ag-ui Logo" width="22"/> AG-UI: The Agent-User Interaction Protocol

AG-UI is a lightweight, event-based protocol that standardizes how AI agents connect to user-facing applications.
Built for simplicity and flexibility, it enables seamless integration between AI agents, real time user context, and user interfaces.

---

[📅 Upcoming Event: August 6th - AG-UI + Mastra: Build a Project Management Canvas](https://lu.ma/94688z7e)

<br>


[![Version](https://img.shields.io/npm/v/@ag-ui/core?label=Version&color=6963ff&logo=npm&logoColor=white)](https://www.npmjs.com/package/@ag-ui/core)
![MIT](https://img.shields.io/github/license/copilotkit/copilotkit?color=%236963ff&label=License)
![Discord](https://img.shields.io/discord/1379082175625953370?logo=discord&logoColor=%23FFFFFF&label=Discord&color=%236963ff)

  <a href="https://discord.gg/Jd3FzfdJa8" target="_blank">
   Join our Discord →
  </a> &nbsp;&nbsp;&nbsp;
    <a href="https://ag-ui.com/" target="_blank">
   Read the Docs →
  </a> &nbsp;&nbsp;&nbsp;
    <a href="https://x.com/CopilotKit" target="_blank">
   Follow us →
  </a> 

<img width="4096" height="1752" alt="Your application-AG-UI protocol" src="https://github.com/user-attachments/assets/dc58c64c-3257-490a-b827-e163475f4166" />

## 🚀 Getting Started
Create a new AG-UI application in seconds:
```bash
npx create-ag-ui-app my-agent-app
```
<h3>Building AG-UI Integrations (new frameworks):</h3>

- [Build new integrations (Quickstart)](https://go.copilotkit.ai/agui-contribute)
- [Book a call to discuss an AG-UI integration with a new framework](https://calendly.com/markus-copilotkit/ag-ui)
- [Join the Discord Community](https://discord.gg/Jd3FzfdJa8)

## What is AG-UI?

AG-UI is an open, lightweight, event-based protocol for agent-human interaction, designed for simplicity & flexibility:

- During agent executions, agent backends **emit events _compatible_ with one of AG-UI's ~16 standard event types**
- Agent backends can **accept one of a few simple AG-UI compatible inputs** as arguments

**AG-UI includes a flexible middleware layer** that ensures compatibility across diverse environments:

- Works with **any event transport** (SSE, WebSockets, webhooks, etc.)
- Allows for **loose event format matching**, enabling broad agent and app interoperability

It also ships with a **reference HTTP implementation** and **default connector** to help teams get started fast.


[Learn more about the specs →](https://go.copilotkit.ai/ag-ui-introduction)


## Why AG-UI?

AG-UI was developed based on real-world requirements and practical experience building in-app agent interactions.


## Where does AGUI fit in the agentic protocol stack?
AG-UI is complementary to the other 2 top agentic protocols
- MCP gives agents tools
- A2A allows agents to communicate with other agents
- AG-UI brings agents into user-facing applications

<div align="center">
  <img src="https://github.com/user-attachments/assets/0c1ec566-050b-4ef8-ab89-15be41abe64f"  />
</div>  

   
## 🚀 Features

- 💬 Real-time agentic chat with streaming
- 🔄 Bi-directional state synchronization
- 🧩 Generative UI and structured messages
- 🧠 Real-time context enrichment
- 🛠️ Frontend tool integration
- 🧑‍💻 Human-in-the-loop collaboration


## 🛠 Supported Frameworks

AG-UI was born from CopilotKit's initial partnership with LangGraph and CrewAI - and brings the incredibly popular agent-user-interactivity infrastructure to the wider agentic ecosystem.

| Framework                                                          | Status                   | AG-UI Resources                                                              | Integrations |
| ------------------------------------------------------------------ | ------------------------ | ---------------------------------------------------------------------------- | ------------------------ |
| No-framework                                                       | ✅ Supported             | ➡️ Docs coming soon                                                          |                          |
| [LangGraph](https://www.langchain.com/langgraph)                   | ✅ Supported             | ➡️ [Demo](https://v0-langgraph-land.vercel.app/)                             | Partnership              |
| [CrewAI](https://crewai.com/)                                      | ✅ Supported             | ➡️ [Demo](https://v0-crew-land.vercel.app/)                                  | Partnership              |
| [Mastra](https://mastra.ai/)                                       | ✅ Supported             | ➡️ [Demo](https://v0-mastra-land.vercel.app/)                                | 1st party                |
| [AG2](https://ag2.ai/)                                             | ✅ Supported             | ➡️ [Demo](https://v0-ag2-land.vercel.app/)                                   | 1st party                |
| [Agno](https://github.com/agno-agi/agno)                           | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/agno)                                   | 1st party                |
| [LlamaIndex](https://github.com/run-llama/llama_index)             | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/llamaindex)                             | 1st party                |
| [Pydantic AI](https://github.com/pydantic/pydantic-ai)             | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/pydantic-ai)                            | 1st party                |
| [Vercel AI SDK](https://github.com/vercel/ai)                      | 🛠️ In Progress           | –                                                                            | Community                |
| [Google ADK](https://google.github.io/adk-docs/get-started/)       | 🛠️ [PR](https://github.com/ag-ui-protocol/ag-ui/pull/274)           | –                                                                            | Community                |
| [OpenAI Agent SDK](https://openai.github.io/openai-agents-python/) | 🛠️ In Progress           | –                                                                            | Community                |
| [AWS Bedrock Agents](https://aws.amazon.com/bedrock/agents/)       | 🛠️ In Progress           | –                                                                            | 1st party                |
| [Cloudflare Agents](https://developers.cloudflare.com/agents/)     | 💡 Open to Contributions | –                                                                            | Community                |
| [Strands Agents SDK](https://github.com/strands-agents/sdk-python) | 💡 Open to Contributions | –                                                                            | Community                |   

[View all supported frameworks →](https://ag-ui.com/frameworks)


| Language SDK                                                       | Status                    | AG-UI Resources                                                              |
| ------------------------------------------------------------------ | ------------------------  | ---------------------------------------------------------------------------- |
| [Kotlin]()                                                         | ✅ Supported              | ➡️ [GitHub Source](https://github.com/Contextable/ag-ui-4k)                  |
| [.NET]()                                                           | 🛠️ In Progress            | ➡️ [PR](https://github.com/ag-ui-protocol/ag-ui/pull/38)                     |
| [Nim]()                                                            | 🛠️ In Progress            | ➡️ [PR](https://github.com/ag-ui-protocol/ag-ui/pull/29)                     |
| [Golang]()                                                         | 🛠️ In Progress            | ➡️ [Issue](https://github.com/ag-ui-protocol/ag-ui/issues/156)               |
| [Rust]()                                                           | 🛠️ In Progress            | ➡️ [Issue](https://github.com/ag-ui-protocol/ag-ui/issues/239)               |
| [Java]()                                                           | 🛠️ In Progress            | ➡️ [GitHub Source](https://github.com/work-m8/ag-ui-4j)                      |


[View all supported frameworks →](https://ag-ui.com/frameworks)


## ✨ Hello World App


Video:

https://github.com/user-attachments/assets/18c03330-1ebc-4863-b2b8-cc6c3a4c7bae

https://agui-demo.vercel.app/



## 🧩 AG-UI Showcase: The AG-UI Dojo (Building-Blocks Viewer)
The [AG-UI Dojo](https://copilotkit-feature-viewer.vercel.app/) showcases many of the building blocks that AG-UI supports ([AG-UI Dojo Source Code](https://github.com/ag-ui-protocol/ag-ui/tree/main/typescript-sdk/apps/dojo)).

The building blocks are designed to be simple and focused -- between 50-200 lines of code.

https://github.com/user-attachments/assets/a67d3d54-36b2-4c7a-ac69-a0ca01365d5b


## 🙋🏽‍♂️ Contributing to AG-UI

Check out the [Contributing guide](https://github.com/ag-ui-protocol/ag-ui/blob/main/CONTRIBUTING.md)

- **[Weekely AG-UI Working Group](https://lu.ma/CopilotKit?k=c)**  
  📅 Follow the CopilotKit Luma Events Calendar

## Roadmap

Check out the [AG-UI Roadmap](https://github.com/orgs/ag-ui-protocol/projects/1) to see what's being built and where you can jump in.


## 📄 License

AG-UI is open source software [licensed as MIT](https://opensource.org/licenses/MIT).  



================================================
FILE: CLAUDE.md
================================================
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Common Development Commands

### TypeScript SDK (Main Development)
```bash
# Navigate to typescript-sdk directory for all TypeScript work
cd typescript-sdk

# Install dependencies (using pnpm)
pnpm install

# Build all packages
pnpm build

# Run development mode
pnpm dev

# Run linting
pnpm lint

# Run type checking
pnpm check-types

# Run tests
pnpm test

# Format code
pnpm format

# Clean build artifacts
pnpm clean

# Full clean build
pnpm build:clean
```

### Python SDK
```bash
# Navigate to python-sdk directory
cd python-sdk

# Install dependencies (using poetry)
poetry install

# Run tests
python -m unittest discover tests

# Build distribution
poetry build
```

### Running Specific Integration Tests
```bash
# For TypeScript packages/integrations
cd typescript-sdk/packages/<package-name>
pnpm test

# For running a single test file
cd typescript-sdk/packages/<package-name>
pnpm test -- path/to/test.spec.ts
```

## High-Level Architecture

AG-UI is an event-based protocol that standardizes agent-user interactions. The codebase is organized as a monorepo with the following structure:

### Core Protocol Architecture
- **Event-Driven Communication**: All agent-UI communication happens through typed events (BaseEvent and its subtypes)
- **Transport Agnostic**: Protocol supports SSE, WebSockets, HTTP binary, and custom transports
- **Observable Pattern**: Uses RxJS Observables for streaming agent responses

### Key Abstractions
1. **AbstractAgent**: Base class that all agents must implement with a `run(input: RunAgentInput) -> Observable<BaseEvent>` method
2. **HttpAgent**: Standard HTTP client supporting SSE and binary protocols for connecting to agent endpoints
3. **Event Types**: Lifecycle events (RUN_STARTED/FINISHED), message events (TEXT_MESSAGE_*), tool events (TOOL_CALL_*), and state management events (STATE_SNAPSHOT/DELTA)

### Repository Structure
- `/typescript-sdk/`: Main TypeScript implementation
  - `/packages/`: Core protocol packages (@ag-ui/core, @ag-ui/client, @ag-ui/encoder, @ag-ui/proto)
  - `/integrations/`: Framework integrations (langgraph, mastra, crewai, etc.)
  - `/apps/`: Example applications including the AG-UI Dojo demo viewer
- `/python-sdk/`: Python implementation of the protocol
- `/docs/`: Documentation site content

### Integration Pattern
Each framework integration follows a similar pattern:
1. Implements the AbstractAgent interface
2. Translates framework-specific events to AG-UI protocol events
3. Provides both TypeScript client and Python server implementations
4. Includes examples demonstrating key AG-UI features (agentic chat, generative UI, human-in-the-loop, etc.)

### State Management
- Uses STATE_SNAPSHOT for complete state representations
- Uses STATE_DELTA with JSON Patch (RFC 6902) for efficient incremental updates
- MESSAGES_SNAPSHOT provides conversation history

### Multiple Sequential Runs
- AG-UI supports multiple sequential runs in a single event stream
- Each run must complete (RUN_FINISHED) before a new run can start (RUN_STARTED)
- Messages accumulate across runs (e.g., messages from run1 + messages from run2)
- State continues to evolve across runs unless explicitly reset with STATE_SNAPSHOT
- Run-specific tracking (active messages, tool calls, steps) resets between runs

### Development Workflow
- Turbo is used for monorepo build orchestration
- Each package has independent versioning
- Integration tests demonstrate protocol compliance
- The AG-UI Dojo app showcases all protocol features with live examples


================================================
FILE: CONTRIBUTING.md
================================================
# 👋 Contributing to AG-UI

Thanks for checking out AG-UI! Whether you’re here to fix a bug, ship a feature, improve the docs, or just figure out how things work—we’re glad you’re here.

Here’s how to get involved:

---

## 🤔 Have a Question or Ran Into Something?

Pick the right spot so we can help you faster:

- **🐛 Bugs / Feature Ideas** → [GitHub Issues](https://github.com/ag-ui-protocol/ag-ui/issues)  
- **❓ "How do I...?" / General Questions** → [GitHub Discussions](https://github.com/ag-ui-protocol/ag-ui/discussions)  
- **💬 Quick chats / casual stuff** → [Discord](https://discord.gg/Jd3FzfdJa8) → `#-💎-contributing`

---

## 🧑‍💻 Want to Contribute Code?

1. **Find Something to Work On**  
   Browse open issues on [GitHub](https://github.com/ag-ui-protocol/ag-ui/issues).  
   Got your own idea? Open an issue first so we can start the discussion.

2. **Ask to Be Assigned**  
   Comment on the issue and tag a code owner:  
   → [Code Owners](https://github.com/ag-ui-protocol/ag-ui/blob/main/.github/CODEOWNERS)

3. **Get on the Roadmap**  
   Once approved, you'll be assigned the issue, and it'll get added to our [roadmap](https://github.com/orgs/ag-ui-protocol/projects/1).

4. **Coordinate With Others**  
   - If you're collaborating or need feedback, start a thread in `#-💎-contributing` on Discord  
   - Or just DM the assignee directly

5. **Open a Pull Request**  
   - When you’re ready, submit your PR  
   - In the description, include: `Fixes #<issue-number>`  
     (This links your PR to the issue and closes it automatically)

6. **Review & Merge**  
   - A maintainer will review your code and leave comments if needed  
   - Once it’s approved, we’ll merge it and move the issue to “done.”

**NOTE:** All community integrations (ie, .NET, Golang SDK, etc.) will need to be maintained by the community

---

## 📝 Want to Contribute to the Docs?

Docs are part of the codebase and super valuable—thanks for helping improve them!

Here’s how to contribute:

1. **Open an Issue First**  
   - Open a [GitHub issue](https://github.com/ag-ui-protocol/ag-ui/issues) describing what you’d like to update or add.  
   - Then comment and ask to be assigned.

2. **Submit a PR**  
   - Once assigned, make your edits and open a pull request.
   - In the description, include: `Fixes #<issue-number>`  
     (This links your PR to the issue and closes it automatically)

   - A maintainer will review it and merge if it looks good.

That’s it! Simple and appreciated.

---

## 🙌 That’s It!

AG-UI is community-built, and every contribution helps shape where we go next.  
Big thanks for being part of it!



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: python-sdk/README.md
================================================
# ag-ui-protocol

Python SDK for the **Agent-User Interaction (AG-UI) Protocol**.

`ag-ui-protocol` provides Python developers with strongly-typed data structures and event encoding for building AG-UI compatible agent servers. Built on Pydantic for robust validation and automatic camelCase serialization for seamless frontend integration.

## Installation

```bash
pip install ag-ui-protocol
poetry add ag-ui-protocol
pipenv install ag-ui-protocol
```

## Features

- 🐍 **Python-native** – Idiomatic Python APIs with full type hints and validation
- 📋 **Pydantic models** – Runtime validation and automatic JSON serialization
- 🔄 **Streaming events** – 16 core event types for real-time agent communication
- ⚡ **High performance** – Efficient event encoding for Server-Sent Events

## Quick example

```python
from ag_ui.core import TextMessageContentEvent, EventType
from ag_ui.encoder import EventEncoder

# Create a streaming text event
event = TextMessageContentEvent(
    type=EventType.TEXT_MESSAGE_CONTENT,
    message_id="msg_123",
    delta="Hello from Python!"
)

# Encode for HTTP streaming
encoder = EventEncoder()
sse_data = encoder.encode(event)
# Output: data: {"type":"TEXT_MESSAGE_CONTENT","messageId":"msg_123","delta":"Hello from Python!"}\n\n
```

## Packages

- **`ag_ui.core`** – Types, events, and data models for AG-UI protocol
- **`ag_ui.encoder`** – Event encoding utilities for HTTP streaming

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/python`](https://docs.ag-ui.com/sdk/python/core/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: python-sdk/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: python-sdk/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-protocol"
version = "0.1.8"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"
packages = [{include = "ag_ui", from = "."}]
[tool.poetry.dependencies]
python = "^3.9"
pydantic = "^2.11.2"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"



================================================
FILE: python-sdk/ag_ui/py.typed
================================================
[Empty file]


================================================
FILE: python-sdk/ag_ui/core/__init__.py
================================================
"""
This module contains the core types and events for the Agent User Interaction Protocol.
"""

from ag_ui.core.events import (
    EventType,
    BaseEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageChunkEvent,
    ThinkingTextMessageStartEvent,
    ThinkingTextMessageContentEvent,
    ThinkingTextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    ToolCallChunkEvent,
    ToolCallResultEvent,
    ThinkingStartEvent,
    ThinkingEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
    Event
)

from ag_ui.core.types import (
    FunctionCall,
    ToolCall,
    BaseMessage,
    DeveloperMessage,
    SystemMessage,
    AssistantMessage,
    UserMessage,
    ToolMessage,
    Message,
    Role,
    Context,
    Tool,
    RunAgentInput,
    State
)

__all__ = [
    # Events
    "EventType",
    "BaseEvent",
    "TextMessageStartEvent",
    "TextMessageContentEvent",
    "TextMessageEndEvent",
    "TextMessageChunkEvent",
    "ThinkingTextMessageStartEvent",
    "ThinkingTextMessageContentEvent",
    "ThinkingTextMessageEndEvent",
    "ToolCallStartEvent",
    "ToolCallArgsEvent",
    "ToolCallEndEvent",
    "ToolCallChunkEvent",
    "ToolCallResultEvent",
    "ThinkingStartEvent",
    "ThinkingEndEvent",
    "StateSnapshotEvent",
    "StateDeltaEvent",
    "MessagesSnapshotEvent",
    "RawEvent",
    "CustomEvent",
    "RunStartedEvent",
    "RunFinishedEvent",
    "RunErrorEvent",
    "StepStartedEvent",
    "StepFinishedEvent",
    "Event",
    # Types
    "FunctionCall",
    "ToolCall",
    "BaseMessage",
    "DeveloperMessage",
    "SystemMessage",
    "AssistantMessage",
    "UserMessage",
    "ToolMessage",
    "Message",
    "Role",
    "Context",
    "Tool",
    "RunAgentInput",
    "State"
]



================================================
FILE: python-sdk/ag_ui/core/events.py
================================================
"""
This module contains the event types for the Agent User Interaction Protocol Python SDK.
"""

from enum import Enum
from typing import Annotated, Any, List, Literal, Optional, Union

from pydantic import Field

from .types import ConfiguredBaseModel, Message, State, Role

# Text messages can have any role except "tool"
TextMessageRole = Literal["developer", "system", "assistant", "user"]


class EventType(str, Enum):
    """
    The type of event.
    """
    TEXT_MESSAGE_START = "TEXT_MESSAGE_START"
    TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT"
    TEXT_MESSAGE_END = "TEXT_MESSAGE_END"
    TEXT_MESSAGE_CHUNK = "TEXT_MESSAGE_CHUNK"
    THINKING_TEXT_MESSAGE_START = "THINKING_TEXT_MESSAGE_START"
    THINKING_TEXT_MESSAGE_CONTENT = "THINKING_TEXT_MESSAGE_CONTENT"
    THINKING_TEXT_MESSAGE_END = "THINKING_TEXT_MESSAGE_END"
    TOOL_CALL_START = "TOOL_CALL_START"
    TOOL_CALL_ARGS = "TOOL_CALL_ARGS"
    TOOL_CALL_END = "TOOL_CALL_END"
    TOOL_CALL_CHUNK = "TOOL_CALL_CHUNK"
    TOOL_CALL_RESULT = "TOOL_CALL_RESULT"
    THINKING_START = "THINKING_START"
    THINKING_END = "THINKING_END"
    STATE_SNAPSHOT = "STATE_SNAPSHOT"
    STATE_DELTA = "STATE_DELTA"
    MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT"
    RAW = "RAW"
    CUSTOM = "CUSTOM"
    RUN_STARTED = "RUN_STARTED"
    RUN_FINISHED = "RUN_FINISHED"
    RUN_ERROR = "RUN_ERROR"
    STEP_STARTED = "STEP_STARTED"
    STEP_FINISHED = "STEP_FINISHED"


class BaseEvent(ConfiguredBaseModel):
    """
    Base event for all events in the Agent User Interaction Protocol.
    """
    type: EventType
    timestamp: Optional[int] = None
    raw_event: Optional[Any] = None


class TextMessageStartEvent(BaseEvent):
    """
    Event indicating the start of a text message.
    """
    type: Literal[EventType.TEXT_MESSAGE_START] = EventType.TEXT_MESSAGE_START  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str
    role: TextMessageRole = "assistant"


class TextMessageContentEvent(BaseEvent):
    """
    Event containing a piece of text message content.
    """
    type: Literal[EventType.TEXT_MESSAGE_CONTENT] = EventType.TEXT_MESSAGE_CONTENT  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str
    delta: str = Field(min_length=1)


class TextMessageEndEvent(BaseEvent):
    """
    Event indicating the end of a text message.
    """
    type: Literal[EventType.TEXT_MESSAGE_END] = EventType.TEXT_MESSAGE_END  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str

class TextMessageChunkEvent(BaseEvent):
    """
    Event containing a chunk of text message content.
    """
    type: Literal[EventType.TEXT_MESSAGE_CHUNK] = EventType.TEXT_MESSAGE_CHUNK  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: Optional[str] = None
    role: Optional[TextMessageRole] = None
    delta: Optional[str] = None

class ThinkingTextMessageStartEvent(BaseEvent):
    """
    Event indicating the start of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_START] = EventType.THINKING_TEXT_MESSAGE_START  # pyright: ignore[reportIncompatibleVariableOverride]

class ThinkingTextMessageContentEvent(BaseEvent):
    """
    Event indicating a piece of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_CONTENT] = EventType.THINKING_TEXT_MESSAGE_CONTENT  # pyright: ignore[reportIncompatibleVariableOverride]
    delta: str = Field(min_length=1)

class ThinkingTextMessageEndEvent(BaseEvent):
    """
    Event indicating the end of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_END] = EventType.THINKING_TEXT_MESSAGE_END  # pyright: ignore[reportIncompatibleVariableOverride]

class ToolCallStartEvent(BaseEvent):
    """
    Event indicating the start of a tool call.
    """
    type: Literal[EventType.TOOL_CALL_START] = EventType.TOOL_CALL_START  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    tool_call_name: str
    parent_message_id: Optional[str] = None


class ToolCallArgsEvent(BaseEvent):
    """
    Event containing tool call arguments.
    """
    type: Literal[EventType.TOOL_CALL_ARGS] = EventType.TOOL_CALL_ARGS  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    delta: str


class ToolCallEndEvent(BaseEvent):
    """
    Event indicating the end of a tool call.
    """
    type: Literal[EventType.TOOL_CALL_END] = EventType.TOOL_CALL_END  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str

class ToolCallChunkEvent(BaseEvent):
    """
    Event containing a chunk of tool call content.
    """
    type: Literal[EventType.TOOL_CALL_CHUNK] = EventType.TOOL_CALL_CHUNK  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: Optional[str] = None
    tool_call_name: Optional[str] = None
    parent_message_id: Optional[str] = None
    delta: Optional[str] = None

class ToolCallResultEvent(BaseEvent):
    """
    Event containing the result of a tool call.
    """
    message_id: str
    type: Literal[EventType.TOOL_CALL_RESULT] = EventType.TOOL_CALL_RESULT  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    content: str
    role: Optional[Literal["tool"]] = None

class ThinkingStartEvent(BaseEvent):
    """
    Event indicating the start of a thinking step event.
    """
    type: Literal[EventType.THINKING_START] = EventType.THINKING_START  # pyright: ignore[reportIncompatibleVariableOverride]
    title: Optional[str] = None

class ThinkingEndEvent(BaseEvent):
    """
    Event indicating the end of a thinking step event.
    """
    type: Literal[EventType.THINKING_END] = EventType.THINKING_END  # pyright: ignore[reportIncompatibleVariableOverride]

class StateSnapshotEvent(BaseEvent):
    """
    Event containing a snapshot of the state.
    """
    type: Literal[EventType.STATE_SNAPSHOT] = EventType.STATE_SNAPSHOT  # pyright: ignore[reportIncompatibleVariableOverride]
    snapshot: State


class StateDeltaEvent(BaseEvent):
    """
    Event containing a delta of the state.
    """
    type: Literal[EventType.STATE_DELTA] = EventType.STATE_DELTA  # pyright: ignore[reportIncompatibleVariableOverride]
    delta: List[Any]  # JSON Patch (RFC 6902)


class MessagesSnapshotEvent(BaseEvent):
    """
    Event containing a snapshot of the messages.
    """
    type: Literal[EventType.MESSAGES_SNAPSHOT] = EventType.MESSAGES_SNAPSHOT  # pyright: ignore[reportIncompatibleVariableOverride]
    messages: List[Message]


class RawEvent(BaseEvent):
    """
    Event containing a raw event.
    """
    type: Literal[EventType.RAW] = EventType.RAW  # pyright: ignore[reportIncompatibleVariableOverride]
    event: Any
    source: Optional[str] = None


class CustomEvent(BaseEvent):
    """
    Event containing a custom event.
    """
    type: Literal[EventType.CUSTOM] = EventType.CUSTOM  # pyright: ignore[reportIncompatibleVariableOverride]
    name: str
    value: Any


class RunStartedEvent(BaseEvent):
    """
    Event indicating that a run has started.
    """
    type: Literal[EventType.RUN_STARTED] = EventType.RUN_STARTED  # pyright: ignore[reportIncompatibleVariableOverride]
    thread_id: str
    run_id: str


class RunFinishedEvent(BaseEvent):
    """
    Event indicating that a run has finished.
    """
    type: Literal[EventType.RUN_FINISHED] = EventType.RUN_FINISHED  # pyright: ignore[reportIncompatibleVariableOverride]
    thread_id: str
    run_id: str
    result: Optional[Any] = None


class RunErrorEvent(BaseEvent):
    """
    Event indicating that a run has encountered an error.
    """
    type: Literal[EventType.RUN_ERROR] = EventType.RUN_ERROR  # pyright: ignore[reportIncompatibleVariableOverride]
    message: str
    code: Optional[str] = None


class StepStartedEvent(BaseEvent):
    """
    Event indicating that a step has started.
    """
    type: Literal[EventType.STEP_STARTED] = EventType.STEP_STARTED  # pyright: ignore[reportIncompatibleVariableOverride]
    step_name: str


class StepFinishedEvent(BaseEvent):
    """
    Event indicating that a step has finished.
    """
    type: Literal[EventType.STEP_FINISHED] = EventType.STEP_FINISHED  # pyright: ignore[reportIncompatibleVariableOverride]
    step_name: str


Event = Annotated[
    Union[
        TextMessageStartEvent,
        TextMessageContentEvent,
        TextMessageEndEvent,
        TextMessageChunkEvent,
        ToolCallStartEvent,
        ToolCallArgsEvent,
        ToolCallEndEvent,
        ToolCallChunkEvent,
        ToolCallResultEvent,
        StateSnapshotEvent,
        StateDeltaEvent,
        MessagesSnapshotEvent,
        RawEvent,
        CustomEvent,
        RunStartedEvent,
        RunFinishedEvent,
        RunErrorEvent,
        StepStartedEvent,
        StepFinishedEvent,
    ],
    Field(discriminator="type")
]



================================================
FILE: python-sdk/ag_ui/core/types.py
================================================
"""
This module contains the types for the Agent User Interaction Protocol Python SDK.
"""

from typing import Annotated, Any, List, Literal, Optional, Union

from pydantic import BaseModel, ConfigDict, Field
from pydantic.alias_generators import to_camel


class ConfiguredBaseModel(BaseModel):
    """
    A configurable base model.
    """
    model_config = ConfigDict(
        extra="forbid",
        alias_generator=to_camel,
        populate_by_name=True,
    )


class FunctionCall(ConfiguredBaseModel):
    """
    Name and arguments of a function call.
    """
    name: str
    arguments: str


class ToolCall(ConfiguredBaseModel):
    """
    A tool call, modelled after OpenAI tool calls.
    """
    id: str
    type: Literal["function"] = "function"  # pyright: ignore[reportIncompatibleVariableOverride]
    function: FunctionCall


class BaseMessage(ConfiguredBaseModel):
    """
    A base message, modelled after OpenAI messages.
    """
    id: str
    role: str
    content: Optional[str] = None
    name: Optional[str] = None


class DeveloperMessage(BaseMessage):
    """
    A developer message.
    """
    role: Literal["developer"] = "developer"  # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class SystemMessage(BaseMessage):
    """
    A system message.
    """
    role: Literal["system"] = "system"  # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class AssistantMessage(BaseMessage):
    """
    An assistant message.
    """
    role: Literal["assistant"] = "assistant"  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_calls: Optional[List[ToolCall]] = None


class UserMessage(BaseMessage):
    """
    A user message.
    """
    role: Literal["user"] = "user" # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class ToolMessage(ConfiguredBaseModel):
    """
    A tool result message.
    """
    id: str
    role: Literal["tool"] = "tool"
    content: str
    tool_call_id: str
    error: Optional[str] = None


Message = Annotated[
    Union[DeveloperMessage, SystemMessage, AssistantMessage, UserMessage, ToolMessage],
    Field(discriminator="role")
]

Role = Literal["developer", "system", "assistant", "user", "tool"]


class Context(ConfiguredBaseModel):
    """
    Additional context for the agent.
    """
    description: str
    value: str


class Tool(ConfiguredBaseModel):
    """
    A tool definition.
    """
    name: str
    description: str
    parameters: Any  # JSON Schema for the tool parameters


class RunAgentInput(ConfiguredBaseModel):
    """
    Input for running an agent.
    """
    thread_id: str
    run_id: str
    state: Any
    messages: List[Message]
    tools: List[Tool]
    context: List[Context]
    forwarded_props: Any


# State can be any type
State = Any



================================================
FILE: python-sdk/ag_ui/encoder/__init__.py
================================================
"""
This module contains the EventEncoder class.
"""

from ag_ui.encoder.encoder import EventEncoder, AGUI_MEDIA_TYPE

__all__ = ["EventEncoder", "AGUI_MEDIA_TYPE"]



================================================
FILE: python-sdk/ag_ui/encoder/encoder.py
================================================
"""
This module contains the EventEncoder class
"""

from ag_ui.core.events import BaseEvent

AGUI_MEDIA_TYPE = "application/vnd.ag-ui.event+proto"

class EventEncoder:
    """
    Encodes Agent User Interaction events.
    """
    def __init__(self, accept: str = None):
        pass

    def get_content_type(self) -> str:
        """
        Returns the content type of the encoder.
        """
        return "text/event-stream"

    def encode(self, event: BaseEvent) -> str:
        """
        Encodes an event.
        """
        return self._encode_sse(event)

    def _encode_sse(self, event: BaseEvent) -> str:
        """
        Encodes an event into an SSE string.
        """
        return f"data: {event.model_dump_json(by_alias=True, exclude_none=True)}\n\n"



================================================
FILE: python-sdk/tests/__init__.py
================================================
[Empty file]


================================================
FILE: python-sdk/tests/test_encoder.py
================================================
import unittest
import json
from datetime import datetime

from ag_ui.encoder.encoder import EventEncoder, AGUI_MEDIA_TYPE
from ag_ui.core.events import BaseEvent, EventType, TextMessageContentEvent, ToolCallStartEvent


class TestEventEncoder(unittest.TestCase):
    """Test suite for EventEncoder class"""

    def test_encoder_initialization(self):
        """Test initializing an EventEncoder"""
        encoder = EventEncoder()
        self.assertIsInstance(encoder, EventEncoder)

        # Test with accept parameter
        encoder_with_accept = EventEncoder(accept=AGUI_MEDIA_TYPE)
        self.assertIsInstance(encoder_with_accept, EventEncoder)

    def test_encode_method(self):
        """Test the encode method which calls encode_sse"""
        # Create a test event
        timestamp = int(datetime.now().timestamp() * 1000)
        event = BaseEvent(type=EventType.RAW, timestamp=timestamp)
        
        # Create encoder and encode event
        encoder = EventEncoder()
        encoded = encoder.encode(event)
        
        # The encode method calls encode_sse, so the result should be in SSE format
        expected = f"data: {event.model_dump_json(by_alias=True, exclude_none=True)}\n\n"
        self.assertEqual(encoded, expected)
        
        # Verify that camelCase is used in the encoded output
        self.assertIn('"type":', encoded)
        self.assertIn('"timestamp":', encoded)
        # Raw event should be excluded if it's None
        self.assertNotIn('"rawEvent":', encoded)
        self.assertNotIn('"raw_event":', encoded)

    def test_encode_sse_method(self):
        """Test the encode_sse method"""
        # Create a test event with specific data
        event = TextMessageContentEvent(
            message_id="msg_123",
            delta="Hello, world!",
            timestamp=1648214400000
        )
        
        # Create encoder and encode event to SSE
        encoder = EventEncoder()
        encoded_sse = encoder._encode_sse(event)
        
        # Verify the format is correct for SSE (data: [json]\n\n)
        self.assertTrue(encoded_sse.startswith("data: "))
        self.assertTrue(encoded_sse.endswith("\n\n"))
        
        # Extract and verify the JSON content
        json_content = encoded_sse[6:-2]  # Remove "data: " prefix and "\n\n" suffix
        decoded = json.loads(json_content)
        
        # Check that all fields were properly encoded
        self.assertEqual(decoded["type"], "TEXT_MESSAGE_CONTENT")
        self.assertEqual(decoded["messageId"], "msg_123")  # Check snake_case converted to camelCase
        self.assertEqual(decoded["delta"], "Hello, world!")
        self.assertEqual(decoded["timestamp"], 1648214400000)
        
        # Verify that snake_case has been converted to camelCase
        self.assertIn("messageId", decoded)  # camelCase key exists
        self.assertNotIn("message_id", decoded)  # snake_case key doesn't exist

    def test_encode_with_different_event_types(self):
        """Test encoding different types of events"""
        # Create encoder
        encoder = EventEncoder()
        
        # Test with a basic BaseEvent
        base_event = BaseEvent(type=EventType.RAW, timestamp=1648214400000)
        encoded_base = encoder.encode(base_event)
        self.assertIn('"type":"RAW"', encoded_base)
        
        # Test with a more complex event
        content_event = TextMessageContentEvent(
            message_id="msg_456",
            delta="Testing different events",
            timestamp=1648214400000
        )
        encoded_content = encoder.encode(content_event)
        
        # Verify correct encoding and camelCase conversion
        self.assertIn('"type":"TEXT_MESSAGE_CONTENT"', encoded_content)
        self.assertIn('"messageId":"msg_456"', encoded_content)  # Check snake_case converted to camelCase
        self.assertIn('"delta":"Testing different events"', encoded_content)
        
        # Extract JSON and verify camelCase conversion
        json_content = encoded_content.split("data: ")[1].rstrip("\n\n")
        decoded = json.loads(json_content)
        
        # Verify messageId is camelCase (not message_id)
        self.assertIn("messageId", decoded)
        self.assertNotIn("message_id", decoded)
        
    def test_null_value_exclusion(self):
        """Test that fields with None values are excluded from the JSON output"""
        # Create an event with some fields set to None
        event = BaseEvent(
            type=EventType.RAW,
            timestamp=1648214400000,
            raw_event=None  # Explicitly set to None
        )
        
        # Create encoder and encode event
        encoder = EventEncoder()
        encoded = encoder.encode(event)
        
        # Extract JSON
        json_content = encoded.split("data: ")[1].rstrip("\n\n")
        decoded = json.loads(json_content)
        
        # Verify fields that are present
        self.assertIn("type", decoded)
        self.assertIn("timestamp", decoded)
        
        # Verify null fields are excluded
        self.assertNotIn("rawEvent", decoded)
        
        # Test with another event that has optional fields
        # Create event with some optional fields set to None
        event_with_optional = ToolCallStartEvent(
            tool_call_id="call_123",
            tool_call_name="test_tool",
            parent_message_id=None,  # Optional field explicitly set to None
            timestamp=1648214400000
        )
        
        encoded_optional = encoder.encode(event_with_optional)
        json_content_optional = encoded_optional.split("data: ")[1].rstrip("\n\n")
        decoded_optional = json.loads(json_content_optional)
        
        # Required fields should be present
        self.assertIn("toolCallId", decoded_optional)
        self.assertIn("toolCallName", decoded_optional)
        
        # Optional field with None value should be excluded
        self.assertNotIn("parentMessageId", decoded_optional)
        
    def test_round_trip_serialization(self):
        """Test that events can be serialized to JSON with camelCase and deserialized back correctly"""
        # Create a complex event with multiple fields
        original_event = ToolCallStartEvent(
            tool_call_id="call_abc123",
            tool_call_name="search_tool",
            parent_message_id="msg_parent_456",
            timestamp=1648214400000
        )
        
        # Serialize to JSON with camelCase fields
        json_str = original_event.model_dump_json(by_alias=True)
        
        # Verify JSON uses camelCase
        json_data = json.loads(json_str)
        self.assertIn("toolCallId", json_data)
        self.assertIn("toolCallName", json_data)
        self.assertIn("parentMessageId", json_data)
        self.assertNotIn("tool_call_id", json_data)
        self.assertNotIn("tool_call_name", json_data)
        self.assertNotIn("parent_message_id", json_data)
        
        # Deserialize back to an event
        deserialized_event = ToolCallStartEvent.model_validate_json(json_str)
        
        # Verify the deserialized event is equivalent to the original
        self.assertEqual(deserialized_event.type, original_event.type)
        self.assertEqual(deserialized_event.tool_call_id, original_event.tool_call_id)
        self.assertEqual(deserialized_event.tool_call_name, original_event.tool_call_name)
        self.assertEqual(deserialized_event.parent_message_id, original_event.parent_message_id)
        self.assertEqual(deserialized_event.timestamp, original_event.timestamp)
        
        # Verify complete equality using model_dump
        self.assertEqual(
            original_event.model_dump(), 
            deserialized_event.model_dump()
        )



================================================
FILE: python-sdk/tests/test_events.py
================================================
import unittest
import json
from datetime import datetime
from pydantic import ValidationError, TypeAdapter

from ag_ui.core.types import Message, UserMessage, AssistantMessage, FunctionCall, ToolCall
from ag_ui.core.events import (
    EventType,
    BaseEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
    Event
)


class TestEvents(unittest.TestCase):
    """Test suite for event classes"""

    def test_event_types_enum(self):
        """Test the EventType enum values"""
        self.assertEqual(EventType.TEXT_MESSAGE_START.value, "TEXT_MESSAGE_START")
        self.assertEqual(EventType.TOOL_CALL_ARGS.value, "TOOL_CALL_ARGS")
        self.assertEqual(EventType.STATE_SNAPSHOT.value, "STATE_SNAPSHOT")
        self.assertEqual(EventType.RUN_ERROR.value, "RUN_ERROR")
        self.assertEqual(EventType.STEP_FINISHED.value, "STEP_FINISHED")

    def test_base_event_creation(self):
        """Test creating a BaseEvent instance"""
        timestamp = int(datetime.now().timestamp() * 1000)
        event = BaseEvent(type=EventType.RAW, timestamp=timestamp)
        self.assertEqual(event.type, EventType.RAW)
        self.assertEqual(event.timestamp, timestamp)
        self.assertIsNone(event.raw_event)

    def test_text_message_start(self):
        """Test creating and serializing a TextMessageStartEvent event"""
        event = TextMessageStartEvent(
            message_id="msg_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        self.assertEqual(event.role, "assistant")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_START")
        self.assertEqual(serialized["messageId"], "msg_123")
        self.assertEqual(serialized["timestamp"], 1648214400000)

    def test_text_message_content(self):
        """Test creating and serializing a TextMessageContentEvent event"""
        event = TextMessageContentEvent(
            message_id="msg_123",
            delta="Hello, world!",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        self.assertEqual(event.delta, "Hello, world!")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_CONTENT")
        self.assertEqual(serialized["messageId"], "msg_123")
        self.assertEqual(serialized["delta"], "Hello, world!")

    def test_text_message_end(self):
        """Test creating and serializing a TextMessageEndEvent event"""
        event = TextMessageEndEvent(
            message_id="msg_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_END")
        self.assertEqual(serialized["messageId"], "msg_123")

    def test_tool_call_start(self):
        """Test creating and serializing a ToolCallStartEvent event"""
        event = ToolCallStartEvent(
            tool_call_id="call_123",
            tool_call_name="get_weather",
            parent_message_id="msg_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        self.assertEqual(event.tool_call_name, "get_weather")
        self.assertEqual(event.parent_message_id, "msg_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_START")
        self.assertEqual(serialized["toolCallId"], "call_123")
        self.assertEqual(serialized["toolCallName"], "get_weather")
        self.assertEqual(serialized["parentMessageId"], "msg_456")

    def test_tool_call_args(self):
        """Test creating and serializing a ToolCallArgsEvent event"""
        event = ToolCallArgsEvent(
            tool_call_id="call_123",
            delta='{"location": "New York"}',
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        self.assertEqual(event.delta, '{"location": "New York"}')
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_ARGS")
        self.assertEqual(serialized["toolCallId"], "call_123")
        self.assertEqual(serialized["delta"], '{"location": "New York"}')

    def test_tool_call_end(self):
        """Test creating and serializing a ToolCallEndEvent event"""
        event = ToolCallEndEvent(
            tool_call_id="call_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_END")
        self.assertEqual(serialized["toolCallId"], "call_123")

    def test_state_snapshot(self):
        """Test creating and serializing a StateSnapshotEvent event"""
        state = {"conversation_state": "active", "user_info": {"name": "John"}}
        event = StateSnapshotEvent(
            snapshot=state,
            timestamp=1648214400000
        )
        self.assertEqual(event.snapshot, state)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STATE_SNAPSHOT")
        self.assertEqual(serialized["snapshot"]["conversation_state"], "active")
        self.assertEqual(serialized["snapshot"]["user_info"]["name"], "John")

    def test_state_delta(self):
        """Test creating and serializing a StateDeltaEvent event"""
        # JSON Patch format
        delta = [
            {"op": "replace", "path": "/conversation_state", "value": "paused"},
            {"op": "add", "path": "/user_info/age", "value": 30}
        ]
        event = StateDeltaEvent(
            delta=delta,
            timestamp=1648214400000
        )
        self.assertEqual(event.delta, delta)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STATE_DELTA")
        self.assertEqual(len(serialized["delta"]), 2)
        self.assertEqual(serialized["delta"][0]["op"], "replace")
        self.assertEqual(serialized["delta"][1]["path"], "/user_info/age")

    def test_messages_snapshot(self):
        """Test creating and serializing a MessagesSnapshotEvent event"""
        messages = [
            UserMessage(id="user_1", content="Hello"),
            AssistantMessage(id="asst_1", content="Hi there", tool_calls=[
                ToolCall(
                    id="call_1",
                    function=FunctionCall(
                        name="get_weather",
                        arguments='{"location": "New York"}'
                    )
                )
            ])
        ]
        event = MessagesSnapshotEvent(
            messages=messages,
            timestamp=1648214400000
        )
        self.assertEqual(len(event.messages), 2)
        self.assertEqual(event.messages[0].id, "user_1")
        self.assertEqual(event.messages[1].tool_calls[0].function.name, "get_weather")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "MESSAGES_SNAPSHOT")
        self.assertEqual(len(serialized["messages"]), 2)
        self.assertEqual(serialized["messages"][0]["role"], "user")
        self.assertEqual(serialized["messages"][1]["toolCalls"][0]["function"]["name"], "get_weather")

    def test_raw_event(self):
        """Test creating and serializing a RawEvent"""
        raw_data = {"origin": "server", "data": {"key": "value"}}
        event = RawEvent(
            event=raw_data,
            source="api",
            timestamp=1648214400000
        )
        self.assertEqual(event.event, raw_data)
        self.assertEqual(event.source, "api")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RAW")
        self.assertEqual(serialized["event"]["origin"], "server")
        self.assertEqual(serialized["source"], "api")

    def test_custom_event(self):
        """Test creating and serializing a CustomEvent"""
        event = CustomEvent(
            name="user_action",
            value={"action": "click", "element": "button"},
            timestamp=1648214400000
        )
        self.assertEqual(event.name, "user_action")
        self.assertEqual(event.value["action"], "click")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "CUSTOM")
        self.assertEqual(serialized["name"], "user_action")
        self.assertEqual(serialized["value"]["element"], "button")

    def test_run_started(self):
        """Test creating and serializing a RunStartedEvent event"""
        event = RunStartedEvent(
            thread_id="thread_123",
            run_id="run_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.thread_id, "thread_123")
        self.assertEqual(event.run_id, "run_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_STARTED")
        self.assertEqual(serialized["threadId"], "thread_123")
        self.assertEqual(serialized["runId"], "run_456")

    def test_run_finished(self):
        """Test creating and serializing a RunFinishedEvent event"""
        event = RunFinishedEvent(
            thread_id="thread_123",
            run_id="run_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.thread_id, "thread_123")
        self.assertEqual(event.run_id, "run_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_FINISHED")
        self.assertEqual(serialized["threadId"], "thread_123")
        self.assertEqual(serialized["runId"], "run_456")

    def test_run_error(self):
        """Test creating and serializing a RunErrorEvent event"""
        event = RunErrorEvent(
            message="An error occurred during execution",
            code="ERROR_001",
            timestamp=1648214400000
        )
        self.assertEqual(event.message, "An error occurred during execution")
        self.assertEqual(event.code, "ERROR_001")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_ERROR")
        self.assertEqual(serialized["message"], "An error occurred during execution")
        self.assertEqual(serialized["code"], "ERROR_001")

    def test_step_started(self):
        """Test creating and serializing a StepStartedEvent event"""
        event = StepStartedEvent(
            step_name="process_data",
            timestamp=1648214400000
        )
        self.assertEqual(event.step_name, "process_data")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STEP_STARTED")
        self.assertEqual(serialized["stepName"], "process_data")

    def test_step_finished(self):
        """Test creating and serializing a StepFinishedEvent event"""
        event = StepFinishedEvent(
            step_name="process_data",
            timestamp=1648214400000
        )
        self.assertEqual(event.step_name, "process_data")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STEP_FINISHED")
        self.assertEqual(serialized["stepName"], "process_data")

    def test_event_union_deserialization(self):
        """Test the Event union type correctly deserializes different event types"""
        event_adapter = TypeAdapter(Event)
        
        # Test different event types
        event_data = [
            {
                "type": "TEXT_MESSAGE_START",
                "messageId": "msg_start",
                "role": "assistant",
                "timestamp": 1648214400000
            },
            {
                "type": "TEXT_MESSAGE_CONTENT",
                "messageId": "msg_content",
                "delta": "Hello!",
                "timestamp": 1648214400000
            },
            {
                "type": "TOOL_CALL_START",
                "toolCallId": "call_start",
                "toolCallName": "get_info",
                "timestamp": 1648214400000
            },
            {
                "type": "STATE_SNAPSHOT",
                "snapshot": {"status": "active"},
                "timestamp": 1648214400000
            },
            {
                "type": "RUN_ERROR",
                "message": "Error occurred",
                "code": "ERR_001",
                "timestamp": 1648214400000
            }
        ]
        
        expected_types = [
            TextMessageStartEvent,
            TextMessageContentEvent,
            ToolCallStartEvent,
            StateSnapshotEvent,
            RunErrorEvent
        ]
        
        for data, expected_type in zip(event_data, expected_types):
            event = event_adapter.validate_python(data)
            self.assertIsInstance(event, expected_type)
            self.assertEqual(event.type.value, data["type"])
            self.assertEqual(event.timestamp, data["timestamp"])

    def test_validation_constraints(self):
        """Test validation constraints for different event types"""
        # TextMessageContentEvent delta cannot be empty
        with self.assertRaises(ValueError):
            TextMessageContentEvent(
                message_id="msg_123",
                delta=""  # Empty delta, should fail
            )

    def test_serialization_round_trip(self):
        """Test serialization and deserialization for different event types"""
        # Create events of different types
        events = [
            TextMessageStartEvent(
                message_id="msg_123",
            ),
            TextMessageContentEvent(
                message_id="msg_123",
                delta="Hello, world!"
            ),
            ToolCallStartEvent(
                tool_call_id="call_123",
                tool_call_name="get_weather"
            ),
            StateSnapshotEvent(
                snapshot={"status": "active"}
            ),
            MessagesSnapshotEvent(
                messages=[
                    UserMessage(id="user_1", content="Hello")
                ]
            ),
            RunStartedEvent(
                thread_id="thread_123",
                run_id="run_456"
            )
        ]
        
        event_adapter = TypeAdapter(Event)
        
        # Test round trip for each event
        for original_event in events:
            # Serialize to JSON
            json_str = original_event.model_dump_json(by_alias=True)
            
            # Deserialize back to object
            deserialized_event = event_adapter.validate_json(json_str)
            
            # Verify the types match
            self.assertIsInstance(deserialized_event, type(original_event))
            self.assertEqual(deserialized_event.type, original_event.type)
            
            # Verify event-specific fields
            if isinstance(original_event, TextMessageStartEvent):
                self.assertEqual(deserialized_event.message_id, original_event.message_id)
                self.assertEqual(deserialized_event.role, original_event.role)
            elif isinstance(original_event, TextMessageContentEvent):
                self.assertEqual(deserialized_event.message_id, original_event.message_id)
                self.assertEqual(deserialized_event.delta, original_event.delta)
            elif isinstance(original_event, ToolCallStartEvent):
                self.assertEqual(deserialized_event.tool_call_id, original_event.tool_call_id)
                self.assertEqual(deserialized_event.tool_call_name, original_event.tool_call_name)
            elif isinstance(original_event, StateSnapshotEvent):
                self.assertEqual(deserialized_event.snapshot, original_event.snapshot)
            elif isinstance(original_event, MessagesSnapshotEvent):
                self.assertEqual(len(deserialized_event.messages), len(original_event.messages))
                self.assertEqual(deserialized_event.messages[0].id, original_event.messages[0].id)
            elif isinstance(original_event, RunStartedEvent):
                self.assertEqual(deserialized_event.thread_id, original_event.thread_id)
                self.assertEqual(deserialized_event.run_id, original_event.run_id)

    def test_raw_event_with_null_source(self):
        """Test RawEvent with null source"""
        event = RawEvent(
            event={"data": "test"},
            source=None  # Explicit None
        )
        self.assertIsNone(event.source)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RAW")
        self.assertEqual(serialized["event"]["data"], "test")
        self.assertIsNone(serialized["source"])
        
        # Test round-trip
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        self.assertIsNone(deserialized.source)

    def test_complex_nested_event_structures(self):
        """Test complex nested structures within events"""
        # Complex state with nested objects and arrays
        complex_state = {
            "session": {
                "user": {
                    "id": "user_123",
                    "preferences": {
                        "theme": "dark",
                        "notifications": True,
                        "filters": ["news", "social", "tech"]
                    }
                },
                "stats": {
                    "messages": 42,
                    "interactions": {
                        "clicks": 18,
                        "searches": 7
                    }
                }
            },
            "active_tools": ["search", "calculator", "weather"],
            "settings": {
                "language": "en",
                "timezone": "UTC-5"
            }
        }
        
        event = StateSnapshotEvent(
            snapshot=complex_state,
            timestamp=1648214400000
        )
        
        # Verify complex state structure
        self.assertEqual(event.snapshot["session"]["user"]["id"], "user_123")
        self.assertEqual(event.snapshot["session"]["user"]["preferences"]["theme"], "dark")
        self.assertEqual(event.snapshot["session"]["stats"]["interactions"]["searches"], 7)
        self.assertEqual(event.snapshot["active_tools"][1], "calculator")
        
        # Test serialization and deserialization
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        
        # Verify structure is preserved
        self.assertEqual(
            deserialized.snapshot["session"]["user"]["preferences"]["filters"],
            ["news", "social", "tech"]
        )
        self.assertEqual(deserialized.snapshot["settings"]["timezone"], "UTC-5")

    def test_event_with_unicode_and_special_chars(self):
        """Test events with Unicode and special characters"""
        # Text with Unicode and special characters
        text = "Hello 你好 こんにちは 안녕하세요 👋 🌍 \n\t\"'\\/<>{}[]"
        
        event = TextMessageContentEvent(
            message_id="msg_unicode",
            delta=text,
            timestamp=1648214400000
        )
        
        # Verify text is stored correctly
        self.assertEqual(event.delta, text)
        
        # Test serialization and deserialization
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        
        # Verify Unicode and special characters are preserved
        self.assertEqual(deserialized.delta, text)


if __name__ == "__main__":
    unittest.main()



================================================
FILE: python-sdk/tests/test_text_roles.py
================================================
"""Tests for text message events with different roles."""

import unittest
from pydantic import ValidationError
from ag_ui.core import (
    EventType,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageChunkEvent,
    Role,
)

# Test all available roles for text messages (excluding "tool")
TEXT_MESSAGE_ROLES = ["developer", "system", "assistant", "user"]


class TestTextMessageRoles(unittest.TestCase):
    """Test text message events with different roles."""

    def test_text_message_start_with_all_roles(self) -> None:
        """Test TextMessageStartEvent with different roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageStartEvent(
                    message_id="test-msg",
                    role=role,
                )
                
                self.assertEqual(event.type, EventType.TEXT_MESSAGE_START)
                self.assertEqual(event.message_id, "test-msg")
                self.assertEqual(event.role, role)

    def test_text_message_chunk_with_all_roles(self) -> None:
        """Test TextMessageChunkEvent with different roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageChunkEvent(
                    message_id="test-msg",
                    role=role,
                    delta=f"Hello from {role}",
                )
                
                self.assertEqual(event.type, EventType.TEXT_MESSAGE_CHUNK)
                self.assertEqual(event.message_id, "test-msg")
                self.assertEqual(event.role, role)
                self.assertEqual(event.delta, f"Hello from {role}")

    def test_text_message_chunk_without_role(self) -> None:
        """Test TextMessageChunkEvent without role (should be optional)."""
        event = TextMessageChunkEvent(
            message_id="test-msg",
            delta="Hello without role",
        )
        
        self.assertEqual(event.type, EventType.TEXT_MESSAGE_CHUNK)
        self.assertEqual(event.message_id, "test-msg")
        self.assertIsNone(event.role)
        self.assertEqual(event.delta, "Hello without role")

    def test_multiple_messages_different_roles(self) -> None:
        """Test creating multiple messages with different roles."""
        events = []
        
        for role in TEXT_MESSAGE_ROLES:
            start_event = TextMessageStartEvent(
                message_id=f"msg-{role}",
                role=role,
            )
            content_event = TextMessageContentEvent(
                message_id=f"msg-{role}",
                delta=f"Message from {role}",
            )
            end_event = TextMessageEndEvent(
                message_id=f"msg-{role}",
            )
            
            events.extend([start_event, content_event, end_event])
        
        # Verify we have 3 events per role
        self.assertEqual(len(events), len(TEXT_MESSAGE_ROLES) * 3)
        
        # Verify each start event has the correct role
        for i, role in enumerate(TEXT_MESSAGE_ROLES):
            start_event = events[i * 3]
            self.assertIsInstance(start_event, TextMessageStartEvent)
            self.assertEqual(start_event.role, role)
            self.assertEqual(start_event.message_id, f"msg-{role}")

    def test_text_message_serialization(self) -> None:
        """Test that text message events serialize correctly with roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageStartEvent(
                    message_id="test-msg",
                    role=role,
                )
                
                # Convert to dict and back
                event_dict = event.model_dump()
                self.assertEqual(event_dict["role"], role)
                self.assertEqual(event_dict["type"], EventType.TEXT_MESSAGE_START)
                self.assertEqual(event_dict["message_id"], "test-msg")
                
                # Recreate from dict
                new_event = TextMessageStartEvent(**event_dict)
                self.assertEqual(new_event.role, role)
                self.assertEqual(new_event, event)

    def test_invalid_role_rejected(self) -> None:
        """Test that invalid roles are rejected."""
        # Test with completely invalid role
        with self.assertRaises(ValidationError):
            TextMessageStartEvent(
                message_id="test-msg",
                role="invalid_role",  # type: ignore
            )
        
        # Test that 'tool' role is not allowed for text messages
        with self.assertRaises(ValidationError):
            TextMessageStartEvent(
                message_id="test-msg",
                role="tool",  # type: ignore
            )
        
        # Test that 'tool' role is not allowed for chunks either
        with self.assertRaises(ValidationError):
            TextMessageChunkEvent(
                message_id="test-msg",
                role="tool",  # type: ignore
                delta="Tool message",
            )

    def test_text_message_start_default_role(self) -> None:
        """Test that TextMessageStartEvent defaults to 'assistant' role."""
        event = TextMessageStartEvent(
            message_id="test-msg",
        )
        
        self.assertEqual(event.type, EventType.TEXT_MESSAGE_START)
        self.assertEqual(event.message_id, "test-msg")
        self.assertEqual(event.role, "assistant")  # Should default to assistant


if __name__ == "__main__":
    unittest.main()


================================================
FILE: python-sdk/tests/test_types.py
================================================
import unittest
from pydantic import ValidationError
from pydantic import TypeAdapter

from ag_ui.core.types import (
    FunctionCall,
    ToolCall,
    DeveloperMessage,
    SystemMessage,
    AssistantMessage,
    UserMessage,
    ToolMessage,
    Message,
    RunAgentInput
)


class TestBaseTypes(unittest.TestCase):
    """Test suite for base type classes"""

    def test_function_call_creation(self):
        """Test creating a FunctionCall instance"""
        func_call = FunctionCall(name="test_function", arguments="{}")
        self.assertEqual(func_call.name, "test_function")
        self.assertEqual(func_call.arguments, "{}")

    def test_message_serialization(self):
        """Test serialization of a basic message"""
        user_msg = UserMessage(
            id="msg_123",
            content="Hello, world!"
        )
        serialized = user_msg.model_dump(by_alias=True)
        self.assertEqual(serialized["id"], "msg_123")
        self.assertEqual(serialized["role"], "user")
        self.assertEqual(serialized["content"], "Hello, world!")

    def test_tool_call_serialization(self):
        """Test camel case serialization for ConfiguredBaseModel subclasses"""
        tool_call = ToolCall(
            id="call_123",
            function=FunctionCall(name="test_function", arguments="{}")
        )
        serialized = tool_call.model_dump(by_alias=True)
        # Should convert function to camelCase
        self.assertIn("function", serialized)

    def test_tool_message_camel_case(self):
        """Test camel case serialization for ToolMessage"""
        tool_msg = ToolMessage(
            id="tool_123",
            content="Tool result",
            tool_call_id="call_456"
        )
        serialized = tool_msg.model_dump(by_alias=True)
        self.assertIn("toolCallId", serialized)
        self.assertEqual(serialized["toolCallId"], "call_456")

    def test_parse_camel_case_json_tool_message(self):
        """Test parsing JSON with camelCase field names"""
        # JSON data with camelCase field names
        json_data = {
            "id": "tool_789",
            "role": "tool",
            "content": "Result from tool",
            "toolCallId": "call_123"  # camelCase field name
        }

        # Parse the JSON data into a ToolMessage instance
        tool_msg = ToolMessage.model_validate(json_data)

        # Verify fields are correctly set
        self.assertEqual(tool_msg.id, "tool_789")
        self.assertEqual(tool_msg.role, "tool")
        self.assertEqual(tool_msg.content, "Result from tool")
        self.assertEqual(tool_msg.tool_call_id, "call_123")

    def test_parse_camel_case_json_function_call(self):
        """Test parsing function call with camelCase fields"""
        # Create a tool call with nested function call in camelCase
        json_data = {
            "id": "call_abc",
            "type": "function",
            "function": {
                "name": "get_weather",
                "arguments": '{"location":"New York"}'
            }
        }

        # Parse JSON into a ToolCall instance
        tool_call = ToolCall.model_validate(json_data)

        # Verify fields are correctly set
        self.assertEqual(tool_call.id, "call_abc")
        self.assertEqual(tool_call.type, "function")
        self.assertEqual(tool_call.function.name, "get_weather")
        self.assertEqual(tool_call.function.arguments, '{"location":"New York"}')

    def test_developer_message(self):
        """Test creating and serializing a developer message"""
        msg = DeveloperMessage(
            id="dev_123",
            content="Developer note"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "developer")
        self.assertEqual(serialized["content"], "Developer note")

    def test_system_message(self):
        """Test creating and serializing a system message"""
        msg = SystemMessage(
            id="sys_123",
            content="System instruction"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "system")
        self.assertEqual(serialized["content"], "System instruction")

    def test_assistant_message(self):
        """Test creating and serializing an assistant message with tool calls"""
        tool_call = ToolCall(
            id="call_456",
            function=FunctionCall(name="get_data", arguments='{"param": "value"}')
        )
        msg = AssistantMessage(
            id="asst_123",
            content="Assistant response",
            tool_calls=[tool_call]
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "assistant")
        self.assertEqual(serialized["content"], "Assistant response")
        self.assertEqual(len(serialized["toolCalls"]), 1)
        self.assertEqual(serialized["toolCalls"][0]["id"], "call_456")

    def test_user_message(self):
        """Test creating and serializing a user message"""
        msg = UserMessage(
            id="user_123",
            content="User query"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "user")
        self.assertEqual(serialized["content"], "User query")

    def test_message_union_deserialization(self):
        """Test that the Message union correctly deserializes to the appropriate type"""
        # Create type adapter for the union
        message_adapter = TypeAdapter(Message)

        # Test each message type
        message_data = [
            {"id": "dev_123", "role": "developer", "content": "Developer note"},
            {"id": "sys_456", "role": "system", "content": "System instruction"},
            {"id": "asst_789", "role": "assistant", "content": "Assistant response"},
            {"id": "user_101", "role": "user", "content": "User query"},
            {
                "id": "tool_202", 
                "role": "tool", 
                "content": "Tool result", 
                "toolCallId": "call_303"
            }
        ]

        expected_types = [
            DeveloperMessage,
            SystemMessage,
            AssistantMessage,
            UserMessage,
            ToolMessage
        ]

        for data, expected_type in zip(message_data, expected_types):
            msg = message_adapter.validate_python(data)
            self.assertIsInstance(msg, expected_type)
            self.assertEqual(msg.id, data["id"])
            self.assertEqual(msg.role, data["role"])
            self.assertEqual(msg.content, data["content"])

    def test_message_union_with_tool_calls(self):
        """Test the Message union with an assistant message containing tool calls"""
        # Create type adapter for the union
        message_adapter = TypeAdapter(Message)

        data = {
            "id": "asst_123",
            "role": "assistant",
            "content": "I'll help with that",
            "toolCalls": [
                {
                    "id": "call_456",
                    "type": "function",
                    "function": {
                        "name": "search_data",
                        "arguments": '{"query": "python"}'
                    }
                }
            ]
        }

        msg = message_adapter.validate_python(data)
        self.assertIsInstance(msg, AssistantMessage)
        self.assertEqual(len(msg.tool_calls), 1)
        self.assertEqual(msg.tool_calls[0].function.name, "search_data")

    def test_run_agent_input_deserialization(self):
        """Test deserializing RunAgentInput JSON with diverse message types"""
        # Create JSON data for RunAgentInput with diverse messages
        run_agent_input_data = {
            "threadId": "thread_12345",
            "runId": "run_67890",
            "state": {"conversation_state": "active", "custom_data": {"key": "value"}},
            "messages": [
                # System message
                {
                    "id": "sys_001",
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                # User message
                {
                    "id": "user_001",
                    "role": "user",
                    "content": "Can you help me analyze this data?"
                },
                # Developer message
                {
                    "id": "dev_001",
                    "role": "developer",
                    "content": "The assistant should provide a detailed analysis."
                },
                # Assistant message with tool calls
                {
                    "id": "asst_001",
                    "role": "assistant",
                    "content": "I'll analyze the data for you.",
                    "toolCalls": [
                        {
                            "id": "call_001",
                            "type": "function",
                            "function": {
                                "name": "analyze_data",
                                "arguments": '{"dataset": "sales_2023", "metrics": ["mean", "median"]}' # pylint: disable=line-too-long
                            }
                        }
                    ]
                },
                # Tool message responding to tool call
                {
                    "id": "tool_001",
                    "role": "tool",
                    "content": '{"mean": 42.5, "median": 38.0}',
                    "toolCallId": "call_001"
                },
                # Another user message
                {
                    "id": "user_002",
                    "role": "user",
                    "content": "Can you explain these results?"
                }
            ],
            "tools": [
                {
                    "name": "analyze_data",
                    "description": "Analyze a dataset and return statistics",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "dataset": {"type": "string"},
                            "metrics": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["dataset"]
                    }
                },
                {
                    "name": "fetch_data",
                    "description": "Fetch data from a database",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "source": {"type": "string"},
                            "query": {"type": "string"}
                        },
                        "required": ["source", "query"]
                    }
                }
            ],
            "context": [
                {
                    "description": "User preferences",
                    "value": '{"theme": "dark", "language": "English"}'
                },
                {
                    "description": "Environment",
                    "value": "production"
                }
            ],
            "forwardedProps": {
                "api_version": "v1",
                "custom_settings": {"max_tokens": 500}
            }
        }

        # Deserialize using TypeAdapter
        run_agent_input = RunAgentInput.model_validate(run_agent_input_data)

        # Verify basic fields
        self.assertEqual(run_agent_input.thread_id, "thread_12345")
        self.assertEqual(run_agent_input.run_id, "run_67890")
        self.assertEqual(run_agent_input.state["conversation_state"], "active")

        # Verify messages count and types
        self.assertEqual(len(run_agent_input.messages), 6)
        self.assertIsInstance(run_agent_input.messages[0], SystemMessage)
        self.assertIsInstance(run_agent_input.messages[1], UserMessage)
        self.assertIsInstance(run_agent_input.messages[2], DeveloperMessage)
        self.assertIsInstance(run_agent_input.messages[3], AssistantMessage)
        self.assertIsInstance(run_agent_input.messages[4], ToolMessage)
        self.assertIsInstance(run_agent_input.messages[5], UserMessage)

        # Verify specific message content
        self.assertEqual(run_agent_input.messages[0].content, "You are a helpful assistant.")
        self.assertEqual(run_agent_input.messages[1].content, "Can you help me analyze this data?")

        # Verify assistant message with tool call
        assistant_msg = run_agent_input.messages[3]
        self.assertEqual(len(assistant_msg.tool_calls), 1)
        self.assertEqual(assistant_msg.tool_calls[0].function.name, "analyze_data")

        # Verify tool message
        tool_msg = run_agent_input.messages[4]
        self.assertEqual(tool_msg.tool_call_id, "call_001")
        self.assertEqual(tool_msg.content, '{"mean": 42.5, "median": 38.0}')

        # Verify tools
        self.assertEqual(len(run_agent_input.tools), 2)
        self.assertEqual(run_agent_input.tools[0].name, "analyze_data")
        self.assertEqual(run_agent_input.tools[1].name, "fetch_data")

        # Verify context
        self.assertEqual(len(run_agent_input.context), 2)
        self.assertEqual(run_agent_input.context[0].description, "User preferences")
        self.assertEqual(run_agent_input.context[1].value, "production")

        # Verify forwarded props
        self.assertEqual(run_agent_input.forwarded_props["api_version"], "v1")
        self.assertEqual(run_agent_input.forwarded_props["custom_settings"]["max_tokens"], 500)

    def test_validation_errors(self):
        """Test validation errors for various message types"""
        message_adapter = TypeAdapter(Message)

        # Test invalid role value
        invalid_role_data = {
            "id": "msg_123",
            "role": "invalid_role",  # Invalid role
            "content": "Hello"
        }
        with self.assertRaises(ValidationError):
            message_adapter.validate_python(invalid_role_data)

        # Test missing required fields
        missing_id_data = {
            # Missing "id" field
            "role": "user",
            "content": "Hello"
        }
        with self.assertRaises(ValidationError):
            UserMessage.model_validate(missing_id_data)

        # Test extra fields
        extra_field_data = {
            "id": "msg_456",
            "role": "user",
            "content": "Hello",
            "extra_field": "This shouldn't be here"  # Extra field
        }
        with self.assertRaises(ValidationError):
            UserMessage.model_validate(extra_field_data)

        # Test invalid tool_call_id in ToolMessage
        invalid_tool_data = {
            "id": "tool_789",
            "role": "tool",
            "content": "Result",
            # Missing required tool_call_id
        }
        with self.assertRaises(ValidationError):
            ToolMessage.model_validate(invalid_tool_data)

    def test_empty_collections(self):
        """Test RunAgentInput with empty collections"""
        # Create RunAgentInput with empty lists
        empty_collections_data = {
            "threadId": "thread_empty",
            "runId": "run_empty",
            "state": {},
            "messages": [],  # Empty messages
            "tools": [],     # Empty tools
            "context": [],   # Empty context
            "forwardedProps": {}
        }

        # Deserialize and verify
        run_input = RunAgentInput.model_validate(empty_collections_data)
        self.assertEqual(run_input.thread_id, "thread_empty")
        self.assertEqual(run_input.run_id, "run_empty")
        self.assertEqual(len(run_input.messages), 0)
        self.assertEqual(len(run_input.tools), 0)
        self.assertEqual(len(run_input.context), 0)
        self.assertEqual(run_input.forwarded_props, {})

    def test_multiple_tool_calls(self):
        """Test assistant message with multiple tool calls"""
        # Create assistant message with multiple tool calls
        assistant_data = {
            "id": "asst_multi",
            "role": "assistant",
            "content": "I'll perform multiple operations",
            "toolCalls": [
                {
                    "id": "call_1",
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "arguments": '{"location": "New York"}'
                    }
                },
                {
                    "id": "call_2",
                    "type": "function",
                    "function": {
                        "name": "search_database",
                        "arguments": '{"query": "recent sales"}'
                    }
                },
                {
                    "id": "call_3",
                    "type": "function",
                    "function": {
                        "name": "calculate",
                        "arguments": '{"operation": "sum", "values": [1, 2, 3, 4, 5]}'
                    }
                }
            ]
        }

        # Deserialize and verify
        assistant_msg = AssistantMessage.model_validate(assistant_data)
        self.assertEqual(assistant_msg.id, "asst_multi")
        self.assertEqual(len(assistant_msg.tool_calls), 3)

        # Check each tool call
        self.assertEqual(assistant_msg.tool_calls[0].id, "call_1")
        self.assertEqual(assistant_msg.tool_calls[0].function.name, "get_weather")

        self.assertEqual(assistant_msg.tool_calls[1].id, "call_2")
        self.assertEqual(assistant_msg.tool_calls[1].function.name, "search_database")

        self.assertEqual(assistant_msg.tool_calls[2].id, "call_3")
        self.assertEqual(assistant_msg.tool_calls[2].function.name, "calculate")

    def test_serialization_round_trip(self):
        """Test serializing to JSON and deserializing back to verify data integrity"""
        # Create original instance
        original_data = {
            "threadId": "thread_round_trip",
            "runId": "run_round_trip",
            "state": {"status": "active"},
            "messages": [
                {
                    "id": "sys_rt",
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "id": "user_rt",
                    "role": "user",
                    "content": "Help me with my task."
                },
                {
                    "id": "asst_rt",
                    "role": "assistant",
                    "content": "I'll help you.",
                    "toolCalls": [
                        {
                            "id": "call_rt",
                            "type": "function",
                            "function": {
                                "name": "get_task_info",
                                "arguments": "{}"
                            }
                        }
                    ]
                }
            ],
            "tools": [
                {
                    "name": "get_task_info",
                    "description": "Get task information",
                    "parameters": {
                        "type": "object",
                        "properties": {}
                    }
                }
            ],
            "context": [
                {
                    "description": "Session",
                    "value": "123456"
                }
            ],
            "forwardedProps": {
                "timestamp": 1648214400
            }
        }

        # Deserialize
        original_obj = RunAgentInput.model_validate(original_data)

        # Serialize back to JSON
        serialized_json = original_obj.model_dump_json(by_alias=True)

        # Deserialize again
        deserialized_obj = RunAgentInput.model_validate_json(serialized_json)

        # Verify round trip preserved data
        self.assertEqual(deserialized_obj.thread_id, original_obj.thread_id)
        self.assertEqual(deserialized_obj.run_id, original_obj.run_id)
        self.assertEqual(len(deserialized_obj.messages), len(original_obj.messages))

        # Verify message types are preserved
        self.assertIsInstance(deserialized_obj.messages[0], SystemMessage)
        self.assertIsInstance(deserialized_obj.messages[1], UserMessage)
        self.assertIsInstance(deserialized_obj.messages[2], AssistantMessage)

        # Verify tool calls are preserved
        self.assertEqual(len(deserialized_obj.messages[2].tool_calls), 1)
        self.assertEqual(
            deserialized_obj.messages[2].tool_calls[0].function.name,
            original_obj.messages[2].tool_calls[0].function.name
        )

    def test_content_edge_cases(self):
        """Test edge cases for message content"""

        # Test empty content
        empty_content_data = {
            "id": "msg_empty",
            "role": "user",
            "content": ""  # Empty string
        }
        empty_msg = UserMessage.model_validate(empty_content_data)
        self.assertEqual(empty_msg.content, "")

        # Test null content (for assistant messages)
        null_content_data = {
            "id": "asst_null",
            "role": "assistant",
            "content": None,  # Null content
            "toolCalls": [
                {
                    "id": "call_null",
                    "type": "function",
                    "function": {
                        "name": "get_data",
                        "arguments": "{}"
                    }
                }
            ]
        }
        null_msg = AssistantMessage.model_validate(null_content_data)
        self.assertIsNone(null_msg.content)

        # Test large content (not testing for performance, just functionality)
        large_content = "A" * 10000  # 10K characters
        large_content_data = {
            "id": "msg_large",
            "role": "user",
            "content": large_content
        }
        large_msg = UserMessage.model_validate(large_content_data)
        self.assertEqual(len(large_msg.content), 10000)

        # Test content with special characters
        special_chars = "Special chars: 你好 こんにちは 안녕하세요 👋 🌍 \n\t\"'\\/<>{}[]"
        special_chars_data = {
            "id": "msg_special",
            "role": "user",
            "content": special_chars
        }
        special_msg = UserMessage.model_validate(special_chars_data)
        self.assertEqual(special_msg.content, special_chars)

    def test_name_field_handling(self):
        """Test optional name field in different message types"""
        # Test user message with name
        user_with_name_data = {
            "id": "user_named",
            "role": "user",
            "content": "Hello",
            "name": "John"
        }
        user_msg = UserMessage.model_validate(user_with_name_data)
        self.assertEqual(user_msg.name, "John")

        # Test assistant message with name
        assistant_with_name_data = {
            "id": "asst_named",
            "role": "assistant",
            "content": "Hello",
            "name": "AI Assistant"
        }
        assistant_msg = AssistantMessage.model_validate(assistant_with_name_data)
        self.assertEqual(assistant_msg.name, "AI Assistant")

        # Verify serialization preserves name
        serialized = assistant_msg.model_dump(by_alias=True)
        self.assertEqual(serialized["name"], "AI Assistant")

        # Verify Union type handling with name
        message_adapter = TypeAdapter(Message)
        parsed_msg = message_adapter.validate_python(assistant_with_name_data)
        self.assertEqual(parsed_msg.name, "AI Assistant")

    def test_state_variations(self):
        """Test state with different structures and complex nested objects"""
        # Simple scalar state
        scalar_state_data = {
            "threadId": "thread_scalar",
            "runId": "run_scalar",
            "state": "ACTIVE",  # Scalar state
            "messages": [],
            "tools": [],
            "context": [],
            "forwardedProps": {}
        }
        scalar_input = RunAgentInput.model_validate(scalar_state_data)
        self.assertEqual(scalar_input.state, "ACTIVE")

        # Complex nested state
        complex_state = {
            "session": {
                "id": "sess_123",
                "user": {
                    "id": "user_456",
                    "preferences": {
                        "theme": "dark",
                        "notifications": True,
                        "filters": ["important", "urgent"]
                    }
                },
                "metrics": {
                    "requests": 42,
                    "tokens": {
                        "input": 1024,
                        "output": 2048
                    }
                }
            },
            "timestamp": 1648214400,
            "version": "1.0.0"
        }

        complex_state_data = {
            "threadId": "thread_complex",
            "runId": "run_complex",
            "state": complex_state,
            "messages": [],
            "tools": [],
            "context": [],
            "forwardedProps": {}
        }
        complex_input = RunAgentInput.model_validate(complex_state_data)

        # Verify nested state structure is preserved
        self.assertEqual(complex_input.state["session"]["id"], "sess_123")
        self.assertEqual(complex_input.state["session"]["user"]["id"], "user_456")
        self.assertEqual(complex_input.state["session"]["user"]["preferences"]["theme"], "dark")
        self.assertEqual(complex_input.state["session"]["metrics"]["tokens"]["output"], 2048)
        self.assertEqual(complex_input.state["version"], "1.0.0")

        # Verify serialization round-trip works with complex state
        serialized = complex_input.model_dump(by_alias=True)
        deserialized = RunAgentInput.model_validate(serialized)
        self.assertEqual(
            deserialized.state["session"]["user"]["preferences"]["filters"],
            ["important", "urgent"]
        )


if __name__ == "__main__":
    unittest.main()



================================================
FILE: typescript-sdk/README.md
================================================
# Agent User Interaction Protocol TypeScript SDK

The TypeScript SDK for the [Agent User Interaction Protocol](https://ag-ui.com).

For more information visit the [official documentation](https://docs.ag-ui.com/).



================================================
FILE: typescript-sdk/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: typescript-sdk/package.json
================================================
{
  "name": "ag-ui",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "private": true,
  "scripts": {
    "build": "turbo run build",
    "clean": "rm -rf dist .turbo node_modules && pnpm -r clean",
    "build:clean": "rm -rf dist .turbo node_modules && pnpm -r clean && pnpm install && turbo run build",
    "dev": "turbo run dev",
    "lint": "turbo run lint",
    "format": "prettier --write \"**/*.{ts,tsx,md,mdx}\"",
    "check-types": "turbo run check-types",
    "test": "turbo run test",
    "bump": "pnpm --filter './packages/*' exec -- pnpm version",
    "bump:alpha": "pnpm --filter './packages/*' exec -- pnpm version --preid alpha",
    "publish": "pnpm -r clean && pnpm install && turbo run build && pnpm publish -r --filter='./packages/*'",
    "publish:alpha": "pnpm -r clean && pnpm install && turbo run build && pnpm publish -r --no-git-checks --filter='./packages/*' --tag alpha"
  },
  "devDependencies": {
    "prettier": "^3.5.3",
    "turbo": "^2.4.4",
    "typescript": "5.8.2"
  },
  "packageManager": "pnpm@10.13.1",
  "engines": {
    "node": ">=18"
  },
  "version": "0.0.1"
}



================================================
FILE: typescript-sdk/pnpm-workspace.yaml
================================================
packages:
  - "apps/*"
  - "packages/*"
  - "integrations/*"



================================================
FILE: typescript-sdk/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2019",
    "module": "ESNext",
    "moduleResolution": "node",
    "declaration": true,
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  }
}



================================================
FILE: typescript-sdk/turbo.json
================================================
{
  "$schema": "https://turbo.build/schema.json",
  "ui": "tui",
  "envMode": "loose",
  "concurrency": "20",
  "tasks": {
    "generate": {
      "outputs": ["src/generated/**"]
    },
    "build": {
      "dependsOn": ["^build", "generate"],
      "inputs": ["$TURBO_DEFAULT$", ".env*"],
      "outputs": ["dist/**", ".next/**", "!.next/cache/**"]
    },
    "demo-viewer#build": {
      "dependsOn": ["^build", "generate"],
      "inputs": ["$TURBO_DEFAULT$", ".env*"],
      "outputs": ["dist/**", ".next/**", "!.next/cache/**"]
    },
    "lint": {
      "dependsOn": ["^lint"]
    },
    "check-types": {
      "dependsOn": ["^check-types"]
    },
    "dev": {
      "dependsOn": ["^build", "generate"],
      "cache": false,
      "persistent": true
    },
    "demo-viewer#dev": {
      "dependsOn": ["^build", "generate"],
      "cache": false,
      "persistent": true
    },
    "test": {
      "dependsOn": ["^build"],
      "outputs": []
    },
    "link:global": {
      "cache": false
    },
    "unlink:global": {
      "cache": false
    }
  }
}



================================================
FILE: typescript-sdk/.npmrc
================================================
[Empty file]


================================================
FILE: typescript-sdk/.prettierrc
================================================
{
  "printWidth": 100,
  "singleQuote": false,
  "semi": true,
  "tabWidth": 2,
  "overrides": [
    {
      "files": "*.mdx",
      "options": {
        "printWidth": 80,
        "proseWrap": "always",
        "semi": false,
        "singleQuote": false
      }
    }
  ]
}



================================================
FILE: typescript-sdk/apps/client-cli-example/README.md
================================================
# AG-UI CLI



================================================
FILE: typescript-sdk/apps/client-cli-example/package.json
================================================
{
  "name": "client-cli-example",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "start": "tsx src/index.ts",
    "dev": "tsx --watch src/index.ts",
    "build": "tsc",
    "clean": "rm -rf dist"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*",
    "@ag-ui/core": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ai-sdk/openai": "1.3.22",
    "@mastra/client-js": "0.10.18",
    "@mastra/core": "0.12.1",
    "@mastra/libsql": "0.12.0",
    "@mastra/loggers": "0.10.5",
    "@mastra/memory": "0.12.0",
    "open": "^10.1.2",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/node": "^20",
    "tsx": "^4.7.0",
    "typescript": "^5"
  }
}



================================================
FILE: typescript-sdk/apps/client-cli-example/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020", "dom"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "moduleResolution": "node"
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/apps/client-cli-example/src/agent.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { MastraAgent } from "@ag-ui/mastra";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { weatherTool } from "./tools/weather.tool";
import { browserTool } from "./tools/browser.tool";

export const agent = new MastraAgent({
  // @ts-ignore
  agent: new Agent({
    name: "AG-UI Agent",
    instructions: `
        You are a helpful assistant that runs a CLI application.
  
        When helping users get weather details for specific locations, respond:
        - Always ask for a location if none is provided.
        - If the location name isn’t in English, please translate it
        - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
        - Include relevant details like humidity, wind conditions, and precipitation
        - Keep responses concise but informative
  
        Use the weatherTool to fetch current weather data.

        When helping users browse the web, always use a full URL, for example: "https://www.google.com"
        Use the browserTool to browse the web.

  `,
    model: openai("gpt-4o-mini"),
    tools: { weatherTool, browserTool },
    memory: new Memory({
      storage: new LibSQLStore({
        url: "file:./mastra.db",
      }),
    }),
  }),
  threadId: "1",
});



================================================
FILE: typescript-sdk/apps/client-cli-example/src/index.ts
================================================
import * as readline from "readline";
import { agent } from "./agent";
import { randomUUID } from "node:crypto";

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

async function chatLoop() {
  console.log("🤖 AG-UI chat started! Type your messages and press Enter. Press Ctrl+D to quit.\n");

  return new Promise<void>((resolve) => {
    const promptUser = () => {
      rl.question("> ", async (input) => {
        if (input.trim() === "") {
          promptUser();
          return;
        }
        console.log("");

        rl.pause();

        agent.messages.push({
          id: randomUUID(),
          role: "user",
          content: input.trim(),
        });

        try {
          await agent.runAgent(
            {},
            {
              onTextMessageStartEvent() {
                process.stdout.write("🤖 AG-UI assistant: ");
              },
              onTextMessageContentEvent({ event }) {
                process.stdout.write(event.delta);
              },
              onTextMessageEndEvent() {
                console.log("\n");
              },
              onToolCallStartEvent({ event }) {
                console.log("🔧 Tool call:", event.toolCallName);
              },
              onToolCallArgsEvent({ event }) {
                process.stdout.write(event.delta);
              },
              onToolCallEndEvent() {
                console.log("");
              },
              onToolCallResultEvent({ event }) {
                if (event.content) {
                  console.log("🔍 Tool call result:", event.content);
                }
              },
            },
          );
        } catch (error) {
          console.error("❌ Error running agent:", error);
        }

        rl.resume();
        promptUser();
      });
    };

    rl.on("close", () => {
      console.log("\n👋 Goodbye!");
      resolve();
    });

    promptUser();
  });
}

async function main() {
  await chatLoop();
}

main().catch(console.error);



================================================
FILE: typescript-sdk/apps/client-cli-example/src/tools/browser.tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";
import open from "open";

export const browserTool = createTool({
  id: "browser",
  description: "Browse the web",
  inputSchema: z.object({
    url: z.string().describe("URL to browse"),
  }),
  outputSchema: z.string(),
  execute: async ({ context }) => {
    open(context.url);
    return `Browsed ${context.url}`;
  },
});



================================================
FILE: typescript-sdk/apps/client-cli-example/src/tools/weather.tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

interface GeocodingResponse {
  results: {
    latitude: number;
    longitude: number;
    name: string;
  }[];
}
interface WeatherResponse {
  current: {
    time: string;
    temperature_2m: number;
    apparent_temperature: number;
    relative_humidity_2m: number;
    wind_speed_10m: number;
    wind_gusts_10m: number;
    weather_code: number;
  };
}

export const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name"),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location);
  },
});

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;
  const geocodingResponse = await fetch(geocodingUrl);
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse;

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`);
  }

  const { latitude, longitude, name } = geocodingData.results[0];

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;

  const response = await fetch(weatherUrl);
  const data = (await response.json()) as WeatherResponse;

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name,
  };
};

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail",
  };
  return conditions[code] || "Unknown";
}



================================================
FILE: typescript-sdk/apps/dojo/README.md
================================================
# AG-UI Protocol Dojo

A modern, interactive viewer for exploring CopilotKit agent demos with a clean, responsive UI and dark/light theme support.

## Overview

The Demo Viewer provides a centralized interface for browsing, viewing, and exploring the source code of various CopilotKit agent demos. It features:

- Clean, modern UI with dark/light theme support
- Interactive demo previews
- Source code exploration with syntax highlighting
- Organized demo listing with tags and descriptions
- LLM provider selection

## Development Setup

To run the Demo Viewer locally for development, follow these steps:

### Install dependencies

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

### Run the Demo Viewer

In a new terminal, navigate to the project root and start the Demo Viewer:

```bash
pnpm install
pnpm run dev
```

The Demo Viewer should now be running at [http://localhost:3000](http://localhost:3000).

### Adding a new integration

On a fresh clone of this repo, you'll find that we've created a mock agent that represents all of the events needed to create an ACP compliant agent. To extend this to support
your own integration, you'll need to:

1. Edit `src/examples/your-custom-http-agent.ts` to implement your own agent.
2. Alternatively, edit `src/examples/your-custom-agent.ts` to implement a non http based integration.
3. Read `src/app/api/sse/agentic_chat/route.ts` to understand what events need to be emitted on the agent side.

## Project Structure

- `src/examples` - Example agents
- `src/app` - Next.js app router files
- `src/components` - Reusable UI components
- `src/demos` - Demo configuration and utilities
- `src/hooks` - Custom React hooks
- `src/types` - TypeScript type definitions
- `public` - Static assets

## Technologies

- Next.js
- React
- TypeScript
- Tailwind CSS
- CopilotKit



================================================
FILE: typescript-sdk/apps/dojo/eslint.config.mjs
================================================
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  // ...compat.extends("next/core-web-vitals", "next/typescript"),
  ...compat.config({
    extends: ["next"],
    rules: {
      "@typescript-eslint/no-unused-vars": "off",
    },
  }),
];

export default eslintConfig;



================================================
FILE: typescript-sdk/apps/dojo/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: typescript-sdk/apps/dojo/next.config.ts
================================================
import type { NextConfig } from "next";
import createMDX from "@next/mdx";

const withMDX = createMDX({
  extension: /\.mdx?$/,
  options: {
    // If you use remark-gfm, you'll need to use next.config.mjs
    // as the package is ESM only
    // https://github.com/remarkjs/remark-gfm#install
    remarkPlugins: [],
    rehypePlugins: [],
    // If you use `MDXProvider`, uncomment the following line.
    providerImportSource: "@mdx-js/react",
  },
});

const nextConfig: NextConfig = {
  /* config options here */
  // Configure pageExtensions to include md and mdx
  pageExtensions: ["ts", "tsx", "js", "jsx", "md", "mdx"],
  webpack: (config, { isServer }) => {
    // Ignore the demo files during build
    config.module.rules.push({
      test: /agent\/demo\/crew_enterprise\/ui\/.*\.(ts|tsx|js|jsx)$/,
      loader: "ignore-loader",
    });

    return config;
  },
  serverExternalPackages: ["@mastra/libsql"],
};

// Merge MDX config with Next.js config
export default withMDX(nextConfig);



================================================
FILE: typescript-sdk/apps/dojo/package.json
================================================
{
  "name": "demo-viewer",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "npm run generate-content-json && next dev",
    "build": "next build",
    "start": "npm run generate-content-json && next start",
    "lint": "next lint",
    "mastra:dev": "mastra dev",
    "generate-content-json": "npx tsx scripts/generate-content-json.ts"
  },
  "dependencies": {
    "@ag-ui/agno": "workspace:*",
    "@ag-ui/crewai": "workspace:*",
    "@ag-ui/langgraph": "workspace:*",
    "@ag-ui/llamaindex": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ag-ui/middleware-starter": "workspace:*",
    "@ag-ui/pydantic-ai": "workspace:*",
    "@ag-ui/server-starter": "workspace:*",
    "@ag-ui/server-starter-all-features": "workspace:*",
    "@ag-ui/vercel-ai-sdk": "workspace:*",
    "@ai-sdk/openai": "^1.3.22",
    "@copilotkit/react-core": "1.10.1",
    "@copilotkit/react-ui": "1.10.1",
    "@copilotkit/runtime": "1.10.1",
    "@copilotkit/runtime-client-gql": "1.10.1",
    "@copilotkit/shared": "1.10.1",
    "@mastra/client-js": "^0.10.18",
    "@mastra/core": "^0.13.0",
    "@mastra/dynamodb": "^0.13.3",
    "@mastra/libsql": "^0.13.0",
    "@mastra/loggers": "^0.10.5",
    "@mastra/memory": "^0.12.0",
    "@mdx-js/loader": "^3.1.0",
    "@mdx-js/mdx": "^3.1.0",
    "@mdx-js/react": "^3.1.0",
    "@monaco-editor/react": "^4.7.0",
    "@next/mdx": "^15.2.3",
    "@phosphor-icons/react": "^2.1.10",
    "@radix-ui/react-dropdown-menu": "^2.1.6",
    "@radix-ui/react-slot": "^1.1.2",
    "@radix-ui/react-tabs": "^1.1.3",
    "@tiptap/extension-color": "^2.11.5",
    "@tiptap/extension-placeholder": "^2.11.5",
    "@tiptap/pm": "^2.11.5",
    "@tiptap/react": "^2.11.5",
    "@tiptap/starter-kit": "^2.11.5",
    "@types/react-syntax-highlighter": "^15.5.13",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "diff": "^7.0.0",
    "fast-json-patch": "^3.1.1",
    "lucide-react": "^0.477.0",
    "markdown-it": "^14.1.0",
    "markdown-it-ins": "^4.0.0",
    "next": "15.2.1",
    "next-themes": "^0.4.6",
    "openai": "^4.98.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-markdown": "^10.1.0",
    "react-syntax-highlighter": "^15.6.1",
    "rxjs": "7.8.1",
    "tailwind-merge": "^3.0.2",
    "tailwindcss-animate": "^1.0.7",
    "uuid": "^11.1.0",
    "zod": "^3.22.4"
  },
  "peerDependencies": {
    "@ag-ui/client": "workspace:*",
    "@ag-ui/core": "workspace:*",
    "@ag-ui/encoder": "workspace:*",
    "@ag-ui/proto": "workspace:*"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@shadcn/ui": "^0.0.4",
    "@tailwindcss/postcss": "^4",
    "@tailwindcss/typography": "^0.5.16",
    "@types/diff": "^7.0.1",
    "@types/markdown-it": "^14.1.2",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "concurrently": "^9.2.0",
    "eslint": "^9",
    "eslint-config-next": "15.2.1",
    "tailwindcss": "^4",
    "tsx": "^4.7.0",
    "typescript": "^5",
    "wait-port": "^1.1.0"
  }
}


================================================
FILE: typescript-sdk/apps/dojo/postcss.config.mjs
================================================
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;



================================================
FILE: typescript-sdk/apps/dojo/tailwind.config.ts
================================================
import type { Config } from "tailwindcss";

const config = {
  darkMode: "class",
  content: [
    "./pages/**/*.{ts,tsx}",
    "./components/**/*.{ts,tsx}",
    "./app/**/*.{ts,tsx}",
    "./src/**/*.{ts,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        // Shadcn/ui colors
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      fontFamily: {
        sans: ['Plus Jakarta Sans', 'ui-sans-serif', 'system-ui', 'sans-serif'],
        mono: ['Spline Sans Mono', 'ui-monospace', 'SFMono-Regular', 'monospace'],
      },
      boxShadow: {
        'elevation-sm': 'var(--shadow-sm)',
        'elevation-md': 'var(--shadow-md)',
        'elevation-lg': 'var(--shadow-lg)',
        'elevation-xl': 'var(--shadow-xl)',
      },
      keyframes: {
        "accordion-down": {
          from: { height: "0" },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: "0" },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate"), require("@tailwindcss/typography")],
} satisfies Config;

export default config;


================================================
FILE: typescript-sdk/apps/dojo/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*", "../../packages/client/src/*"],
      "@ag-ui/client": ["../../packages/client/src"],
      "@ag-ui/client/*": ["../../packages/client/src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules", "e2e"]
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/README.md
================================================
# CopilotKit Demo Smoke Tests

This repository houses Playwright-based smoke tests that run on a 6-hour schedule to make sure CopilotKit demo apps remain live and functional.

## 🔧 Local development

```bash
# Install deps
npm install

# Install browsers once
npx playwright install --with-deps

# Run the full suite
npm test
```

Playwright HTML reports are saved to `./playwright-report`.

## ➕ Adding a new smoke test

1. Duplicate an existing file in `tests/` or create `tests/<demo>.spec.ts`.
2. Use Playwright's `test` API—keep the test short (<30 s).
3. Commit and push—GitHub Actions will pick it up on the next scheduled run.

## 🚦 CI / CD

- `.github/workflows/scheduled-tests.yml` executes the suite every 6 hours and on manual trigger.
- Failing runs surface in the Actions tab; the HTML report is uploaded as an artifact.
- (Optional) Slack notifications can be wired by adding a step after the tests.
- Slack alert on failure is baked into the workflow. Just add `SLACK_WEBHOOK_URL` (Incoming Webhook) in repo secrets.



================================================
FILE: typescript-sdk/apps/dojo/e2e/clean-reporter.js
================================================
function getTimestamp() {
  return (process.env.CI || process.env.VERBOSE)
    ? new Date().toLocaleTimeString('en-US', { hour12: false })
    : '';
}

function logStamp(...args) {
  console.log(getTimestamp(), ...args);
}

class CleanReporter {
  onBegin(config, suite) {
    console.log(`\n🎭 Running ${suite.allTests().length} tests...\n`);
  }

  onTestEnd(test, result) {
    const suiteName = test.parent?.title || "Unknown";
    const testName = test.title;

    // Clean up suite name
    const cleanSuite = suiteName
      .replace(/Tests?$/i, "")
      .replace(/Page$/i, "")
      .replace(/([a-z])([A-Z])/g, "$1 $2")
      .trim();

    if (result.status === "passed") {
      logStamp(`✅ ${cleanSuite}: ${testName}`);
    } else if (result.status === "failed") {
      logStamp(`❌ ${cleanSuite}: ${testName}`);

      // Extract the most relevant error info
      const error = result.error || result.errors?.[0];
      if (error) {
        let errorMsg = error.message || "Unknown error";

        // Clean up common error patterns to make them more readable
        if (errorMsg.includes("None of the expected patterns matched")) {
          const patterns = errorMsg.match(/patterns matched[^:]*: ([^`]+)/);
          errorMsg = `AI response timeout - Expected: ${
            patterns?.[1] || "AI response"
          }`;
        } else if (
          errorMsg.includes("Timed out") &&
          errorMsg.includes("toBeVisible")
        ) {
          const element = errorMsg.match(/locator\('([^']+)'\)/);
          errorMsg = `Element not found: ${element?.[1] || "UI element"}`;
        } else if (errorMsg.includes("toBeGreaterThan")) {
          errorMsg = "Expected content not generated (count was 0)";
        }

        // Show just the key error info
        console.log(`   💥 ${errorMsg.split("\n")[0]}`);

        // If it's an AI/API issue, make it clear
        if (
          errorMsg.includes("AI") ||
          errorMsg.includes("patterns") ||
          errorMsg.includes("timeout")
        ) {
          console.log(`   🔑 Likely cause: AI service down or API key issue`);
        }
      }
      console.log(""); // Extra spacing after failures
    } else if (result.status === "skipped") {
      console.log(`⏭ ${cleanSuite}: ${testName} (skipped)`);
    }
  }

  onEnd(result) {
    console.log("\n" + "=".repeat(60));
    logStamp(`📊 TEST SUMMARY`);
    console.log("=".repeat(60));

    if (!process.env.CI) {
      console.log(
        `• Run 'pnpm exec playwright show-report' for detailed HTML report`
      );
    }

    console.log("=".repeat(60) + "\n");
  }
}

module.exports = CleanReporter;



================================================
FILE: typescript-sdk/apps/dojo/e2e/package.json
================================================
{
  "name": "copilotkit-e2e",
  "version": "0.1.0",
  "private": true,
  "description": "Scheduled Playwright smoke tests for CopilotKit demo apps",
  "scripts": {
    "postinstall": "playwright install --with-deps",
    "test": "playwright test",
    "test:ui": "playwright test --ui",
    "report": "playwright show-report"
  },
  "devDependencies": {
    "@playwright/test": "^1.43.1",
    "@slack/types": "^2.14.0",
    "@types/node": "^22.15.28",
    "playwright-slack-report": "^1.1.93"
  },
  "dependencies": {
    "@aws-sdk/client-s3": "^3.600.0",
    "json2md": "^2.0.1"
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/playwright.config.ts
================================================
import { defineConfig, ReporterDescription } from "@playwright/test";
import { generateSimpleLayout } from "./slack-layout-simple";



function getReporters(): ReporterDescription[] {
  const videoReporter: ReporterDescription = [
    "./reporters/s3-video-reporter.ts",
    {
      outputFile: "test-results/video-urls.json",
      uploadVideos: true,
    },
  ];
  const s3Reporter: ReporterDescription = [
      "./node_modules/playwright-slack-report/dist/src/SlackReporter.js",
      {
        slackWebHookUrl: process.env.SLACK_WEBHOOK_URL,
        sendResults: "always", // always send results
        maxNumberOfFailuresToShow: 10,
        layout: generateSimpleLayout, // Use our simple layout
      },
    ];
  const githubReporter: ReporterDescription = ["github"];
  const htmlReporter: ReporterDescription = ["html", { open: "never" }];
  const cleanReporter: ReporterDescription = ["./clean-reporter.js"];

  const addVideoAndSlack = process.env.SLACK_WEBHOOK_URL && process.env.AWS_S3_BUCKET_NAME;

  return [
    process.env.CI ? githubReporter : undefined,
    addVideoAndSlack ? videoReporter : undefined,
    addVideoAndSlack ? s3Reporter : undefined,
    htmlReporter,
    cleanReporter,
  ].filter(Boolean) as ReporterDescription[];
}

function getBaseUrl(): string {
  if (process.env.BASE_URL) {
    return new URL(process.env.BASE_URL).toString();
  }
  console.error("BASE_URL is not set");
  process.exit(1);
}

export default defineConfig({
  timeout: process.env.CI ? 300_000 : 120_000, // 5min in CI, 2min locally for AI tests
  testDir: "./tests",
  retries: process.env.CI ? 1 : 0, // More retries for flaky AI tests in CI, 0 for local
  // Make this sequential for now to avoid race conditions
  workers: process.env.CI ? 1 : undefined,
  fullyParallel: process.env.CI ? false : true,
  use: {
    headless: true,
    viewport: { width: 1280, height: 720 },
    // Video recording for failed tests
    video: {
      mode: "retain-on-failure", // Only keep videos for failed tests
      size: { width: 1280, height: 720 },
    },
    // Increased timeouts for AI interactions
    navigationTimeout: 90_000, // 1.5 minutes for slow AI app loads
    actionTimeout: 60_000, // 1 minute for AI-driven actions (clicking, filling)
    // Test isolation - ensure clean state between tests
    testIdAttribute: "data-testid",
    baseURL: getBaseUrl(),
  },
  expect: {
    timeout: 90_000, // 1.5 minutes for AI-generated content to appear
  },
  // Test isolation between each test
  projects: [
    {
      name: "chromium",
      use: {
        ...require("@playwright/test").devices["Desktop Chrome"],
        // Force new context for each test to ensure isolation
        contextOptions: {
          // Clear all data between tests
          storageState: undefined,
        },
      },
    },
  ],
  reporter: getReporters(),
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/pnpm-workspace.yaml
================================================
packages:
  - '.'


================================================
FILE: typescript-sdk/apps/dojo/e2e/setup-aws.sh
================================================
#!/bin/bash

# AWS S3 Video Upload Setup Script
# This script creates the necessary AWS infrastructure for Playwright video uploads

set -e  # Exit on any error

# Configuration
BUCKET_NAME="copilotkit-e2e-smoke-test-recordings-$(openssl rand -hex 4)"
IAM_USER_NAME="copilotkit-e2e-smoke-test-uploader"
POLICY_NAME="CopilotKitE2ESmokeTestVideoUploadPolicy"
AWS_REGION="us-east-1"

echo "🚀 Setting up AWS infrastructure for Playwright video uploads..."
echo "Bucket name: $BUCKET_NAME"
echo "IAM user: $IAM_USER_NAME"
echo "Region: $AWS_REGION"
echo ""

# Check if AWS CLI is installed and configured
if ! command -v aws &> /dev/null; then
    echo "❌ AWS CLI is not installed. Please install it first."
    exit 1
fi

# Check if AWS credentials are configured
if ! aws sts get-caller-identity &> /dev/null; then
    echo "❌ AWS credentials not configured. Run 'aws configure' first."
    exit 1
fi

echo "✅ AWS CLI is configured"

# Step 1: Create S3 Bucket
echo "📦 Creating S3 bucket: $BUCKET_NAME"
aws s3api create-bucket \
    --bucket "$BUCKET_NAME" \
    --region "$AWS_REGION" \
    --create-bucket-configuration LocationConstraint="$AWS_REGION" 2>/dev/null || {
    # Handle us-east-1 special case (no LocationConstraint needed)
    if [ "$AWS_REGION" = "us-east-1" ]; then
        aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$AWS_REGION"
    else
        echo "❌ Failed to create bucket"
        exit 1
    fi
}

# Step 2: Configure bucket for public read access
echo "🔓 Configuring bucket for public read access..."

# Disable block public access
aws s3api put-public-access-block \
    --bucket "$BUCKET_NAME" \
    --public-access-block-configuration \
    "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false"

# Apply bucket policy for public read access
aws s3api put-bucket-policy --bucket "$BUCKET_NAME" --policy "{
    \"Version\": \"2012-10-17\",
    \"Statement\": [
        {
            \"Sid\": \"PublicReadGetObject\",
            \"Effect\": \"Allow\",
            \"Principal\": \"*\",
            \"Action\": \"s3:GetObject\",
            \"Resource\": \"arn:aws:s3:::$BUCKET_NAME/*\"
        }
    ]
}"

# Step 3: Set up lifecycle policy for automatic cleanup (30 days)
echo "🗂️ Setting up lifecycle policy for automatic cleanup..."
aws s3api put-bucket-lifecycle-configuration \
    --bucket "$BUCKET_NAME" \
    --lifecycle-configuration '{
        "Rules": [
            {
                "ID": "DeleteOldVideos",
                "Status": "Enabled",
                "Filter": {
                    "Prefix": "github-runs/"
                },
                "Expiration": {
                    "Days": 30
                }
            }
        ]
    }'

# Step 4: Create IAM policy for S3 upload permissions
echo "👤 Creating IAM policy..."
POLICY_ARN=$(aws iam create-policy \
    --policy-name "$POLICY_NAME" \
    --policy-document '{
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "S3VideoUploadPermissions",
                "Effect": "Allow",
                "Action": [
                    "s3:PutObject",
                    "s3:PutObjectAcl",
                    "s3:GetObject"
                ],
                "Resource": "arn:aws:s3:::'"$BUCKET_NAME"'/*"
            },
            {
                "Sid": "S3ListBucketPermission",
                "Effect": "Allow",
                "Action": "s3:ListBucket",
                "Resource": "arn:aws:s3:::'"$BUCKET_NAME"'"
            }
        ]
    }' \
    --query 'Policy.Arn' \
    --output text)

echo "✅ Created policy: $POLICY_ARN"

# Step 5: Create IAM user
echo "👤 Creating IAM user: $IAM_USER_NAME"
aws iam create-user --user-name "$IAM_USER_NAME" || {
    echo "⚠️  User might already exist, continuing..."
}

# Step 6: Attach policy to user
echo "🔗 Attaching policy to user..."
aws iam attach-user-policy \
    --user-name "$IAM_USER_NAME" \
    --policy-arn "$POLICY_ARN"

# Step 7: Create access keys
echo "🔑 Creating access keys..."
ACCESS_KEY_OUTPUT=$(aws iam create-access-key --user-name "$IAM_USER_NAME")
ACCESS_KEY_ID=$(echo "$ACCESS_KEY_OUTPUT" | jq -r '.AccessKey.AccessKeyId')
SECRET_ACCESS_KEY=$(echo "$ACCESS_KEY_OUTPUT" | jq -r '.AccessKey.SecretAccessKey')

# No temporary files to clean up

# Step 8: Test the setup
echo "🧪 Testing S3 upload..."
echo "test file" > /tmp/test-upload.txt
aws s3 cp /tmp/test-upload.txt "s3://$BUCKET_NAME/test-upload.txt" \
    --region "$AWS_REGION"

# Test public access
TEST_URL="https://$BUCKET_NAME.s3.$AWS_REGION.amazonaws.com/test-upload.txt"
echo "🌐 Testing public access..."
if curl -s -f "$TEST_URL" > /dev/null; then
    echo "✅ Public access working!"
else
    echo "⚠️  Public access test failed, but bucket is created"
fi

# Clean up test file
aws s3 rm "s3://$BUCKET_NAME/test-upload.txt"
rm -f /tmp/test-upload.txt

echo ""
echo "🎉 AWS Setup Complete!"
echo "===================="
echo ""
echo "📋 Add these to your GitHub repository secrets:"
echo "AWS_ACCESS_KEY_ID: $ACCESS_KEY_ID"
echo "AWS_SECRET_ACCESS_KEY: $SECRET_ACCESS_KEY"
echo ""
echo "📦 S3 Bucket Details:"
echo "Bucket Name: $BUCKET_NAME"
echo "Region: $AWS_REGION"
echo "Public URL Pattern: https://$BUCKET_NAME.s3.$AWS_REGION.amazonaws.com/{path}"
echo ""
echo "🔄 Next Steps:"
echo "1. Add the above secrets to your GitHub repository"
echo "2. Update your Playwright configuration with the bucket name"
echo "3. Run your tests to start uploading videos!"
echo ""
echo "💡 Videos will be automatically deleted after 30 days"
echo "💡 Upload path format: github-runs/{RUN_ID}/{PROJECT}/{filename}.webm" 


================================================
FILE: typescript-sdk/apps/dojo/e2e/slack-layout-simple.ts
================================================
import { Block, KnownBlock } from "@slack/types";
import { SummaryResults } from "playwright-slack-report/dist/src";
import { readFileSync, existsSync } from "fs";

interface VideoInfo {
  url: string;
  testName: string;
}

function getVideos(): VideoInfo[] {
  const videoFilePath = "test-results/video-urls.json";
  if (!existsSync(videoFilePath)) {
    return [];
  }

  try {
    const videoData = JSON.parse(readFileSync(videoFilePath, "utf8"));
    return videoData.videos || [];
  } catch (error) {
    console.error("Failed to read videos:", error);
    return [];
  }
}

export function generateSimpleLayout(
  summaryResults: SummaryResults
): Array<KnownBlock | Block> {
  const { passed, failed, skipped, tests } = summaryResults;

  // Summary
  const summary = {
    type: "section",
    text: {
      type: "mrkdwn",
      text:
        failed === 0
          ? `✅ All ${passed} tests passed!`
          : `✅ ${passed} passed • ❌ ${failed} failed • ⏭ ${skipped} skipped`,
    },
  };

  if (failed === 0) {
    return [summary];
  }

  // Get videos
  const videos = getVideos();
  const videoMap = new Map(videos.map((v) => [v.testName, v.url]));

  // List failed tests
  const failedTests = tests.filter(
    (test) => test.status === "failed" || test.status === "timedOut"
  );

  const failureLines = failedTests.map((test) => {
    const videoUrl = videoMap.get(test.name);
    const videoLink = videoUrl ? ` • <${videoUrl}|📹 Video>` : "";
    return `• *${test.name}*${videoLink}`;
  });

  const failures = {
    type: "section",
    text: {
      type: "mrkdwn",
      text: `*Failed Tests:*\n${failureLines.join("\n")}`,
    },
  };

  return [summary, failures];
}

export default generateSimpleLayout;



================================================
FILE: typescript-sdk/apps/dojo/e2e/slack-layout.ts
================================================
import { Block, KnownBlock } from "@slack/types";
import { SummaryResults } from "playwright-slack-report/dist/src";
import { readFileSync, existsSync } from "fs";

interface VideoInfo {
  url: string;
  testName: string;
  suiteName?: string;
  category?: string;
}

function getVideosByCategory(): Map<string, VideoInfo[]> {
  const categoryMap = new Map<string, VideoInfo[]>();

  // Read from the JSON file that S3 reporter creates
  const videoFilePath = "test-results/video-urls.json";
  if (!existsSync(videoFilePath)) {
    console.log("📹 No video URLs file found yet");
    return categoryMap;
  }

  try {
    const videoData = JSON.parse(readFileSync(videoFilePath, "utf8"));
    const videos: VideoInfo[] = videoData.videos || [];

    for (const video of videos) {
      const category = video.category || "❓ Other Issues";
      if (!categoryMap.has(category)) {
        categoryMap.set(category, []);
      }
      categoryMap.get(category)!.push(video);
    }

    console.log(`📹 Loaded ${videos.length} videos from file for Slack`);
  } catch (error) {
    console.error("📹 Failed to read video URLs file:", error);
  }

  return categoryMap;
}

function getTestDisplayName(test: any): string {
  // Create a cleaner test name
  const suiteName =
    test.suiteName ||
    test.file?.replace(/\.spec\.ts$/, "").replace(/Tests?/g, "");
  const testName = test.name;

  // Remove redundant words and clean up
  const cleanSuite = suiteName
    ?.replace(/Tests?$/i, "")
    ?.replace(/Page$/i, "")
    ?.replace(/Spec$/i, "")
    ?.replace(/([a-z])([A-Z])/g, "$1 $2") // camelCase to spaces
    ?.trim();

  return `${cleanSuite}: ${testName}`;
}

function categorizeAndCleanError(test: any): {
  category: string;
  cleanError: string;
  action: string;
} {
  const error =
    test.error?.message || test.errors?.[0]?.message || "Unknown error";

  // Debug logging to see what error data we're getting
  console.log(`🐛 DEBUG: Categorizing test "${test.name}"`);
  console.log(
    `🐛 DEBUG: Error object:`,
    JSON.stringify(
      {
        hasError: !!test.error,
        hasErrors: !!test.errors,
        errorMessage: test.error?.message,
        errorsLength: test.errors?.length,
        firstErrorMessage: test.errors?.[0]?.message,
      },
      null,
      2
    )
  );

  // AI Response Timeouts
  if (error.includes("None of the expected patterns matched")) {
    const patterns = error.match(/patterns matched[^:]*: ([^`]+)/);
    return {
      category: "🤖 AI Response Issues",
      cleanError: `No AI response - Expected: ${
        patterns?.[1] || "AI response"
      }`,
      action: "Check API keys and AI service status",
    };
  }

  // Test timeout (usually AI-related in our suite)
  if (
    error.includes("Test timeout") ||
    test.name?.toLowerCase().includes("human")
  ) {
    return {
      category: "🤖 AI Response Issues",
      cleanError: "Test timeout waiting for AI response",
      action: "Check AI service availability and response times",
    };
  }

  // UI Element Missing
  if (error.includes("Timed out") && error.includes("toBeVisible")) {
    const element = error.match(/locator\('([^']+)'\)/);
    return {
      category: "🎨 UI Issues",
      cleanError: `Element not found: ${element?.[1] || "UI element"}`,
      action: "Check if demo app is loading correctly",
    };
  }

  // Content Generation Failures
  if (error.includes("toBeGreaterThan") && error.includes("0")) {
    return {
      category: "🎯 Content Generation",
      cleanError: "Expected AI content not generated (count was 0)",
      action: "AI generative features not working",
    };
  }

  // Strict Mode Violations (multiple elements found)
  if (error.includes("strict mode violation")) {
    return {
      category: "🎯 Test Reliability",
      cleanError: "Multiple matching elements found",
      action: "Test selectors need to be more specific",
    };
  }

  // CSS/Style Issues
  if (error.includes("toHaveCSS")) {
    return {
      category: "🎨 Styling Issues",
      cleanError: "Expected CSS styles not applied",
      action: "Check if dynamic styling is working",
    };
  }

  // Default fallback
  return {
    category: "❓ Other Issues",
    cleanError: error.split("\n")[0]?.trim() || error,
    action: "Check logs for details",
  };
}

export function generateCustomLayout(
  summaryResults: SummaryResults
): Array<KnownBlock | Block> {
  const { passed, failed, skipped, tests } = summaryResults;

  const summary = {
    type: "section",
    text: {
      type: "mrkdwn",
      text:
        failed === 0
          ? `✅ All ${passed} tests passed!`
          : `✅ ${passed} passed • ❌ ${failed} failed • ⏭ ${skipped} skipped`,
    },
  };

  // Only show failures if there are any
  const failures: Array<KnownBlock | Block> = [];
  if (failed > 0) {
    const failedTests = tests.filter(
      (test) => test.status === "failed" || test.status === "timedOut"
    );

    // Categorize failures
    const categorizedFailures = new Map<
      string,
      Array<{ test: any; cleanError: string; action: string }>
    >();

    failedTests.forEach((test) => {
      const { category, cleanError, action } = categorizeAndCleanError(test);
      if (!categorizedFailures.has(category)) {
        categorizedFailures.set(category, []);
      }
      categorizedFailures.get(category)!.push({ test, cleanError, action });
    });

    // Get video URLs by category
    const videosByCategory = getVideosByCategory();

    // Display failures by category
    for (const [category, categoryFailures] of categorizedFailures) {
      const failureLines = categoryFailures.map(
        ({ test, cleanError, action }) => {
          const testName = getTestDisplayName(test);

          // Look for videos for this test - search across ALL categories since
          // S3 reporter uses different categorization than Slack layout
          let testVideo: VideoInfo | undefined;
          for (const [_, videos] of videosByCategory) {
            testVideo = videos.find(
              (v) =>
                v.testName === test.name ||
                v.testName.includes(test.name) ||
                test.name.includes(v.testName)
            );
            if (testVideo) break;
          }

          const videoLink = testVideo
            ? `\n  📹 [Watch Video](${testVideo.url})`
            : "";

          return `• **${testName}**\n  → ${cleanError}${videoLink}`;
        }
      );

      const uniqueActions = [...new Set(categoryFailures.map((f) => f.action))];
      const actionText =
        uniqueActions.length === 1
          ? `\n🔧 *Action:* ${uniqueActions[0]}`
          : `\n🔧 *Actions:* ${uniqueActions.join(", ")}`;

      failures.push({
        type: "section",
        text: {
          type: "mrkdwn",
          text: `*${category}* (${categoryFailures.length} failure${
            categoryFailures.length > 1 ? "s" : ""
          })\n${failureLines.join("\n\n")}${actionText}`,
        },
      });
    }

    // Add overall action summary if there are AI issues
    const hasAIIssues =
      categorizedFailures.has("🤖 AI Response Issues") ||
      categorizedFailures.has("🎯 Content Generation");

    if (hasAIIssues) {
      failures.push({
        type: "context",
        elements: [
          {
            type: "mrkdwn",
            text: "💡 *Most failures are AI-related.* Check API keys, service status, and rate limits.",
          },
        ],
      });
    }
  }

  return [summary, ...failures];
}

export default generateCustomLayout;



================================================
FILE: typescript-sdk/apps/dojo/e2e/test-isolation-helper.ts
================================================
import { test as base, Page } from "@playwright/test";

// Extend base test with isolation setup
export const test = base.extend<{}, {}>({
  page: async ({ page }, use) => {
    // Before each test - ensure clean state
    await page.context().clearCookies();
    await page.context().clearPermissions();

    // Add delay to ensure AI services are ready
    await page.waitForTimeout(1000);

    await use(page);

    // After each test - cleanup
    await page.context().clearCookies();
  },
});

// Add AI-specific wait helpers for better reliability
export async function waitForAIResponse(page: Page, timeout: number = 90000) {
  // Wait for AI response indicators
  await page.waitForFunction(
    () => {
      // Look for common AI loading indicators
      const loadingIndicators = document.querySelectorAll(
        '[data-testid*="loading"], .loading, .spinner'
      );
      return loadingIndicators.length === 0;
    },
    { timeout }
  );

  // Additional wait for content to stabilize
  await page.waitForTimeout(2000);
}

export async function retryOnAIFailure<T>(
  operation: () => Promise<T>,
  maxRetries: number = 3,
  delayMs: number = 5000
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await operation();
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);

      // Check if this is an AI service error we should retry
      const shouldRetry =
        errorMsg.includes("timeout") ||
        errorMsg.includes("rate limit") ||
        errorMsg.includes("503") ||
        errorMsg.includes("502") ||
        errorMsg.includes("AI response") ||
        errorMsg.includes("network");

      if (shouldRetry && i < maxRetries - 1) {
        console.log(
          `🔄 Retrying operation (attempt ${
            i + 2
          }/${maxRetries}) after AI service error: ${errorMsg}`
        );
        await new Promise((resolve) => setTimeout(resolve, delayMs));
        continue;
      }

      throw error;
    }
  }

  throw new Error("Max retries exceeded");
}

export { expect } from "@playwright/test";



================================================
FILE: typescript-sdk/apps/dojo/e2e/test-isolation-setup.ts
================================================
import { chromium, FullConfig } from "@playwright/test";

async function globalSetup(config: FullConfig) {
  console.log("🧹 Setting up test isolation...");

  // Launch browser to clear any persistent state
  const browser = await chromium.launch();
  const context = await browser.newContext();

  // Clear all storage
  await context.clearCookies();
  await context.clearPermissions();

  // Clear any cached data
  const page = await context.newPage();
  await page.evaluate(() => {
    // Clear all storage types
    localStorage.clear();
    sessionStorage.clear();

    // Clear IndexedDB
    if (window.indexedDB) {
      indexedDB.deleteDatabase("test-db");
    }

    // Clear WebSQL (if supported)
    if (window.openDatabase) {
      try {
        const db = window.openDatabase("", "", "", "");
        db.transaction((tx) => {
          tx.executeSql("DELETE FROM test_table");
        });
      } catch (e) {
        // Ignore WebSQL errors
      }
    }
  });

  await browser.close();

  console.log("✅ Test isolation setup complete");
}

export default globalSetup;



================================================
FILE: typescript-sdk/apps/dojo/e2e/VIDEO_SETUP.md
================================================
# 📹 S3 Video Upload System

This system automatically uploads videos of failed Playwright tests to S3 and embeds clickable links in Slack notifications.

## ✅ **Setup Complete Checklist**

- [x] AWS infrastructure created (`setup-aws.sh`)
- [x] Dependencies installed (`@aws-sdk/client-s3`, `json2md`)
- [x] S3 video uploader created (`lib/upload-video.ts`)
- [x] Custom reporter created (`reporters/s3-video-reporter.ts`)
- [x] Playwright config updated (video recording enabled)
- [x] Slack layout updated (video links embedded)
- [x] GitHub Actions updated (AWS credentials)

## 🔧 **Required GitHub Secrets**

Add these secrets to your repository:

```
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_S3_BUCKET_NAME=copilotkit-e2e-smoke-test-recordings-abc123
AWS_S3_REGION=us-east-1
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
```

## 🎯 **How It Works**

### **1. Video Recording**

- Videos recorded only for **failed tests** (`retain-on-failure`)
- 1280x720 resolution, WebM format
- Stored temporarily in `test-results/`

### **2. S3 Upload Process**

```
Failed Test → Video Recorded → S3 Upload → Slack Notification
```

### **3. S3 File Organization**

```
copilotkit-e2e-smoke-test-recordings-{random}/
└── github-runs/
    └── {GITHUB_RUN_ID}/
        └── cpk-demos-smoke-tests/
            └── {SUITE_NAME}/
                └── {TEST_NAME}/
                    └── video.webm
```

### **4. Slack Integration**

Videos appear as clickable links in categorized failure notifications:

```
🤖 AI Response Issues (2 failures)
• Human in the Loop Feature: Chat interaction steps
  → No AI response - Expected: /Travel Guide/i
  📹 [Watch Video](https://bucket.s3.amazonaws.com/path/video.webm)

🔧 Action: Check API keys and AI service status
```

## 🛠 **Local Development**

### **Test Video Upload Locally**

```bash
# Set environment variables
export AWS_S3_BUCKET_NAME="your-bucket-name"
export AWS_S3_REGION="us-east-1"
export AWS_ACCESS_KEY_ID="your-key"
export AWS_SECRET_ACCESS_KEY="your-secret"

# Run tests with video upload enabled
CI=true pnpm exec playwright test --reporter=./reporters/s3-video-reporter.ts
```

### **Disable Video Upload Locally**

Videos are automatically disabled in local runs. To force enable:

```bash
# Edit playwright.config.ts
uploadVideos: true  // In local reporter config
```

## 📊 **Monitoring & Debugging**

### **Check Upload Status**

- Videos upload logs appear in GitHub Actions output
- Failed uploads are logged but don't fail the workflow
- Video URLs written to `test-results/video-urls.json`

### **Common Issues**

**❌ No videos in Slack**

- Check AWS credentials in GitHub secrets
- Verify S3 bucket permissions
- Look for upload errors in Actions logs

**❌ Videos not accessible**

- Verify S3 bucket has public read access
- Check bucket policy and CORS settings

**❌ Upload timeouts**

- Large video files may timeout
- Check network connectivity to S3
- Consider video compression settings

## 🧹 **Maintenance**

### **Automatic Cleanup**

- Videos automatically deleted after **30 days**
- Lifecycle policy configured in S3 bucket
- No manual cleanup required

### **Cost Management**

- Only failed tests generate videos (~5-10 MB each)
- 30-day retention keeps costs low
- Monitor S3 usage in AWS console

## 🚀 **Next Steps**

1. **Run `setup-aws.sh`** to create infrastructure ✅
2. **Add GitHub secrets** from script output ⏳
3. **Test the system** by running a failing test ⏳
4. **Check Slack notifications** for video links ⏳

## 🔗 **File Structure**

```
cpk-demos-smoke-tests/
├── lib/
│   └── upload-video.ts          # S3 upload functionality
├── reporters/
│   └── s3-video-reporter.ts     # Playwright reporter
├── .github/workflows/
│   └── scheduled-tests.yml      # AWS credentials setup
├── playwright.config.ts         # Video recording config
├── slack-layout.ts             # Video links in notifications
├── setup-aws.sh               # AWS infrastructure script
└── VIDEO_SETUP.md              # This file
```

## 📹 **Video URL Format**

```
https://{bucket}.s3.{region}.amazonaws.com/github-runs/{run-id}/{project}/{suite}/{test}/video-{timestamp}.webm
```

Example:

```
https://copilotkit-e2e-recordings.s3.us-east-1.amazonaws.com/github-runs/1234567890/cpk-demos-smoke-tests/Human-in-the-Loop-Feature/Chat-interaction-steps/video-20240115-143022.webm
```

**🎉 Your failed test videos are now automatically uploaded to S3 and linked in Slack!**



================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/AgenticChatPage.ts
================================================
import { Page, Locator, expect } from "@playwright/test";

export class AgenticChatPage {
  readonly page: Page;
  readonly openChatButton: Locator;
  readonly agentGreeting: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly chatBackground: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.openChatButton = page.getByRole("button", {
      name: /chat/i,
    });
    this.agentGreeting = page
      .getByText("Hi, I'm an agent. Want to chat?");
    this.chatInput = page
      .getByRole("textbox", { name: "Type a message..." })
      .or(page.getByRole("textbox"))
      .or(page.locator('input[type="text"]'))
      .or(page.locator('textarea'));
    this.sendButton = page
      .locator('[data-test-id="copilot-chat-ready"]')
      .or(page.getByRole("button", { name: /send/i }))
      .or(page.locator('button[type="submit"]'));
    this.chatBackground = page
      .locator('div[style*="background"]')
      .or(page.locator('.flex.justify-center.items-center.h-full.w-full'))
      .or(page.locator('body'));
    this.agentMessage = page
      .locator(".copilotKitAssistantMessage");
    this.userMessage = page
      .locator(".copilotKitUserMessage");
  }

  async openChat() {
    try {
      await this.openChatButton.click({ timeout: 3000 });
    } catch (error) {
      // Chat might already be open
    }
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    try {
      await this.sendButton.click();
    } catch (error) {
      await this.chatInput.press("Enter");
    }
  }

  async getBackground(
    property: "backgroundColor" | "backgroundImage" = "backgroundColor"
  ): Promise<string> {
    // Wait a bit for background to apply
    await this.page.waitForTimeout(500);

    // Try multiple selectors for the background element
    const selectors = [
      'div[style*="background"]',
      'div[style*="background-color"]',
      '.flex.justify-center.items-center.h-full.w-full',
      'div.flex.justify-center.items-center.h-full.w-full',
      '[class*="bg-"]',
      'div[class*="background"]'
    ];

    for (const selector of selectors) {
      try {
        const element = this.page.locator(selector).first();
        if (await element.isVisible({ timeout: 1000 })) {
          const value = await element.evaluate(
            (el, prop) => {
              // Check inline style first
              if (el.style.background) return el.style.background;
              if (el.style.backgroundColor) return el.style.backgroundColor;
              // Then computed style
              return getComputedStyle(el)[prop as any];
            },
            property
          );
          if (value && value !== "rgba(0, 0, 0, 0)" && value !== "transparent") {
            console.log(`[${selector}] ${property}: ${value}`);
            return value;
          }
        }
      } catch (e) {
        continue;
      }
    }

    // Fallback to original element
    const value = await this.chatBackground.first().evaluate(
      (el, prop) => getComputedStyle(el)[prop as any],
      property
    );
    console.log(`[Fallback] ${property}: ${value}`);
    return value;
  }

  async getGradientButtonByName(name: string | RegExp) {
    return this.page.getByRole("button", { name });
  }

  async assertUserMessageVisible(text: string | RegExp) {
    await expect(this.userMessage.getByText(text)).toBeVisible();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage", {
      hasText: expectedText,
    });
    await expect(agentMessage.last()).toBeVisible({ timeout: 10000 });
  }

  async assertAgentReplyContains(expectedText: string) {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage").last();
    await expect(agentMessage).toContainText(expectedText, { timeout: 10000 });
  }

  async assertWeatherResponseStructure() {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage").last();

    // Check for main weather response structure
    await expect(agentMessage).toContainText("The current weather in Islamabad is as follows:", { timeout: 10000 });

    // Check for temperature information
    await expect(agentMessage).toContainText("Temperature:", { timeout: 5000 });
    // Check for humidity
    await expect(agentMessage).toContainText("Humidity:", { timeout: 5000 });

    // Check for wind speed
    await expect(agentMessage).toContainText("Wind Speed:", { timeout: 5000 });
    // Check for conditions
    await expect(agentMessage).toContainText("Conditions:", { timeout: 5000 });
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/SharedStatePage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class SharedStatePage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly promptResponseLoader: Locator;
  readonly ingredientCards: Locator;
  readonly instructionsContainer: Locator;
  readonly addIngredient: Locator;

  constructor(page: Page) {
    this.page = page;
    // Remove iframe references and use actual greeting text
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your recipe?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.promptResponseLoader = page.getByRole('button', { name: 'Please Wait...', disabled: true });
    this.instructionsContainer = page.locator('.instructions-container');
    this.addIngredient = page.getByRole('button', { name: '+ Add Ingredient' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.ingredientCards = page.locator('.ingredient-card');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async loader() {
    const timeout = (ms) => new Promise((_, reject) => {
      setTimeout(() => reject(new Error("Timeout waiting for promptResponseLoader to become visible")), ms);
    });

    await Promise.race([
      this.promptResponseLoader.isVisible(),
      timeout(5000) // 5 seconds timeout
    ]);
  }

  async awaitIngredientCard(name: string) {
    const selector = `.ingredient-card:has(input.ingredient-name-input[value="${name}"])`;
    const cardLocator = this.page.locator(selector);
    await expect(cardLocator).toBeVisible();
  }

  async addNewIngredient(placeholderText: string) {
      this.addIngredient.click();
      this.page.locator(`input[placeholder="${placeholderText}"]`);
  }

  async getInstructionItems(containerLocator: Locator ) {
    const count = await containerLocator.locator('.instruction-item').count();
    if (count <= 0) {
      throw new Error('No instruction items found in the container.');
    }
    console.log(`✅ Found ${count} instruction items.`);
    return count;
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/ToolBaseGenUIPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class ToolBaseGenUIPage {
  readonly page: Page;
  readonly haikuAgentIntro: Locator;
  readonly messageBox: Locator;
  readonly sendButton: Locator;
  readonly applyButton: Locator;
  readonly appliedButton: Locator;
  readonly haikuBlock: Locator;
  readonly japaneseLines: Locator;

  constructor(page: Page) {
    this.page = page;
    this.haikuAgentIntro = page.getByText("I'm a haiku generator 👋. How can I help you?");
    this.messageBox = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.haikuBlock = page.locator('[data-testid="haiku-card"]');
    this.applyButton = page.getByRole('button', { name: 'Apply' });
    this.japaneseLines = page.locator('[data-testid="haiku-line"]');
  }

  async generateHaiku(message: string) {
    await this.messageBox.click();
    await this.messageBox.fill(message);
    await this.sendButton.click();
  }

  async checkGeneratedHaiku() {
    await this.page.locator('[data-testid="haiku-card"]').last().isVisible();
    const mostRecentCard = this.page.locator('[data-testid="haiku-card"]').last();
    await mostRecentCard.locator('[data-testid="haiku-line"]').first().waitFor({ state: 'visible', timeout: 10000 });
  }

  async extractChatHaikuContent(page: Page): Promise<string> {
    await page.waitForTimeout(3000);
    await page.locator('[data-testid="haiku-card"]').first().waitFor({ state: 'visible' });
    const allHaikuCards = page.locator('[data-testid="haiku-card"]');
    const cardCount = await allHaikuCards.count();
    let chatHaikuContainer;
    let chatHaikuLines;

    for (let cardIndex = cardCount - 1; cardIndex >= 0; cardIndex--) {
      chatHaikuContainer = allHaikuCards.nth(cardIndex);
      chatHaikuLines = chatHaikuContainer.locator('[data-testid="haiku-line"]');
      const linesCount = await chatHaikuLines.count();

      if (linesCount > 0) {
        try {
          await chatHaikuLines.first().waitFor({ state: 'visible', timeout: 5000 });
          break;
        } catch (error) {
          continue;
        }
      }
    }

    if (!chatHaikuLines) {
      throw new Error('No haiku cards with visible lines found');
    }

    const count = await chatHaikuLines.count();
    const lines: string[] = [];

    for (let i = 0; i < count; i++) {
      const haikuLine = chatHaikuLines.nth(i);
      const japaneseText = await haikuLine.locator('p').first().innerText();
      lines.push(japaneseText);
    }

    const chatHaikuContent = lines.join('').replace(/\s/g, '');
    return chatHaikuContent;
  }

  async extractMainDisplayHaikuContent(page: Page): Promise<string> {
    const mainDisplayLines = page.locator('[data-testid="main-haiku-line"]');
    const mainCount = await mainDisplayLines.count();
    const lines: string[] = [];

    if (mainCount > 0) {
      for (let i = 0; i < mainCount; i++) {
        const haikuLine = mainDisplayLines.nth(i);
        const japaneseText = await haikuLine.locator('p').first().innerText();
        lines.push(japaneseText);
      }
    }

    const mainHaikuContent = lines.join('').replace(/\s/g, '');
    return mainHaikuContent;
  }

  async checkHaikuDisplay(page: Page): Promise<void> {
    const chatHaikuContent = await this.extractChatHaikuContent(page);

    await page.waitForTimeout(5000);

    const mainHaikuContent = await this.extractMainDisplayHaikuContent(page);

    if (mainHaikuContent === '') {
      expect(chatHaikuContent.length).toBeGreaterThan(0);
      return;
    }

    if (chatHaikuContent === mainHaikuContent) {
      expect(mainHaikuContent).toBe(chatHaikuContent);
    } else {
      await page.waitForTimeout(3000);

      const updatedMainContent = await this.extractMainDisplayHaikuContent(page);

      expect(updatedMainContent).toBe(chatHaikuContent);
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/lib/upload-video.ts
================================================
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
import { readFileSync, existsSync } from "fs";
import { basename } from "path";

export interface VideoToUpload {
  videoPath: string;
  s3ObjectPath: string;
  testName: string;
  suiteName?: string;
}

export interface S3Config {
  bucketName: string;
  region: string;
  accessKeyId?: string;
  secretAccessKey?: string;
}

export class S3VideoUploader {
  private s3Client: S3Client;
  private config: S3Config;

  constructor(config: S3Config) {
    this.config = config;

    // Initialize S3 client with credentials from environment or passed config
    this.s3Client = new S3Client({
      region: config.region,
      credentials:
        config.accessKeyId && config.secretAccessKey
          ? {
              accessKeyId: config.accessKeyId,
              secretAccessKey: config.secretAccessKey,
            }
          : undefined, // Use default credential chain if not provided
    });
  }

  /**
   * Generate S3 object path for a video file
   */
  generateS3Path(
    videoPath: string,
    testName: string,
    suiteName?: string
  ): string {
    const filename = basename(videoPath);
    const runId = process.env.GITHUB_RUN_ID || `local-${Date.now()}`;
    const projectName =
      process.env.GITHUB_REPOSITORY?.split("/")[1] || "cpk-demos-smoke-tests";

    // Clean test names for file paths
    const cleanSuite =
      suiteName?.replace(/[^a-zA-Z0-9-_]/g, "-") || "unknown-suite";
    const cleanTest = testName.replace(/[^a-zA-Z0-9-_]/g, "-");

    return `github-runs/${runId}/${projectName}/${cleanSuite}/${cleanTest}/${filename}`;
  }

  /**
   * Generate public S3 URL for a given object path
   */
  generatePublicUrl(s3ObjectPath: string): string {
    return `https://${this.config.bucketName}.s3.${this.config.region}.amazonaws.com/${s3ObjectPath}`;
  }

  /**
   * Upload a single video file to S3
   */
  async uploadVideo(video: VideoToUpload): Promise<string> {
    try {
      // Check if file exists
      if (!existsSync(video.videoPath)) {
        throw new Error(`Video file not found: ${video.videoPath}`);
      }

      console.log(
        `📹 Uploading video: ${basename(video.videoPath)} for test: ${
          video.testName
        }`
      );

      // Read file content
      const fileContent = readFileSync(video.videoPath);

      // Upload to S3
      const command = new PutObjectCommand({
        Bucket: this.config.bucketName,
        Key: video.s3ObjectPath,
        Body: fileContent,
        ContentType: "video/webm",
        CacheControl: "public, max-age=86400", // Cache for 1 day
        Metadata: {
          "test-name": video.testName,
          "suite-name": video.suiteName || "unknown",
          "upload-time": new Date().toISOString(),
        },
      });

      await this.s3Client.send(command);

      const publicUrl = this.generatePublicUrl(video.s3ObjectPath);
      console.log(`✅ Video uploaded successfully: ${publicUrl}`);

      return publicUrl;
    } catch (error) {
      console.error(`❌ Failed to upload video ${video.videoPath}:`, error);
      throw error;
    }
  }

  /**
   * Upload multiple videos concurrently
   */
  async uploadVideos(
    videos: VideoToUpload[]
  ): Promise<{ url: string; testName: string; suiteName?: string }[]> {
    if (videos.length === 0) {
      console.log("📹 No videos to upload");
      return [];
    }

    console.log(`📹 Uploading ${videos.length} video(s) to S3...`);

    const uploadPromises = videos.map(async (video) => {
      try {
        const url = await this.uploadVideo(video);
        return {
          url,
          testName: video.testName,
          suiteName: video.suiteName,
        };
      } catch (error) {
        console.error(
          `Failed to upload video for test ${video.testName}:`,
          error
        );
        return null;
      }
    });

    const results = await Promise.allSettled(uploadPromises);

    // Filter out failed uploads
    const successfulUploads = results
      .filter(
        (
          result
        ): result is PromiseFulfilledResult<{
          url: string;
          testName: string;
          suiteName?: string;
        } | null> => result.status === "fulfilled" && result.value !== null
      )
      .map((result) => result.value!);

    const failedUploads = results.filter(
      (result) => result.status === "rejected"
    ).length;

    console.log(`✅ Successfully uploaded ${successfulUploads.length} videos`);
    if (failedUploads > 0) {
      console.warn(`⚠️  ${failedUploads} videos failed to upload`);
    }

    return successfulUploads;
  }
}

/**
 * Factory function to create uploader with environment variables
 */
export function createS3Uploader(): S3VideoUploader | null {
  const bucketName = process.env.AWS_S3_BUCKET_NAME;
  const region = process.env.AWS_S3_REGION || "us-east-1";

  if (!bucketName) {
    console.warn("⚠️  AWS_S3_BUCKET_NAME not set, video upload disabled");
    return null;
  }

  return new S3VideoUploader({
    bucketName,
    region,
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  });
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }
    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('div.bg-white.rounded.shadow-lg >> text=Confirm Changes');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('div.copilotKitMarkdown').first();
    this.rejectedChangesResponse = page.locator('div.copilotKitMarkdown').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Confirm");
    const acceptedLabel = this.userApprovalModal.last().locator('text=✓ Accepted');
  }

  async getUserRejection() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Reject");
    const rejectedLabel = await this.getStatusLabelOfButton(this.page, "✕ Rejected");
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];

    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }

    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('div.bg-white.rounded.shadow-lg');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText('This agent demonstrates human-in-the-loop');
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: '✨Perform Steps' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.planTaskButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();
    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/SubgraphsPage.ts
================================================
export { SubgraphsPage } from '../langGraphPages/SubgraphsPage'


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText('This agent demonstrates human-in-the-loop');
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: '✨Perform Steps' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.planTaskButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/SubgraphsPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class SubgraphsPage {
  readonly page: Page;
  readonly travelPlannerButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  
  // Flight-related elements
  readonly flightOptions: Locator;
  readonly klmFlightOption: Locator;
  readonly unitedFlightOption: Locator;
  readonly flightSelectionInterface: Locator;
  
  // Hotel-related elements
  readonly hotelOptions: Locator;
  readonly hotelZephyrOption: Locator;
  readonly ritzCarltonOption: Locator;
  readonly hotelZoeOption: Locator;
  readonly hotelSelectionInterface: Locator;
  
  // Itinerary and state elements
  readonly itineraryDisplay: Locator;
  readonly selectedFlight: Locator;
  readonly selectedHotel: Locator;
  readonly experienceRecommendations: Locator;
  
  // Subgraph activity indicators
  readonly activeAgent: Locator;
  readonly supervisorIndicator: Locator;
  readonly flightsAgentIndicator: Locator;
  readonly hotelsAgentIndicator: Locator;
  readonly experiencesAgentIndicator: Locator;

  constructor(page: Page) {
    this.page = page;
    this.travelPlannerButton = page.getByRole('button', { name: /travel.*planner|subgraphs/i });
    this.agentGreeting = page.getByText(/travel.*planning|supervisor.*coordinate/i);
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    
    // Flight selection elements
    this.flightOptions = page.locator('[data-testid*="flight"], .flight-option');
    this.klmFlightOption = page.getByText(/KLM.*\$650.*11h 30m/);
    this.unitedFlightOption = page.getByText(/United.*\$720.*12h 15m/);
    this.flightSelectionInterface = page.locator('[data-testid*="flight-select"], .flight-selection');
    
    // Hotel selection elements
    this.hotelOptions = page.locator('[data-testid*="hotel"], .hotel-option');
    this.hotelZephyrOption = page.getByText(/Hotel Zephyr.*Fisherman\'s Wharf.*\$280/);
    this.ritzCarltonOption = page.getByText(/Ritz-Carlton.*Nob Hill.*\$550/);
    this.hotelZoeOption = page.getByText(/Hotel Zoe.*Union Square.*\$320/);
    this.hotelSelectionInterface = page.locator('[data-testid*="hotel-select"], .hotel-selection');
    
    // Itinerary elements
    this.itineraryDisplay = page.locator('[data-testid*="itinerary"], .itinerary');
    this.selectedFlight = page.locator('[data-testid*="selected-flight"], .selected-flight');
    this.selectedHotel = page.locator('[data-testid*="selected-hotel"], .selected-hotel');
    this.experienceRecommendations = page.locator('[data-testid*="experience"], .experience');
    
    // Agent activity indicators
    this.activeAgent = page.locator('[data-testid*="active-agent"], .active-agent');
    this.supervisorIndicator = page.locator('[data-testid*="supervisor"], .supervisor-active');
    this.flightsAgentIndicator = page.locator('[data-testid*="flights-agent"], .flights-agent-active');
    this.hotelsAgentIndicator = page.locator('[data-testid*="hotels-agent"], .hotels-agent-active');
    this.experiencesAgentIndicator = page.locator('[data-testid*="experiences-agent"], .experiences-agent-active');
  }

  async openChat() {
    await this.travelPlannerButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectFlight(airline: 'KLM' | 'United') {
    const flightOption = airline === 'KLM' ? this.klmFlightOption : this.unitedFlightOption;
    
    // Wait for flight options to be presented
    await expect(this.flightOptions.first()).toBeVisible({ timeout: 15000 });
    
    // Click on the desired flight option
    await flightOption.click();
  }

  async selectHotel(hotel: 'Zephyr' | 'Ritz-Carlton' | 'Zoe') {
    let hotelOption: Locator;
    
    switch (hotel) {
      case 'Zephyr':
        hotelOption = this.hotelZephyrOption;
        break;
      case 'Ritz-Carlton':
        hotelOption = this.ritzCarltonOption;
        break;
      case 'Zoe':
        hotelOption = this.hotelZoeOption;
        break;
    }
    
    // Wait for hotel options to be presented
    await expect(this.hotelOptions.first()).toBeVisible({ timeout: 15000 });
    
    // Click on the desired hotel option
    await hotelOption.click();
  }

  async waitForFlightsAgent() {
    // Wait for flights agent to become active (or look for flight-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/flight.*options|Amsterdam.*San Francisco|KLM|United/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async waitForHotelsAgent() {
    // Wait for hotels agent to become active (or look for hotel-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async waitForExperiencesAgent() {
    // Wait for experiences agent to become active (or look for experience-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/experience|activities|restaurant|Pier 39|Golden Gate|Swan Oyster|Tartine/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async verifyStaticFlightData() {
    // Verify the hardcoded flight options are present
    await expect(this.page.getByText(/KLM.*\$650.*11h 30m/).first()).toBeVisible();
    await expect(this.page.getByText(/United.*\$720.*12h 15m/).first()).toBeVisible();
  }

  async verifyStaticHotelData() {
    // Verify the hardcoded hotel options are present
    await expect(this.page.getByText(/Hotel Zephyr.*\$280/).first()).toBeVisible();
    await expect(this.page.getByText(/Ritz-Carlton.*\$550/).first()).toBeVisible();
    await expect(this.page.getByText(/Hotel Zoe.*\$320/).first()).toBeVisible();
  }

  async verifyStaticExperienceData() {
    // Wait for experiences to load - this can take time as it's the final step in the agent flow
    // First ensure we're not stuck in "No experiences planned yet" state
    await expect(this.page.getByText('No experiences planned yet')).not.toBeVisible({ timeout: 20000 }).catch(() => {
      console.log('Still waiting for experiences to load...');
    });
    
    // Wait for actual experience content to appear
    await expect(this.page.locator('.activity-name').first()).toBeVisible({ timeout: 15000 });
    
    // Verify we have meaningful experience content (either static or AI-generated)
    const experienceContent = this.page.locator('.activity-name').first().or(
      this.page.getByText(/Pier 39|Golden Gate Bridge|Swan Oyster Depot|Tartine Bakery/i).first()
    );
    await expect(experienceContent).toBeVisible();
  }

  async verifyItineraryContainsFlight(airline: 'KLM' | 'United') {
    // Check that the selected flight appears in the itinerary or conversation
    await expect(this.page.getByText(new RegExp(airline, 'i'))).toBeVisible();
  }

  async verifyItineraryContainsHotel(hotel: 'Zephyr' | 'Ritz-Carlton' | 'Zoe') {
    // Check that the selected hotel appears in the itinerary or conversation
    const hotelName = hotel === 'Ritz-Carlton' ? 'Ritz-Carlton' : `Hotel ${hotel}`;
    await expect(this.page.getByText(new RegExp(hotelName, 'i'))).toBeVisible();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }

  async waitForSupervisorCoordination() {
    // Wait for supervisor to appear in the conversation
    await expect(
      this.page.getByText(/supervisor|coordinate|specialist|routing/i).first()
    ).toBeVisible({ timeout: 15000 });
  }

  async waitForAgentCompletion() {
    // Wait for the travel planning process to complete
    await expect(
      this.page.getByText(/complete|finished|planning.*done|itinerary.*ready/i).first()
    ).toBeVisible({ timeout: 30000 });
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/llamaIndexPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/llamaIndexPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }
    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('div.bg-white.rounded.shadow-lg >> text=Confirm Changes');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('div.copilotKitMarkdown').first();
    this.rejectedChangesResponse = page.locator('div.copilotKitMarkdown').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Confirm");
    const acceptedLabel = this.userApprovalModal.last().locator('text=✓ Accepted');
  }

  async getUserRejection() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Reject");
    const rejectedLabel = await this.getStatusLabelOfButton(this.page, "✕ Rejected");
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];

    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }

    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('div.bg-white.rounded.shadow-lg');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {

    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();
    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');
    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }

  async getResponseContent() {
    const contentSelectors = [
      'div.tiptap.ProseMirror',
      'div.copilotKitMarkdown',
      '.copilotKitAssistantMessage',
      'div.tiptap'
    ];
    
    for (const selector of contentSelectors) {
      const elements = this.page.locator(selector);
      const count = await elements.count();
      
      if (count > 0) {
        try {
          const lastElement = elements.nth(count - 1);
          const content = await lastElement.textContent();
          if (content && content.trim().length > 0) {
            return content.trim();
          }
        } catch (error) {
          continue;
        }
      }
    }
    
    const fallbackElements = this.page.locator('div.tiptap, div.copilotKitMarkdown');
    const fallbackCount = await fallbackElements.count();
    if (fallbackCount > 0) {
      const fallbackContent = await fallbackElements.nth(fallbackCount - 1).textContent();
      return fallbackContent ? fallbackContent.trim() : null;
    }
    
    return null;
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/reporters/s3-video-reporter.ts
================================================
import {
  FullConfig,
  FullResult,
  Reporter,
  Suite,
  TestCase,
  TestResult,
  TestStep,
} from "@playwright/test/reporter";
import { createS3Uploader, VideoToUpload } from "../lib/upload-video";
import { writeFileSync, existsSync } from "fs";
import { dirname } from "path";
import { mkdirSync } from "fs";

interface S3VideoReporterOptions {
  outputFile?: string;
  uploadVideos?: boolean;
}

interface VideoInfo {
  url: string;
  testName: string;
  suiteName?: string;
  videoPath?: string; // Store the file path for upload
  timestamp?: number; // For deduplication - keep most recent
}

// Global variable to store video URLs for other reporters to access
export const uploadedVideos: VideoInfo[] = [];

export default class S3VideoReporter implements Reporter {
  private options: S3VideoReporterOptions;
  private videos: VideoInfo[] = []; // Only final attempt videos

  constructor(options: S3VideoReporterOptions = {}) {
    this.options = {
      outputFile: options.outputFile || "test-results/video-urls.json",
      uploadVideos: options.uploadVideos !== false, // Default to true
      ...options,
    };
    console.log(
      `📹 DEBUG: S3VideoReporter constructor called with options:`,
      options
    );
  }

  onBegin(config: FullConfig, suite: Suite) {
    console.log(`📹 S3 Video Reporter initialized`);
    console.log(`   Upload enabled: ${this.options.uploadVideos}`);
    console.log(`   Output file: ${this.options.outputFile}`);
  }

  onTestEnd(test: TestCase, result: TestResult) {
    // Only process failed tests
    if (result.status !== "failed" && result.status !== "timedOut") {
      return;
    }

    console.log(`📹 Processing test attempt for: ${test.title}`);

    // Look for video attachments
    const videoAttachments = result.attachments.filter(
      (attachment) => attachment.name === "video" && attachment.path
    );

    if (videoAttachments.length === 0) {
      console.log(`📹 No video attachments found for final attempt`);
      return;
    }

    console.log(
      `📹 Found ${videoAttachments.length} video(s) for failed test: ${test.title}`
    );

    // Store video info for later upload
    videoAttachments.forEach((attachment) => {
      console.log(
        `📹 DEBUG: Processing attachment path=${attachment.path}, exists=${
          attachment.path ? existsSync(attachment.path) : false
        }`
      );
      if (attachment.path && existsSync(attachment.path)) {
        const videoInfo = {
          url: "", // Will be set after upload
          testName: test.title,
          suiteName: test.parent?.title,
          videoPath: attachment.path, // Store actual file path
          timestamp: Date.now(), // For deduplication
        };
        this.videos.push(videoInfo);
        console.log(`📹 DEBUG: Added video info:`, videoInfo);
        console.log(`📹 DEBUG: Total videos now: ${this.videos.length}`);
      } else {
        console.log(
          `📹 DEBUG: Skipping attachment - path invalid or file doesn't exist`
        );
      }
    });
  }

  async onEnd(result: FullResult) {
    console.log(`📹 DEBUG: onEnd called`);
    console.log(`📹 DEBUG: uploadVideos=${this.options.uploadVideos}`);
    console.log(`📹 DEBUG: videos.length=${this.videos.length}`);
    console.log(
      `📹 DEBUG: videos=`,
      this.videos.map((v) => ({
        testName: v.testName,
        hasPath: !!v.videoPath,
        pathExists: v.videoPath ? existsSync(v.videoPath) : false,
      }))
    );

    if (!this.options.uploadVideos) {
      console.log("📹 Upload disabled in options");
      return;
    }

    if (this.videos.length === 0) {
      console.log("📹 No videos collected");
      return;
    }

    const uploader = createS3Uploader();
    if (!uploader) {
      console.warn("⚠️  S3 uploader not configured, skipping video upload");
      return;
    }

    try {
      // Deduplicate videos - keep only the most recent one for each test
      const videoMap = new Map<string, VideoInfo>();
      this.videos.forEach((video) => {
        const existing = videoMap.get(video.testName);
        if (!existing || (video.timestamp || 0) > (existing.timestamp || 0)) {
          videoMap.set(video.testName, video);
        }
      });

      const deduplicatedVideos = Array.from(videoMap.values());
      console.log(
        `📹 Deduplicated ${this.videos.length} videos down to ${deduplicatedVideos.length} (keeping most recent per test)`
      );

      // Use the deduplicated videos for upload
      const videosToUpload: VideoToUpload[] = deduplicatedVideos
        .filter((video) => video.videoPath && existsSync(video.videoPath))
        .map((video) => {
          const s3ObjectPath = uploader.generateS3Path(
            video.videoPath!,
            video.testName,
            video.suiteName
          );

          return {
            videoPath: video.videoPath!,
            s3ObjectPath,
            testName: video.testName,
            suiteName: video.suiteName,
          };
        });

      if (videosToUpload.length === 0) {
        console.log("📹 No video files found to upload");
        return;
      }

      console.log(
        `📹 Preparing to upload ${videosToUpload.length} video(s)...`
      );

      // Upload videos to S3
      const uploadResults = await uploader.uploadVideos(videosToUpload);

      // Update our video info with URLs
      this.videos = uploadResults;

      // Store globally for other reporters
      uploadedVideos.splice(0);
      uploadedVideos.push(...this.videos);

      // Write video URLs to file for other processes
      await this.writeVideoUrls();

      console.log(
        `✅ Successfully uploaded ${this.videos.length} videos to S3`
      );
    } catch (error) {
      console.error("❌ Failed to upload videos:", error);
    }
  }

  private async writeVideoUrls() {
    if (!this.options.outputFile) return;

    const outputDir = dirname(this.options.outputFile);
    if (!existsSync(outputDir)) {
      mkdirSync(outputDir, { recursive: true });
    }

    const videoData = {
      uploadTime: new Date().toISOString(),
      runId: process.env.GITHUB_RUN_ID || `local-${Date.now()}`,
      repository: process.env.GITHUB_REPOSITORY || "unknown",
      videos: this.videos,
    };

    writeFileSync(this.options.outputFile, JSON.stringify(videoData, null, 2));
    console.log(`📄 Video URLs written to: ${this.options.outputFile}`);
  }

  // Helper methods removed - we now collect videos directly in onTestEnd
}

/**
 * Get uploaded video URLs for use in other reporters
 */
export function getUploadedVideos(): VideoInfo[] {
  return [...uploadedVideos];
}

/**
 * Get all uploaded videos
 */
export function getAllVideos(): VideoInfo[] {
  return [...uploadedVideos];
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/copilotkit-home.spec.ts
================================================
import { test, expect } from "@playwright/test";

// Smoke test: ensure CopilotKit homepage loads and renders key content.

test('[Core] CopilotKit homepage renders', async ({ page }) => {
  await page.goto("https://copilotkit.ai/", { waitUntil: "domcontentloaded" });

  await expect(page).toHaveTitle(/CopilotKit/i);

  // Validate hero heading content.
  await expect(
    page.getByRole("heading", {
      name: /Build User-Facing Agentic Applications/i,
      exact: false,
    })
  ).toBeVisible();
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/agnoTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

const appleAsk = "What is the current stock price of AAPL? Please respond in the format of 'The current stock price of Apple Inc. (AAPL) is {{price}}'"

test("[Agno] Agentic Chat sends and receives a greeting message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi");
    await chat.assertAgentReplyVisible(/Hello|Hi|hey/i);
  });
});

test("[Agno] Agentic Chat provides stock price information", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Ask for AAPL stock price
    await chat.sendMessage(appleAsk);
    await chat.assertUserMessageVisible(appleAsk);
    await waitForAIResponse(page);

    // Check if the response contains the expected stock price information
    await chat.assertAgentReplyContains("The current stock price of Apple Inc. (AAPL) is");
  });
});

test("[Agno] Agentic Chat retains memory of previous questions", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // First question
    await chat.sendMessage("Hi");
    await chat.sendMessage(appleAsk);
    await chat.assertUserMessageVisible(appleAsk);
    await waitForAIResponse(page);
    await chat.assertAgentReplyContains("The current stock price of Apple Inc. (AAPL) is");

    // Ask about the first question to test memory
    await chat.sendMessage("What was my first question");
    await chat.assertUserMessageVisible("What was my first question");
    await waitForAIResponse(page);

    // Check if the agent remembers the first question about AAPL stock price
    await chat.assertAgentReplyVisible(/Hi/i);
  });
});

test("[Agno] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/agnoTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/agno/feature/tool_based_generative_ui";

test('[Agno] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Agno] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[CrewAI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[CrewAI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color");
    await chat.assertUserMessageVisible("Reset the background color");
    await waitForAIResponse(page);
  });
});

test("[CrewAI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/crewAIPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  // Flaky
  test.fixme("[CrewAI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/crewai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  // Flaky
  test.fixme("[CrewAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/crewai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/crewAIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[CrewAI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/crewai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[CrewAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/crewai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/crewAIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[CrewAI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/crewai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.nth(1).isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[CrewAI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/crewai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called called Atlantis in document"
      );
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[CrewAI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/crewai/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[CrewAI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/crewai/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/crewai/feature/tool_based_generative_ui";

test('[CrewAI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[CrewAI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/integration/ai-features.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { waitForAIPatterns } from "../../utils/aiWaitHelpers";

test.describe("Demo Viewer AI Features", () => {
  test("[Crew] Restaurant Finder Agent - Complex workflow", async ({
    page,
  }) => {
    try {
      await page.goto(
        "https://demo.copilotkit.ai/crew_enterprise_restaurant_finder",
        {
          waitUntil: "networkidle",
          timeout: 30_000,
        }
      );

      // Navigate through nested iframes
      const demoFrame = page.frameLocator('iframe[title="Demo Preview"]');
      const agentFrame = demoFrame.frameLocator(
        'iframe[title="Restaurant Finder Agent"]'
      );

      // Wait for agent interface to load
      await expect(agentFrame.locator("body")).toBeVisible({ timeout: 30_000 });

      // Look for input field
      const chatInput = agentFrame.locator("input, textarea").first();
      if ((await chatInput.count()) > 0) {
        await chatInput.fill("Find me a restaurant in San Francisco");
        await chatInput.press("Enter");

        // Wait for restaurant results or AI response
        await expect(
          agentFrame.locator("*", {
            hasText: /restaurant|san francisco|recommendation/i,
          })
        ).toBeVisible({ timeout: 90_000 });
        console.log("✅ Restaurant finder agent working");
      }
    } catch (error) {
      console.log("⚠️ Restaurant finder demo not available or not working");
      // Don't fail the test - this is expected if the demo is down
    }
  });
});

// Test configuration for CI vs local
test.describe.configure({
  timeout: process.env.CI ? 300_000 : 120_000, // 5min in CI, 2min locally
  retries: process.env.CI ? 1 : 0,
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LangGraph FastAPI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LangGraph FastAPI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color");
    await chat.assertUserMessageVisible("Reset the background color");
    await waitForAIResponse(page);
  });
});

test("[LangGraph FastAPI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/langGraphFastAPIPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-fastapi/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[LangGraph FastAPI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-fastapi/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/langGraphFastAPIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();
      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[LangGraph FastAPI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();
      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/langGraphFastAPIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[LangGraph FastAPI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[LangGraph FastAPI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/langgraph-fastapi/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LangGraph FastAPI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/langgraph-fastapi/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients, also list them in your message");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/subgraphsPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { SubgraphsPage } from "../../pages/langGraphPages/SubgraphsPage";

test.describe("Subgraphs Travel Agent Feature", () => {
  test("[LangGraph] should complete full travel planning flow with feature validation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-fastapi/feature/subgraphs");

      await subgraphsPage.openChat();

      // Initiate travel planning
      await subgraphsPage.sendMessage("Help me plan a trip to San Francisco");
      await waitForAIResponse(page);

      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test interrupt pause behavior - flow shouldn't auto-proceed
      await page.waitForTimeout(3000);
      // await expect(page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i)).not.toBeVisible();

      // Select KLM flight through interrupt
      await subgraphsPage.selectFlight('KLM');

      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('KLM').catch(async () => {
        await expect(page.getByText(/KLM/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // Select Hotel Zoe through interrupt
      await subgraphsPage.selectHotel('Zoe');

      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Zoe').catch(async () => {
        await expect(page.getByText(/Hotel Zoe|Zoe/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticExperienceData();
    });
  });

  test("[LangGraph] should handle different selections and demonstrate supervisor routing patterns", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-fastapi/feature/subgraphs");

      await subgraphsPage.openChat();

      await subgraphsPage.sendMessage("I want to visit San Francisco from Amsterdam");
      await waitForAIResponse(page);

      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticFlightData();

      await page.waitForTimeout(3000);
      // FEATURE TEST: Test different selection - United instead of KLM
      await subgraphsPage.selectFlight('United');

      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('United').catch(async () => {
        await expect(page.getByText(/United/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // FEATURE TEST: Test different hotel selection - Ritz-Carlton
      await subgraphsPage.selectHotel('Ritz-Carlton');

      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton').catch(async () => {
        await expect(page.getByText(/Ritz-Carlton/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      // FEATURE TEST: Verify subgraph streaming detection - experiences agent is active
      await expect(subgraphsPage.experiencesAgentIndicator).toHaveClass(/active/).catch(() => {
        console.log("Experiences agent not active, checking content instead");
      });

      // FEATURE TEST: Verify complete state persistence across all agents
      await expect(subgraphsPage.selectedFlight).toContainText('United'); // Flight selection persisted
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton'); // Hotel selection persisted
      await subgraphsPage.verifyStaticExperienceData(); // Experiences provided based on selections
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/langgraph-fastapi/feature/tool_based_generative_ui";

test('[LangGraph FastAPI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[LangGraph FastAPI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LangGraph] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LangGraph] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[LangGraph] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/langGraphPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[LangGraph] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[LangGraph] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/langGraphPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LangGraph] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);
      await page.goto(
        "/langgraph/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/langGraphPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[LangGraph] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[LangGraph] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LangGraph] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/langgraph/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LangGraph] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/langgraph/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/subgraphsPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { SubgraphsPage } from "../../pages/langGraphPages/SubgraphsPage";

test.describe("Subgraphs Travel Agent Feature", () => {
  test("[LangGraph] should complete full travel planning flow with feature validation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph/feature/subgraphs");

      await subgraphsPage.openChat();

      // Initiate travel planning
      await subgraphsPage.sendMessage("Help me plan a trip to San Francisco");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test interrupt pause behavior - flow shouldn't auto-proceed
      await page.waitForTimeout(3000);
      // await expect(page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i)).not.toBeVisible();

      // Select KLM flight through interrupt
      await subgraphsPage.selectFlight('KLM');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('KLM').catch(async () => {
        await expect(page.getByText(/KLM/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // Select Hotel Zoe through interrupt
      await subgraphsPage.selectHotel('Zoe');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Zoe').catch(async () => {
        await expect(page.getByText(/Hotel Zoe|Zoe/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticExperienceData();
    });
  });

  test("[LangGraph] should handle different selections and demonstrate supervisor routing patterns", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph/feature/subgraphs");

      await subgraphsPage.openChat();

      await subgraphsPage.sendMessage("I want to visit San Francisco from Amsterdam");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test different selection - United instead of KLM
      await subgraphsPage.selectFlight('United');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('United').catch(async () => {
        await expect(page.getByText(/United/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      // FEATURE TEST: Test different hotel selection - Ritz-Carlton
      await subgraphsPage.selectHotel('Ritz-Carlton');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton').catch(async () => {
        await expect(page.getByText(/Ritz-Carlton/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      // FEATURE TEST: Verify subgraph streaming detection - experiences agent is active
      await expect(subgraphsPage.experiencesAgentIndicator).toHaveClass(/active/).catch(() => {
        console.log("Experiences agent not active, checking content instead");
      });

      // FEATURE TEST: Verify complete state persistence across all agents
      await expect(subgraphsPage.selectedFlight).toContainText('United'); // Flight selection persisted
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton'); // Hotel selection persisted
      await subgraphsPage.verifyStaticExperienceData(); // Experiences provided based on selections
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/langgraph/feature/tool_based_generative_ui";

test('[LangGraph] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[LangGraph] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LlamaIndex] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LlamaIndex] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color to default");
    await chat.assertUserMessageVisible("Reset the background color to default");
    await waitForAIResponse(page);
  });
});

test("[LlamaIndex] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/llamaIndexPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  // Fails. Issue with integration or something.
  test.fixme("[LlamaIndex] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/llama-index/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  // Fails. Issue with integration or something.
  test.fixme("[LlamaIndex] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/llama-index/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/llamaIndexPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LlamaIndex] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/llama-index/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[LlamaIndex] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/llama-index/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with multiple steps and the first step being 'Start The Planning'"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
        
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LlamaIndex] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/llama-index/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LlamaIndex] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/llama-index/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[MastraAgentLocal] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[MastraAgentLocal] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color to default");
    await chat.assertUserMessageVisible("Reset the background color to default");
    await waitForAIResponse(page);
  });
});

test("[MastraAgentLocal] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[MastraAgentLocal] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/mastra-agent-local/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[MastraAgentLocal] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/mastra-agent-local/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/mastra-agent-local/feature/tool_based_generative_ui";

test('[Mastra Agent Local] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Mastra Agent Local] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Mastra] Agentic Chat sends and receives a greeting message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi");
    await chat.assertAgentReplyVisible(/Hello|Hi|hey/i);
  });
});

test("[Mastra] Agentic Chat provides weather information", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Ask for Islamabad weather
    await chat.sendMessage("What is the weather in Islamabad");
    await chat.assertUserMessageVisible("What is the weather in Islamabad");
    await waitForAIResponse(page);

    // Check if the response contains the expected weather information structure
    await chat.assertWeatherResponseStructure();
  });
});

test("[Mastra] Agentic Chat retains memory of previous questions", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // First question about weather
    await chat.sendMessage("What is the weather in Islamabad");
    await chat.assertUserMessageVisible("What is the weather in Islamabad");
    await waitForAIResponse(page);
    await chat.assertWeatherResponseStructure();

    // Ask about the first question to test memory
    await chat.sendMessage("What was my first question");
    await chat.assertUserMessageVisible("What was my first question");
    await waitForAIResponse(page);

    // Check if the agent remembers the first question about weather
    await chat.assertAgentReplyVisible(/weather|Islamabad/i);
  });
});

test("[Mastra] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/mastra/feature/tool_based_generative_ui";

// Fails. Not a test issue, issue with the integration or cpk.
test.fixme('[Mastra] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

// Fails. Not a test issue, issue with the integration or cpk.
test.fixme('[Mastra] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/middlewareStarterTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Middleware Starter] Testing Agentic Chat", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/middleware-starter/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Hello world!/i);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[PydanticAI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[PydanticAI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color");
    await chat.assertUserMessageVisible("Reset the background color");
    await waitForAIResponse(page);
  });
});

test("[PydanticAI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/pydanticAIPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  // Flaky. Sometimes the steps render but never process.
  test.fixme("[PydanticAI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/pydantic-ai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[PydanticAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/pydantic-ai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/pydanticAIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test.fixme("[PydanticAI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/pydantic-ai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[PydanticAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/pydantic-ai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';

          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/pydanticAIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  // Fails. Issue with integration or something.
  test.fixme("[PydanticAI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/pydantic-ai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.nth(1).isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[PydanticAI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/pydantic-ai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called called Atlantis in document"
      );
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[PydanticAI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/pydantic-ai/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[PydanticAI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/pydantic-ai/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/pydantic-ai/feature/tool_based_generative_ui";

test('[PydanticAI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[PydanticAI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Server Starter all features] Agentic Chat displays countdown from 10 to 1 with tick mark", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/server-starter-all-features/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);

    const countdownMessage = page
      .locator('.copilotKitAssistantMessage')
      .filter({ hasText: 'counting down:' });

    await expect(countdownMessage).toBeVisible({ timeout: 30000 });

    // Wait for countdown to complete by checking for the tick mark
    await expect(countdownMessage.locator('.copilotKitMarkdownElement'))
      .toContainText('✓', { timeout: 15000 });

    const countdownText = await countdownMessage
      .locator('.copilotKitMarkdownElement')
      .textContent();

    expect(countdownText).toContain("counting down:");
    expect(countdownText).toMatch(/counting down:\s*10\s+9\s+8\s+7\s+6\s+5\s+4\s+3\s+2\s+1\s+✓/);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/serverStarterAllFeaturesPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[Server Starter all features] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/server-starter-all-features/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    
    await genUIAgent.plan();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 8000 });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/serverStarterAllFeaturesPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test(" [Server Starter all features] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/server-starter-all-features/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';

          return messages.length >= 2 && content.length > 0;
        },
        { timeout: 30000 }
      );
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/predictiveStateUpdatePage.spec.ts
================================================
import { test, expect, retryOnAIFailure, } from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/serverStarterAllFeaturesPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[Server Starter all features] should interact with agent and approve asked changes", async ({ page, }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/server-starter-all-features/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage("Hi");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const originalContent = await predictiveStateUpdates.getResponseContent();
      expect(originalContent).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change the dog name");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();

      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const updatedContent = await predictiveStateUpdates.getResponseContent();

      expect(updatedContent).not.toBe(originalContent);
    });
  });

  test("[Server Starter all features] should interact with agent and reject asked changes", async ({ page, }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/server-starter-all-features/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage("Hi");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const originalContent = await predictiveStateUpdates.getResponseContent();
      expect(originalContent).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change the dog name");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();

      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();

      const currentContent = await predictiveStateUpdates.getResponseContent();

      expect(currentContent).toBe(originalContent);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[Server Starter all features] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/server-starter-all-features/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Salt');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  // Fails. Issue with the test, most likely
  test("[Server Starter all features] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/server-starter-all-features/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify hardcoded ingredients
    await sharedStateAgent.awaitIngredientCard('chicken breast');
    await sharedStateAgent.awaitIngredientCard('chili powder');
    await sharedStateAgent.awaitIngredientCard('Salt');
    await sharedStateAgent.awaitIngredientCard('Lettuce leaves');

    expect(await sharedStateAgent.getInstructionItems(sharedStateAgent.instructionsContainer)).toBe(3);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/server-starter-all-features/feature/tool_based_generative_ui";

test('[Server Starter all features] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Server Starter all features] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Server Starter] Testing Agentic Chat", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/server-starter/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Hello world!/i);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/smoke-only/basic-loading.spec.ts
================================================
import { test, expect } from "@playwright/test";

test.describe("Demo Apps Loading Smoke Tests", () => {
  test("[Smoke] AG2 Agentic Chat app loads successfully", async ({ page }) => {
    await page.goto(
      "https://ag2-feature-viewer.vercel.app/feature/agentic_chat"
    );

    // Just verify the page loads and key elements are present
    await expect(
      page.getByRole("button", { name: "Agentic Chat Chat with your" })
    ).toBeVisible();
    await expect(page.getByText("Hi, I'm an agent. Want to")).toBeVisible();

    // Click to open chat
    await page
      .getByRole("button", { name: "Agentic Chat Chat with your" })
      .click();

    // Verify chat interface appears (not AI response)
    await expect(
      page.getByRole("textbox", { name: "Type a message..." })
    ).toBeVisible();
    await expect(
      page.locator('[data-test-id="copilot-chat-ready"]')
    ).toBeVisible();
  });

  test("[Smoke] Human in the Loop app loads successfully", async ({ page }) => {
    await page.goto(
      "https://ag2-feature-viewer.vercel.app/feature/human_in_the_loop"
    );

    await expect(
      page.getByRole("button", { name: "Human in the loop Plan a task" })
    ).toBeVisible();

    // Click to open chat
    await page
      .getByRole("button", { name: "Human in the loop Plan a task" })
      .click();

    // Verify chat interface appears
    await expect(
      page.getByRole("textbox", { name: "Type a message..." })
    ).toBeVisible();
    await expect(
      page.locator('[data-test-id="copilot-chat-ready"]')
    ).toBeVisible();
  });

  test("[Smoke] CoBankKit loads successfully", async ({ page }) => {
    await page.goto("https://co-bank-kit.vercel.app/");

    // Verify the app loads - just check that the page responds
    await expect(page.locator("body")).toBeVisible();

    // Wait for page to fully load and check for any interactive elements
    await page.waitForLoadState("networkidle");

    // Check for any visible content (more generic)
    const hasAnyContent = await page.locator("*").count();
    expect(hasAnyContent).toBeGreaterThan(1); // At least html and body
  });

  test("[Smoke] AG2 feature viewer homepage loads", async ({ page }) => {
    await page.goto("https://ag2-feature-viewer.vercel.app/");

    // Verify the homepage loads
    await expect(page.locator("body")).toBeVisible();

    // Check that we can navigate to features
    const hasFeatureLinks = await page.locator("a, button").count();
    expect(hasFeatureLinks).toBeGreaterThan(0);
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/vercelAISdkTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[verceAISdkPages] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[Vercel AI SDK] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const initialBackground = await chat.getBackground();
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    const backgroundBlue = await chat.getBackground();
    expect(backgroundBlue).not.toBe(initialBackground);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    const backgroundPink = await chat.getBackground();
    expect(backgroundPink).not.toBe(backgroundBlue);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 3. Reset to default
    await chat.sendMessage("Reset the background color to default");
    await chat.assertUserMessageVisible("Reset the background color to default");
    await waitForAIResponse(page);
  });
});

test("[Vercel AI SDK] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/utils/aiWaitHelpers.ts
================================================
import { expect, Locator, Page } from "@playwright/test";

/**
 * Wait for AI assistant messages with extended timeout and retry logic
 */
export async function waitForAIResponse(
  locator: Locator,
  pattern: RegExp,
  timeoutMs: number = 120_000 // 2 minutes default
) {
  await expect(locator.getByText(pattern)).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for AI-generated content to appear with polling
 */
export async function waitForAIContent(
  locator: Locator,
  timeoutMs: number = 120_000 // 2 minutes default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for AI form interactions with extended timeout
 */
export async function waitForAIFormReady(
  locator: Locator,
  timeoutMs: number = 60_000 // 1 minute default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
  await expect(locator).toBeEnabled({ timeout: timeoutMs });
  await expect(locator).toBeEditable({ timeout: timeoutMs });
}

/**
 * Wait for AI dialog/modal to appear
 */
export async function waitForAIDialog(
  locator: Locator,
  timeoutMs: number = 90_000 // 1.5 minutes default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for pattern matching with custom timeout for AI responses
 */
export async function waitForAIPatterns(
  page: Page,
  patterns: RegExp[],
  timeoutMs: number = 120_000 // 2 minutes default
): Promise<void> {
  const endTime = Date.now() + timeoutMs;

  while (Date.now() < endTime) {
    for (const pattern of patterns) {
      try {
        const element = page.locator("body").getByText(pattern);
        if ((await element.count()) > 0) {
          await expect(element.first()).toBeVisible({ timeout: 5000 });
          return; // Found a match
        }
      } catch {
        // Continue searching
      }
    }

    await page.waitForTimeout(2000); // Wait 2s before next check
  }

  throw new Error(
    `None of the expected patterns matched within ${timeoutMs}ms: ${patterns
      .map((p) => p.toString())
      .join(", ")}`
  );
}



================================================
FILE: typescript-sdk/apps/dojo/public/logo_dark.webp
================================================
[Binary file]


================================================
FILE: typescript-sdk/apps/dojo/public/logo_light.webp
================================================
[Binary file]


================================================
FILE: typescript-sdk/apps/dojo/scripts/generate-content-json.ts
================================================
import fs from "fs";
import path from "path";

// Function to parse agents.ts file and extract agent keys without executing
function parseAgentsFile(): Array<{id: string, agentKeys: string[]}> {
  const agentsFilePath = path.join(__dirname, '../src/agents.ts');
  const agentsContent = fs.readFileSync(agentsFilePath, 'utf8');

  const agentConfigs: Array<{id: string, agentKeys: string[]}> = [];

  // Split the content to process each agent configuration individually
  const agentBlocks = agentsContent.split(/(?=\s*{\s*id:\s*["'])/);

  for (const block of agentBlocks) {
    // Extract the ID
    const idMatch = block.match(/id:\s*["']([^"']+)["']/);
    if (!idMatch) continue;

    const id = idMatch[1];

    // Find the return object by looking for the pattern and then manually parsing balanced braces
    const returnMatch = block.match(/agents:\s*async\s*\(\)\s*=>\s*{\s*return\s*{/);
    if (!returnMatch) continue;

    const startIndex = returnMatch.index! + returnMatch[0].length;
    const returnObjectContent = extractBalancedBraces(block, startIndex);


    // Extract keys from the return object - only capture keys that are followed by a colon and then 'new'
    // This ensures we only get the top-level keys like "agentic_chat: new ..." not nested keys like "url: ..."
    const keyRegex = /^\s*(\w+):\s*new\s+\w+/gm;
    const keys: string[] = [];
    let keyMatch;
    while ((keyMatch = keyRegex.exec(returnObjectContent)) !== null) {
      keys.push(keyMatch[1]);
    }

    agentConfigs.push({ id, agentKeys: keys });
  }

  return agentConfigs;
}

// Helper function to extract content between balanced braces
function extractBalancedBraces(text: string, startIndex: number): string {
  let braceCount = 0;
  let i = startIndex;

  while (i < text.length) {
    if (text[i] === '{') {
      braceCount++;
    } else if (text[i] === '}') {
      if (braceCount === 0) {
        // Found the closing brace for the return object
        return text.substring(startIndex, i);
      }
      braceCount--;
    }
    i++;
  }

  return '';
}

const agentConfigs = parseAgentsFile();

const featureFiles = ["page.tsx", "style.css", "README.mdx"]

async function getFile(_filePath: string | undefined, _fileName?: string) {
  if (!_filePath) {
    console.warn(`File path is undefined, skipping.`);
    return {}
  }

  const fileName = _fileName ?? _filePath.split('/').pop() ?? ''
  const filePath = _fileName ? path.join(_filePath, fileName) : _filePath;

  // Check if it's a remote URL
  const isRemoteUrl = _filePath.startsWith('http://') || _filePath.startsWith('https://');

  let content: string;

  try {
    if (isRemoteUrl) {
      // Convert GitHub URLs to raw URLs for direct file access
      let fetchUrl = _filePath;
      if (_filePath.includes('github.com') && _filePath.includes('/blob/')) {
        fetchUrl = _filePath.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/');
      }

      // Fetch remote file content
      console.log(`Fetching remote file: ${fetchUrl}`);
      const response = await fetch(fetchUrl);
      if (!response.ok) {
        console.warn(`Failed to fetch remote file: ${fetchUrl}, status: ${response.status}`);
        return {}
      }
      content = await response.text();
    } else {
      // Handle local file
      if (!fs.existsSync(filePath)) {
        console.warn(`File not found: ${filePath}, skipping.`);
        return {}
      }
      content = fs.readFileSync(filePath, "utf8");
    }

    const extension = fileName.split(".").pop();
    let language = extension;
    if (extension === "py") language = "python";
    else if (extension === "css") language = "css";
    else if (extension === "md" || extension === "mdx") language = "markdown";
    else if (extension === "tsx") language = "typescript";
    else if (extension === "js") language = "javascript";
    else if (extension === "json") language = "json";
    else if (extension === "yaml" || extension === "yml") language = "yaml";
    else if (extension === "toml") language = "toml";

    return {
      name: fileName,
      content,
      language,
      type: 'file'
    }
  } catch (error) {
    console.error(`Error reading file ${filePath}:`, error);
    return {}
  }
}

async function getFeatureFrontendFiles(featureId: string) {
  const featurePath = path.join(__dirname, `../src/app/[integrationId]/feature/${featureId as string}`);
  const retrievedFiles = []

  for (const fileName of featureFiles) {
    retrievedFiles.push(await getFile(featurePath, fileName))
  }

  return retrievedFiles;
}

const integrationsFolderPath = '../../../integrations'
const agentFilesMapper: Record<string, (agentKeys: string[]) => Record<string, string[]>> = {
  'middleware-starter': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/middleware-starter/src/index.ts`)]
  }),
  'pydantic-ai': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/pydantic-ai/examples/server/api/${agentId}.py`)]
    }), {})
  },
  'server-starter': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/server-starter/server/python/example_server/__init__.py`)]
  }),
  'server-starter-all-features': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/server-starter-all-features/server/python/example_server/${agentId}.py`)]
    }), {})
  },
  'mastra': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/mastra/example/src/mastra/agents/weather-agent.ts`)]
  }),
  'mastra-agent-lock': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/mastra/example/src/mastra/agents/weather-agent.ts`)]
  }),
  'vercel-ai-sdk': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/vercel-ai-sdk/src/index.ts`)]
  }),
  'langgraph': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`),
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/typescript/src/agents/${agentId}/agent.ts`)
      ]
    }), {})
  },
  'langgraph-typescript': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`),
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/typescript/src/agents/${agentId}/agent.ts`)
      ]
    }), {})
  },
  'langgraph-fastapi': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`)]
    }), {})
  },
  'agno': () => ({}),
  'llama-index': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/llamaindex/server-py/server/routers/${agentId}.py`)]
    }), {})
  },
  'crewai': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/crewai/python/ag_ui_crewai/examples/${agentId}.py`)]
    }), {})
  }
}

async function runGenerateContent() {
  const result = {}
  for (const agentConfig of agentConfigs) {
    // Use the parsed agent keys instead of executing the agents function
    const agentsPerFeatures = agentConfig.agentKeys

    const agentFilePaths = agentFilesMapper[agentConfig.id](agentConfig.agentKeys)

    // Per feature, assign all the frontend files like page.tsx as well as all agent files
    for (const featureId of agentsPerFeatures) {
      const agentFilePathsForFeature = agentFilePaths[featureId] ?? []
      // @ts-expect-error -- redundant error about indexing of a new object.
      result[`${agentConfig.id}::${featureId}`] = [
        // Get all frontend files for the feature
        ...(await getFeatureFrontendFiles(featureId)),
        // Get the agent (python/TS) file
        ...(await Promise.all(agentFilePathsForFeature.map(async f => await getFile(f))))
      ]
    }
  }

  return result
}

(async () => {
  const result = await runGenerateContent();
  fs.writeFileSync(
      path.join(__dirname, "../src/files.json"),
      JSON.stringify(result, null, 2)
  );

  console.log("Successfully generated src/files.json");
})();


================================================
FILE: typescript-sdk/apps/dojo/scripts/link-cpk.js
================================================
#!/usr/bin/env node
const fs = require('fs');
const { execSync } = require('child_process');
const path = require('path');

const cpkPath = process.argv[2];
if (!cpkPath) {
  console.error('Usage: node link-cpk.js <cpk-path>');
  process.exit(1);
}

if (!fs.existsSync(cpkPath)) {
  console.error(`copilot kit repo path ${cpkPath} does not exist`);
  process.exit(1);
}


const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8', cwd: __dirname }).trim();
const dojoDir = path.join(gitRoot, 'typescript-sdk/apps/dojo');
const cpkPackageDir = path.join(cpkPath, 'CopilotKit', 'packages');
const relative = `./${path.relative(dojoDir, cpkPackageDir)}`;

function linkCopilotKit() {
  const pkgPath = path.join(dojoDir, 'package.json');
  const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
  const packages = Object.keys(pkg.dependencies).filter(pkg => pkg.startsWith('@copilotkit/'));

  success = true;
  packages.forEach(packageName => {
    const packageFolderName = packageName.replace('@copilotkit/', '');

    if (!fs.existsSync(path.join(cpkPackageDir, packageFolderName))) {
      console.error(`Package ${packageName} does not exist in ${cpkPackageDir}!!`);
      success = false;
    }

    pkg.dependencies[packageName] = path.join(relative, packageFolderName);
  });



  if (!success) {
    console.error('One or more packages do not exist in the copilot kit repo!');
    process.exit(1);
  }

  fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2));

}

linkCopilotKit();


================================================
FILE: typescript-sdk/apps/dojo/scripts/prep-dojo-everything.js
================================================
#!/usr/bin/env node

const { execSync } = require('child_process');
const path = require('path');
const concurrently = require('concurrently');

// Parse command line arguments
const args = process.argv.slice(2);
const showHelp = args.includes('--help') || args.includes('-h');
const dryRun = args.includes('--dry-run');

if (showHelp) {
  console.log(`
Usage: node prep-dojo-everything.js [options]

Options:
  --dry-run       Show what would be installed without actually running
  --help, -h      Show this help message

Examples:
  node prep-dojo-everything.js
  node prep-dojo-everything.js --dry-run
`);
  process.exit(0);
}

const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8' }).trim();
const integrationsRoot = path.join(gitRoot, 'typescript-sdk', 'integrations');



// Server Starter
const serverStarter = {
  command: 'poetry install',
  name: 'Server Starter',
  cwd: path.join(integrationsRoot, 'server-starter/server/python'),
}

// Server Starter All Features
const serverStarterAllFeatures = {
  command: 'poetry install',
  name: 'Server AF',
  cwd: path.join(integrationsRoot, 'server-starter-all-features/server/python'),
}

// Agno
const agno = {
  command: 'uv sync',
  name: 'Agno',
  cwd: path.join(integrationsRoot, 'agno/examples'),
}

// CrewAI
const crewai = {
  command: 'poetry install',
  name: 'CrewAI',
  cwd: path.join(integrationsRoot, 'crewai/python'),
}

// Langgraph (FastAPI)
const langgraphFastapi = {
  command: 'poetry install',
  name: 'LG FastAPI',
  cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
  env: {
    POETRY_VIRTUALENVS_IN_PROJECT: "false"
  }
}

// Langgraph (Platorm {typescript})
const langgraphPlatformTypescript = {
  command: 'pnpm install',
  name: 'LG Platform TS',
  cwd: path.join(integrationsRoot, 'langgraph/examples/typescript/'),
}

// Llama Index
const llamaIndex = {
  command: 'uv sync',
  name: 'Llama Index',
  cwd: path.join(integrationsRoot, 'llamaindex/server-py'),
}

// Mastra
const mastra = {
  command: 'npm install',
  name: 'Mastra',
  cwd: path.join(integrationsRoot, 'mastra/example'),
}

// Pydantic AI
const pydanticAi = {
  command: 'uv sync',
  name: 'Pydantic AI',
  cwd: path.join(integrationsRoot, 'pydantic-ai/examples'),
}

// THE ACTUAL DOJO
const dojo = {
  command: 'pnpm install --no-frozen-lockfile && pnpm build --filter=demo-viewer...',
  name: 'Dojo',
  cwd: path.join(gitRoot, 'typescript-sdk'),
}

function printDryRunServices(procs) {
  console.log('Dry run - would install dependencies for the following services:');
  procs.forEach(proc => {
    console.log(`  - ${proc.name} (${proc.cwd})`);
    console.log(`    Command: ${proc.command}`);
    console.log('');
  });
  process.exit(0);
}

async function main() {
  const procs = [
    serverStarter,
    serverStarterAllFeatures,
    agno,
    crewai,
    langgraphFastapi,
    langgraphPlatformTypescript,
    llamaIndex,
    mastra,
    pydanticAi,
    dojo
  ];

  if (dryRun) {
    printDryRunServices(procs);
  }

  const {result} = concurrently(procs);

  result.then(() => process.exit(0)).catch((err) => {
    console.error(err);
    process.exit(1);
  });
}

main();



================================================
FILE: typescript-sdk/apps/dojo/scripts/run-dojo-everything.js
================================================
#!/usr/bin/env node

const { execSync } = require('child_process');
const path = require('path');
const concurrently = require('concurrently');

// Parse command line arguments
const args = process.argv.slice(2);
const showHelp = args.includes('--help') || args.includes('-h');
const dryRun = args.includes('--dry-run');

if (showHelp) {
  console.log(`
Usage: node run-dojo-everything.js [options]

Options:
  --dry-run       Show what would be started without actually running
  --help, -h      Show this help message

Examples:
  node run-dojo-everything.js
  node run-dojo-everything.js --dry-run
`);
  process.exit(0);
}

const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8' }).trim();
const integrationsRoot = path.join(gitRoot, 'typescript-sdk', 'integrations');

// Server Starter
const serverStarter = {
  command: 'poetry run dev',
  name: 'Server Starter',
  cwd: path.join(integrationsRoot, 'server-starter/server/python'),
  env: {PORT: 8000},
}

// Server Starter All Features
const serverStarterAllFeatures = {
  command: 'poetry run dev',
  name: 'Server AF',
  cwd: path.join(integrationsRoot, 'server-starter-all-features/server/python'),
  env: {PORT: 8001},
}

// Agno
const agno = {
  command: 'uv run dev',
  name: 'Agno',
  cwd: path.join(integrationsRoot, 'agno/examples'),
  env: {PORT: 8002},
}

// CrewAI
const crewai = {
  command: 'poetry run dev',
  name: 'CrewAI',
  cwd: path.join(integrationsRoot, 'crewai/python'),
  env: {PORT: 8003},
}

// Langgraph (FastAPI)
const langgraphFastapi = {
  command: 'poetry run dev',
  name: 'LG FastAPI',
  cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
  env: {
    PORT: 8004,
    POETRY_VIRTUALENVS_IN_PROJECT: "false"
  },
}

// Langgraph (Platform {python})
const langgraphPlatformPython = {
  command: 'pnpx @langchain/langgraph-cli@latest dev --no-browser --port 8005',
  name: 'LG Platform Py',
  cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
  env: {PORT: 8005},
}

// Langgraph (Platform {typescript})
const langgraphPlatformTypescript = {
  command: 'pnpx @langchain/langgraph-cli@latest dev --no-browser --port 8006',
  name: 'LG Platform TS',
  cwd: path.join(integrationsRoot, 'langgraph/examples/typescript/'),
  env: {PORT: 8006},
}

// Llama Index
const llamaIndex = {
  command: 'uv run dev',
  name: 'Llama Index',
  cwd: path.join(integrationsRoot, 'llamaindex/server-py'),
  env: {PORT: 8007},
}

// Mastra
const mastra = {
  command: 'npm run dev',
  name: 'Mastra',
  cwd: path.join(integrationsRoot, 'mastra/example'),
  env: {PORT: 8008},
}

// Pydantic AI
const pydanticAi = {
  command: 'uv run dev',
  name: 'Pydantic AI',
  cwd: path.join(integrationsRoot, 'pydantic-ai/examples'),
  env: {PORT: 8009},
}

// THE ACTUAL DOJO
const dojo = {
  command: 'pnpm run start',
  name: 'Dojo',
  cwd: path.join(gitRoot, 'typescript-sdk/apps/dojo'),
  env: {
    PORT: 9999,
    SERVER_STARTER_URL: 'http://localhost:8000',
    SERVER_STARTER_ALL_FEATURES_URL: 'http://localhost:8001',
    AGNO_URL: 'http://localhost:8002',
    CREW_AI_URL: 'http://localhost:8003',
    LANGGRAPH_FAST_API_URL: 'http://localhost:8004',
    LANGGRAPH_PYTHON_URL: 'http://localhost:8005',
    LANGGRAPH_TYPESCRIPT_URL: 'http://localhost:8006',
    LLAMA_INDEX_URL: 'http://localhost:8007',
    MASTRA_URL: 'http://localhost:8008',
    PYDANTIC_AI_URL: 'http://localhost:8009',
    NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE: 'cpkdojo.local___CopilotKit Feature Viewer',
  }
}

const procs = [
  serverStarter,
  serverStarterAllFeatures,
  agno,
  crewai,
  langgraphFastapi,
  langgraphPlatformPython,
  langgraphPlatformTypescript,
  llamaIndex,
  mastra,
  pydanticAi,
  dojo
];

function printDryRunServices(procs) {
  console.log('Dry run - would start the following services:');
  procs.forEach(proc => {
    console.log(`  - ${proc.name} (${proc.cwd})`);
    console.log(`    Command: ${proc.command}`);
    console.log(`    Environment variables:`);
    if (proc.env) {
      Object.entries(proc.env).forEach(([key, value]) => {
        console.log(`      ${key}: ${value}`);
      });
    } else {
      console.log('      No environment variables specified.');
    }
    console.log('');
  });
  process.exit(0);
}

async function main() {
  if (dryRun) {
    printDryRunServices(procs);
  }

  console.log('Starting services: ', procs.map(p => p.name).join(', '));

  const {result} = concurrently(procs, {killOthersOn: ['failure', 'success']});

  result.then(() => process.exit(0)).catch((err) => {
    console.error(err);
    process.exit(1);
  });
}

main();



================================================
FILE: typescript-sdk/apps/dojo/src/agents.ts
================================================
import "server-only";

import { AgentIntegrationConfig } from "./types/integration";
import { MiddlewareStarterAgent } from "@ag-ui/middleware-starter";
import { ServerStarterAgent } from "@ag-ui/server-starter";
import { ServerStarterAllFeaturesAgent } from "@ag-ui/server-starter-all-features";
import { MastraClient } from "@mastra/client-js";
import { MastraAgent } from "@ag-ui/mastra";
import { VercelAISDKAgent } from "@ag-ui/vercel-ai-sdk";
import { openai } from "@ai-sdk/openai";
import { LangGraphAgent, LangGraphHttpAgent } from "@ag-ui/langgraph";
import { AgnoAgent } from "@ag-ui/agno";
import { LlamaIndexAgent } from "@ag-ui/llamaindex";
import { CrewAIAgent } from "@ag-ui/crewai";
import getEnvVars from "./env";
import { mastra } from "./mastra";
import { PydanticAIAgent } from "@ag-ui/pydantic-ai";

const envVars = getEnvVars();
export const agentsIntegrations: AgentIntegrationConfig[] = [
  {
    id: "middleware-starter",
    agents: async () => {
      return {
        agentic_chat: new MiddlewareStarterAgent(),
      };
    },
  },
  {
    id: "pydantic-ai",
    agents: async () => {
      return {
        agentic_chat: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/agentic_chat/`,
        }),
        agentic_generative_ui: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/agentic_generative_ui/`,
        }),
        human_in_the_loop: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/human_in_the_loop/`,
        }),
        predictive_state_updates: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/predictive_state_updates/`,
        }),
        shared_state: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/shared_state/`,
        }),
        tool_based_generative_ui: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/tool_based_generative_ui/`,
        }),
      };
    },
  },
  {
    id: "server-starter",
    agents: async () => {
      return {
        agentic_chat: new ServerStarterAgent({ url: envVars.serverStarterUrl }),
      };
    },
  },
  {
    id: "server-starter-all-features",
    agents: async () => {
      return {
        agentic_chat: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/agentic_chat`,
        }),
        human_in_the_loop: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/human_in_the_loop`,
        }),
        agentic_generative_ui: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/agentic_generative_ui`,
        }),
        tool_based_generative_ui: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/tool_based_generative_ui`,
        }),
        shared_state: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/shared_state`,
        }),
        predictive_state_updates: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/predictive_state_updates`,
        }),
      };
    },
  },
  {
    id: "mastra",
    agents: async () => {
      const mastraClient = new MastraClient({
        baseUrl: envVars.mastraUrl,
      });

      return MastraAgent.getRemoteAgents({
        mastraClient,
      });
    },
  },
  {
    id: "mastra-agent-local",
    agents: async () => {
      return MastraAgent.getLocalAgents({ mastra });
    },
  },
  {
    id: "vercel-ai-sdk",
    agents: async () => {
      return {
        agentic_chat: new VercelAISDKAgent({ model: openai("gpt-4o") }),
      };
    },
  },
  {
    id: "langgraph",
    agents: async () => {
      return {
        agentic_chat: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "agentic_chat",
        }),
        agentic_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "agentic_generative_ui",
        }),
        human_in_the_loop: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "human_in_the_loop",
        }),
        predictive_state_updates: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "predictive_state_updates",
        }),
        shared_state: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "shared_state",
        }),
        tool_based_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "tool_based_generative_ui",
        }),
        agentic_chat_reasoning: new LangGraphHttpAgent({
          url: `${envVars.langgraphPythonUrl}/agent/agentic_chat_reasoning`,
        }),
        subgraphs: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "subgraphs",
        }),
      };
    },
  },
  {
    id: "langgraph-fastapi",
    agents: async () => {
      return {
        agentic_chat: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_chat`,
        }),
        agentic_generative_ui: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_generative_ui`,
        }),
        human_in_the_loop: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/human_in_the_loop`,
        }),
        predictive_state_updates: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/predictive_state_updates`,
        }),
        shared_state: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/shared_state`,
        }),
        tool_based_generative_ui: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/tool_based_generative_ui`,
        }),
        agentic_chat_reasoning: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_chat_reasoning`,
        }),
        subgraphs: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/subgraphs`,
        }),
      };
    },
  },
  {
    id: "langgraph-typescript",
    agents: async () => {
      return {
        agentic_chat: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "agentic_chat",
        }),
        agentic_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "agentic_generative_ui",
        }),
        human_in_the_loop: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "human_in_the_loop",
        }),
        predictive_state_updates: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "predictive_state_updates",
        }),
        shared_state: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "shared_state",
        }),
        tool_based_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "tool_based_generative_ui",
        }),
        subgraphs: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "subgraphs",
        })
      };
    },
  },
  {
    id: "agno",
    agents: async () => {
      return {
        agentic_chat: new AgnoAgent({
          url: `${envVars.agnoUrl}/agentic_chat/agui`,
        }),
        tool_based_generative_ui: new AgnoAgent({
          url: `${envVars.agnoUrl}/tool_based_generative_ui/agui`,
        }),
      };
    },
  },
  {
    id: "llama-index",
    agents: async () => {
      return {
        agentic_chat: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/agentic_chat/run`,
        }),
        human_in_the_loop: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/human_in_the_loop/run`,
        }),
        agentic_generative_ui: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/agentic_generative_ui/run`,
        }),
        shared_state: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/shared_state/run`,
        }),
      };
    },
  },
  {
    id: "crewai",
    agents: async () => {
      return {
        agentic_chat: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/agentic_chat`,
        }),
        human_in_the_loop: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/human_in_the_loop`,
        }),
        tool_based_generative_ui: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/tool_based_generative_ui`,
        }),
        agentic_generative_ui: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/agentic_generative_ui`,
        }),
        shared_state: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/shared_state`,
        }),
        predictive_state_updates: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/predictive_state_updates`,
        }),
      };
    },
  },
];



================================================
FILE: typescript-sdk/apps/dojo/src/config.ts
================================================
import { FeatureConfig } from "@/types/feature";

// A helper method to creating a config
function createFeatureConfig({
  id,
  name,
  description,
  tags,
}: Pick<FeatureConfig, "id" | "name" | "description" | "tags">): FeatureConfig {
  return {
    id,
    name,
    description,
    path: `/feature/${id}`,
    tags,
  };
}

export const featureConfig: FeatureConfig[] = [
  createFeatureConfig({
    id: "agentic_chat",
    name: "Agentic Chat",
    description: "Chat with your Copilot and call frontend tools",
    tags: ["Chat", "Tools", "Streaming"],
  }),
  createFeatureConfig({
    id: "human_in_the_loop",
    name: "Human in the loop",
    description: "Plan a task together and direct the Copilot to take the right steps",
    tags: ["HITL", "Interactivity"],
  }),
  createFeatureConfig({
    id: "agentic_generative_ui",
    name: "Agentic Generative UI",
    description: "Assign a long running task to your Copilot and see how it performs!",
    tags: ["Generative ui (agent)", "Long running task"],
  }),
  createFeatureConfig({
    id: "tool_based_generative_ui",
    name: "Tool Based Generative UI",
    description: "Haiku generator that uses tool based generative UI.",
    tags: ["Generative ui (action)", "Tools"],
  }),
  createFeatureConfig({
    id: "shared_state",
    name: "Shared State between agent and UI",
    description: "A recipe Copilot which reads and updates collaboratively",
    tags: ["Agent State", "Collaborating"],
  }),
  createFeatureConfig({
    id: "predictive_state_updates",
    name: "Predictive State Updates",
    description: "Use collaboration to edit a document in real time with your Copilot",
    tags: ["State", "Streaming", "Tools"],
  }),
  createFeatureConfig({
    id: "agentic_chat_reasoning",
    name: "Agentic Chat Reasoning",
    description: "Chat with a reasoning Copilot and call frontend tools",
    tags: ["Chat", "Tools", "Streaming", "Reasoning"],
  }),
  createFeatureConfig({
    id: "subgraphs",
    name: "Subgraphs",
    description: "Have your tasks performed by multiple agents, working together",
    tags: ["Chat", "Multi-agent architecture", "Streaming", "Subgraphs"],
  }),
];

export default featureConfig;



================================================
FILE: typescript-sdk/apps/dojo/src/env.ts
================================================
type envVars = {
  serverStarterUrl: string;
  serverStarterAllFeaturesUrl: string;
  mastraUrl: string;
  langgraphPythonUrl: string;
  langgraphFastApiUrl: string;
  langgraphTypescriptUrl: string;
  agnoUrl: string;
  llamaIndexUrl: string;
  crewAiUrl: string;
  pydanticAIUrl: string;
  customDomainTitle: Record<string, string>;
}

export default function getEnvVars(): envVars {
  const customDomainTitle: Record<string, string> = {};
  if (process.env.NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE) {
    const [domain, title] = process.env.NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE.split('___');
    if (domain && title) {
      customDomainTitle[domain] = title;
    }
  }

  return {
    serverStarterUrl: process.env.SERVER_STARTER_URL || 'http://localhost:8000',
    serverStarterAllFeaturesUrl: process.env.SERVER_STARTER_ALL_FEATURES_URL || 'http://localhost:8000',
    mastraUrl: process.env.MASTRA_URL || 'http://localhost:4111',
    langgraphPythonUrl: process.env.LANGGRAPH_PYTHON_URL || 'http://localhost:2024',
    langgraphFastApiUrl: process.env.LANGGRAPH_FAST_API_URL || 'http://localhost:8000',
    langgraphTypescriptUrl: process.env.LANGGRAPH_TYPESCRIPT_URL || 'http://localhost:2024',
    agnoUrl: process.env.AGNO_URL || 'http://localhost:9001',
    llamaIndexUrl: process.env.LLAMA_INDEX_URL || 'http://localhost:9000',
    crewAiUrl: process.env.CREW_AI_URL || 'http://localhost:9002',
    pydanticAIUrl: process.env.PYDANTIC_AI_URL || 'http://localhost:9000',
    customDomainTitle: customDomainTitle,
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/menu.ts
================================================
import { MenuIntegrationConfig } from "./types/integration";

export const menuIntegrations: MenuIntegrationConfig[] = [
  {
    id: "middleware-starter",
    name: "Middleware Starter",
    features: ["agentic_chat"],
  },
  {
    id: "server-starter",
    name: "Server Starter",
    features: ["agentic_chat"],
  },
  {
    id: "server-starter-all-features",
    name: "Server Starter (All Features)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_chat_reasoning",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "agno",
    name: "Agno",
    features: ["agentic_chat", "tool_based_generative_ui"],
  },
  {
    id: "crewai",
    name: "CrewAI",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "langgraph",
    name: "LangGraph (Python)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "langgraph-fastapi",
    name: "LangGraph (FastAPI)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_chat_reasoning",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "langgraph-typescript",
    name: "LangGraph (Typescript)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "llama-index",
    name: "LlamaIndex",
    features: ["agentic_chat", "human_in_the_loop", "agentic_generative_ui", "shared_state"],

  },
  {
    id: "mastra",
    name: "Mastra",
    features: ["agentic_chat", "tool_based_generative_ui"],
  },
  {
    id: "mastra-agent-local",
    name: "Mastra Agent (Local)",
    features: ["agentic_chat", "shared_state", "tool_based_generative_ui"],
  },
  {
    id: "pydantic-ai",
    name: "Pydantic AI",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "vercel-ai-sdk",
    name: "Vercel AI SDK",
    features: ["agentic_chat"],
  },
];




================================================
FILE: typescript-sdk/apps/dojo/src/app/globals.css
================================================
@import "tailwindcss";
@import "../styles/typography.css";

@plugin "tailwindcss-animate";

@custom-variant dark (&:is(.dark *));

@theme {
  /* Base Shadcn Colors */
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --color-card: var(--card);
  --color-card-foreground: var(--card-foreground);
  --color-popover: var(--popover);
  --color-popover-foreground: var(--popover-foreground);
  --color-primary: var(--primary);
  --color-primary-foreground: var(--primary-foreground);
  --color-secondary: var(--secondary);
  --color-secondary-foreground: var(--secondary-foreground);
  --color-muted: var(--muted);
  --color-muted-foreground: var(--muted-foreground);
  --color-accent: var(--accent);
  --color-accent-foreground: var(--accent-foreground);
  --color-destructive: var(--destructive);
  --color-destructive-foreground: var(--destructive-foreground);
  --color-border: var(--border);
  --color-input: var(--input);
  --color-ring: var(--ring);
  
  /* Provider Colors */
  --color-provider-openai: var(--openai);
  --color-provider-anthropic: var(--anthropic);
  --color-provider-cohere: var(--cohere);
  
  /* CopilotCloud Palette Colors */
  --color-palette-grey-0: #FFFFFF;
  --color-palette-grey-25: #FAFCFA;
  --color-palette-grey-100: #F7F7F9;
  --color-palette-grey-200: #F0F0F4;
  --color-palette-grey-300: #E9E9EF;
  --color-palette-grey-400: #E2E2EA;
  --color-palette-grey-500: #DBDBE5;
  --color-palette-grey-600: #AFAFB7;
  --color-palette-grey-700: #838389;
  --color-palette-grey-800: #575758;
  --color-palette-grey-900: #2B2B2B;
  --color-palette-grey-1000: #010507;
  
  --color-palette-mint-40030: rgba(133,224,206,0.3);
  --color-palette-mint-400: #85E0CE;
  --color-palette-mint-800: #1B936F;
  
  --color-palette-lilac-40010: rgba(190,194,255,0.1);
  --color-palette-lilac-40020: rgba(190,194,255,0.2);
  --color-palette-lilac-40030: rgba(190,194,255,0.3);
  --color-palette-lilac-400: #BEC2FF;
  
  --color-palette-yellow-40030: rgba(255,243,136,0.3);
  --color-palette-yellow-400: #FFF388;
  
  --color-palette-orange-40020: rgba(255,172,77,0.2);
  --color-palette-orange-400: #FFAC4D;
  
  --color-palette-surface-main: #DEDEE9;
  --color-palette-surface-solidEquivalentDefault70: #F8F8FB;
  --color-palette-surface-default70: rgba(255,255,255,0.7);
  --color-palette-surface-default50: rgba(255,255,255,0.5);
  --color-palette-surface-default30: rgba(255,255,255,0.3);
  --color-palette-surface-container: #FFFFFF;
  --color-palette-surface-containerHovered: #FAFCFA;
  --color-palette-surface-containerFocusedPressed: rgba(190,194,255,0.1);
  --color-palette-surface-containerActive: #BEC2FF1A;
  --color-palette-surface-containerActiveHovered: rgba(190,194,255,0.2);
  --color-palette-surface-containerActiveFocused: rgba(190,194,255,0.3);
  --color-palette-surface-containerMint: #B5E0CE;
  --color-palette-surface-containerMint30: rgba(181,224,206,0.3);
  --color-palette-surface-containerLilac: #BEC2FF;
  --color-palette-surface-containerInvert: #010507;
  --color-palette-surface-background: #DBDBE5;
  --color-palette-surface-progressBarEmpty: #0105071A;
  --color-palette-surface-progressBarFull: #189370;
  --color-palette-surface-surfaceActionFilledHoveredAndFocused: #2B2B2B;
  --color-palette-surface-surfaceActionFilledPressed: #57575B;
  --color-palette-surface-containerPressed: #BEC2FF4D;
  --color-palette-surface-containerEnabledSolidEquivalent: #F8F9FF;
  --color-palette-surface-containerPressedHoverSolidEquivalent: #F1F2FF;
  --color-palette-surface-containerActivePressedSolidEquivalent: #E5E7FD;
  --color-palette-surface-containerHoveredAndFocused: #F0F0F4;
  --color-palette-surface-actionGhostHoveredAndFocused: #0105070D;
  
  --color-palette-text-primary: #010507;
  --color-palette-text-secondary: #57575B;
  --color-palette-text-disabled: #838389;
  --color-palette-text-invert: #FFFFFF;
  --color-palette-text-details: #189370;
  --color-palette-text-title: #3C464A;
  --color-palette-text-progressBar: #525252;
  --color-palette-text-link: #0D2E41;
  
  --color-palette-icon-default: #010507;
  --color-palette-icon-disabled: #838389;
  --color-palette-icon-invert: #FFFFFF;
  
  --color-palette-border-default: #FFFFFF;
  --color-palette-border-container: #DBDBE5;
  --color-palette-border-actionEnabled: #BEC2FF;
  --color-palette-border-divider: #DBDBE5;
  
  --color-palette-gradient-primary: linear-gradient(90deg, #85E0CE 0%, #FFF388 100%);
  
  /* CopilotCloud Spacing */
  --spacing-spacing-1: 4px;
  --spacing-spacing-2: 8px;
  --spacing-spacing-3: 12px;
  --spacing-spacing-4: 16px;
  --spacing-spacing-5: 20px;
  --spacing-spacing-6: 24px;
  --spacing-spacing-7: 28px;
  --spacing-spacing-8: 32px;
  --spacing-spacing-9: 36px;
  --spacing-spacing-10: 40px;
  --spacing-spacing-11: 44px;
  --spacing-spacing-12: 48px;
  --spacing-spacing-13: 52px;
  --spacing-spacing-14: 56px;
  --spacing-spacing-15: 60px;
  --spacing-spacing-16: 64px;
  --spacing-spacing-17: 68px;
  --spacing-spacing-18: 72px;
  
  /* CopilotCloud Border Radius */
  --radius-xs: 4px;
  --radius-sm: 8px;
  --radius-md: 12px;
  --radius-lg: 16px;
  --radius-xl: 24px;
  --radius-2xl: 48px;
  --radius-3xl: 200px;
  
  /* Font Families */
  --font-family-sans: 'Plus Jakarta Sans', ui-sans-serif, system-ui, sans-serif;
  --font-family-mono: 'Spline Sans Mono', ui-monospace, SFMono-Regular, monospace;
  
  /* Elevation/Shadows */
  --shadow-sm: 0px 1px 3px 0px rgba(1, 5, 7, 0.08);
  --shadow-md: 0px 6px 6px -2px rgba(1, 5, 7, 0.08);
  --shadow-lg: 0px 16px 24px -8px rgba(1, 5, 7, 0.12);
  --shadow-xl: 0px 24px 32px -12px rgba(1, 5, 7, 0.16);
}

:root {
  --background: oklch(1 0 0);
  --foreground: oklch(0.145 0 0);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.145 0 0);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.145 0 0);
  --primary: oklch(0.205 0 0);
  --primary-foreground: oklch(0.985 0 0);
  --secondary: oklch(0.97 0 0);
  --secondary-foreground: oklch(0.205 0 0);
  --muted: oklch(0.97 0 0);
  --muted-foreground: oklch(0.556 0 0);
  --accent: oklch(0.97 0 0);
  --accent-foreground: oklch(0.205 0 0);
  --destructive: oklch(0.577 0.245 27.325);
  --destructive-foreground: oklch(0.577 0.245 27.325);
  --border: oklch(0.922 0 0);
  --input: oklch(0.922 0 0);
  --ring: oklch(0.708 0 0);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --radius: 0.5rem;
  --sidebar: oklch(0.985 0 0);
  --sidebar-foreground: oklch(0.145 0 0);
  --sidebar-primary: oklch(0.205 0 0);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.97 0 0);
  --sidebar-accent-foreground: oklch(0.205 0 0);
  --sidebar-border: oklch(0.922 0 0);
  --sidebar-ring: oklch(0.708 0 0);
  
  /* Provider Colors */
  --openai: hsl(160 70% 50%); /* Bright green */
  --anthropic: hsl(240 80% 60%); /* Bright blue */
  --cohere: hsl(0 80% 60%); /* Bright red */
  
}

.dark {
  --background: hsl(222.2 84% 4.9%);
  --foreground: hsl(210 40% 98%);
  
  --card: hsl(222.2 84% 4.9%);
  --card-foreground: hsl(210 40% 98%);
  
  --popover: hsl(222.2 84% 4.9%);
  --popover-foreground: hsl(210 40% 98%);
  
  --primary: hsl(210 40% 98%);
  --primary-foreground: hsl(222.2 47.4% 11.2%);
  
  --secondary: hsl(217.2 32.6% 17.5%);
  --secondary-foreground: hsl(210 40% 98%);
  
  --muted: hsl(217.2 32.6% 17.5%);
  --muted-foreground: hsl(215 20.2% 65.1%);
  
  --accent: hsl(217.2 32.6% 17.5%);
  --accent-foreground: hsl(210 40% 98%);
  
  --destructive: hsl(0 62.8% 50.6%);
  --destructive-foreground: hsl(210 40% 98%);
  
  --border: hsl(217.2 32.6% 17.5%);
  --input: hsl(217.2 32.6% 17.5%);
  --ring: hsl(212.7 26.8% 83.9%);
  
  --sidebar: hsl(222.2 84% 4.9%);
  --sidebar-foreground: hsl(210 40% 98%);
  --sidebar-primary: hsl(210 40% 98%);
  --sidebar-primary-foreground: hsl(222.2 47.4% 11.2%);
  --sidebar-accent: hsl(217.2 32.6% 17.5%);
  --sidebar-accent-foreground: hsl(210 40% 98%);
  --sidebar-border: hsl(217.2 32.6% 17.5%);
  --sidebar-ring: hsl(212.7 26.8% 83.9%);
  
  --chart-1: hsl(240 80% 60%);
  --chart-2: hsl(160 70% 50%);
  --chart-3: hsl(0 80% 60%);
  --chart-4: hsl(280 70% 60%);
  --chart-5: hsl(30 80% 60%);
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground font-sans;
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/layout.tsx
================================================
import { Suspense } from "react";
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";
import "@copilotkit/react-ui/styles.css";
import { ThemeProvider } from "@/components/theme-provider";
import { MainLayout } from "@/components/layout/main-layout";
import { URLParamsProvider } from "@/contexts/url-params-context";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Demo Viewer by CopilotKit",
  description: "Demo Viewer by CopilotKit",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en" suppressHydrationWarning>
      <body className={`${geistSans.variable} ${geistMono.variable} antialiased`}>
        <ThemeProvider
          attribute="class"
          defaultTheme="light"
          enableSystem={false}
          themes={['light']}
          disableTransitionOnChange
        >
          <Suspense>
            <URLParamsProvider>
              <MainLayout>{children}</MainLayout>
            </URLParamsProvider>
          </Suspense>
        </ThemeProvider>
      </body>
    </html>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/page.tsx
================================================
"use client";

import React from "react";

export default function Home() {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-center p-8">
      <h1 className="text-base font-normal text-muted-foreground mb-4">
        Select an integration to get started
      </h1>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/not-found.tsx
================================================
import React from "react";
import Link from "next/link";

export default function NotFound() {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-center p-8">
      <h1 className="text-4xl font-bold text-center mb-4">Integration Not Found</h1>
      <p className="text-muted-foreground mb-6 text-center">
        The integration you&apos;re looking for doesn&apos;t exist.
      </p>
      <Link
        href="/"
        className="px-4 py-2 bg-primary text-primary-foreground rounded-md hover:bg-primary/90 transition-colors"
      >
        Back to Home
      </Link>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/page.tsx
================================================
import React from "react";
import { menuIntegrations } from "@/menu";
import { notFound } from "next/navigation";
import Readme from "@/components/readme/readme";
import path from "path";
import fs from "fs";

export async function generateStaticParams() {
  return menuIntegrations.map((integration) => ({
    integrationId: integration.id,
  }));
}

interface IntegrationPageProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function IntegrationPage({ params }: IntegrationPageProps) {
  const { integrationId } = React.use(params);

  // Find the integration by ID
  const integration = menuIntegrations.find((integration) => integration.id === integrationId);

  const readmePath = path.join(
    process.cwd(),
    "..",
    "..",
    "integrations",
    integrationId,
    "README.md",
  );

  let md: string | undefined = undefined;

  if (fs.existsSync(readmePath)) {
    md = fs.readFileSync(readmePath, "utf8");
  }

  // If integration not found, show 404
  if (!integration) {
    notFound();
  }

  if (!md) {
    return (
      <div className="flex-1 h-screen w-full flex flex-col items-center justify-start pt-16 px-8">
        <div className="w-full max-w-4xl">
          <h1 className="text-4xl font-bold text-center">{integration.name}</h1>
          <p className="text-muted-foreground mt-4 text-center">Integration ID: {integration.id}</p>
        </div>
      </div>
    );
  } else {
    return <Readme content={md} />;
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/layout.tsx
================================================
'use client';

import React, { useMemo } from "react";
import { usePathname } from "next/navigation";
import filesJSON from '../../../files.json'
import Readme from "@/components/readme/readme";
import CodeViewer from "@/components/code-viewer/code-viewer";
import { useURLParams } from "@/contexts/url-params-context";

type FileItem = {
  name: string;
  content: string;
  language: string;
  type: string;
};

type FilesJsonType = Record<string, FileItem[]>;

interface Props {
  params: Promise<{
    integrationId: string;
  }>;
  children: React.ReactNode
}

export default function FeatureLayout({ children, params }: Props) {
  const { integrationId } = React.use(params);
  const pathname = usePathname();
  const { view } = useURLParams();

  // Extract featureId from pathname: /[integrationId]/feature/[featureId]
  const pathParts = pathname.split('/');
  const featureId = pathParts[pathParts.length - 1]; // Last segment is the featureId

  const files = (filesJSON as FilesJsonType)[`${integrationId}::${featureId}`] || [];

  const readme = files.find((file) => file?.name?.includes(".mdx")) || null;
  const codeFiles = files.filter(
    (file) => file && Object.keys(file).length > 0 && !file.name?.includes(".mdx"),
  );


  const content = useMemo(() => {
    switch (view) {
      case "code":
        return (
          <CodeViewer codeFiles={codeFiles} />
        )
      case "readme":
        return (
          <Readme content={readme?.content ?? ''} />
        )
      default:
        return (
          <div className="h-full">{children}</div>
        )
    }
  }, [children, codeFiles, readme, view])

  return (
    <div className="bg-white rounded-lg w-full h-full overflow-hidden">
      <div className="flex flex-col h-full overflow-auto">
        {content}
      </div>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/README.mdx
================================================
# 🤖 Agentic Chat with Frontend Tools

## What This Demo Shows

This demo showcases CopilotKit's **agentic chat** capabilities with **frontend
tool integration**:

1. **Natural Conversation**: Chat with your Copilot in a familiar chat interface
2. **Frontend Tool Execution**: The Copilot can directly interacts with your UI
   by calling frontend functions
3. **Seamless Integration**: Tools defined in the frontend and automatically
   discovered and made available to the agent

## How to Interact

Try asking your Copilot to:

- "Can you change the background color to something more vibrant?"
- "Make the background a blue to purple gradient"
- "Set the background to a sunset-themed gradient"
- "Change it back to a simple light color"

You can also chat about other topics - the agent will respond conversationally
while having the ability to use your UI tools when appropriate.

## ✨ Frontend Tool Integration in Action

**What's happening technically:**

- The React component defines a frontend function using `useCopilotAction`
- CopilotKit automatically exposes this function to the agent
- When you make a request, the agent determines whether to use the tool
- The agent calls the function with the appropriate parameters
- The UI immediately updates in response

**What you'll see in this demo:**

- The Copilot understands requests to change the background
- It generates CSS values for colors and gradients
- When it calls the tool, the background changes instantly
- The agent provides a conversational response about the changes it made

This technique of exposing frontend functions to your Copilot can be extended to
any UI manipulation you want to enable, from theme changes to data filtering,
navigation, or complex UI state management!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/page.tsx
================================================
"use client";
import React, { useState } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";

interface AgenticChatProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticChat: React.FC<AgenticChatProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_chat"
    >
      <Chat />
    </CopilotKit>
  );
};

const Chat = () => {
  const [background, setBackground] = useState<string>("--copilot-kit-background-color");

  useCopilotAction({
    name: "change_background",
    description:
      "Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.",
    parameters: [
      {
        name: "background",
        type: "string",
        description: "The background. Prefer gradients.",
      },
    ],
    handler: ({ background }) => {
      setBackground(background);
      return {
        status: "success",
        message: `Background changed to ${background}`,
      };
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full" style={{ background }}>
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{ initial: "Hi, I'm an agent. Want to chat?" }}
        />
      </div>
    </div>
  );
};

export default AgenticChat;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}
  
.copilotKitChat {
  background-color: #fff !important;
}
  


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/README.mdx
================================================
# 🤖 Agentic Chat with Reasoning

## What This Demo Shows

This demo showcases CopilotKit's **agentic chat** capabilities with **frontend
tool integration**:

1. **Natural Conversation**: Chat with your Copilot in a familiar chat interface
2. **Frontend Tool Execution**: The Copilot can directly interacts with your UI
   by calling frontend functions
3. **Seamless Integration**: Tools defined in the frontend and automatically
   discovered and made available to the agent

## How to Interact

Try asking your Copilot to:

- "Can you change the background color to something more vibrant?"
- "Make the background a blue to purple gradient"
- "Set the background to a sunset-themed gradient"
- "Change it back to a simple light color"

You can also chat about other topics - the agent will respond conversationally
while having the ability to use your UI tools when appropriate.

## ✨ Frontend Tool Integration in Action

**What's happening technically:**

- The React component defines a frontend function using `useCopilotAction`
- CopilotKit automatically exposes this function to the agent
- When you make a request, the agent determines whether to use the tool
- The agent calls the function with the appropriate parameters
- The UI immediately updates in response

**What you'll see in this demo:**

- The Copilot understands requests to change the background
- It generates CSS values for colors and gradients
- When it calls the tool, the background changes instantly
- The agent provides a conversational response about the changes it made

This technique of exposing frontend functions to your Copilot can be extended to
any UI manipulation you want to enable, from theme changes to data filtering,
navigation, or complex UI state management!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/page.tsx
================================================
"use client";
import React, { useState } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { ChevronDown } from "lucide-react";
import { Button } from "@/components/ui/button";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from "@/components/ui/dropdown-menu";

interface AgenticChatProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticChat: React.FC<AgenticChatProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_chat_reasoning"
    >
      <Chat />
    </CopilotKit>
  );
};

interface AgentState {
  model: string;
}

const Chat = () => {
  const [background, setBackground] = useState<string>("--copilot-kit-background-color");
  const { state: agentState, setState: setAgentState } = useCoAgent<AgentState>({
    name: "agentic_chat_reasoning",
    initialState: {
      model: "OpenAI",
    },
  });

  // Initialize model if not set
  const selectedModel = agentState?.model || "OpenAI";

  const handleModelChange = (model: string) => {
    setAgentState({ model });
  };

  useCopilotAction({
    name: "change_background",
    description:
      "Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.",
    parameters: [
      {
        name: "background",
        type: "string",
        description: "The background. Prefer gradients.",
      },
    ],
    handler: ({ background }) => {
      setBackground(background);
    },
  });

  return (
    <div className="flex flex-col h-full w-full" style={{ background }}>
      {/* Reasoning Model Dropdown */}
      <div className="h-[65px] border-b border-gray-200 dark:border-gray-700">
        <div className="h-full flex items-center justify-center">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
              Reasoning Model:
            </span>
            <DropdownMenu>
              <DropdownMenuTrigger asChild>
                <Button variant="outline" className="w-[140px] justify-between">
                  {selectedModel}
                  <ChevronDown className="h-4 w-4 opacity-50" />
                </Button>
              </DropdownMenuTrigger>
              <DropdownMenuContent className="w-[140px]">
                <DropdownMenuLabel>Select Model</DropdownMenuLabel>
                <DropdownMenuSeparator />
                <DropdownMenuItem onClick={() => handleModelChange("OpenAI")}>
                  OpenAI
                </DropdownMenuItem>
                <DropdownMenuItem onClick={() => handleModelChange("Anthropic")}>
                  Anthropic
                </DropdownMenuItem>
                <DropdownMenuItem onClick={() => handleModelChange("Gemini")}>
                  Gemini
                </DropdownMenuItem>
              </DropdownMenuContent>
            </DropdownMenu>
          </div>
        </div>
      </div>

      {/* Chat Container */}
      <div className="flex-1 flex justify-center items-center p-4">
        <div className="w-8/10 h-full rounded-lg">
          <CopilotChat
            className="h-full rounded-2xl"
            labels={{ initial: "Hi, I'm an agent. Want to chat?" }}
          />
        </div>
      </div>
    </div>
  );
};

export default AgenticChat;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}
  
.copilotKitChat {
  background-color: #fff !important;
}
  


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/README.mdx
================================================
# 🚀 Agentic Generative UI Task Executor

## What This Demo Shows

This demo showcases CopilotKit's **agentic generative UI** capabilities:

1. **Real-time Status Updates**: The Copilot provides live feedback as it works
   through complex tasks
2. **Long-running Task Execution**: See how agents can handle extended processes
   with continuous feedback
3. **Dynamic UI Generation**: The interface updates in real-time to reflect the
   agent's progress

## How to Interact

Simply ask your Copilot to perform any moderately complex task:

- "Make me a sandwich"
- "Plan a vacation to Japan"
- "Create a weekly workout routine"

The Copilot will break down the task into steps and begin "executing" them,
providing real-time status updates as it progresses.

## ✨ Agentic Generative UI in Action

**What's happening technically:**

- The agent analyzes your request and creates a detailed execution plan
- Each step is processed sequentially with realistic timing
- Status updates are streamed to the frontend using CopilotKit's streaming
  capabilities
- The UI dynamically renders these updates without page refreshes
- The entire flow is managed by the agent, requiring no manual intervention

**What you'll see in this demo:**

- The Copilot breaks your task into logical steps
- A status indicator shows the current progress
- Each step is highlighted as it's being executed
- Detailed status messages explain what's happening at each moment
- Upon completion, you receive a summary of the task execution

This pattern of providing real-time progress for long-running tasks is perfect
for scenarios where users benefit from transparency into complex processes -
from data analysis to content creation, system configurations, or multi-stage
workflows!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/page.tsx
================================================
"use client";
import React from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgentStateRender } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { useTheme } from "next-themes";

interface AgenticGenerativeUIProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticGenerativeUI: React.FC<AgenticGenerativeUIProps> = ({ params }) => {
  const { integrationId } = React.use(params);
  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_generative_ui"
    >
      <Chat />
    </CopilotKit>
  );
};

interface AgentState {
  steps: {
    description: string;
    status: "pending" | "completed";
  }[];
}

const Chat = () => {
  const { theme } = useTheme();
  useCoAgentStateRender<AgentState>({
    name: "agentic_generative_ui",
    render: ({ state }) => {
      if (!state.steps || state.steps.length === 0) {
        return null;
      }

      const completedCount = state.steps.filter(step => step.status === "completed").length;
      const progressPercentage = (completedCount / state.steps.length) * 100;

      return (
        <div className="flex">
          <div 
          data-testid="task-progress"
          className={`relative rounded-xl w-[700px] p-6 shadow-lg backdrop-blur-sm ${
            theme === "dark" 
              ? "bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white border border-slate-700/50 shadow-2xl"
              : "bg-gradient-to-br from-white via-gray-50 to-white text-gray-800 border border-gray-200/80"
          }`}>
            {/* Header */}
            <div className="mb-5">
              <div className="flex items-center justify-between mb-3">
                <h3 className="text-xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
                  Task Progress
                </h3>
                <div className={`text-sm ${theme === "dark" ? "text-slate-400" : "text-gray-500"}`}>
                  {completedCount}/{state.steps.length} Complete
                </div>
              </div>
              
              {/* Progress Bar */}
              <div className={`relative h-2 rounded-full overflow-hidden ${theme === "dark" ? "bg-slate-700" : "bg-gray-200"}`}>
                <div 
                  className="absolute top-0 left-0 h-full bg-gradient-to-r from-blue-500 to-purple-500 rounded-full transition-all duration-1000 ease-out"
                  style={{ width: `${progressPercentage}%` }}
                />
                <div className={`absolute top-0 left-0 h-full w-full bg-gradient-to-r from-transparent to-transparent animate-pulse ${
                  theme === "dark" ? "via-white/20" : "via-white/40"
                }`} />
              </div>
            </div>

            {/* Steps */}
            <div className="space-y-2">
              {state.steps.map((step, index) => {
                const isCompleted = step.status === "completed";
                const isCurrentPending = step.status === "pending" && 
                  index === state.steps.findIndex((s) => s.status === "pending");
                const isFuturePending = step.status === "pending" && !isCurrentPending;

                return (
                  <div 
                    key={index} 
                    className={`relative flex items-center p-2.5 rounded-lg transition-all duration-500 ${
                      isCompleted 
                        ? theme === "dark" 
                          ? "bg-gradient-to-r from-green-900/30 to-emerald-900/20 border border-green-500/30"
                          : "bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200/60"
                        : isCurrentPending
                        ? theme === "dark"
                          ? "bg-gradient-to-r from-blue-900/40 to-purple-900/30 border border-blue-500/50 shadow-lg shadow-blue-500/20"
                          : "bg-gradient-to-r from-blue-50 to-purple-50 border border-blue-200/60 shadow-md shadow-blue-200/50"
                        : theme === "dark"
                          ? "bg-slate-800/50 border border-slate-600/30"
                          : "bg-gray-50/50 border border-gray-200/60"
                    }`}
                  >
                    {/* Connector Line */}
                    {index < state.steps.length - 1 && (
                      <div className={`absolute left-5 top-full w-0.5 h-2 bg-gradient-to-b ${
                        theme === "dark" ? "from-slate-500 to-slate-600" : "from-gray-300 to-gray-400"
                      }`} />
                    )}

                    {/* Status Icon */}
                    <div className={`flex-shrink-0 w-6 h-6 rounded-full flex items-center justify-center mr-2 ${
                      isCompleted 
                        ? theme === "dark"
                          ? "bg-gradient-to-br from-green-500 to-emerald-600 shadow-lg shadow-green-500/30"
                          : "bg-gradient-to-br from-green-500 to-emerald-600 shadow-md shadow-green-200"
                        : isCurrentPending
                        ? theme === "dark"
                          ? "bg-gradient-to-br from-blue-500 to-purple-600 shadow-lg shadow-blue-500/30"
                          : "bg-gradient-to-br from-blue-500 to-purple-600 shadow-md shadow-blue-200"
                        : theme === "dark"
                          ? "bg-slate-700 border border-slate-600"
                          : "bg-gray-300 border border-gray-400"
                    }`}>
                      {isCompleted ? (
                        <CheckIcon />
                      ) : isCurrentPending ? (
                        <SpinnerIcon />
                      ) : (
                        <ClockIcon theme={theme} />
                      )}
                    </div>

                    {/* Step Content */}
                    <div className="flex-1 min-w-0">
                      <div 
                      data-testid="task-step-text"
                      className={`font-semibold transition-all duration-300 text-sm ${
                        isCompleted 
                          ? theme === "dark" ? "text-green-300" : "text-green-700"
                          : isCurrentPending
                          ? theme === "dark" ? "text-blue-300 text-base" : "text-blue-700 text-base"
                          : theme === "dark" ? "text-slate-400" : "text-gray-500"
                      }`}>
                        {step.description}
                      </div>
                      {isCurrentPending && (
                        <div className={`text-sm mt-1 animate-pulse ${
                          theme === "dark" ? "text-blue-400" : "text-blue-600"
                        }`}>
                          Processing...
                        </div>
                      )}
                    </div>

                    {/* Animated Background for Current Step */}
                    {isCurrentPending && (
                      <div className={`absolute inset-0 rounded-lg bg-gradient-to-r animate-pulse ${
                        theme === "dark" 
                          ? "from-blue-500/10 to-purple-500/10" 
                          : "from-blue-100/50 to-purple-100/50"
                      }`} />
                    )}
                  </div>
                );
              })}
            </div>

            {/* Decorative Elements */}
            <div className={`absolute top-3 right-3 w-16 h-16 rounded-full blur-xl ${
              theme === "dark" 
                ? "bg-gradient-to-br from-blue-500/10 to-purple-500/10" 
                : "bg-gradient-to-br from-blue-200/30 to-purple-200/30"
            }`} />
            <div className={`absolute bottom-3 left-3 w-12 h-12 rounded-full blur-xl ${
              theme === "dark" 
                ? "bg-gradient-to-br from-green-500/10 to-emerald-500/10" 
                : "bg-gradient-to-br from-green-200/30 to-emerald-200/30"
            }`} />
          </div>
        </div>
      );
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full">
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{
            initial:
              "Hi, I'm an agent! I can help you with anything you need and will show you progress as I work. What can I do for you?",
          }}
        />
      </div>
    </div>
  );
};

// Enhanced Icons
function CheckIcon() {
  return (
    <svg className="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={3} d="M5 13l4 4L19 7" />
    </svg>
  );
}

function SpinnerIcon() {
  return (
    <svg
      className="w-4 h-4 animate-spin text-white"
      xmlns="http://www.w3.org/2000/svg"
      fill="none"
      viewBox="0 0 24 24"
    >
      <circle
        className="opacity-25"
        cx="12"
        cy="12"
        r="10"
        stroke="currentColor"
        strokeWidth="4"
      />
      <path
        className="opacity-75"
        fill="currentColor"
        d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
      />
    </svg>
  );
}

function ClockIcon({ theme }: { theme?: string }) {
  return (
    <svg className={`w-3 h-3 ${theme === "dark" ? "text-slate-400" : "text-gray-600"}`} fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <circle cx="12" cy="12" r="10" strokeWidth="2"/>
      <polyline points="12,6 12,12 16,14" strokeWidth="2"/>
    </svg>
  );
}

export default AgenticGenerativeUI;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}

.copilotKitChat {
  background-color: #fff !important;
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/README.mdx
================================================
# 🤝 Human-in-the-Loop Task Planner

## What This Demo Shows

This demo showcases CopilotKit's **human-in-the-loop** capabilities:

1. **Collaborative Planning**: The Copilot generates task steps and lets you
   decide which ones to perform
2. **Interactive Decision Making**: Select or deselect steps to customize the
   execution plan
3. **Adaptive Responses**: The Copilot adapts its execution based on your
   choices, even handling missing steps

## How to Interact

Try these steps to experience the demo:

1. Ask your Copilot to help with a task, such as:

   - "Make me a sandwich"
   - "Plan a weekend trip"
   - "Organize a birthday party"
   - "Start a garden"

2. Review the suggested steps provided by your Copilot

3. Select or deselect steps using the checkboxes to customize the plan

   - Try removing essential steps to see how the Copilot adapts!

4. Click "Execute Plan" to see the outcome based on your selections

## ✨ Human-in-the-Loop Magic in Action

**What's happening technically:**

- The agent analyzes your request and breaks it down into logical steps
- These steps are presented to you through a dynamic UI component
- Your selections are captured as user input
- The agent considers your choices when executing the plan
- The agent adapts to missing steps with creative problem-solving

**What you'll see in this demo:**

- The Copilot provides a detailed, step-by-step plan for your task
- You have complete control over which steps to include
- If you remove essential steps, the Copilot provides entertaining and creative
  workarounds
- The final execution reflects your choices, showing how human input shapes the
  outcome
- Each response is tailored to your specific selections

This human-in-the-loop pattern creates a powerful collaborative experience where
both human judgment and AI capabilities work together to achieve better results
than either could alone!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/page.tsx
================================================
"use client";
import React, { useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCopilotAction, useLangGraphInterrupt } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { useTheme } from "next-themes";

interface HumanInTheLoopProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const HumanInTheLoop: React.FC<HumanInTheLoopProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="human_in_the_loop"
    >
      <Chat integrationId={integrationId} />
    </CopilotKit>
  );
};

interface Step {
  description: string;
  status: "disabled" | "enabled" | "executing";
}

// Shared UI Components
const StepContainer = ({ theme, children }: { theme?: string; children: React.ReactNode }) => (
  <div 
  data-testid="select-steps"
  className="flex">
    <div className={`relative rounded-xl w-[600px] p-6 shadow-lg backdrop-blur-sm ${
      theme === "dark" 
        ? "bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white border border-slate-700/50 shadow-2xl"
        : "bg-gradient-to-br from-white via-gray-50 to-white text-gray-800 border border-gray-200/80"
    }`}>
      {children}
    </div>
  </div>
);

const StepHeader = ({ 
  theme, 
  enabledCount, 
  totalCount, 
  status, 
  showStatus = false 
}: { 
  theme?: string; 
  enabledCount: number; 
  totalCount: number; 
  status?: string;
  showStatus?: boolean;
}) => (
  <div className="mb-5">
    <div className="flex items-center justify-between mb-3">
      <h2 className="text-xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
        Select Steps
      </h2>
      <div className="flex items-center gap-3">
        <div className={`text-sm ${theme === "dark" ? "text-slate-400" : "text-gray-500"}`}>
          {enabledCount}/{totalCount} Selected
        </div>
        {showStatus && (
          <div className={`text-xs px-2 py-1 rounded-full font-medium ${
            status === "executing" 
              ? theme === "dark" 
                ? "bg-blue-900/30 text-blue-300 border border-blue-500/30"
                : "bg-blue-50 text-blue-600 border border-blue-200"
              : theme === "dark"
                ? "bg-slate-700 text-slate-300"
                : "bg-gray-100 text-gray-600"
          }`}>
            {status === "executing" ? "Ready" : "Waiting"}
          </div>
        )}
      </div>
    </div>
    
    <div className={`relative h-2 rounded-full overflow-hidden ${theme === "dark" ? "bg-slate-700" : "bg-gray-200"}`}>
      <div 
        className="absolute top-0 left-0 h-full bg-gradient-to-r from-blue-500 to-purple-500 rounded-full transition-all duration-500 ease-out"
        style={{ width: `${totalCount > 0 ? (enabledCount / totalCount) * 100 : 0}%` }}
      />
    </div>
  </div>
);

const StepItem = ({ 
  step, 
  theme, 
  status, 
  onToggle, 
  disabled = false 
}: { 
  step: { description: string; status: string }; 
  theme?: string; 
  status?: string;
  onToggle: () => void;
  disabled?: boolean;
}) => (
  <div className={`flex items-center p-3 rounded-lg transition-all duration-300 ${
    step.status === "enabled"
      ? theme === "dark" 
        ? "bg-gradient-to-r from-blue-900/20 to-purple-900/10 border border-blue-500/30"
        : "bg-gradient-to-r from-blue-50 to-purple-50 border border-blue-200/60"
      : theme === "dark"
        ? "bg-slate-800/30 border border-slate-600/30"
        : "bg-gray-50/50 border border-gray-200/40"
  }`}>
    <label 
    data-testid="step-item" 
    className="flex items-center cursor-pointer w-full">
      <div className="relative">
        <input
          type="checkbox"
          checked={step.status === "enabled"}
          onChange={onToggle}
          className="sr-only"
          disabled={disabled}
        />
        <div className={`w-5 h-5 rounded border-2 flex items-center justify-center transition-all duration-200 ${
          step.status === "enabled"
            ? "bg-gradient-to-br from-blue-500 to-purple-600 border-blue-500"
            : theme === "dark"
              ? "border-slate-400 bg-slate-700"
              : "border-gray-300 bg-white"
        } ${disabled ? "opacity-60" : ""}`}>
          {step.status === "enabled" && (
            <svg className="w-3 h-3 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={3} d="M5 13l4 4L19 7" />
            </svg>
          )}
        </div>
      </div>
      <span 
       data-testid="step-text"
       className={`ml-3 font-medium transition-all duration-300 ${
        step.status !== "enabled" && status != "inProgress"
          ? `line-through ${theme === "dark" ? "text-slate-500" : "text-gray-400"}`
          : theme === "dark" ? "text-white" : "text-gray-800"
      } ${disabled ? "opacity-60" : ""}`}>
        {step.description}
      </span>
    </label>
  </div>
);

const ActionButton = ({ 
  variant, 
  theme, 
  disabled, 
  onClick, 
  children 
}: { 
  variant: "primary" | "secondary" | "success" | "danger";
  theme?: string;
  disabled?: boolean;
  onClick: () => void;
  children: React.ReactNode;
}) => {
  const baseClasses = "px-6 py-3 rounded-lg font-semibold transition-all duration-200";
  const enabledClasses = "hover:scale-105 shadow-md hover:shadow-lg";
  const disabledClasses = "opacity-50 cursor-not-allowed";
  
  const variantClasses = {
    primary: "bg-gradient-to-r from-purple-500 to-purple-700 hover:from-purple-600 hover:to-purple-800 text-white shadow-lg hover:shadow-xl",
    secondary: theme === "dark"
      ? "bg-slate-700 hover:bg-slate-600 text-white border border-slate-600 hover:border-slate-500"
      : "bg-gray-100 hover:bg-gray-200 text-gray-800 border border-gray-300 hover:border-gray-400",
    success: "bg-gradient-to-r from-green-500 to-emerald-600 hover:from-green-600 hover:to-emerald-700 text-white shadow-lg hover:shadow-xl",
    danger: "bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white shadow-lg hover:shadow-xl"
  };

  return (
    <button
      className={`${baseClasses} ${disabled ? disabledClasses : enabledClasses} ${
        disabled && variant === "secondary" ? "bg-gray-200 text-gray-500" : 
        disabled && variant === "success" ? "bg-gray-400" :
        variantClasses[variant]
      }`}
      disabled={disabled}
      onClick={onClick}
    >
      {children}
    </button>
  );
};

const DecorativeElements = ({ 
  theme, 
  variant = "default" 
}: { 
  theme?: string; 
  variant?: "default" | "success" | "danger" 
}) => (
  <>
    <div className={`absolute top-3 right-3 w-16 h-16 rounded-full blur-xl ${
      variant === "success"
        ? theme === "dark" 
          ? "bg-gradient-to-br from-green-500/10 to-emerald-500/10" 
          : "bg-gradient-to-br from-green-200/30 to-emerald-200/30"
        : variant === "danger"
          ? theme === "dark" 
            ? "bg-gradient-to-br from-red-500/10 to-pink-500/10" 
            : "bg-gradient-to-br from-red-200/30 to-pink-200/30"
          : theme === "dark" 
            ? "bg-gradient-to-br from-blue-500/10 to-purple-500/10" 
            : "bg-gradient-to-br from-blue-200/30 to-purple-200/30"
    }`} />
    <div className={`absolute bottom-3 left-3 w-12 h-12 rounded-full blur-xl ${
      variant === "default"
        ? theme === "dark" 
          ? "bg-gradient-to-br from-purple-500/10 to-pink-500/10" 
          : "bg-gradient-to-br from-purple-200/30 to-pink-200/30"
        : "opacity-50"
    }`} />
  </>
);
const InterruptHumanInTheLoop: React.FC<{
  event: { value: { steps: Step[] } };
  resolve: (value: string) => void;
}> = ({ event, resolve }) => {
  const { theme } = useTheme();
  
  // Parse and initialize steps data
  let initialSteps: Step[] = [];
  if (event.value && event.value.steps && Array.isArray(event.value.steps)) {
    initialSteps = event.value.steps.map((step: any) => ({
      description: typeof step === "string" ? step : step.description || "",
      status: typeof step === "object" && step.status ? step.status : "enabled",
    }));
  }

  const [localSteps, setLocalSteps] = useState<Step[]>(initialSteps);
  const enabledCount = localSteps.filter(step => step.status === "enabled").length;

  const handleStepToggle = (index: number) => {
    setLocalSteps((prevSteps) =>
      prevSteps.map((step, i) =>
        i === index
          ? { ...step, status: step.status === "enabled" ? "disabled" : "enabled" }
          : step,
      ),
    );
  };

  const handlePerformSteps = () => {
    const selectedSteps = localSteps
      .filter((step) => step.status === "enabled")
      .map((step) => step.description);
    resolve("The user selected the following steps: " + selectedSteps.join(", "));
  };

  return (
    <StepContainer theme={theme}>
      <StepHeader theme={theme} enabledCount={enabledCount} totalCount={localSteps.length} />
      
      <div className="space-y-3 mb-6">
        {localSteps.map((step, index) => (
          <StepItem
            key={index}
            step={step}
            theme={theme}
            onToggle={() => handleStepToggle(index)}
          />
        ))}
      </div>

      <div className="flex justify-center">
        <ActionButton
          variant="primary"
          theme={theme}
          onClick={handlePerformSteps}
        >
          <span className="text-lg">✨</span>
          Perform Steps
          <span className={`ml-1 px-2 py-1 rounded-full text-xs font-bold ${
            theme === "dark" ? "bg-purple-800/50" : "bg-purple-600/20"
          }`}>
            {enabledCount}
          </span>
        </ActionButton>
      </div>

      <DecorativeElements theme={theme} />
    </StepContainer>
  );
};

const Chat = ({ integrationId }: { integrationId: string }) => {
  // Langgraph uses it's own hook to handle human-in-the-loop interactions via langgraph interrupts,
  // This hook won't do anything for other integrations.
  useLangGraphInterrupt({
    render: ({ event, resolve }) => <InterruptHumanInTheLoop event={event} resolve={resolve} />,
  });
  useCopilotAction({
    name: "generate_task_steps",
    description: "Generates a list of steps for the user to perform",
    parameters: [
      {
        name: "steps",
        type: "object[]",
        attributes: [
          {
            name: "description",
            type: "string",
          },
          {
            name: "status",
            type: "string",
            enum: ["enabled", "disabled", "executing"],
          },
        ],
      },
    ],
    // Langgraph uses it's own hook to handle human-in-the-loop interactions via langgraph interrupts,
    // so don't use this action for langgraph integration.
    available: ['langgraph', 'langgraph-fastapi', 'langgraph-typescript'].includes(integrationId) ? 'disabled' : 'enabled',
    renderAndWaitForResponse: ({ args, respond, status }) => {
      return <StepsFeedback args={args} respond={respond} status={status} />;
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full">
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{
            initial:
              "Hi, I'm an agent specialized in helping you with your tasks. How can I help you?",
          }}
        />
      </div>
    </div>
  );
};

const StepsFeedback = ({ args, respond, status }: { args: any; respond: any; status: any }) => {
  const { theme } = useTheme();
  const [localSteps, setLocalSteps] = useState<Step[]>([]);
  const [accepted, setAccepted] = useState<boolean | null>(null);

  useEffect(() => {
    if (status === "executing" && localSteps.length === 0) {
      setLocalSteps(args.steps);
    }
  }, [status, args.steps, localSteps]);

  if (args.steps === undefined || args.steps.length === 0) {
    return <></>;
  }

  const steps = localSteps.length > 0 ? localSteps : args.steps;
  const enabledCount = steps.filter((step: any) => step.status === "enabled").length;

  const handleStepToggle = (index: number) => {
    setLocalSteps((prevSteps) =>
      prevSteps.map((step, i) =>
        i === index
          ? { ...step, status: step.status === "enabled" ? "disabled" : "enabled" }
          : step,
      ),
    );
  };

  const handleReject = () => {
    if (respond) {
      setAccepted(false);
      respond({ accepted: false });
    }
  };

  const handleConfirm = () => {
    if (respond) {
      setAccepted(true);
      respond({ accepted: true, steps: localSteps.filter(step => step.status === "enabled")});
    }
  };

  return (
    <StepContainer theme={theme}>
      <StepHeader 
        theme={theme} 
        enabledCount={enabledCount} 
        totalCount={steps.length} 
        status={status}
        showStatus={true}
      />
      
      <div className="space-y-3 mb-6">
        {steps.map((step: any, index: any) => (
          <StepItem
            key={index}
            step={step}
            theme={theme}
            status={status}
            onToggle={() => handleStepToggle(index)}
            disabled={status !== "executing"}
          />
        ))}
      </div>

      {/* Action Buttons - Different logic from InterruptHumanInTheLoop */}
      {accepted === null && (
        <div className="flex justify-center gap-4">
          <ActionButton
            variant="secondary"
            theme={theme}
            disabled={status !== "executing"}
            onClick={handleReject}
          >
            <span className="mr-2">✗</span>
            Reject
          </ActionButton>
          <ActionButton
            variant="success"
            theme={theme}
            disabled={status !== "executing"}
            onClick={handleConfirm}
          >
            <span className="mr-2">✓</span>
            Confirm
            <span className={`ml-2 px-2 py-1 rounded-full text-xs font-bold ${
              theme === "dark" ? "bg-green-800/50" : "bg-green-600/20"
            }`}>
              {enabledCount}
            </span>
          </ActionButton>
        </div>
      )}

      {/* Result State - Unique to StepsFeedback */}
      {accepted !== null && (
        <div className="flex justify-center">
          <div className={`px-6 py-3 rounded-lg font-semibold flex items-center gap-2 ${
            accepted 
              ? theme === "dark"
                ? "bg-green-900/30 text-green-300 border border-green-500/30"
                : "bg-green-50 text-green-700 border border-green-200"
              : theme === "dark"
                ? "bg-red-900/30 text-red-300 border border-red-500/30"
                : "bg-red-50 text-red-700 border border-red-200"
          }`}>
            <span className="text-lg">{accepted ? "✓" : "✗"}</span>
            {accepted ? "Accepted" : "Rejected"}
          </div>
        </div>
      )}

      <DecorativeElements theme={theme} variant={
        accepted === true ? "success" : accepted === false ? "danger" : "default"
      } />
    </StepContainer>
  );
};


export default HumanInTheLoop;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}

.copilotKitChat {
  background-color: #fff !important;
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/README.mdx
================================================
# 📝 Predictive State Updates Document Editor

## What This Demo Shows

This demo showcases CopilotKit's **predictive state updates** for real-time
document collaboration:

1. **Live Document Editing**: Watch as your Copilot makes changes to a document
   in real-time
2. **Diff Visualization**: See exactly what's being changed as it happens
3. **Streaming Updates**: Changes are displayed character-by-character as the
   Copilot works

## How to Interact

Try these interactions with the collaborative document editor:

- "Fix the grammar and typos in this document"
- "Make this text more professional"
- "Add a section about [topic]"
- "Summarize this content in bullet points"
- "Change the tone to be more casual"

Watch as the Copilot processes your request and edits the document in real-time
right before your eyes.

## ✨ Predictive State Updates in Action

**What's happening technically:**

- The document state is shared between your UI and the Copilot
- As the Copilot generates content, changes are streamed to the UI
- Each modification is visualized with additions and deletions
- The UI renders these changes progressively, without waiting for completion
- All edits are tracked and displayed in a visually intuitive way

**What you'll see in this demo:**

- Text changes are highlighted in different colors (green for additions, red for
  deletions)
- The document updates character-by-character, creating a typing-like effect
- You can see the Copilot's thought process as it refines the content
- The final document seamlessly incorporates all changes
- The experience feels collaborative, as if someone is editing alongside you

This pattern of real-time collaborative editing with diff visualization is
perfect for document editors, code review tools, content creation platforms, or
any application where users benefit from seeing exactly how content is being
transformed!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/page.tsx
================================================
"use client";
import "@copilotkit/react-ui/styles.css";
import "./style.css";

import MarkdownIt from "markdown-it";
import React from "react";

import { diffWords } from "diff";
import { useEditor, EditorContent } from "@tiptap/react";
import StarterKit from "@tiptap/starter-kit";
import { useEffect, useState } from "react";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat, CopilotSidebar } from "@copilotkit/react-ui";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

const extensions = [StarterKit];

interface PredictiveStateUpdatesProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function PredictiveStateUpdates({ params }: PredictiveStateUpdatesProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)
  const chatTitle = 'AI Document Editor'
  const chatDescription = 'Ask me to create or edit a document'
  const initialLabel = 'Hi 👋 How can I help with your document?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="predictive_state_updates"
    >
      <div
        className="min-h-screen w-full"
        style={
          {
            // "--copilot-kit-primary-color": "#222",
            // "--copilot-kit-separator-color": "#CCC",
          } as React.CSSProperties
        }
      >
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight); // Reset to good default when opening
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content - Flexible container for messages and input */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotChat
                  className="h-full flex flex-col"
                  labels={{
                    initial: initialLabel,
                  }}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
        <DocumentEditor />
      </div>
    </CopilotKit>
  );
}

interface AgentState {
  document: string;
}

const DocumentEditor = () => {
  const editor = useEditor({
    extensions,
    immediatelyRender: false,
    editorProps: {
      attributes: { class: "min-h-screen p-10" },
    },
  });
  const [placeholderVisible, setPlaceholderVisible] = useState(false);
  const [currentDocument, setCurrentDocument] = useState("");
  const { isLoading } = useCopilotChat();

  const {
    state: agentState,
    setState: setAgentState,
    nodeName,
  } = useCoAgent<AgentState>({
    name: "predictive_state_updates",
    initialState: {
      document: "",
    },
  });

  useEffect(() => {
    if (isLoading) {
      setCurrentDocument(editor?.getText() || "");
    }
    editor?.setEditable(!isLoading);
  }, [isLoading]);

  useEffect(() => {
    if (nodeName == "end") {
      // set the text one final time when loading is done
      if (currentDocument.trim().length > 0 && currentDocument !== agentState?.document) {
        const newDocument = agentState?.document || "";
        const diff = diffPartialText(currentDocument, newDocument, true);
        const markdown = fromMarkdown(diff);
        editor?.commands.setContent(markdown);
      }
    }
  }, [nodeName]);

  useEffect(() => {
    if (isLoading) {
      if (currentDocument.trim().length > 0) {
        const newDocument = agentState?.document || "";
        const diff = diffPartialText(currentDocument, newDocument);
        const markdown = fromMarkdown(diff);
        editor?.commands.setContent(markdown);
      } else {
        const markdown = fromMarkdown(agentState?.document || "");
        editor?.commands.setContent(markdown);
      }
    }
  }, [agentState?.document]);

  const text = editor?.getText() || "";

  useEffect(() => {
    setPlaceholderVisible(text.length === 0);

    if (!isLoading) {
      setCurrentDocument(text);
      setAgentState({
        document: text,
      });
    }
  }, [text]);

  // TODO(steve): Remove this when all agents have been updated to use write_document tool.
  useCopilotAction({
    name: "confirm_changes",
    renderAndWaitForResponse: ({ args, respond, status }) => (
      <ConfirmChanges
        args={args}
        respond={respond}
        status={status}
        onReject={() => {
          editor?.commands.setContent(fromMarkdown(currentDocument));
          setAgentState({ document: currentDocument });
        }}
        onConfirm={() => {
          editor?.commands.setContent(fromMarkdown(agentState?.document || ""));
          setCurrentDocument(agentState?.document || "");
          setAgentState({ document: agentState?.document || "" });
        }}
      />
    ),
  }, [agentState?.document]);

  // Action to write the document.
  useCopilotAction({
    name: "write_document",
    description: `Present the proposed changes to the user for review`,
    parameters: [
      {
        name: "document",
        type: "string",
        description: "The full updated document in markdown format",
      },
    ],
    renderAndWaitForResponse({ args, status, respond }) {
      if (status === "executing") {
        return (
          <ConfirmChanges
            args={args}
            respond={respond}
            status={status}
            onReject={() => {
              editor?.commands.setContent(fromMarkdown(currentDocument));
              setAgentState({ document: currentDocument });
            }}
            onConfirm={() => {
              editor?.commands.setContent(fromMarkdown(agentState?.document || ""));
              setCurrentDocument(agentState?.document || "");
              setAgentState({ document: agentState?.document || "" });
            }}
          />
        );
      }
      return <></>;
    },
  }, [agentState?.document]);

  return (
    <div className="relative min-h-screen w-full">
      {placeholderVisible && (
        <div className="absolute top-6 left-6 m-4 pointer-events-none text-gray-400">
          Write whatever you want here in Markdown format...
        </div>
      )}
      <EditorContent editor={editor} />
    </div>
  );
};

interface ConfirmChangesProps {
  args: any;
  respond: any;
  status: any;
  onReject: () => void;
  onConfirm: () => void;
}

function ConfirmChanges({ args, respond, status, onReject, onConfirm }: ConfirmChangesProps) {
  const [accepted, setAccepted] = useState<boolean | null>(null);
  return (
    <div 
    data-testid="confirm-changes-modal"
    className="bg-white p-6 rounded shadow-lg border border-gray-200 mt-5 mb-5">
      <h2 className="text-lg font-bold mb-4">Confirm Changes</h2>
      <p className="mb-6">Do you want to accept the changes?</p>
      {accepted === null && (
        <div className="flex justify-end space-x-4">
          <button
            data-testid="reject-button"
            className={`bg-gray-200 text-black py-2 px-4 rounded disabled:opacity-50 ${
              status === "executing" ? "cursor-pointer" : "cursor-default"
            }`}
            disabled={status !== "executing"}
            onClick={() => {
              if (respond) {
                setAccepted(false);
                onReject();
                respond({ accepted: false });
              }
            }}
          >
            Reject
          </button>
          <button
            data-testid="confirm-button"
            className={`bg-black text-white py-2 px-4 rounded disabled:opacity-50 ${
              status === "executing" ? "cursor-pointer" : "cursor-default"
            }`}
            disabled={status !== "executing"}
            onClick={() => {
              if (respond) {
                setAccepted(true);
                onConfirm();
                respond({ accepted: true });
              }
            }}
          >
            Confirm
          </button>
        </div>
      )}
      {accepted !== null && (
        <div className="flex justify-end">
          <div 
          data-testid="status-display"
          className="mt-4 bg-gray-200 text-black py-2 px-4 rounded inline-block">
            {accepted ? "✓ Accepted" : "✗ Rejected"}
          </div>
        </div>
      )}
    </div>
  );
}

function fromMarkdown(text: string) {
  const md = new MarkdownIt({
    typographer: true,
    html: true,
  });

  return md.render(text);
}

function diffPartialText(oldText: string, newText: string, isComplete: boolean = false) {
  let oldTextToCompare = oldText;
  if (oldText.length > newText.length && !isComplete) {
    // make oldText shorter
    oldTextToCompare = oldText.slice(0, newText.length);
  }

  const changes = diffWords(oldTextToCompare, newText);

  let result = "";
  changes.forEach((part) => {
    if (part.added) {
      result += `<em>${part.value}</em>`;
    } else if (part.removed) {
      result += `<s>${part.value}</s>`;
    } else {
      result += part.value;
    }
  });

  if (oldText.length > newText.length && !isComplete) {
    result += oldText.slice(newText.length);
  }

  return result;
}

function isAlpha(text: string) {
  return /[a-zA-Z\u00C0-\u017F]/.test(text.trim());
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/style.css
================================================
/* Basic editor styles */
.tiptap-container {
  height: 100vh; /* Full viewport height */
  width: 100vw; /* Full viewport width */
  display: flex;
  flex-direction: column;
}

.tiptap {
  flex: 1; /* Take up remaining space */
  overflow: auto; /* Allow scrolling if content overflows */
}

.tiptap :first-child {
  margin-top: 0;
}

/* List styles */
.tiptap ul,
.tiptap ol {
  padding: 0 1rem;
  margin: 1.25rem 1rem 1.25rem 0.4rem;
}

.tiptap ul li p,
.tiptap ol li p {
  margin-top: 0.25em;
  margin-bottom: 0.25em;
}

/* Heading styles */
.tiptap h1,
.tiptap h2,
.tiptap h3,
.tiptap h4,
.tiptap h5,
.tiptap h6 {
  line-height: 1.1;
  margin-top: 2.5rem;
  text-wrap: pretty;
  font-weight: bold;
}

.tiptap h1,
.tiptap h2,
.tiptap h3,
.tiptap h4,
.tiptap h5,
.tiptap h6 {
  margin-top: 3.5rem;
  margin-bottom: 1.5rem;
}

.tiptap p {
  margin-bottom: 1rem;
}

.tiptap h1 {
  font-size: 1.4rem;
}

.tiptap h2 {
  font-size: 1.2rem;
}

.tiptap h3 {
  font-size: 1.1rem;
}

.tiptap h4,
.tiptap h5,
.tiptap h6 {
  font-size: 1rem;
}

/* Code and preformatted text styles */
.tiptap code {
  background-color: var(--purple-light);
  border-radius: 0.4rem;
  color: var(--black);
  font-size: 0.85rem;
  padding: 0.25em 0.3em;
}

.tiptap pre {
  background: var(--black);
  border-radius: 0.5rem;
  color: var(--white);
  font-family: "JetBrainsMono", monospace;
  margin: 1.5rem 0;
  padding: 0.75rem 1rem;
}

.tiptap pre code {
  background: none;
  color: inherit;
  font-size: 0.8rem;
  padding: 0;
}

.tiptap blockquote {
  border-left: 3px solid var(--gray-3);
  margin: 1.5rem 0;
  padding-left: 1rem;
}

.tiptap hr {
  border: none;
  border-top: 1px solid var(--gray-2);
  margin: 2rem 0;
}

.tiptap s {
  background-color: #f9818150;
  padding: 2px;
  font-weight: bold;
  color: rgba(0, 0, 0, 0.7);
}

.tiptap em {
  background-color: #b2f2bb;
  padding: 2px;
  font-weight: bold;
  font-style: normal;
}

.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}




================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/README.mdx
================================================
# 🍳 Shared State Recipe Creator

## What This Demo Shows

This demo showcases CopilotKit's **shared state** functionality - a powerful
feature that enables bidirectional data flow between:

1. **Frontend → Agent**: UI controls update the agent's context in real-time
2. **Agent → Frontend**: The Copilot's recipe creations instantly update the UI
   components

It's like having a cooking buddy who not only listens to what you want but also
updates your recipe card as you chat - no refresh needed! ✨

## How to Interact

Mix and match any of these parameters (or none at all - it's up to you!):

- **Skill Level**: Beginner to expert 👨‍🍳
- **Cooking Time**: Quick meals or slow cooking ⏱️
- **Special Preferences**: Dietary needs, flavor profiles, health goals 🥗
- **Ingredients**: Items you want to include 🧅🥩🍄
- **Instructions**: Any specific steps

Then chat with your Copilot chef with prompts like:

- "I'm a beginner cook. Can you make me a quick dinner?"
- "I need something spicy with chicken that takes under 30 minutes!"

## ✨ Shared State Magic in Action

**What's happening technically:**

- The UI and Copilot agent share the same state object (**Agent State = UI
  State**)
- Changes from either side automatically update the other
- Neither side needs to manually request updates from the other

**What you'll see in this demo:**

- Set cooking time to 20 minutes in the UI and watch the Copilot immediately
  respect your time constraint
- Add ingredients through the UI and see them appear in your recipe
- When the Copilot suggests new ingredients, watch them automatically appear in
  the UI ingredients list
- Change your skill level and see how the Copilot adapts its instructions in
  real-time

This synchronized state creates a seamless experience where the agent always has
your current preferences, and any updates to the recipe are instantly reflected
in both places.

This shared state pattern can be applied to any application where you want your
UI and Copilot to work together in perfect harmony!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/page.tsx
================================================
"use client";
import { CopilotKit, useCoAgent, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat, CopilotSidebar } from "@copilotkit/react-ui";
import React, { useState, useEffect, useRef } from "react";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface SharedStateProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function SharedState({ params }: SharedStateProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)

  const chatTitle = 'AI Recipe Assistant'
  const chatDescription = 'Ask me to craft recipes'
  const initialLabel = 'Hi 👋 How can I help with your recipe?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="shared_state"
    >
      <div
        className="min-h-screen w-full flex items-center justify-center"
        style={
          {
            backgroundImage: "url('/shared_state_background.png')",
            backgroundSize: "cover",
            backgroundPosition: "center",
            backgroundRepeat: "no-repeat",
          } as React.CSSProperties
        }
      >
        <Recipe />
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight); // Reset to good default when opening
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content - Flexible container for messages and input */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotChat
                  className="h-full flex flex-col"
                  labels={{
                    initial: initialLabel,
                  }}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
      </div>
    </CopilotKit>
  );
}

enum SkillLevel {
  BEGINNER = "Beginner",
  INTERMEDIATE = "Intermediate",
  ADVANCED = "Advanced",
}

enum CookingTime {
  FiveMin = "5 min",
  FifteenMin = "15 min",
  ThirtyMin = "30 min",
  FortyFiveMin = "45 min",
  SixtyPlusMin = "60+ min",
}

const cookingTimeValues = [
  { label: CookingTime.FiveMin, value: 0 },
  { label: CookingTime.FifteenMin, value: 1 },
  { label: CookingTime.ThirtyMin, value: 2 },
  { label: CookingTime.FortyFiveMin, value: 3 },
  { label: CookingTime.SixtyPlusMin, value: 4 },
];

enum SpecialPreferences {
  HighProtein = "High Protein",
  LowCarb = "Low Carb",
  Spicy = "Spicy",
  BudgetFriendly = "Budget-Friendly",
  OnePotMeal = "One-Pot Meal",
  Vegetarian = "Vegetarian",
  Vegan = "Vegan",
}

interface Ingredient {
  icon: string;
  name: string;
  amount: string;
}

interface Recipe {
  title: string;
  skill_level: SkillLevel;
  cooking_time: CookingTime;
  special_preferences: string[];
  ingredients: Ingredient[];
  instructions: string[];
}

interface RecipeAgentState {
  recipe: Recipe;
}

const INITIAL_STATE: RecipeAgentState = {
  recipe: {
    title: "Make Your Recipe",
    skill_level: SkillLevel.INTERMEDIATE,
    cooking_time: CookingTime.FortyFiveMin,
    special_preferences: [],
    ingredients: [
      { icon: "🥕", name: "Carrots", amount: "3 large, grated" },
      { icon: "🌾", name: "All-Purpose Flour", amount: "2 cups" },
    ],
    instructions: ["Preheat oven to 350°F (175°C)"],
  },
};

function Recipe() {
  const { isMobile } = useMobileView();
  const { state: agentState, setState: setAgentState } = useCoAgent<RecipeAgentState>({
    name: "shared_state",
    initialState: INITIAL_STATE,
  });

  const [recipe, setRecipe] = useState(INITIAL_STATE.recipe);
  const { appendMessage, isLoading } = useCopilotChat();
  const [editingInstructionIndex, setEditingInstructionIndex] = useState<number | null>(null);
  const newInstructionRef = useRef<HTMLTextAreaElement>(null);

  const updateRecipe = (partialRecipe: Partial<Recipe>) => {
    setAgentState({
      ...agentState,
      recipe: {
        ...recipe,
        ...partialRecipe,
      },
    });
    setRecipe({
      ...recipe,
      ...partialRecipe,
    });
  };

  const newRecipeState = { ...recipe };
  const newChangedKeys = [];
  const changedKeysRef = useRef<string[]>([]);

  for (const key in recipe) {
    if (
      agentState &&
      agentState.recipe &&
      (agentState.recipe as any)[key] !== undefined &&
      (agentState.recipe as any)[key] !== null
    ) {
      let agentValue = (agentState.recipe as any)[key];
      const recipeValue = (recipe as any)[key];

      // Check if agentValue is a string and replace \n with actual newlines
      if (typeof agentValue === "string") {
        agentValue = agentValue.replace(/\\n/g, "\n");
      }

      if (JSON.stringify(agentValue) !== JSON.stringify(recipeValue)) {
        (newRecipeState as any)[key] = agentValue;
        newChangedKeys.push(key);
      }
    }
  }

  if (newChangedKeys.length > 0) {
    changedKeysRef.current = newChangedKeys;
  } else if (!isLoading) {
    changedKeysRef.current = [];
  }

  useEffect(() => {
    setRecipe(newRecipeState);
  }, [JSON.stringify(newRecipeState)]);

  const handleTitleChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    updateRecipe({
      title: event.target.value,
    });
  };

  const handleSkillLevelChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    updateRecipe({
      skill_level: event.target.value as SkillLevel,
    });
  };

  const handleDietaryChange = (preference: string, checked: boolean) => {
    if (checked) {
      updateRecipe({
        special_preferences: [...recipe.special_preferences, preference],
      });
    } else {
      updateRecipe({
        special_preferences: recipe.special_preferences.filter((p) => p !== preference),
      });
    }
  };

  const handleCookingTimeChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    updateRecipe({
      cooking_time: cookingTimeValues[Number(event.target.value)].label,
    });
  };

  const addIngredient = () => {
    // Pick a random food emoji from our valid list
    updateRecipe({
      ingredients: [...recipe.ingredients, { icon: "🍴", name: "", amount: "" }],
    });
  };

  const updateIngredient = (index: number, field: keyof Ingredient, value: string) => {
    const updatedIngredients = [...recipe.ingredients];
    updatedIngredients[index] = {
      ...updatedIngredients[index],
      [field]: value,
    };
    updateRecipe({ ingredients: updatedIngredients });
  };

  const removeIngredient = (index: number) => {
    const updatedIngredients = [...recipe.ingredients];
    updatedIngredients.splice(index, 1);
    updateRecipe({ ingredients: updatedIngredients });
  };

  const addInstruction = () => {
    const newIndex = recipe.instructions.length;
    updateRecipe({
      instructions: [...recipe.instructions, ""],
    });
    // Set the new instruction as the editing one
    setEditingInstructionIndex(newIndex);

    // Focus the new instruction after render
    setTimeout(() => {
      const textareas = document.querySelectorAll(".instructions-container textarea");
      const newTextarea = textareas[textareas.length - 1] as HTMLTextAreaElement;
      if (newTextarea) {
        newTextarea.focus();
      }
    }, 50);
  };

  const updateInstruction = (index: number, value: string) => {
    const updatedInstructions = [...recipe.instructions];
    updatedInstructions[index] = value;
    updateRecipe({ instructions: updatedInstructions });
  };

  const removeInstruction = (index: number) => {
    const updatedInstructions = [...recipe.instructions];
    updatedInstructions.splice(index, 1);
    updateRecipe({ instructions: updatedInstructions });
  };

  // Simplified icon handler that defaults to a fork/knife for any problematic icons
  const getProperIcon = (icon: string | undefined): string => {
    // If icon is undefined  return the default
    if (!icon) {
      return "🍴";
    }

    return icon;
  };

  return (
    <form 
    data-testid="recipe-card"
    style={isMobile ? { marginBottom: "100px" } : {}}
    className="recipe-card">
      {/* Recipe Title */}
      <div className="recipe-header">
        <input
          type="text"
          value={recipe.title || ""}
          onChange={handleTitleChange}
          className="recipe-title-input"
        />

        <div className="recipe-meta">
          <div className="meta-item">
            <span className="meta-icon">🕒</span>
            <select
              className="meta-select"
              value={cookingTimeValues.find((t) => t.label === recipe.cooking_time)?.value || 3}
              onChange={handleCookingTimeChange}
              style={{
                backgroundImage:
                  "url(\"data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='none' stroke='%23555' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3e%3cpolyline points='6 9 12 15 18 9'%3e%3c/polyline%3e%3c/svg%3e\")",
                backgroundRepeat: "no-repeat",
                backgroundPosition: "right 0px center",
                backgroundSize: "12px",
                appearance: "none",
                WebkitAppearance: "none",
              }}
            >
              {cookingTimeValues.map((time) => (
                <option key={time.value} value={time.value}>
                  {time.label}
                </option>
              ))}
            </select>
          </div>

          <div className="meta-item">
            <span className="meta-icon">🏆</span>
            <select
              className="meta-select"
              value={recipe.skill_level}
              onChange={handleSkillLevelChange}
              style={{
                backgroundImage:
                  "url(\"data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='none' stroke='%23555' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3e%3cpolyline points='6 9 12 15 18 9'%3e%3c/polyline%3e%3c/svg%3e\")",
                backgroundRepeat: "no-repeat",
                backgroundPosition: "right 0px center",
                backgroundSize: "12px",
                appearance: "none",
                WebkitAppearance: "none",
              }}
            >
              {Object.values(SkillLevel).map((level) => (
                <option key={level} value={level}>
                  {level}
                </option>
              ))}
            </select>
          </div>
        </div>
      </div>

      {/* Dietary Preferences */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("special_preferences") && <Ping />}
        <h2 className="section-title">Dietary Preferences</h2>
        <div className="dietary-options">
          {Object.values(SpecialPreferences).map((option) => (
            <label key={option} className="dietary-option">
              <input
                type="checkbox"
                checked={recipe.special_preferences.includes(option)}
                onChange={(e: React.ChangeEvent<HTMLInputElement>) =>
                  handleDietaryChange(option, e.target.checked)
                }
              />
              <span>{option}</span>
            </label>
          ))}
        </div>
      </div>

      {/* Ingredients */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("ingredients") && <Ping />}
        <div className="section-header">
          <h2 className="section-title">Ingredients</h2>
          <button
            data-testid="add-ingredient-button"
            type="button"
            className="add-button"
            onClick={addIngredient}
          >
            + Add Ingredient
          </button>
        </div>
        <div
          data-testid="ingredients-container"
          className="ingredients-container"
        >
          {recipe.ingredients.map((ingredient, index) => (
            <div key={index} 
             data-testid="ingredient-card"
             className="ingredient-card">
              <div className="ingredient-icon">{getProperIcon(ingredient.icon)}</div>
              <div className="ingredient-content">
                <input
                  type="text"
                  value={ingredient.name || ""}
                  onChange={(e) => updateIngredient(index, "name", e.target.value)}
                  placeholder="Ingredient name"
                  className="ingredient-name-input"
                />
                <input
                  type="text"
                  value={ingredient.amount || ""}
                  onChange={(e) => updateIngredient(index, "amount", e.target.value)}
                  placeholder="Amount"
                  className="ingredient-amount-input"
                />
              </div>
              <button
                type="button"
                className="remove-button"
                onClick={() => removeIngredient(index)}
                aria-label="Remove ingredient"
              >
                ×
              </button>
            </div>
          ))}
        </div>
      </div>

      {/* Instructions */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("instructions") && <Ping />}
        <div className="section-header">
          <h2 className="section-title">Instructions</h2>
          <button type="button" className="add-step-button" onClick={addInstruction}>
            + Add Step
          </button>
        </div>
        <div 
          data-testid="instructions-container"
          className="instructions-container">
          {recipe.instructions.map((instruction, index) => (
            <div key={index} className="instruction-item">
              {/* Number Circle */}
              <div className="instruction-number">{index + 1}</div>

              {/* Vertical Line */}
              {index < recipe.instructions.length - 1 && <div className="instruction-line" />}

              {/* Instruction Content */}
              <div
                className={`instruction-content ${
                  editingInstructionIndex === index
                    ? "instruction-content-editing"
                    : "instruction-content-default"
                }`}
                onClick={() => setEditingInstructionIndex(index)}
              >
                <textarea
                  className="instruction-textarea"
                  value={instruction || ""}
                  onChange={(e) => updateInstruction(index, e.target.value)}
                  placeholder={!instruction ? "Enter cooking instruction..." : ""}
                  onFocus={() => setEditingInstructionIndex(index)}
                  onBlur={(e) => {
                    // Only blur if clicking outside this instruction
                    if (!e.relatedTarget || !e.currentTarget.contains(e.relatedTarget as Node)) {
                      setEditingInstructionIndex(null);
                    }
                  }}
                />

                {/* Delete Button (only visible on hover) */}
                <button
                  type="button"
                  className={`instruction-delete-btn ${
                    editingInstructionIndex === index
                      ? "instruction-delete-btn-editing"
                      : "instruction-delete-btn-default"
                  } remove-button`}
                  onClick={(e) => {
                    e.stopPropagation(); // Prevent triggering parent onClick
                    removeInstruction(index);
                  }}
                  aria-label="Remove instruction"
                >
                  ×
                </button>
              </div>
            </div>
          ))}
        </div>
      </div>

      {/* Improve with AI Button */}
      <div className="action-container">
        <button
          data-testid="improve-button"
          className={isLoading ? "improve-button loading" : "improve-button"}
          type="button"
          onClick={() => {
            if (!isLoading) {
              appendMessage(
                new TextMessage({
                  content: "Improve the recipe",
                  role: Role.User,
                }),
              );
            }
          }}
          disabled={isLoading}
        >
          {isLoading ? "Please Wait..." : "Improve with AI"}
        </button>
      </div>
    </form>
  );
}

function Ping() {
  return (
    <span className="ping-animation">
      <span className="ping-circle"></span>
      <span className="ping-dot"></span>
    </span>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/style.css
================================================
.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.copilotKitHeader {
  border-top-left-radius: 5px !important;
  background-color: #fff;
  color: #000;
  border-bottom: 0px;
}

/* Recipe App Styles */
.app-container {
  min-height: 100vh;
  width: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
  background-size: cover;
  background-position: center;
  background-repeat: no-repeat;
  background-attachment: fixed;
  position: relative;
  overflow: auto;
}

.recipe-card {
  background-color: rgba(255, 255, 255, 0.97);
  border-radius: 16px;
  box-shadow: 0 15px 30px rgba(0, 0, 0, 0.25), 0 5px 15px rgba(0, 0, 0, 0.15);
  width: 100%;
  max-width: 750px;
  margin: 20px auto;
  padding: 14px 32px;
  position: relative;
  z-index: 1;
  backdrop-filter: blur(5px);
  border: 1px solid rgba(255, 255, 255, 0.3);
  transition: transform 0.2s ease, box-shadow 0.2s ease;
  animation: fadeIn 0.5s ease-out forwards;
  box-sizing: border-box;
  overflow: hidden;
}

.recipe-card:hover {
  transform: translateY(-5px);
  box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3), 0 10px 20px rgba(0, 0, 0, 0.2);
}

/* Recipe Header */
.recipe-header {
  margin-bottom: 24px;
}

.recipe-title-input {
  width: 100%;
  font-size: 24px;
  font-weight: bold;
  border: none;
  outline: none;
  padding: 8px 0;
  margin-bottom: 0px;
}

.recipe-meta {
  display: flex;
  align-items: center;
  gap: 20px;
  margin-top: 5px;
  margin-bottom: 14px;
}

.meta-item {
  display: flex;
  align-items: center;
  gap: 8px;
  color: #555;
}

.meta-icon {
  font-size: 20px;
  color: #777;
}

.meta-text {
  font-size: 15px;
}

/* Recipe Meta Selects */
.meta-item select {
  border: none;
  background: transparent;
  font-size: 15px;
  color: #555;
  cursor: pointer;
  outline: none;
  padding-right: 18px;
  transition: color 0.2s, transform 0.1s;
  font-weight: 500;
}

.meta-item select:hover,
.meta-item select:focus {
  color: #FF5722;
}

.meta-item select:active {
  transform: scale(0.98);
}

.meta-item select option {
  color: #333;
  background-color: white;
  font-weight: normal;
  padding: 8px;
}

/* Section Container */
.section-container {
  margin-bottom: 20px;
  position: relative;
  width: 100%;
}

.section-title {
  font-size: 20px;
  font-weight: 700;
  margin-bottom: 20px;
  color: #333;
  position: relative;
  display: inline-block;
}

.section-title:after {
  content: "";
  position: absolute;
  bottom: -8px;
  left: 0;
  width: 40px;
  height: 3px;
  background-color: #ff7043;
  border-radius: 3px;
}

/* Dietary Preferences */
.dietary-options {
  display: flex;
  flex-wrap: wrap;
  gap: 10px 16px;
  margin-bottom: 16px;
  width: 100%;
}

.dietary-option {
  display: flex;
  align-items: center;
  gap: 6px;
  font-size: 14px;
  cursor: pointer;
  margin-bottom: 4px;
}

.dietary-option input {
  cursor: pointer;
}

/* Ingredients */
.ingredients-container {
  display: flex;
  flex-wrap: wrap;
  gap: 10px;
  margin-bottom: 15px;
  width: 100%;
  box-sizing: border-box;
}

.ingredient-card {
  display: flex;
  align-items: center;
  background-color: rgba(255, 255, 255, 0.9);
  border-radius: 12px;
  padding: 12px;
  margin-bottom: 10px;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.08);
  position: relative;
  transition: all 0.2s ease;
  border: 1px solid rgba(240, 240, 240, 0.8);
  width: calc(33.333% - 7px);
  box-sizing: border-box;
}

.ingredient-card:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 15px rgba(0, 0, 0, 0.12);
}

.ingredient-card .remove-button {
  position: absolute;
  right: 10px;
  top: 10px;
  background: none;
  border: none;
  color: #ccc;
  font-size: 16px;
  cursor: pointer;
  display: none;
  padding: 0;
  width: 24px;
  height: 24px;
  line-height: 1;
}

.ingredient-card:hover .remove-button {
  display: block;
}

.ingredient-icon {
  font-size: 24px;
  margin-right: 12px;
  display: flex;
  align-items: center;
  justify-content: center;
  width: 40px;
  height: 40px;
  background-color: #f7f7f7;
  border-radius: 50%;
  flex-shrink: 0;
}

.ingredient-content {
  flex: 1;
  display: flex;
  flex-direction: column;
  gap: 3px;
  min-width: 0;
}

.ingredient-name-input,
.ingredient-amount-input {
  border: none;
  background: transparent;
  outline: none;
  width: 100%;
  padding: 0;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.ingredient-name-input {
  font-weight: 500;
  font-size: 14px;
}

.ingredient-amount-input {
  font-size: 13px;
  color: #666;
}

.ingredient-name-input::placeholder,
.ingredient-amount-input::placeholder {
  color: #aaa;
}

.remove-button {
  background: none;
  border: none;
  color: #999;
  font-size: 20px;
  cursor: pointer;
  padding: 0;
  width: 28px;
  height: 28px;
  display: flex;
  align-items: center;
  justify-content: center;
  margin-left: 10px;
}

.remove-button:hover {
  color: #FF5722;
}

/* Instructions */
.instructions-container {
  display: flex;
  flex-direction: column;
  gap: 6px;
  position: relative;
  margin-bottom: 12px;
  width: 100%;
}

.instruction-item {
  position: relative;
  display: flex;
  width: 100%;
  box-sizing: border-box;
  margin-bottom: 8px;
  align-items: flex-start;
}

.instruction-number {
  display: flex;
  align-items: center;
  justify-content: center;
  min-width: 26px;
  height: 26px;
  background-color: #ff7043;
  color: white;
  border-radius: 50%;
  font-weight: 600;
  flex-shrink: 0;
  box-shadow: 0 2px 4px rgba(255, 112, 67, 0.3);
  z-index: 1;
  font-size: 13px;
  margin-top: 2px;
}

.instruction-line {
  position: absolute;
  left: 13px; /* Half of the number circle width */
  top: 22px;
  bottom: -18px;
  width: 2px;
  background: linear-gradient(to bottom, #ff7043 60%, rgba(255, 112, 67, 0.4));
  z-index: 0;
}

.instruction-content {
  background-color: white;
  border-radius: 10px;
  padding: 10px 14px;
  margin-left: 12px;
  flex-grow: 1;
  transition: all 0.2s ease;
  box-shadow: 0 2px 6px rgba(0, 0, 0, 0.08);
  border: 1px solid rgba(240, 240, 240, 0.8);
  position: relative;
  width: calc(100% - 38px);
  box-sizing: border-box;
  display: flex;
  align-items: center;
}

.instruction-content-editing {
  background-color: #fff9f6;
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12), 0 0 0 2px rgba(255, 112, 67, 0.2);
}

.instruction-content:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12);
}

.instruction-textarea {
  width: 100%;
  background: transparent;
  border: none;
  resize: vertical;
  font-family: inherit;
  font-size: 14px;
  line-height: 1.4;
  min-height: 20px;
  outline: none;
  padding: 0;
  margin: 0;
}

.instruction-delete-btn {
  position: absolute;
  background: none;
  border: none;
  color: #ccc;
  font-size: 16px;
  cursor: pointer;
  display: none;
  padding: 0;
  width: 20px;
  height: 20px;
  line-height: 1;
  top: 50%;
  transform: translateY(-50%);
  right: 8px;
}

.instruction-content:hover .instruction-delete-btn {
  display: flex;
  align-items: center;
  justify-content: center;
}

/* Action Button */
.action-container {
  display: flex;
  justify-content: center;
  margin-top: 40px;
  padding-bottom: 20px;
  position: relative;
}

.improve-button {
  background-color: #ff7043;
  border: none;
  color: white;
  border-radius: 30px;
  font-size: 18px;
  font-weight: 600;
  padding: 14px 28px;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 4px 15px rgba(255, 112, 67, 0.4);
  display: flex;
  align-items: center;
  justify-content: center;
  text-align: center;
  position: relative;
  min-width: 180px;
}

.improve-button:hover {
  background-color: #ff5722;
  transform: translateY(-2px);
  box-shadow: 0 8px 20px rgba(255, 112, 67, 0.5);
}

.improve-button.loading {
  background-color: #ff7043;
  opacity: 0.8;
  cursor: not-allowed;
  padding-left: 42px; /* Reduced padding to bring text closer to icon */
  padding-right: 22px; /* Balance the button */
  justify-content: flex-start; /* Left align text for better alignment with icon */
}

.improve-button.loading:after {
  content: ""; /* Add space between icon and text */
  display: inline-block;
  width: 8px; /* Width of the space */
}

.improve-button:before {
  content: "";
  background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='white' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpath d='M12 2v4M12 18v4M4.93 4.93l2.83 2.83M16.24 16.24l2.83 2.83M2 12h4M18 12h4M4.93 19.07l2.83-2.83M16.24 7.76l2.83-2.83'/%3E%3C/svg%3E");
  width: 20px; /* Slightly smaller icon */
  height: 20px;
  background-repeat: no-repeat;
  background-size: contain;
  position: absolute;
  left: 16px; /* Slightly adjusted */
  top: 50%;
  transform: translateY(-50%);
  display: none;
}

.improve-button.loading:before {
  display: block;
  animation: spin 1.5s linear infinite;
}

@keyframes spin {
  0% { transform: translateY(-50%) rotate(0deg); }
  100% { transform: translateY(-50%) rotate(360deg); }
}

/* Ping Animation */
.ping-animation {
  position: absolute;
  display: flex;
  width: 12px;
  height: 12px;
  top: 0;
  right: 0;
}

.ping-circle {
  position: absolute;
  display: inline-flex;
  width: 100%;
  height: 100%;
  border-radius: 50%;
  background-color: #38BDF8;
  opacity: 0.75;
  animation: ping 1.5s cubic-bezier(0, 0, 0.2, 1) infinite;
}

.ping-dot {
  position: relative;
  display: inline-flex;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background-color: #0EA5E9;
}

@keyframes ping {
  75%, 100% {
    transform: scale(2);
    opacity: 0;
  }
}

/* Instruction hover effects */
.instruction-item:hover .instruction-delete-btn {
  display: flex !important;
}

/* Add some subtle animations */
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(20px); }
  to { opacity: 1; transform: translateY(0); }
}

/* Better center alignment for the recipe card */
.recipe-card-container {
  display: flex;
  justify-content: center;
  width: 100%;
  position: relative;
  z-index: 1;
  margin: 0 auto;
  box-sizing: border-box;
}

/* Add Buttons */
.add-button {
  background-color: transparent;
  color: #FF5722;
  border: 1px dashed #FF5722;
  border-radius: 8px;
  padding: 10px 16px;
  cursor: pointer;
  font-weight: 500;
  display: inline-block;
  font-size: 14px;
  margin-bottom: 0;
}

.add-step-button {
  background-color: transparent;
  color: #FF5722;
  border: 1px dashed #FF5722;
  border-radius: 6px;
  padding: 6px 12px;
  cursor: pointer;
  font-weight: 500;
  font-size: 13px;
}

/* Section Headers */
.section-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 12px;
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/README.mdx
================================================
# LangGraph Subgraphs Demo: Travel Planning Assistant ✈️

This demo showcases **LangGraph subgraphs** through an interactive travel planning assistant. Watch as specialized AI agents collaborate to plan your perfect trip!

## What are LangGraph Subgraphs? 🤖

**Subgraphs** are the key to building modular, scalable AI systems in LangGraph. A subgraph is essentially "a graph that is used as a node in another graph" - enabling powerful encapsulation and reusability.
For more info, check out the [LangGraph docs](https://langchain-ai.github.io/langgraph/concepts/subgraphs/).

### Key Concepts

- **Encapsulation**: Each subgraph handles a specific domain with its own expertise
- **Modularity**: Subgraphs can be developed, tested, and maintained independently  
- **Reusability**: The same subgraph can be used across multiple parent graphs
- **State Communication**: Subgraphs can share state or use different schemas with transformations

## Demo Architecture 🗺️

This travel planner demonstrates **supervisor-coordinated subgraphs** with **human-in-the-loop** decision making:

### Parent Graph: Travel Supervisor
- **Role**: Coordinates the travel planning process and routes to specialized agents
- **State Management**: Maintains a shared itinerary object across all subgraphs
- **Intelligence**: Determines what's needed and when each agent should be called

### Subgraph 1: ✈️ Flights Agent
- **Specialization**: Finding and booking flight options
- **Process**: Presents flight options from Amsterdam to San Francisco with recommendations
- **Interaction**: Uses interrupts to let users choose their preferred flight
- **Data**: Static flight options (KLM, United) with pricing and duration

### Subgraph 2: 🏨 Hotels Agent  
- **Specialization**: Finding and booking accommodation
- **Process**: Shows hotel options in San Francisco with different price points
- **Interaction**: Uses interrupts for user to select their preferred hotel
- **Data**: Static hotel options (Hotel Zephyr, Ritz-Carlton, Hotel Zoe)

### Subgraph 3: 🎯 Experiences Agent
- **Specialization**: Curating restaurants and activities
- **Process**: AI-powered recommendations based on selected flights and hotels
- **Features**: Combines 2 restaurants and 2 activities with location-aware suggestions
- **Data**: Static experiences (Pier 39, Golden Gate Bridge, Swan Oyster Depot, Tartine Bakery)

## How It Works 🔄

1. **User Request**: "Help me plan a trip to San Francisco"
2. **Supervisor Analysis**: Determines what travel components are needed
3. **Sequential Routing**: Routes to each agent in logical order:
   - First: Flights Agent (get transportation sorted)
   - Then: Hotels Agent (book accommodation)  
   - Finally: Experiences Agent (plan activities)
4. **Human Decisions**: Each agent presents options and waits for user choice via interrupts
5. **State Building**: Selected choices are stored in the shared itinerary object
6. **Completion**: All agents report back to supervisor for final coordination

## State Communication Patterns 📊

### Shared State Schema
All subgraph agents share and contribute to a common state object. When any agent updates the shared state, these changes are immediately reflected in the frontend through real-time syncing. This ensures that:

- **Flight selections** from the Flights Agent are visible to subsequent agents
- **Hotel choices** influence the Experiences Agent's recommendations  
- **All updates** are synchronized with the frontend UI in real-time
- **State persistence** maintains the travel itinerary throughout the workflow

### Human-in-the-Loop Pattern
Two of the specialist agents use **interrupts** to pause execution and gather user preferences:

- **Flights Agent**: Presents options → interrupt → waits for selection → continues
- **Hotels Agent**: Shows hotels → interrupt → waits for choice → continues

## Try These Examples! 💡

### Getting Started
- "Help me plan a trip to San Francisco"
- "I want to visit San Francisco from Amsterdam"
- "Plan my travel itinerary"

### During the Process
When the Flights Agent presents options:
- Choose between KLM ($650, 11h 30m) or United ($720, 12h 15m)

When the Hotels Agent shows accommodations:
- Select from Hotel Zephyr, The Ritz-Carlton, or Hotel Zoe

The Experiences Agent will then provide tailored recommendations based on your choices!

## Frontend Capabilities 👁️

- **Human-in-the-loop with interrupts** from subgraphs for user decision making
- **Subgraphs detection and streaming** to show which agent is currently active
- **Real-time state updates** as the shared itinerary is built across agents



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/page.tsx
================================================
"use client";
import React, { useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useLangGraphInterrupt } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface SubgraphsProps {
  params: Promise<{
    integrationId: string;
  }>;
}

// Travel planning data types
interface Flight {
  airline: string;
  arrival: string;
  departure: string;
  duration: string;
  price: string;
}

interface Hotel {
  location: string;
  name: string;
  price_per_night: string;
  rating: string;
}

interface Experience {
  name: string;
  description: string;
  location: string;
  type: string;
}

interface Itinerary {
  hotel?: Hotel;
  flight?: Flight;
  experiences?: Experience[];
}

type AvailableAgents = 'flights' | 'hotels' | 'experiences' | 'supervisor'

interface TravelAgentState {
  experiences: Experience[],
  flights: Flight[],
  hotels: Hotel[],
  itinerary: Itinerary
  planning_step: string
  active_agent: AvailableAgents
}

const INITIAL_STATE: TravelAgentState = {
  itinerary: {},
  experiences: [],
  flights: [],
  hotels: [],
  planning_step: "start",
  active_agent: 'supervisor'
};

interface InterruptEvent<TAgent extends AvailableAgents> {
  message: string;
  options: TAgent extends 'flights' ? Flight[] : TAgent extends 'hotels' ? Hotel[] : never,
  recommendation: TAgent extends 'flights' ? Flight : TAgent extends 'hotels' ? Hotel : never,
  agent: TAgent
}

function InterruptHumanInTheLoop<TAgent extends AvailableAgents>({
  event,
  resolve,
}: {
  event: { value: InterruptEvent<TAgent> };
  resolve: (value: string) => void;
}) {
  const { message, options, agent, recommendation } = event.value;

  // Format agent name with emoji
  const formatAgentName = (agent: string) => {
    switch (agent) {
      case 'flights': return 'Flights Agent';
      case 'hotels': return 'Hotels Agent';
      case 'experiences': return 'Experiences Agent';
      default: return `${agent} Agent`;
    }
  };

  const handleOptionSelect = (option: any) => {
    resolve(JSON.stringify(option));
  };

  return (
    <div className="interrupt-container">
      <p>{formatAgentName(agent)}: {message}</p>

      <div className="interrupt-options">
        {options.map((opt, idx) => {
          if ('airline' in opt) {
            const isRecommended = (recommendation as Flight).airline === opt.airline;
            // Flight options
            return (
              <button
                key={idx}
                className={`option-card flight-option ${isRecommended ? 'recommended' : ''}`}
                onClick={() => handleOptionSelect(opt)}
              >
                {isRecommended && <span className="recommendation-badge">⭐ Recommended</span>}
                <div className="option-header">
                  <span className="airline-name">{opt.airline}</span>
                  <span className="price">{opt.price}</span>
                </div>
                <div className="route-info">
                  {opt.departure} → {opt.arrival}
                </div>
                <div className="duration-info">
                  {opt.duration}
                </div>
              </button>
            );
          }
          const isRecommended = (recommendation as Hotel).name === opt.name;

          // Hotel options
          return (
            <button
              key={idx}
              className={`option-card hotel-option ${isRecommended ? 'recommended' : ''}`}
              onClick={() => handleOptionSelect(opt)}
            >
              {isRecommended && <span className="recommendation-badge">⭐ Recommended</span>}
              <div className="option-header">
                <span className="hotel-name">{opt.name}</span>
                <span className="rating">{opt.rating}</span>
              </div>
              <div className="location-info">
                📍 {opt.location}
              </div>
              <div className="price-info">
                {opt.price_per_night}
              </div>
            </button>
          );
        })}
      </div>
    </div>
  )
}

export default function Subgraphs({ params }: SubgraphsProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50;
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight);

  const chatTitle = 'Travel Planning Assistant';
  const chatDescription = 'Plan your perfect trip with AI specialists';
  const initialLabel = 'Hi! ✈️ Ready to plan an amazing trip? Try saying "Plan a trip to Paris" or "Find me flights to Tokyo"';

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      agent="subgraphs"
    >
      <div className="travel-planner-container">
        <TravelPlanner />
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight);
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)'
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotSidebar
                  defaultOpen={true}
                  labels={{
                    title: chatTitle,
                    initial: initialLabel,
                  }}
                  clickOutsideToClose={false}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
      </div>
    </CopilotKit>
  );
}

function TravelPlanner() {
  const { isMobile } = useMobileView();
  const { state: agentState, nodeName } = useCoAgent<TravelAgentState>({
    name: "subgraphs",
    initialState: INITIAL_STATE,
    config: {
      streamSubgraphs: true,
    }
  });

  useLangGraphInterrupt({
    render: ({ event, resolve }) => <InterruptHumanInTheLoop event={event} resolve={resolve} />,
  });

  // Current itinerary strip
  const ItineraryStrip = () => {
    const selectedFlight = agentState?.itinerary?.flight;
    const selectedHotel = agentState?.itinerary?.hotel;
    const hasExperiences = agentState?.experiences?.length > 0;

    return (
      <div className="itinerary-strip">
        <div className="itinerary-label">Current Itinerary:</div>
        <div className="itinerary-items">
          <div className="itinerary-item">
            <span className="item-icon">📍</span>
            <span>Amsterdam → San Francisco</span>
          </div>
          {selectedFlight && (
            <div className="itinerary-item" data-testid="selected-flight">
              <span className="item-icon">✈️</span>
              <span>{selectedFlight.airline} - {selectedFlight.price}</span>
            </div>
          )}
          {selectedHotel && (
            <div className="itinerary-item" data-testid="selected-hotel">
              <span className="item-icon">🏨</span>
              <span>{selectedHotel.name}</span>
            </div>
          )}
          {hasExperiences && (
            <div className="itinerary-item">
              <span className="item-icon">🎯</span>
              <span>{agentState.experiences.length} experiences planned</span>
            </div>
          )}
        </div>
      </div>
    );
  };

  // Compact agent status
  const AgentStatus = () => {
    let activeAgent = 'supervisor';
    if (nodeName?.includes('flights_agent')) {
      activeAgent = 'flights';
    }
    if (nodeName?.includes('hotels_agent')) {
      activeAgent = 'hotels';
    }
    if (nodeName?.includes('experiences_agent')) {
      activeAgent = 'experiences';
    }
    return (
      <div className="agent-status">
        <div className="status-label">Active Agent:</div>
        <div className="agent-indicators">
          <div className={`agent-indicator ${activeAgent === 'supervisor' ? 'active' : ''}`} data-testid="supervisor-indicator">
            <span>👨‍💼</span>
            <span>Supervisor</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'flights' ? 'active' : ''}`} data-testid="flights-agent-indicator">
            <span>✈️</span>
            <span>Flights</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'hotels' ? 'active' : ''}`} data-testid="hotels-agent-indicator">
            <span>🏨</span>
            <span>Hotels</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'experiences' ? 'active' : ''}`} data-testid="experiences-agent-indicator">
            <span>🎯</span>
            <span>Experiences</span>
          </div>
        </div>
      </div>
    )
  };

  // Travel details component
  const TravelDetails = () => (
    <div className="travel-details">
      <div className="details-section">
        <h4>✈️ Flight Options</h4>
        <div className="detail-items">
          {agentState?.flights?.length > 0 ? (
            agentState.flights.map((flight, index) => (
              <div key={index} className="detail-item">
                <strong>{flight.airline}:</strong>
                <span>{flight.departure} → {flight.arrival} ({flight.duration}) - {flight.price}</span>
              </div>
            ))
          ) : (
            <p className="no-activities">No flights found yet</p>
          )}
          {agentState?.itinerary?.flight && (
            <div className="detail-tips">
              <strong>Selected:</strong> {agentState.itinerary.flight.airline} - {agentState.itinerary.flight.price}
            </div>
          )}
        </div>
      </div>

      <div className="details-section">
        <h4>🏨 Hotel Options</h4>
        <div className="detail-items">
          {agentState?.hotels?.length > 0 ? (
            agentState.hotels.map((hotel, index) => (
              <div key={index} className="detail-item">
                <strong>{hotel.name}:</strong>
                <span>{hotel.location} - {hotel.price_per_night} ({hotel.rating})</span>
              </div>
            ))
          ) : (
            <p className="no-activities">No hotels found yet</p>
          )}
          {agentState?.itinerary?.hotel && (
            <div className="detail-tips">
              <strong>Selected:</strong> {agentState.itinerary.hotel.name} - {agentState.itinerary.hotel.price_per_night}
            </div>
          )}
        </div>
      </div>

      <div className="details-section">
        <h4>🎯 Experiences</h4>
        <div className="detail-items">
          {agentState?.experiences?.length > 0 ? (
            agentState.experiences.map((experience, index) => (
              <div key={index} className="activity-item">
                <div className="activity-name">{experience.name}</div>
                <div className="activity-category">{experience.type}</div>
                <div className="activity-description">{experience.description}</div>
                <div className="activity-meta">Location: {experience.location}</div>
              </div>
            ))
          ) : (
            <p className="no-activities">No experiences planned yet</p>
          )}
        </div>
      </div>
    </div>
  );

  return (
    <div className="travel-content">
      <ItineraryStrip />
      <AgentStatus />
      <TravelDetails />
    </div>
  );
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/style.css
================================================
/* Travel Planning Subgraphs Demo Styles */
/* Essential styles that cannot be achieved with Tailwind classes */

/* Main container with CopilotSidebar layout */
.travel-planner-container {
  min-height: 100vh;
  padding: 2rem;
  background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
}

/* Travel content area styles */
.travel-content {
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 1rem;
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

/* Itinerary strip */
.itinerary-strip {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.itinerary-label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #6b7280;
  margin-bottom: 0.5rem;
}

.itinerary-items {
  display: flex;
  flex-wrap: wrap;
  gap: 1rem;
}

.itinerary-item {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 0.75rem;
  background: #f9fafb;
  border-radius: 0.375rem;
  font-size: 0.875rem;
}

.item-icon {
  font-size: 1rem;
}

/* Agent status */
.agent-status {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.status-label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #6b7280;
  margin-bottom: 0.5rem;
}

.agent-indicators {
  display: flex;
  gap: 0.75rem;
}

.agent-indicator {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 0.75rem;
  border-radius: 0.375rem;
  font-size: 0.875rem;
  background: #f9fafb;
  border: 1px solid #e5e7eb;
  transition: all 0.2s ease;
}

.agent-indicator.active {
  background: #dbeafe;
  border-color: #3b82f6;
  color: #1d4ed8;
  box-shadow: 0 0 0 2px rgba(59, 130, 246, 0.1);
}

/* Travel details sections */
.travel-details {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  display: grid;
  gap: 1rem;
}

.details-section h4 {
  font-size: 1rem;
  font-weight: 600;
  color: #1f2937;
  margin-bottom: 0.5rem;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.detail-items {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.detail-item {
  padding: 0.5rem;
  background: #f9fafb;
  border-radius: 0.25rem;
  font-size: 0.875rem;
  display: flex;
  justify-content: space-between;
}

.detail-item strong {
  color: #6b7280;
  font-weight: 500;
}

.detail-tips {
  padding: 0.5rem;
  background: #eff6ff;
  border-radius: 0.25rem;
  font-size: 0.75rem;
  color: #1d4ed8;
}

.activity-item {
  padding: 0.75rem;
  background: #f0f9ff;
  border-radius: 0.25rem;
  border-left: 2px solid #0ea5e9;
}

.activity-name {
  font-weight: 600;
  color: #1f2937;
  font-size: 0.875rem;
  margin-bottom: 0.25rem;
}

.activity-category {
  font-size: 0.75rem;
  color: #0ea5e9;
  margin-bottom: 0.25rem;
}

.activity-description {
  color: #4b5563;
  font-size: 0.75rem;
  margin-bottom: 0.25rem;
}

.activity-meta {
  font-size: 0.75rem;
  color: #6b7280;
}

.no-activities {
  text-align: center;
  color: #9ca3af;
  font-style: italic;
  padding: 1rem;
  font-size: 0.875rem;
}

/* Interrupt UI for Chat Sidebar (Generative UI) */
.interrupt-container {
  display: flex;
  flex-direction: column;
  gap: 1rem;
  max-width: 100%;
  padding-top: 34px;
}

.interrupt-header {
  margin-bottom: 0.5rem;
}

.agent-name {
  font-size: 0.875rem;
  font-weight: 600;
  color: #1f2937;
  margin: 0 0 0.25rem 0;
}

.agent-message {
  font-size: 0.75rem;
  color: #6b7280;
  margin: 0;
  line-height: 1.4;
}

.interrupt-options {
    padding: 0.75rem;
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  max-height: 300px;
  overflow-y: auto;
}

.option-card {
  display: flex;
  flex-direction: column;
  gap: 0.25rem;
  padding: 0.75rem;
  background: #f9fafb;
  border: 1px solid #e5e7eb;
  border-radius: 0.5rem;
  cursor: pointer;
  transition: all 0.2s ease;
  text-align: left;
  position: relative;
  min-height: auto;
}

.option-card:hover {
  background: #f3f4f6;
  border-color: #d1d5db;
}

.option-card:active {
  background: #e5e7eb;
}

.option-card.recommended {
  background: #eff6ff;
  border-color: #3b82f6;
  box-shadow: 0 0 0 1px rgba(59, 130, 246, 0.1);
}

.option-card.recommended:hover {
  background: #dbeafe;
}

.recommendation-badge {
  position: absolute;
  top: -2px;
  right: -2px;
  background: #3b82f6;
  color: white;
  font-size: 0.625rem;
  padding: 0.125rem 0.375rem;
  border-radius: 0.75rem;
  font-weight: 500;
}

.option-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.125rem;
}

.airline-name, .hotel-name {
  font-weight: 600;
  font-size: 0.8rem;
  color: #1f2937;
}

.price, .rating {
  font-weight: 600;
  font-size: 0.75rem;
  color: #059669;
}

.route-info, .location-info {
  font-size: 0.7rem;
  color: #6b7280;
  margin-bottom: 0.125rem;
}

.duration-info, .price-info {
  font-size: 0.7rem;
  color: #9ca3af;
}

/* Mobile responsive adjustments */
@media (max-width: 768px) {
  .travel-planner-container {
    padding: 0.5rem;
    padding-bottom: 120px; /* Space for mobile chat */
  }
  
  .travel-content {
    padding: 0;
    gap: 0.75rem;
  }
  
  .itinerary-items {
    flex-direction: column;
    gap: 0.5rem;
  }
  
  .agent-indicators {
    flex-direction: column;
    gap: 0.5rem;
  }
  
  .agent-indicator {
    padding: 0.75rem;
  }
  
  .travel-details {
    padding: 0.75rem;
  }

  .interrupt-container {
    padding: 0.5rem;
  }

  .option-card {
    padding: 0.625rem;
  }

  .interrupt-options {
    max-height: 250px;
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/README.mdx
================================================
# 🪶 Tool-Based Generative UI Haiku Creator

## What This Demo Shows

This demo showcases CopilotKit's **tool-based generative UI** capabilities:

1. **Frontend Rendering of Tool Calls**: Backend tool calls are automatically
   rendered in the UI
2. **Dynamic UI Generation**: The UI updates in real-time as the agent generates
   content
3. **Elegant Content Presentation**: Complex structured data (haikus) are
   beautifully displayed

## How to Interact

Chat with your Copilot and ask for haikus about different topics:

- "Create a haiku about nature"
- "Write a haiku about technology"
- "Generate a haiku about the changing seasons"
- "Make a humorous haiku about programming"

Each request will trigger the agent to generate a haiku and display it in a
visually appealing card format in the UI.

## ✨ Tool-Based Generative UI in Action

**What's happening technically:**

- The agent processes your request and determines it should create a haiku
- It calls a backend tool that returns structured haiku data
- CopilotKit automatically renders this tool call in the frontend
- The rendering is handled by the registered tool component in your React app
- No manual state management is required to display the results

**What you'll see in this demo:**

- As you request a haiku, a beautifully formatted card appears in the UI
- The haiku follows the traditional 5-7-5 syllable structure
- Each haiku is presented with consistent styling
- Multiple haikus can be generated in sequence
- The UI adapts to display each new piece of content

This pattern of tool-based generative UI can be extended to create any kind of
dynamic content - from data visualizations to interactive components, all driven
by your Copilot's tool calls!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/page.tsx
================================================
"use client";
import { CopilotKit, useCopilotAction } from "@copilotkit/react-core";
import { CopilotKitCSSProperties, CopilotSidebar, CopilotChat } from "@copilotkit/react-ui";
import { Dispatch, SetStateAction, useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import React, { useMemo } from "react";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface ToolBasedGenerativeUIProps {
  params: Promise<{
    integrationId: string;
  }>;
}

interface GenerateHaiku {
  japanese: string[] | [],
  english: string[] | [],
  image_names: string[] | [],
  selectedImage: string | null,
}

interface HaikuCardProps {
  generatedHaiku: GenerateHaiku | Partial<GenerateHaiku>
  setHaikus: Dispatch<SetStateAction<GenerateHaiku[]>>
  haikus: GenerateHaiku[]
}

export default function ToolBasedGenerativeUI({ params }: ToolBasedGenerativeUIProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();


  const chatTitle = 'Haiku Generator'
  const chatDescription = 'Ask me to create haikus'
  const initialLabel = 'I\'m a haiku generator 👋. How can I help you?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      agent="tool_based_generative_ui"
    >
      <div
        className={`${isMobile ? 'h-screen' : 'min-h-full flex'} w-full relative overflow-hidden`}
      >
        <Haiku />

        {/* Desktop Sidebar */}
        {!isMobile && (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}

        {/* Mobile Pull-Up Chat */}
        {isMobile && <MobileChat chatTitle={chatTitle} chatDescription={chatDescription} initialLabel={initialLabel} />}
      </div>
    </CopilotKit>
  );
}

function MobileChat({ chatTitle, chatDescription, initialLabel }: { chatTitle: string, chatDescription: string, initialLabel: string }) {
  const defaultChatHeight = 50

  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)
  return (
    <>
      {/* Chat Toggle Button */}
      <div className="fixed bottom-0 left-0 right-0 z-50">
        <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
        <div
          className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
          onClick={() => {
            if (!isChatOpen) {
              setChatHeight(defaultChatHeight); // Reset to good default when opening
            }
            setIsChatOpen(!isChatOpen);
          }}
        >
          <div className="flex items-center gap-3">
            <div>
              <div className="font-medium text-gray-900">{chatTitle}</div>
              <div className="text-sm text-gray-500">{chatDescription}</div>
            </div>
          </div>
          <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
            <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
            </svg>
          </div>
        </div>
      </div>

      {/* Pull-Up Chat Container */}
      <div
        className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${isChatOpen ? 'translate-y-0' : 'translate-y-full'
          } ${isDragging ? 'transition-none' : ''}`}
        style={{
          height: `${chatHeight}vh`,
          paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
        }}
      >
        {/* Drag Handle Bar */}
        <div
          className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
          onMouseDown={handleDragStart}
        >
          <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
        </div>

        {/* Chat Header */}
        <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-3">
              <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
            </div>
            <button
              onClick={() => setIsChatOpen(false)}
              className="p-2 hover:bg-gray-100 rounded-full transition-colors"
            >
              <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>
        </div>

        {/* Chat Content - Flexible container for messages and input */}
        <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
          <CopilotChat
            className="h-full flex flex-col"
            labels={{
              initial: initialLabel,
            }}
          />
        </div>
      </div>

      {/* Backdrop */}
      {isChatOpen && (
        <div
          className="fixed inset-0 z-30"
          onClick={() => setIsChatOpen(false)}
        />
      )}
    </>
  )
}

const VALID_IMAGE_NAMES = [
  "Osaka_Castle_Turret_Stone_Wall_Pine_Trees_Daytime.jpg",
  "Tokyo_Skyline_Night_Tokyo_Tower_Mount_Fuji_View.jpg",
  "Itsukushima_Shrine_Miyajima_Floating_Torii_Gate_Sunset_Long_Exposure.jpg",
  "Takachiho_Gorge_Waterfall_River_Lush_Greenery_Japan.jpg",
  "Bonsai_Tree_Potted_Japanese_Art_Green_Foliage.jpeg",
  "Shirakawa-go_Gassho-zukuri_Thatched_Roof_Village_Aerial_View.jpg",
  "Ginkaku-ji_Silver_Pavilion_Kyoto_Japanese_Garden_Pond_Reflection.jpg",
  "Senso-ji_Temple_Asakusa_Cherry_Blossoms_Kimono_Umbrella.jpg",
  "Cherry_Blossoms_Sakura_Night_View_City_Lights_Japan.jpg",
  "Mount_Fuji_Lake_Reflection_Cherry_Blossoms_Sakura_Spring.jpg"
];

function getRandomImage(): string {
  return VALID_IMAGE_NAMES[Math.floor(Math.random() * VALID_IMAGE_NAMES.length)];
}

const validateAndCorrectImageNames = (rawNames: string[] | undefined): string[] | null => {
  if (!rawNames || rawNames.length !== 3) {
    return null;
  }

  const correctedNames: string[] = [];
  const usedValidNames = new Set<string>();

  for (const name of rawNames) {
    if (VALID_IMAGE_NAMES.includes(name) && !usedValidNames.has(name)) {
      correctedNames.push(name);
      usedValidNames.add(name);
      if (correctedNames.length === 3) break;
    }
  }

  while (correctedNames.length < 3) {
    const nextImage = getRandomImage();
    if (!usedValidNames.has(nextImage)) {
      correctedNames.push(nextImage);
      usedValidNames.add(nextImage);
    }
  }

  return correctedNames.slice(0, 3);
};

function HaikuCard({ generatedHaiku, setHaikus, haikus }: HaikuCardProps) {
  return (
    <div
      data-testid="haiku-card"
      className="suggestion-card text-left rounded-md p-4 mt-4 mb-4 flex flex-col bg-gray-100">
      <div className="mb-4 pb-4">
        {generatedHaiku?.japanese?.map((line, index) => (
          <div className="flex items-center gap-3 mb-2" data-testid="haiku-line" key={index}>
            <p className="text-lg font-bold">{line}</p>
            <p className="text-sm font-light">
              {generatedHaiku.english?.[index]}
            </p>
          </div>
        ))}
        {generatedHaiku?.japanese && generatedHaiku.japanese.length >= 2 && (
          <div className="mt-3 flex gap-2 justify-between w-full suggestion-image-container">
            {(() => {
              const firstLine = generatedHaiku?.japanese?.[0];
              if (!firstLine) return null;
              const haikuIndex = haikus.findIndex((h: any) => h.japanese[0] === firstLine);
              const haiku = haikus[haikuIndex];
              if (!haiku?.image_names) return null;

              return haiku.image_names.map((imageName, imgIndex) => (
                <img
                  key={haikus.length + "_" + imageName}
                  src={`/images/${imageName}`}
                  alt={imageName}
                  tabIndex={0}
                  className={`${haiku.selectedImage === imageName ? "suggestion-card-image-focus" : "suggestion-card-image"}`}
                  onClick={() => {
                    setHaikus(prevHaikus => {
                      const newHaikus = prevHaikus.map((h, idx) => {
                        if (idx === haikuIndex) {
                          return {
                            ...h,
                            selectedImage: imageName
                          };
                        }
                        return h;
                      });
                      return newHaikus;
                    });
                  }}
                />
              ));
            })()}
          </div>
        )}
      </div>
    </div>
  );
}

interface Haiku {
  japanese: string[];
  english: string[];
  image_names: string[];
  selectedImage: string | null;
}

function Haiku() {
  const [haikus, setHaikus] = useState<Haiku[]>([{
    japanese: ["仮の句よ", "まっさらながら", "花を呼ぶ"],
    english: [
      "A placeholder verse—",
      "even in a blank canvas,",
      "it beckons flowers.",
    ],
    image_names: [],
    selectedImage: null,
  }])
  const [activeIndex, setActiveIndex] = useState(0);
  const [isJustApplied, setIsJustApplied] = useState(false);

  useCopilotAction({
    name: "generate_haiku",
    parameters: [
      {
        name: "japanese",
        type: "string[]",
      },
      {
        name: "english",
        type: "string[]",
      },
      {
        name: "image_names",
        type: "string[]",
        description: `Names of 3 relevant images selected from the following: \n  -${VALID_IMAGE_NAMES.join('\n  -')}`,
      },
    ],
    followUp: false,
    handler: async ({ japanese, english, image_names }: { japanese: string[], english: string[], image_names: string[] }) => {
      const finalCorrectedImages = validateAndCorrectImageNames(image_names);
      const newHaiku = {
        japanese: japanese || [],
        english: english || [],
        image_names: finalCorrectedImages || [],
        selectedImage: finalCorrectedImages?.[0] || null,
      };
      setHaikus(prev => [newHaiku, ...prev].filter(h => h.english[0] !== "A placeholder verse—"));
      setActiveIndex(haikus.length - 1);
      setIsJustApplied(true);
      setTimeout(() => setIsJustApplied(false), 600);
      return "Haiku generated.";
    },
    render: ({ args: generatedHaiku }: { args: Partial<GenerateHaiku> }) => {
      return (
        <HaikuCard generatedHaiku={generatedHaiku} setHaikus={setHaikus} haikus={haikus} />
      );
    },
  }, [haikus]);

  const { isMobile } = useMobileView();

  return (
    <div className="flex h-full w-full">
      <Thumbnails haikus={haikus} activeIndex={activeIndex} setActiveIndex={setActiveIndex} isMobile={isMobile} />

      {/* Main Display */}
      <div className={`flex-1 flex items-center justify-center h-full ${isMobile
        ? 'px-6'
        : 'p-8'
        }`} style={{ marginLeft: isMobile ? '0' : '-48px' }}>
        <div className="haiku-stack w-full max-w-lg">
          {haikus.map((haiku, index) => (
            (haikus.length == 1 || index == activeIndex) && (

              <div
                key={index}
                data-testid="main-haiku-display"
                className={`haiku-card animated-fade-in ${isJustApplied && index === activeIndex ? 'applied-flash' : ''} ${index === activeIndex ? 'active' : ''}`}
                style={{
                  zIndex: index === activeIndex ? haikus.length : index,
                  transform: `translateY(${index === activeIndex ? '0' : `${(index - activeIndex) * 20}px`}) scale(${index === activeIndex ? '1' : '0.95'})`,
                }}
              >
                {haiku.japanese.map((line, lineIndex) => (
                  <div
                    data-testid="main-haiku-line"
                    className={`flex items-start mb-4 haiku-line ${isMobile
                      ? 'flex-col gap-1'
                      : 'gap-4'
                      }`}
                    key={lineIndex}
                    style={{ animationDelay: `${lineIndex * 0.1}s` }}
                  >
                    <p className={`font-bold text-gray-600 w-auto ${isMobile
                      ? 'text-2xl leading-tight'
                      : 'text-4xl'
                      }`}>
                      {line}
                    </p>
                    <p className={`font-light text-gray-500 w-auto ${isMobile
                      ? 'text-sm ml-2'
                      : 'text-base'
                      }`}>
                      {haiku.english?.[lineIndex]}
                    </p>
                  </div>
                ))}
                {haiku.image_names && haiku.image_names.length === 3 && (
                  <div className={`flex justify-center ${isMobile
                    ? 'mt-4 gap-2 flex-wrap'
                    : 'mt-6 gap-4'
                    }`}>
                    {haiku.image_names.map((imageName, imgIndex) => (
                      <img
                        key={imageName}
                        src={`/images/${imageName}`}
                        alt={imageName || ""}
                        style={{
                          width: isMobile ? '90px' : '130px',
                          height: isMobile ? '90px' : '130px',
                          objectFit: 'cover',
                          marginTop: 0,
                        }}
                        className={(haiku.selectedImage === imageName) ? `suggestion-card-image-focus ` : `haiku-card-image`}
                        onClick={() => setHaikus((prevHaikus) => {
                          return prevHaikus.map((h, idx) => {
                            if (idx === index) {
                              return { ...h, selectedImage: imageName }
                            } else {
                              return { ...h }
                            }
                          })
                        })}
                      />
                    ))}
                  </div>
                )}
              </div>
            )
          ))}
        </div>
      </div>
    </div>
  );
}

function Thumbnails({ haikus, activeIndex, setActiveIndex, isMobile }: { haikus: Haiku[], activeIndex: number, setActiveIndex: (index: number) => void, isMobile: boolean }) {
  if (haikus.length == 0 || isMobile) { return null }
  return (
    <div className="w-40 p-4 border-r border-gray-200 overflow-y-auto overflow-x-hidden">
      {haikus.map((haiku, index) => (
        <div
          key={index}
          data-testid="thumbnail-haiku"
          className={`haiku-card animated-fade-in mb-4 cursor-pointer ${index === activeIndex ? 'active' : ''}`}
          style={{
            width: '80px',
            transform: 'scale(0.2)',
            transformOrigin: 'top left',
            marginBottom: '-340px',
            opacity: index === activeIndex ? 1 : 0.5,
            transition: 'opacity 0.2s',
          }}
          onClick={() => setActiveIndex(index)}
        >
          {haiku.japanese.map((line, lineIndex) => (
            <div
              className="flex items-start gap-2 mb-2 haiku-line"
              key={lineIndex}
            >
              <p className="text-2xl font-bold text-gray-600 w-auto">{line}</p>
              <p className="text-xs font-light text-gray-500 w-auto">{haiku.english?.[lineIndex]}</p>
            </div>
          ))}
          {haiku.image_names && haiku.image_names.length === 3 && (
            <div className="mt-2 flex gap-2 justify-center">
              {haiku.image_names.map((imageName, imgIndex) => (
                <img
                  style={{
                    width: '110px',
                    height: '110px',
                    objectFit: 'cover',
                  }}
                  key={imageName}
                  src={`/images/${imageName}`}
                  alt={imageName || ""}
                  className="haiku-card-image w-12 h-12 object-cover"
                />
              ))}
            </div>
          )}
        </div>
      ))}
    </div>
  )

}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/style.css
================================================
.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.copilotKitHeader {
  border-top-left-radius: 5px !important;
}

.page-background {
  /* Darker gradient background */
  background: linear-gradient(170deg, #e9ecef 0%, #ced4da 100%);
}

@keyframes fade-scale-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.98);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

/* Updated card entry animation */
@keyframes pop-in {
  0% {
    opacity: 0;
    transform: translateY(15px) scale(0.95);
  }
  70% {
    opacity: 1;
    transform: translateY(-2px) scale(1.02);
  }
  100% {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

/* Animation for subtle background gradient movement */
@keyframes animated-gradient {
  0% {
    background-position: 0% 50%;
  }
  50% {
    background-position: 100% 50%;
  }
  100% {
    background-position: 0% 50%;
  }
}

/* Animation for flash effect on apply */
@keyframes flash-border-glow {
  0% {
    /* Start slightly intensified */
    border-top-color: #ff5b4a !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 25px rgba(255, 91, 74, 0.5);
  }
  50% {
    /* Peak intensity */
    border-top-color: #ff4733 !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.08),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 35px rgba(255, 71, 51, 0.7);
  }
  100% {
    /* Return to default state appearance */
    border-top-color: #ff6f61 !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 10px rgba(255, 111, 97, 0.15);
  }
}

/* Existing animation for haiku lines */
@keyframes fade-slide-in {
  from {
    opacity: 0;
    transform: translateX(-15px);
  }
  to {
    opacity: 1;
    transform: translateX(0);
  }
}

.animated-fade-in {
  /* Use the new pop-in animation */
  animation: pop-in 0.6s ease-out forwards;
}

.haiku-card {
  /* Subtle animated gradient background */
  background: linear-gradient(120deg, #ffffff 0%, #fdfdfd 50%, #ffffff 100%);
  background-size: 200% 200%;
  animation: animated-gradient 10s ease infinite;

  /* === Explicit Border Override Attempt === */
  /* 1. Set the default grey border for all sides */
  border: 1px solid #dee2e6;

  /* 2. Explicitly override the top border immediately after */
  border-top: 10px solid #ff6f61 !important; /* Orange top - Added !important */
  /* === End Explicit Border Override Attempt === */

  padding: 2.5rem 3rem;
  border-radius: 20px;

  /* Default glow intensity */
  box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
  inset 0 1px 2px rgba(0, 0, 0, 0.01),
  0 0 15px rgba(255, 111, 97, 0.25);
  text-align: left;
  max-width: 745px;
  margin: 3rem auto;
  min-width: 600px;

  /* Transition */
  transition: transform 0.35s ease, box-shadow 0.35s ease, border-top-width 0.35s ease, border-top-color 0.35s ease;
}

.haiku-card:hover {
  transform: translateY(-8px) scale(1.03);
  /* Enhanced shadow + Glow */
  box-shadow: 0 15px 35px rgba(0, 0, 0, 0.1),
  inset 0 1px 2px rgba(0, 0, 0, 0.01),
  0 0 25px rgba(255, 91, 74, 0.5);
  /* Modify only top border properties */
  border-top-width: 14px !important; /* Added !important */
  border-top-color: #ff5b4a !important; /* Added !important */
}

.haiku-card .flex {
  margin-bottom: 1.5rem;
}

.haiku-card .flex.haiku-line { /* Target the lines specifically */
  margin-bottom: 1.5rem;
  opacity: 0; /* Start hidden for animation */
  animation: fade-slide-in 0.5s ease-out forwards;
  /* animation-delay is set inline in page.tsx */
}

/* Remove previous explicit color overrides - rely on Tailwind */
/* .haiku-card p.text-4xl {
  color: #212529;
}

.haiku-card p.text-base {
  color: #495057;
} */

.haiku-card.applied-flash {
  /* Apply the flash animation once */
  /* Note: animation itself has !important on border-top-color */
  animation: flash-border-glow 0.6s ease-out forwards;
}

/* Styling for images within the main haiku card */
.haiku-card-image {
  width: 9.5rem; /* Increased size (approx w-48) */
  height: 9.5rem; /* Increased size (approx h-48) */
  object-fit: cover;
  border-radius: 1.5rem; /* rounded-xl */
  border: 1px solid #e5e7eb;
  /* Enhanced shadow with subtle orange hint */
  box-shadow: 0 8px 15px rgba(0, 0, 0, 0.1),
  0 3px 6px rgba(0, 0, 0, 0.08),
  0 0 10px rgba(255, 111, 97, 0.2);
  /* Inherit animation delay from inline style */
  animation-name: fadeIn;
  animation-duration: 0.5s;
  animation-fill-mode: both;
}

/* Styling for images within the suggestion card */
.suggestion-card-image {
  width: 6.5rem; /* Increased slightly (w-20) */
  height: 6.5rem; /* Increased slightly (h-20) */
  object-fit: cover;
  border-radius: 1rem; /* Equivalent to rounded-md */
  border: 1px solid #d1d5db; /* Equivalent to border (using Tailwind gray-300) */
  margin-top: 0.5rem;
  /* Added shadow for suggestion images */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1),
  0 2px 4px rgba(0, 0, 0, 0.06);
  transition: all 0.2s ease-in-out; /* Added for smooth deselection */
}

/* Styling for the focused suggestion card image */
.suggestion-card-image-focus {
  width: 6.5rem;
  height: 6.5rem;
  object-fit: cover;
  border-radius: 1rem;
  margin-top: 0.5rem;
  /* Highlight styles */
  border: 2px solid #ff6f61; /* Thicker, themed border */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1), /* Base shadow for depth */
  0 0 12px rgba(255, 111, 97, 0.6); /* Orange glow */
  transform: scale(1.05); /* Slightly scale up */
  transition: all 0.2s ease-in-out; /* Smooth transition for focus */
}

/* Styling for the suggestion card container in the sidebar */
.suggestion-card {
  border: 1px solid #dee2e6; /* Same default border as haiku-card */
  border-top: 10px solid #ff6f61; /* Same orange top border */
  border-radius: 0.375rem; /* Default rounded-md */
  /* Note: background-color is set by Tailwind bg-gray-100 */
  /* Other styles like padding, margin, flex are handled by Tailwind */
}

.suggestion-image-container {
  display: flex;
  gap: 1rem;
  justify-content: space-between;
  width: 100%;
  height: 6.5rem;
}

/* Mobile responsive styles - matches useMobileView hook breakpoint */
@media (max-width: 767px) {
  .haiku-card {
    padding: 1rem 1.5rem; /* Reduced from 2.5rem 3rem */
    min-width: auto; /* Remove min-width constraint */
    max-width: 100%; /* Full width on mobile */
    margin: 1rem auto; /* Reduced margin */
  }

  .haiku-card-image {
    width: 5.625rem; /* 90px - smaller on mobile */
    height: 5.625rem; /* 90px - smaller on mobile */
  }

  .suggestion-card-image {
    width: 5rem; /* Slightly smaller on mobile */
    height: 5rem; /* Slightly smaller on mobile */
  }

  .suggestion-card-image-focus {
    width: 5rem; /* Slightly smaller on mobile */
    height: 5rem; /* Slightly smaller on mobile */
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/api/copilotkit/[integrationId]/route.ts
================================================
import {
  CopilotRuntime,
  ExperimentalEmptyAdapter,
  copilotRuntimeNextJSAppRouterEndpoint,
} from "@copilotkit/runtime";
import { agentsIntegrations } from "@/agents";

import { NextRequest } from "next/server";

export async function POST(request: NextRequest) {
  const integrationId = request.url.split("/").pop();

  const integration = agentsIntegrations.find((i) => i.id === integrationId);
  if (!integration) {
    return new Response("Integration not found", { status: 404 });
  }
  const agents = await integration.agents();
  const runtime = new CopilotRuntime({
    // @ts-ignore for now
    agents,
  });
  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter: new ExperimentalEmptyAdapter(),
    endpoint: `/api/copilotkit/${integrationId}`,
  });

  return handleRequest(request);
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/theme-provider.tsx
================================================
"use client";

import * as React from "react";
import { ThemeProvider as NextThemesProvider, ThemeProviderProps as NextThemeProviderProps } from "next-themes";

export function ThemeProvider({ children, ...props }: NextThemeProviderProps) {
  return <NextThemesProvider {...props}>{children}</NextThemesProvider>;
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/code-viewer/code-editor.tsx
================================================
import React from "react";
import Editor from "@monaco-editor/react";
import { useTheme } from "next-themes";
import { FeatureFile } from "@/types/feature";
interface CodeEditorProps {
  file?: FeatureFile;
  onFileChange?: (fileName: string, content: string) => void;
}

export function CodeEditor({ file, onFileChange }: CodeEditorProps) {
  const handleEditorChange = (value: string | undefined) => {
    if (value && onFileChange) {
      onFileChange(file!.name, value);
    }
  };

  const theme = useTheme();

  return file ? (
    <div className="h-full flex flex-col">
      <Editor
        height="100%"
        language={file.language}
        value={file.content}
        onChange={handleEditorChange}
        options={{
          minimap: { enabled: false },
          fontSize: 16,
          lineNumbers: "on",
          readOnly: true,
          wordWrap: "on",
          stickyScroll: {
            enabled: false,
          },
        }}
        theme="vs-dark"
      />
    </div>
  ) : (
    <div className="p-6 text-center text-muted-foreground">
      Select a file from the file tree to view its code
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/code-viewer/code-viewer.tsx
================================================
import { useMemo, useState } from "react";
import { FileTree } from "@/components/file-tree/file-tree";
import { CodeEditor } from './code-editor'
import { FeatureFile } from "@/types/feature";
import { useURLParams } from "@/contexts/url-params-context";

export default function CodeViewer({
  codeFiles
}: {
  codeFiles: FeatureFile[];
}) {
  const { file, setCodeFile } = useURLParams();

  const selectedFile = useMemo(() => (
    codeFiles.find(f => f.name === file) ?? codeFiles[0]
  ), [codeFiles, file])

  return (
    <div className="flex h-full">
      <div className="w-72 border-r flex flex-col bg-background">
        <div className="flex-1 overflow-auto">
          <FileTree
            files={codeFiles}
            selectedFile={selectedFile}
            onFileSelect={setCodeFile}
          />
        </div>
      </div>
      <div className="flex-1 h-full py-5 bg-[#1e1e1e]">
        {selectedFile ? (
          <div className="h-full">
            <CodeEditor
              file={selectedFile}
            />
          </div>
        ) : (
          <div className="flex items-center justify-center h-full text-muted-foreground">
            Select a file to view its content.
          </div>
        )}
      </div>
    </div>
  )
}


================================================
FILE: typescript-sdk/apps/dojo/src/components/demo-list/demo-list.tsx
================================================
import React from "react";
import { FeatureConfig } from "@/types/feature";
import { cn } from "@/lib/utils";
import { Badge } from "@/components/ui/badge";

interface DemoListProps {
  demos: FeatureConfig[];
  selectedDemo?: string;
  onSelect: (demoId: string) => void;
  llmSelector?: React.ReactNode;
}

export function DemoList({ demos, selectedDemo, onSelect, llmSelector }: DemoListProps) {
  return (
    <div className="h-full">
      <div className="px-4 pt-3 pb-2">
        <h2
          className={cn(
            "transition-all duration-300 ease-in-out inline-block whitespace-nowrap paragraphs-Small-Regular-Uppercase text-[10px] text-palette-text-secondary opacity-100 scale-100 w-fit",
          )}
        >
          Demos
        </h2>
        {llmSelector && <div className="mt-2">{llmSelector}</div>}
      </div>
      <ul className="px-2 space-y-1">
        {demos.map((demo) => (
          <li key={demo.id}>
            <button
              className={cn(
                "w-full text-left py-2 px-3 rounded-sm hover:bg-white/50 transition-colors",
                "flex flex-col gap-0.5",
                selectedDemo === demo.id && "bg-white/70",
              )}
              onClick={() => onSelect(demo.id)}
            >
              <div className="text-sm font-medium leading-tight">{demo.name}</div>
              <div className="text-xs text-muted-foreground line-clamp-2 leading-relaxed">
                {demo.description}
              </div>
              {demo.tags && demo.tags.length > 0 && (
                <div className="flex gap-1 flex-wrap mt-0.5">
                  {demo.tags.map((tag) => (
                    <Badge
                      key={tag}
                      className={cn(
                        "text-xs px-1.5 py-0.5 rounded-full bg-white/65 text-primary",
                        selectedDemo === demo.id &&
                        "bg-primary text-primary-foreground border-transparent",
                      )}
                    >
                      {tag}
                    </Badge>
                  ))}
                </div>
              )}
            </button>
          </li>
        ))}
      </ul>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/file-tree/file-tree-nav.tsx
================================================
import React from "react";
import { ChevronRight, FolderOpen } from "lucide-react";
import { Button } from "@/components/ui/button";
import { cn } from "@/lib/utils";
import { relative } from "path";

interface FileTreeNavProps {
  path: string;
  rootPath: string; // The demo's root path
  onNavigate?: (path: string) => void;
}

export function FileTreeNav({ path, rootPath, onNavigate }: FileTreeNavProps) {
  const folderName = rootPath.split("/").pop();

  return (
    <div className="flex items-center gap-1 p-2 text-sm border-b overflow-x-auto">
      <Button variant="ghost" size="sm" className="h-6 px-2" onClick={() => onNavigate?.(rootPath)}>
        <FolderOpen className="h-4 w-4" />
      </Button>
      <Button
        variant="ghost"
        size="sm"
        className={cn("h-6 px-2 truncate", "font-medium text-foreground")}
      >
        {folderName}
      </Button>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/file-tree/file-tree.tsx
================================================
import React from "react";
import { ChevronDown, ChevronRight, File, Folder } from "lucide-react";
import { cn } from "@/lib/utils";
import { FeatureFile } from "@/types/feature";

interface FileTreeProps {
  files: FeatureFile[];
  onFileSelect: (fileName: string) => void;
  selectedFile?: FeatureFile;
}

function FileTreeNode({
  entry,
  depth = 0,
  onFileSelect,
  selectedFileName,
}: {
  entry: FeatureFile;
  depth?: number;
  onFileSelect: (fileName: string) => void;
  selectedFileName?: string;
}) {
  const [isOpen, setIsOpen] = React.useState(true);
  const isDirectory = entry.type === "directory";
  const isSelected = entry.name === selectedFileName;

  return (
    <div className={cn("relative", depth > 0 && "pl-2")}>
      {depth > 0 && <div className="absolute left-0 top-0 h-full w-px bg-border" />}
      <button
        className={cn(
          "flex w-full items-center gap-2 rounded-sm px-2 py-1 text-sm hover:bg-accent/50",
          isSelected && "bg-accent",
          depth === 1 && "ml-0.5",
          depth === 2 && "ml-1",
          depth === 3 && "ml-1.5",
          depth === 4 && "ml-2",
          depth > 4 && "ml-2.5",
        )}
        onClick={() => {
          if (isDirectory) {
            setIsOpen(!isOpen);
          } else {
            onFileSelect(entry.name);
          }
        }}
      >
        {isDirectory ? (
          <>
            {isOpen ? <ChevronDown className="h-4 w-4" /> : <ChevronRight className="h-4 w-4" />}
            <Folder className="h-4 w-4" />
          </>
        ) : (
          <>
            <span className="w-4" />
            <File className="h-4 w-4" />
          </>
        )}
        <span className="truncate">{entry.name}</span>
      </button>
    </div>
  );
}

export function FileTree({ files, onFileSelect, selectedFile }: FileTreeProps) {
  return (
    <div className="p-2">
      {files.map((entry) => (
        <FileTreeNode
          key={entry.name}
          entry={entry}
          onFileSelect={onFileSelect}
          selectedFileName={selectedFile?.name}
        />
      ))}
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/layout/main-layout.tsx
================================================
"use client";

import React, { Suspense, useState, useEffect } from "react";
import { ViewerLayout } from "@/components/layout/viewer-layout";
import { Sidebar } from "@/components/sidebar/sidebar";
import { Menu, X } from "lucide-react";
import { Button } from "@/components/ui/button";

import { useURLParams } from "@/contexts/url-params-context";
import { getTitleForCurrentDomain } from "@/utils/domain-config";

export function MainLayout({ children }: { children: React.ReactNode }) {
  const [isMobileSidebarOpen, setIsMobileSidebarOpen] = useState(false);
  const [isMobile, setIsMobile] = useState(false);

  // Check if we're on mobile
  useEffect(() => {
    const checkMobile = () => {
      const mobile = window.innerWidth < 768; // md breakpoint
      setIsMobile(mobile);
      // Auto-close sidebar when switching to desktop
      if (!mobile) {
        setIsMobileSidebarOpen(false);
      }
    };

    // Initial check
    if (typeof window !== 'undefined') {
      checkMobile();
    }

    // Listen for resize events
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  const toggleMobileSidebar = () => {
    setIsMobileSidebarOpen(!isMobileSidebarOpen);
  };

  return (
    <ViewerLayout>
      <div className="flex h-full w-full overflow-hidden relative gap-2">
        {/* Mobile Header with Hamburger Menu */}
        {isMobile && (
          <div className="absolute top-0 left-0 right-0 z-50 bg-background border-b p-2 md:hidden">
            <div className="flex items-center justify-between">
              <Button
                variant="ghost"
                size="sm"
                onClick={toggleMobileSidebar}
                className="p-2"
              >
                {isMobileSidebarOpen ? <X className="h-5 w-5" /> : <Menu className="h-5 w-5" />}
              </Button>
              <h1 className="text-sm font-medium text-center flex-1">{getTitleForCurrentDomain() || "AG-UI Dojo"}</h1>
              <div className="w-9" /> {/* Spacer for centering */}
            </div>
          </div>
        )}

        {/* Mobile Overlay */}
        {isMobile && isMobileSidebarOpen && (
          <div
            className="absolute inset-0 bg-black/50 z-40 md:hidden"
            onClick={toggleMobileSidebar}
          />
        )}
        {/* Sidebar */}
        <Suspense>
          <MaybeSidebar
            isMobile={isMobile}
            isMobileSidebarOpen={isMobileSidebarOpen}
            onMobileClose={() => setIsMobileSidebarOpen(false)}
          />
        </Suspense>

        {/* Content */}
        <div className={`flex-1 overflow-auto ${isMobile ? 'pt-12' : ''}`}>
          <div className="h-full">{children}</div>
        </div>
      </div>
    </ViewerLayout>
  );
}

interface MaybeSidebarProps {
  isMobile: boolean;
  isMobileSidebarOpen: boolean;
  onMobileClose: () => void;
}

function MaybeSidebar({ isMobile, isMobileSidebarOpen, onMobileClose }: MaybeSidebarProps) {
  const { sidebarHidden } = useURLParams();

  // Don't render sidebar if disabled by query param
  if (sidebarHidden) return null;

  // On mobile, only show if open
  if (isMobile && !isMobileSidebarOpen) return null;

  return (
    <div className={`
      ${isMobile
        ? 'absolute left-0 top-0 z-50 h-full w-80 transform transition-transform duration-300 ease-in-out'
        : 'relative'
      }
    `}>
      <Sidebar
        isMobile={isMobile}
        onMobileClose={onMobileClose}
      />
    </div>
  );
}


================================================
FILE: typescript-sdk/apps/dojo/src/components/layout/viewer-layout.tsx
================================================
import React from "react";
import { ViewerConfig } from "@/types/feature";
import { cn } from "@/lib/utils";
import { useMobileView } from "@/utils/use-mobile-view";

interface ViewerLayoutProps extends ViewerConfig {
  className?: string;
  children?: React.ReactNode;
  codeEditor?: React.ReactNode;
  fileTree?: React.ReactNode;
  sidebarHeader?: React.ReactNode;
}

export function ViewerLayout({
  className,
  children,
}: ViewerLayoutProps) {
  const { isMobile } = useMobileView();

  return (
    <div className={cn("relative flex h-screen overflow-hidden bg-palette-surface-main", className, {
      "p-spacing-2": !isMobile,
    })}>
      <div className="flex flex-1 overflow-hidden z-1">
        <main className="flex-1 overflow-auto">
          <div className="h-full">{children}</div>
        </main>
      </div>
      {/* Background blur circles - Figma exact specs */}
      {/* Ellipse 1351 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[1040px] top-[11px] rounded-full z-0" 
           style={{ background: 'rgba(255, 172, 77, 0.2)', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1347 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[1338.97px] top-[624.5px] rounded-full z-0"
           style={{ background: '#C9C9DA', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1350 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[670px] top-[-365px] rounded-full z-0"
           style={{ background: '#C9C9DA', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1348 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[507.87px] top-[702.14px] rounded-full z-0"
           style={{ background: '#F3F3FC', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1346 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[127.91px] top-[331px] rounded-full z-0"
           style={{ background: 'rgba(255, 243, 136, 0.3)', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1268 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[-205px] top-[802.72px] rounded-full z-0"
           style={{ background: 'rgba(255, 172, 77, 0.2)', filter: 'blur(103.196px)' }} />
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/readme/readme.tsx
================================================
"use client";

import { MDXRenderer } from "@/utils/mdx-utils";

export default function Readme({ content }: { content: string }) {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-start pt-24 px-8">
      <div className="w-full max-w-4xl">{<MDXRenderer content={content} />}</div>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/sidebar/sidebar.tsx
================================================
"use client";

import React, { useState, useEffect } from "react";
import { EyeIcon as Eye, CodeIcon as Code, BookOpenTextIcon as Book } from "@phosphor-icons/react";
import { cn } from "@/lib/utils";
import { useRouter, usePathname } from "next/navigation";
import { DemoList } from "@/components/demo-list/demo-list";
import { ThemeToggle } from "@/components/ui/theme-toggle";
import { ChevronDown } from "lucide-react";
import featureConfig from "@/config";
import {
  DropdownMenu,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuItem,
} from "../ui/dropdown-menu";
import { Tabs, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Button } from "../ui/button";
import { menuIntegrations } from "@/menu";
import { Feature } from "@/types/integration";
import { useURLParams } from "@/contexts/url-params-context";
import { View } from "@/types/interface";
import { getTitleForCurrentDomain } from "@/utils/domain-config";
import { useTheme } from "next-themes";

interface SidebarProps {
  isMobile?: boolean;
  onMobileClose?: () => void;
}

export function Sidebar({ isMobile, onMobileClose }: SidebarProps) {
  const router = useRouter();
  const pathname = usePathname();
  const { theme, setTheme } = useTheme();
  const isDarkTheme = theme === "dark"
  const { view, frameworkPickerHidden, viewPickerHidden, featurePickerHidden, setView} = useURLParams();

  // Extract the current integration ID from the pathname
  const pathParts = pathname.split("/");
  const currentIntegrationId = pathParts[1]; // First segment after root
  const currentDemoId = pathParts[pathParts.length - 1];

  // Find the current integration (only if we have a valid integration ID)
  const currentIntegration =
    currentIntegrationId && currentIntegrationId !== ""
      ? menuIntegrations.find((integration) => integration.id === currentIntegrationId)
      : null;

  // Filter demos based on current integration's features
  const filteredDemos = currentIntegration
    ? featureConfig.filter((demo) =>
        currentIntegration.features.includes(demo.id as unknown as Feature),
      )
    : []; // Show no demos if no integration is selected

  // Handle selecting a demo
  const handleDemoSelect = (demoId: string) => {
    if (currentIntegration) {
      router.push(`/${currentIntegration.id}/feature/${demoId}`);
      // Close mobile sidebar when demo is selected
      if (isMobile && onMobileClose) {
        onMobileClose();
      }
    }
  };

  // Handle integration selection
  const handleIntegrationSelect = (integrationId: string) => {
    router.push(`/${integrationId}`);
  };

  const tabClass = `cursor-pointer flex-1 h-8 px-2 text-sm text-primary shadow-none bg-none border-none font-medium gap-1 rounded-lg data-[state=active]:bg-white data-[state=active]:text-primary data-[state=active]:shadow-none`

  return (
    <div className={`flex flex-col h-full border-2 border-palette-border-default
      ${isMobile ? 'w-80 shadow-xl bg-white z-99' : 'bg-white/50 w-74 min-w-[296px] flex-shrink-0 rounded-lg overflow-hidden'}
    `}>
      {/* Sidebar Header */}
      <div className="p-4">
        <div className="flex items-center justify-between ml-1">
          <div className="flex items-start flex-col">
            <h1 className={`text-lg font-light ${isDarkTheme ? "text-white" : "text-gray-900"}`}>
              {getTitleForCurrentDomain() || "AG-UI Interactive Dojo"}
            </h1>
          </div>

          {/*<ThemeToggle />*/}
        </div>
      </div>

      {/* Controls Section */}
      {(!frameworkPickerHidden|| !viewPickerHidden) && (
      <div className="p-4 border-b">
        {/* Integration picker */}
        {!frameworkPickerHidden&& (
          <div className="mb-spacing-4">
            <SectionTitle title="Integrations" />
            <DropdownMenu>
              <DropdownMenuTrigger asChild>
                <div className="flex items-center justify-between h-spacing-8 rounded-sm gap-spacing-2 px-spacing-3 transition-colors hover:bg-palette-surface-containerHovered cursor-pointer">
                  <span className="pb-[2px] text-palette-text-primary font-medium leading-[22px] inline-block truncate">
                    {currentIntegration ? currentIntegration.name : "Select Integration"}
                  </span>
                  <ChevronDown className="text-palette-icon-default transition-transform" size={16} />
                </div>
              </DropdownMenuTrigger>
              <DropdownMenuContent className="w-64 bg-palette-surface-container border-palette-border-container shadow-elevation-md">
                {menuIntegrations.map((integration) => (
                  <DropdownMenuItem
                    key={integration.id}
                    onClick={() => handleIntegrationSelect(integration.id)}
                    className="cursor-pointer hover:bg-palette-grey-200 text-palette-text-primary text-base h-10 rounded-sm"
                  >
                    <span>{integration.name}</span>
                  </DropdownMenuItem>
                ))}
              </DropdownMenuContent>
            </DropdownMenu>
          </div>
        )}

        {/* Preview/Code Tabs */}
        {!viewPickerHidden &&
        <div className="mb-1">
          <SectionTitle title="View" />
          <Tabs
            value={view}
            onValueChange={tab => setView(tab as View)}
            className="w-full rounded-lg bg-none border-none"
          >
            <TabsList className="w-full rounded-lg h-8 p-0 bg-transparent border-none">
              <TabsTrigger
                value="preview"
                className={tabClass}
              >
                <Eye className="h-3 w-3" />
                <span>Preview</span>
              </TabsTrigger>
              <TabsTrigger
                value="code"
                className={tabClass}
              >
                <Code className="h-3 w-3" />
                <span>Code</span>
              </TabsTrigger>
              <TabsTrigger
                value="readme"
                className={tabClass}
              >
                <Book className="h-3 w-3" />
                <span>Docs</span>
              </TabsTrigger>
            </TabsList>
          </Tabs>
        </div>
        }
      </div>
      )}

      {/* Demo List */}
      <div className="flex-1 overflow-auto">
        {(currentIntegration && !featurePickerHidden) ? (
          <DemoList
            demos={filteredDemos}
            selectedDemo={currentDemoId}
            onSelect={handleDemoSelect}
          />
        ) : (
          <div className="flex items-center justify-center h-full p-8">
            <p className="text-muted-foreground text-center"></p>
          </div>
        )}
      </div>
    </div>
  );
}

function SectionTitle({ title }: { title: string }) {
  return (
    <div
      className={cn(
        "items-center",
        "flex px-spacing-1 gap-spacing-2 mb-2",
      )}
    >
      <label
        className={cn(
          "transition-all duration-300 ease-in-out inline-block whitespace-nowrap paragraphs-Small-Regular-Uppercase text-[10px] text-palette-text-secondary opacity-100 scale-100 w-fit",
        )}
      >
        {title}
      </label>
      <div
        className={cn(
          "h-[1px] bg-palette-border-container transition-all duration-300 ease-[cubic-bezier(0.36,0.01,0.22,1)]",
          "w-full",
        )}
      />
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/badge.tsx
================================================
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cva, type VariantProps } from "class-variance-authority";

import { cn } from "@/lib/utils";

const badgeVariants = cva(
  "inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden",
  {
    variants: {
      variant: {
        default: "border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90",
        destructive:
          "border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40",
        outline: "text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  },
);

function Badge({
  className,
  variant,
  asChild = false,
  ...props
}: React.ComponentProps<"span"> & VariantProps<typeof badgeVariants> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "span";

  return (
    <Comp data-slot="badge" className={cn(badgeVariants({ variant }), className)} {...props} />
  );
}

export { Badge, badgeVariants };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/button.tsx
================================================
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cva, type VariantProps } from "class-variance-authority";

import { cn } from "@/lib/utils";

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-[color,box-shadow] disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
  {
    variants: {
      variant: {
        default: "bg-primary text-primary-foreground shadow-xs hover:bg-primary/90",
        destructive:
          "bg-destructive text-white shadow-xs hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40",
        outline:
          "border border-input bg-background shadow-xs hover:bg-accent hover:text-accent-foreground",
        secondary: "bg-secondary text-secondary-foreground shadow-xs hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2 has-[>svg]:px-3",
        sm: "h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",
        lg: "h-10 rounded-md px-6 has-[>svg]:px-4",
        icon: "size-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  },
);

function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean;
  }) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  );
}

export { Button, buttonVariants };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/dropdown-menu.tsx
================================================
"use client";

import * as React from "react";
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu";
import { CheckIcon, ChevronRightIcon, CircleIcon } from "lucide-react";

import { cn } from "@/lib/utils";

function DropdownMenu({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Root>) {
  return <DropdownMenuPrimitive.Root data-slot="dropdown-menu" {...props} />;
}

function DropdownMenuPortal({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Portal>) {
  return <DropdownMenuPrimitive.Portal data-slot="dropdown-menu-portal" {...props} />;
}

function DropdownMenuTrigger({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Trigger>) {
  return <DropdownMenuPrimitive.Trigger data-slot="dropdown-menu-trigger" {...props} />;
}

function DropdownMenuContent({
  className,
  sideOffset = 4,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Content>) {
  return (
    <DropdownMenuPrimitive.Portal>
      <DropdownMenuPrimitive.Content
        data-slot="dropdown-menu-content"
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 max-h-(--radix-dropdown-menu-content-available-height) min-w-[8rem] overflow-x-hidden overflow-y-auto rounded-md border p-1 shadow-md",
          className,
        )}
        {...props}
      />
    </DropdownMenuPrimitive.Portal>
  );
}

function DropdownMenuGroup({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Group>) {
  return <DropdownMenuPrimitive.Group data-slot="dropdown-menu-group" {...props} />;
}

function DropdownMenuItem({
  className,
  inset,
  variant = "default",
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Item> & {
  inset?: boolean;
  variant?: "default" | "destructive";
}) {
  return (
    <DropdownMenuPrimitive.Item
      data-slot="dropdown-menu-item"
      data-inset={inset}
      data-variant={variant}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[variant=destructive]:text-destructive-foreground data-[variant=destructive]:focus:bg-destructive/10 dark:data-[variant=destructive]:focus:bg-destructive/40 data-[variant=destructive]:focus:text-destructive-foreground data-[variant=destructive]:*:[svg]:!text-destructive-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function DropdownMenuCheckboxItem({
  className,
  children,
  checked,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.CheckboxItem>) {
  return (
    <DropdownMenuPrimitive.CheckboxItem
      data-slot="dropdown-menu-checkbox-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      checked={checked}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.CheckboxItem>
  );
}

function DropdownMenuRadioGroup({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioGroup>) {
  return <DropdownMenuPrimitive.RadioGroup data-slot="dropdown-menu-radio-group" {...props} />;
}

function DropdownMenuRadioItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioItem>) {
  return (
    <DropdownMenuPrimitive.RadioItem
      data-slot="dropdown-menu-radio-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CircleIcon className="size-2 fill-current" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.RadioItem>
  );
}

function DropdownMenuLabel({
  className,
  inset,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Label> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.Label
      data-slot="dropdown-menu-label"
      data-inset={inset}
      className={cn("px-2 py-1.5 text-sm font-medium data-[inset]:pl-8", className)}
      {...props}
    />
  );
}

function DropdownMenuSeparator({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Separator>) {
  return (
    <DropdownMenuPrimitive.Separator
      data-slot="dropdown-menu-separator"
      className={cn("bg-border -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function DropdownMenuShortcut({ className, ...props }: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="dropdown-menu-shortcut"
      className={cn("text-muted-foreground ml-auto text-xs tracking-widest", className)}
      {...props}
    />
  );
}

function DropdownMenuSub({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Sub>) {
  return <DropdownMenuPrimitive.Sub data-slot="dropdown-menu-sub" {...props} />;
}

function DropdownMenuSubTrigger({
  className,
  inset,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubTrigger> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.SubTrigger
      data-slot="dropdown-menu-sub-trigger"
      data-inset={inset}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex cursor-default items-center rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[inset]:pl-8",
        className,
      )}
      {...props}
    >
      {children}
      <ChevronRightIcon className="ml-auto size-4" />
    </DropdownMenuPrimitive.SubTrigger>
  );
}

function DropdownMenuSubContent({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubContent>) {
  return (
    <DropdownMenuPrimitive.SubContent
      data-slot="dropdown-menu-sub-content"
      className={cn(
        "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[8rem] overflow-hidden rounded-md border p-1 shadow-lg",
        className,
      )}
      {...props}
    />
  );
}

export {
  DropdownMenu,
  DropdownMenuPortal,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuGroup,
  DropdownMenuLabel,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioGroup,
  DropdownMenuRadioItem,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuSub,
  DropdownMenuSubTrigger,
  DropdownMenuSubContent,
};



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/markdown-components.tsx
================================================
import React from "react";
import { cn } from "@/lib/utils";

export const MarkdownComponents = {
  // Header components
  h1: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h1
        className={cn(
          "text-3xl font-bold mt-8 mb-6 text-gray-900 dark:text-gray-50 border-b pb-2",
          className,
        )}
        {...props}
      >
        {children}
      </h1>
    );
  },

  h2: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h2
        className={cn("text-2xl font-bold mt-8 mb-4 text-gray-900 dark:text-gray-50", className)}
        {...props}
      >
        {children}
      </h2>
    );
  },

  h3: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h3
        className={cn("text-xl font-bold mt-6 mb-3 text-gray-900 dark:text-gray-50", className)}
        {...props}
      >
        {children}
      </h3>
    );
  },

  // Paragraph component
  p: ({ className, children, ...props }: React.HTMLAttributes<HTMLParagraphElement>) => {
    return (
      <p
        className={cn("my-4 text-gray-700 dark:text-gray-300 leading-relaxed", className)}
        {...props}
      >
        {children}
      </p>
    );
  },

  // List components
  ul: ({ className, children, ...props }: React.HTMLAttributes<HTMLUListElement>) => {
    return (
      <ul className={cn("my-4 pl-6 list-disc space-y-2", className)} {...props}>
        {children}
      </ul>
    );
  },

  ol: ({ className, children, ...props }: React.HTMLAttributes<HTMLOListElement>) => {
    return (
      <ol className={cn("my-4 pl-6 list-decimal space-y-2", className)} {...props}>
        {children}
      </ol>
    );
  },

  li: ({ className, children, ...props }: React.HTMLAttributes<HTMLLIElement>) => {
    return (
      <li className={cn("text-gray-700 dark:text-gray-300 my-1", className)} {...props}>
        {children}
      </li>
    );
  },

  // Custom code block rendering
  code: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    const match = /language-(\w+)/.exec(className || "");
    const language = match ? match[1] : "";

    // If it's an inline code block (no language specified and no line breaks)
    if (!match && typeof children === "string" && !children.includes("\n")) {
      return (
        <code
          className={cn(
            "bg-gray-100 dark:bg-gray-800 text-gray-800 dark:text-gray-200 px-1.5 py-0.5 rounded text-sm font-mono",
            className,
          )}
          {...props}
        >
          {children}
        </code>
      );
    }

    return (
      <div className="relative group my-6">
        {language && (
          <div className="absolute right-2 top-2 text-xs text-gray-500 dark:text-gray-400 font-mono bg-gray-100 dark:bg-gray-800 px-2 py-1 rounded">
            {language}
          </div>
        )}
        <pre
          className={cn(
            "p-4 rounded-lg overflow-x-auto border border-gray-200 dark:border-gray-700 bg-gray-100 dark:bg-gray-800",
            className,
          )}
        >
          <code {...props} className="text-sm font-mono">
            {children}
          </code>
        </pre>
      </div>
    );
  },

  // Custom link rendering
  a: ({ className, children, ...props }: React.AnchorHTMLAttributes<HTMLAnchorElement>) => {
    return (
      <a
        className={cn(
          "text-blue-600 dark:text-blue-400 font-medium underline underline-offset-2 hover:text-blue-800 dark:hover:text-blue-300 transition-colors",
          className,
        )}
        target="_blank"
        rel="noopener noreferrer"
        {...props}
      >
        {children}
      </a>
    );
  },

  // Custom table rendering
  table: ({ className, children, ...props }: React.TableHTMLAttributes<HTMLTableElement>) => {
    return (
      <div className="overflow-x-auto my-6">
        <table
          className={cn(
            "w-full border-collapse border border-gray-300 dark:border-gray-700",
            className,
          )}
          {...props}
        >
          {children}
        </table>
      </div>
    );
  },

  // Custom image rendering
  img: ({ className, alt, ...props }: React.ImgHTMLAttributes<HTMLImageElement>) => {
    return (
      <img
        className={cn("rounded-lg mx-auto my-6 max-w-full h-auto", className)}
        alt={alt || ""}
        {...props}
      />
    );
  },

  // Blockquote component
  blockquote: ({ className, children, ...props }: React.HTMLAttributes<HTMLQuoteElement>) => {
    return (
      <blockquote
        className={cn(
          "border-l-4 border-gray-300 dark:border-gray-700 pl-4 py-1 my-4 italic text-gray-700 dark:text-gray-300",
          className,
        )}
        {...props}
      >
        {children}
      </blockquote>
    );
  },

  // Horizontal rule
  hr: ({ className, ...props }: React.HTMLAttributes<HTMLHRElement>) => {
    return (
      <hr
        className={cn("my-8 border-t border-gray-300 dark:border-gray-700", className)}
        {...props}
      />
    );
  },

  // Strong/bold text
  strong: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    return (
      <strong className={cn("font-bold text-gray-900 dark:text-white", className)} {...props}>
        {children}
      </strong>
    );
  },

  // Emphasis/italic text
  em: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    return (
      <em className={cn("italic text-gray-800 dark:text-gray-200", className)} {...props}>
        {children}
      </em>
    );
  },
};



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/mdx-components.tsx
================================================
import React from "react";
import { cn } from "@/lib/utils";
import { MarkdownComponents } from "./markdown-components";
import type { Components } from "react-markdown";

// Video component specifically for MDX
export const VideoPlayer = ({
  src,
  width = "100%",
  className,
  ...props
}: React.VideoHTMLAttributes<HTMLVideoElement> & { src: string }) => {
  return (
    <div className="my-8">
      <video controls width={width} className={cn("rounded-lg w-full", className)} {...props}>
        <source src={src} type="video/mp4" />
        Your browser does not support the video tag.
      </video>
    </div>
  );
};

// Type definition for MDX components that includes our custom components
type CustomMDXComponents = Components & {
  Video: typeof VideoPlayer;
  video: typeof VideoPlayer;
};

// Combine all components for MDX
export const MDXComponents: CustomMDXComponents = {
  ...MarkdownComponents,
  // Custom components for MDX
  Video: VideoPlayer,
  video: VideoPlayer,
} as CustomMDXComponents;



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/tabs.tsx
================================================
"use client";

import * as React from "react";
import * as TabsPrimitive from "@radix-ui/react-tabs";

import { cn } from "@/lib/utils";

function Tabs({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Root>) {
  return (
    <TabsPrimitive.Root data-slot="tabs" className={cn("flex flex-col", className)} {...props} />
  );
}

function TabsList({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.List>) {
  return (
    <TabsPrimitive.List
      data-slot="tabs-list"
      className={cn(
        "bg-muted text-muted-foreground inline-flex h-9 w-fit items-center justify-center rounded-lg p-1",
        className,
      )}
      {...props}
    />
  );
}

function TabsTrigger({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Trigger>) {
  return (
    <TabsPrimitive.Trigger
      data-slot="tabs-trigger"
      className={cn(
        "data-[state=active]:bg-background data-[state=active]:text-foreground focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:outline-ring inline-flex flex-1 items-center justify-center gap-1.5 rounded-md px-2 py-1 text-sm font-medium whitespace-nowrap transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:shadow-sm [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function TabsContent({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Content>) {
  return (
    <TabsPrimitive.Content
      data-slot="tabs-content"
      className={cn("flex-1 outline-none", className)}
      {...props}
    />
  );
}

export { Tabs, TabsList, TabsTrigger, TabsContent };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/theme-toggle.tsx
================================================
"use client";

import * as React from "react";
import { Moon, Sun } from "lucide-react";
import { useTheme } from "next-themes";

import { Button } from "@/components/ui/button";

export function ThemeToggle() {
  const { theme, setTheme } = useTheme();

  return (
    <Button
      variant="ghost"
      size="icon"
      onClick={() => setTheme(theme === "light" ? "dark" : "light")}
      className="h-8 w-8 px-0"
    >
      <Sun className="h-4 w-4 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" />
      <Moon className="absolute h-4 w-4 rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" />
      <span className="sr-only">Toggle theme</span>
    </Button>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/contexts/url-params-context.tsx
================================================
'use client';

import React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { useRouter, usePathname, useSearchParams } from 'next/navigation';
import { View } from "@/types/interface";

interface URLParamsState {
  view: View;
  sidebarHidden: boolean;
  frameworkPickerHidden: boolean;
  viewPickerHidden: boolean;
  featurePickerHidden: boolean;
  file?: string;
}

interface URLParamsContextType extends URLParamsState {
  setView: (view: View) => void;
  setSidebarHidden: (disabled: boolean) => void;
  setFrameworkPickerHidden: (disabled: boolean) => void;
  setViewPickerHidden: (disabled: boolean) => void;
  setFeaturePickerHidden: (disabled: boolean) => void;
  setCodeFile: (fileName: string) => void;
}

const URLParamsContext = createContext<URLParamsContextType | undefined>(undefined);

interface URLParamsProviderProps {
  children: ReactNode;
}

export function URLParamsProvider({ children }: URLParamsProviderProps) {
  const router = useRouter();
  const pathname = usePathname();
  const searchParams = useSearchParams();

  // Initialize state from URL params
  const [state, setState] = useState<URLParamsState>(() => ({
    view: (searchParams.get("view") as View) || "preview",
    sidebarHidden: searchParams.get("sidebar") === "false",
    frameworkPickerHidden: searchParams.get("frameworkPicker") === "false",
    viewPickerHidden: searchParams.get("viewPicker") === "false",
    featurePickerHidden: searchParams.get("featurePicker") === "false",
  }));

  // Update URL when state changes
  const updateURL = (newState: Partial<URLParamsState>) => {
    const params = new URLSearchParams(searchParams.toString());

    // Update view param
    if (newState.view !== undefined) {
      if (newState.view === "preview") {
        params.delete("view"); // Remove default value to keep URL clean
      } else {
        params.set("view", newState.view);
      }
    }

    // Update sidebar param
    if (newState.sidebarHidden !== undefined) {
      if (newState.sidebarHidden) {
        params.set("sidebar", "false");
      } else {
        params.delete("sidebar");
      }
    }

    // Update frameworkPicker param
    if (newState.frameworkPickerHidden !== undefined) {
      if (newState.frameworkPickerHidden) {
        params.set("frameworkPicker", "false");
      } else {
        params.delete("frameworkPicker");
      }
    }

    // Update viewPicker param
    if (newState.viewPickerHidden !== undefined) {
      if (newState.viewPickerHidden) {
        params.set("viewPicker", "false");
      } else {
        params.delete("viewPicker");
      }
    }
    // Update featurePicker param
    if (newState.featurePickerHidden !== undefined) {
      if (newState.featurePickerHidden) {
        params.set("featurePicker", "false");
      } else {
        params.delete("features");
      }
    }

    const queryString = params.toString();
    router.push(pathname + (queryString ? '?' + queryString : ''));
  };

  // Sync state with URL changes (e.g., browser back/forward)
  useEffect(() => {
    const newState: URLParamsState = {
      view: (searchParams.get("view") as View) || "preview",
      sidebarHidden: searchParams.get("sidebar") === "false",
      frameworkPickerHidden: searchParams.get("frameworkPicker") === "false",
      viewPickerHidden: searchParams.get("viewPicker") === "false",
      featurePickerHidden: searchParams.get("featurePicker") === "false",
    };

    setState(newState);
  }, [searchParams]);

  // Context methods
  const setView = (view: View) => {
    const newState = { ...state, view };
    setState(newState);
    updateURL({ view });
  };

  const setSidebarHidden = (sidebarHidden: boolean) => {
    const newState = { ...state, sidebarHidden };
    setState(newState);
    updateURL({ sidebarHidden });
  };

  const setFrameworkPickerHidden = (frameworkPickerHidden: boolean) => {
    const newState = { ...state, frameworkPickerHidden };
    setState(newState);
    updateURL({ frameworkPickerHidden });
  };

  const setViewPickerHidden = (viewPickerHidden: boolean) => {
    const newState = { ...state, viewPickerHidden };
    setState(newState);
    updateURL({ viewPickerHidden });
  };

  const setFeaturePickerHidden = (featurePickerHidden: boolean) => {
    const newState = { ...state, featurePickerHidden };
    setState(newState);
    updateURL({ featurePickerHidden });
  };

  const setCodeFile = (fileName: string) => {
    const newState = { ...state, file: fileName };
    setState(newState);
    updateURL({ file: fileName });
  };

  const contextValue: URLParamsContextType = {
    ...state,
    setView,
    setSidebarHidden,
    setFrameworkPickerHidden,
    setViewPickerHidden,
    setFeaturePickerHidden,
    setCodeFile,
  };

  return (
    <URLParamsContext.Provider value={contextValue}>
      {children}
    </URLParamsContext.Provider>
  );
}

export function useURLParams(): URLParamsContextType {
  const context = useContext(URLParamsContext);
  if (context === undefined) {
    throw new Error('useURLParams must be used within a URLParamsProvider');
  }
  return context;
}



================================================
FILE: typescript-sdk/apps/dojo/src/lib/utils.ts
================================================
import { type ClassValue, clsx } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: typescript-sdk/apps/dojo/src/mastra/index.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { DynamoDBStore } from "@mastra/dynamodb";

import { Mastra } from "@mastra/core";
import { createTool } from "@mastra/core";
import { z } from "zod";



function getStorage(): LibSQLStore | DynamoDBStore {
  if (process.env.DYNAMODB_TABLE_NAME) {
    return new DynamoDBStore({
    name: "dynamodb",
    config: {
      tableName: process.env.DYNAMODB_TABLE_NAME
    },
  });
  } else {
    return new LibSQLStore({ url: "file::memory:" });
  }
}



export const mastra = new Mastra({
  agents: {
    agentic_chat: new Agent({
      name: "agentic_chat",
      instructions: `
        You are a helpful weather assistant that provides accurate weather information.

        Your primary function is to help users get weather details for specific locations. When responding:
        - Always ask for a location if none is provided
        - If the location name isn’t in English, please translate it
        - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
        - Include relevant details like humidity, wind conditions, and precipitation
        - Keep responses concise but informative

        Use the weatherTool to fetch current weather data.
  `,
      model: openai("gpt-4o"),
      memory: new Memory({
        storage: getStorage(),
        options: {
          workingMemory: {
            enabled: true,
            schema: z.object({
              firstName: z.string(),
            }),
          },
        },
      }),
    }),
    shared_state: new Agent({
      name: "shared_state",
      instructions: `
        You are a helpful assistant for creating recipes.

        IMPORTANT:
        1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
        2. For ingredients, append new ingredients to the existing ones.
        3. For instructions, append new steps to the existing ones.
        4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
        5. 'instructions' is always an array of strings

        If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did. Do not mention "working memory", "memory", or "state" in your answer.
      `,
      model: openai("gpt-4o"),
      memory: new Memory({
        storage: getStorage(),
        options: {
          workingMemory: {
            enabled: true,
            schema: z.object({
              recipe: z.object({
                skill_level: z
                  .enum(["Beginner", "Intermediate", "Advanced"])
                  .describe("The skill level required for the recipe"),
                special_preferences: z
                  .array(
                    z.enum([
                      "High Protein",
                      "Low Carb",
                      "Spicy",
                      "Budget-Friendly",
                      "One-Pot Meal",
                      "Vegetarian",
                      "Vegan",
                    ]),
                  )
                  .describe("A list of special preferences for the recipe"),
                cooking_time: z
                  .enum(["5 min", "15 min", "30 min", "45 min", "60+ min"])
                  .describe("The cooking time of the recipe"),
                ingredients: z
                  .array(
                    z.object({
                      icon: z
                        .string()
                        .describe(
                          "The icon emoji (not emoji code like '\x1f35e', but the actual emoji like 🥕) of the ingredient",
                        ),
                      name: z.string().describe("The name of the ingredient"),
                      amount: z.string().describe("The amount of the ingredient"),
                    }),
                  )
                  .describe(
                    "Entire list of ingredients for the recipe, including the new ingredients and the ones that are already in the recipe",
                  ),
                instructions: z
                  .array(z.string())
                  .describe(
                    "Entire list of instructions for the recipe, including the new instructions and the ones that are already there",
                  ),
                changes: z.string().describe("A description of the changes made to the recipe"),
              }),
            }),
          },
        },
      }),
    }),
    tool_based_generative_ui: new Agent({
      name: "tool_based_generative_ui",
      instructions: `
        You are a helpful assistant for creating haikus.
      `,
      model: openai("gpt-4o"),
      tools: {
        generate_haiku: createTool({
          id: "generate_haiku",
          description:
            "Generate a haiku in Japanese and its English translation. Also select exactly 3 relevant images from the provided list based on the haiku's theme.",
          inputSchema: z.object({
            japanese: z
              .array(z.string())
              .describe("An array of three lines of the haiku in Japanese"),
            english: z
              .array(z.string())
              .describe("An array of three lines of the haiku in English"),
          }),
          outputSchema: z.string(),
          execute: async ({ context }) => {
            return "Haiku generated.";
          },
        }),
      },
    }),
  },
});



================================================
FILE: typescript-sdk/apps/dojo/src/styles/typography.css
================================================
/* CopilotCloud Typography Components */

/* Headings */
.H1-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 56px;
  line-height: 64px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H1-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 56px;
  line-height: 64px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H2-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 40px;
  line-height: 46px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H2-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 40px;
  line-height: 46px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H3-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 32px;
  line-height: 36px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H3-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 32px;
  line-height: 36px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H4-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 24px;
  line-height: 28px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H4-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 24px;
  line-height: 28px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H5-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 20px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H5-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 20px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H6-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 18px;
  line-height: 20px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H6-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 18px;
  line-height: 20px;
  letter-spacing: 0px;
  font-weight: 500;
}

/* Paragraphs */
.paragraphs-Large-Bold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 700;
}

.paragraphs-Large-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Large-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Large-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Medium-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Medium-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Medium-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Small-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Small-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Small-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Small-Regular-Uppercase {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 400;
  text-transform: uppercase;
}

/* Details */
.details-Medium-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 14px;
  line-height: 14px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-Medium-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 14px;
  line-height: 14px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}

.details-Small-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 12px;
  line-height: 12px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-Small-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 12px;
  line-height: 12px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}

.details-ExtraSmall-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 10px;
  line-height: 10px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-ExtraSmall-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 10px;
  line-height: 10px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}


================================================
FILE: typescript-sdk/apps/dojo/src/types/feature.ts
================================================
export interface ViewerConfig {
  showCodeEditor?: boolean;
  showFileTree?: boolean;
  showLLMSelector?: boolean;
}

export interface FeatureFile {
  name: string;
  content: string;
  // path: string;
  language: string;
  type: string;
}

export interface FeatureConfig {
  id: string;
  name: string;
  description: string;
  path: string;
  tags?: string[];
}



================================================
FILE: typescript-sdk/apps/dojo/src/types/integration.ts
================================================
import { AbstractAgent } from "@ag-ui/client";

export type Feature =
  | "agentic_chat"
  | "agentic_generative_ui"
  | "human_in_the_loop"
  | "predictive_state_updates"
  | "shared_state"
  | "tool_based_generative_ui"
  | "agentic_chat_reasoning"
  | "subgraphs";

export interface MenuIntegrationConfig {
  id: string;
  name: string;
  features: Feature[];
}

export interface AgentIntegrationConfig {
  id: string;
  agents: () => Promise<Partial<Record<Feature, AbstractAgent>>>;
}



================================================
FILE: typescript-sdk/apps/dojo/src/types/interface.ts
================================================
export type View = "preview" | "code" | "readme";



================================================
FILE: typescript-sdk/apps/dojo/src/utils/domain-config.ts
================================================
import getEnvVars from "@/env";


export function getTitleForCurrentDomain(): string | undefined {
  const envVars = getEnvVars();

  // Check if we're in the browser
  if (typeof window == "undefined") {
    return undefined;
  }

  const host = window.location.hostname;
  return envVars.customDomainTitle[host] || undefined;
}


================================================
FILE: typescript-sdk/apps/dojo/src/utils/mdx-utils.tsx
================================================
import React from "react";
import { MDXComponents } from "@/components/ui/mdx-components";
import ReactMarkdown from "react-markdown";

/**
 * Enhanced MDX content renderer component
 */
export const MDXRenderer: React.FC<{
  content: string;
  demoId?: string;
}> = ({ content, demoId }) => {
  // Process content to enhance video tags
  const processedVideos = React.useMemo(() => {
    if (!content) return "";

    // Extract and process video tags
    const videoRegex = /<Video\s+src="([^"]+)"([^>]*)>/gi;
    let match;
    let processedHtml = "";

    while ((match = videoRegex.exec(content)) !== null) {
      const [fullMatch, src, attrs] = match;
      let videoHtml = "";

      // Process the video source based on demoId
      if (demoId && !src.startsWith("http") && !src.startsWith("/")) {
        videoHtml = `<div class="video-wrapper"><video controls width="100%" src="/api/demo-assets?demoId=${demoId}&fileName=${src}"${attrs}></video></div>`;
      } else {
        videoHtml = `<div class="video-wrapper"><video controls width="100%" src="${src}"${attrs}></video></div>`;
      }

      processedHtml += videoHtml;
    }

    return processedHtml;
  }, [content, demoId]);

  // Early return if no content
  if (!content) return null;

  return (
      <div className="mdx-content">
        {/* Render the markdown content with proper formatting */}
        <ReactMarkdown components={MDXComponents}>{content}</ReactMarkdown>

        {/* Insert processed video elements if any */}
        {processedVideos && (
          <div className="mt-4" dangerouslySetInnerHTML={{ __html: processedVideos }} />
        )}
      </div>
  );
};

/**
 * Safe component rendering with error boundary
 */
export const SafeComponent: React.FC<{
  component: React.ComponentType | (() => React.ReactNode);
  fallback?: React.ReactNode;
}> = ({
  component: Component,
  fallback = <div className="p-4 text-amber-600">Content could not be displayed</div>,
}) => {
  if (!Component) return <>{fallback}</>;

  try {
    return typeof Component === "function" ? (
      typeof Component.prototype?.render === "function" ? (
        <Component />
      ) : (
        <>{(Component as () => React.ReactNode)()}</>
      )
    ) : (
      <>{Component}</>
    );
  } catch (error) {
    console.error("Error rendering component:", error);
    return <>{fallback}</>;
  }
};



================================================
FILE: typescript-sdk/apps/dojo/src/utils/use-mobile-chat.ts
================================================
import { CopilotKitCSSProperties, CopilotSidebar } from "@copilotkit/react-ui";
import React, { useEffect, useState } from "react";


export function useMobileChat(defaultChatHeight = 50) {
  const [isChatOpen, setIsChatOpen] = useState(false);
  const [chatHeight, setChatHeight] = useState(defaultChatHeight); // Initial height as percentage
  const [isDragging, setIsDragging] = useState(false);
  const [dragStartY, setDragStartY] = useState(0);
  const [dragStartHeight, setDragStartHeight] = useState(defaultChatHeight);

  // Drag functionality for chat resize
  useEffect(() => {
    const handleMouseMove = (e: MouseEvent) => {
      if (!isDragging) return;

      const deltaY = dragStartY - e.clientY;
      const windowHeight = window.innerHeight;
      const newHeightPx = (dragStartHeight / 100) * windowHeight + deltaY;
      const newHeightPercent = (newHeightPx / windowHeight) * 100;

      // Clamp between 50% and 100%
      const clampedHeight = Math.max(50, Math.min(100, newHeightPercent));
      setChatHeight(clampedHeight);
    };

    const handleMouseUp = () => {
      if (isDragging) {
        // Close if dragged below 50%
        if (chatHeight < 50) {
          setIsChatOpen(false);
          setChatHeight(defaultChatHeight); // Reset to default
        }
        setIsDragging(false);
      }
    };

    if (isDragging) {
      document.addEventListener('mousemove', handleMouseMove);
      document.addEventListener('mouseup', handleMouseUp);
      document.body.style.userSelect = 'none'; // Prevent text selection while dragging
    }

    return () => {
      document.removeEventListener('mousemove', handleMouseMove);
      document.removeEventListener('mouseup', handleMouseUp);
      document.body.style.userSelect = '';
    };
  }, [isDragging, dragStartY, dragStartHeight, chatHeight]);

  const handleDragStart = (e: React.MouseEvent) => {
    setIsDragging(true);
    setDragStartY(e.clientY);
    setDragStartHeight(chatHeight);
  };

  return {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/utils/use-mobile-view.ts
================================================
import { useEffect, useState } from "react";

export function useMobileView() {
  const [isMobile, setIsMobile] = useState(false);

  useEffect(() => {
    const checkMobile = () => {
      setIsMobile(window.innerWidth < 768);
    };

    checkMobile();
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  return {
    isMobile,
  }
}


================================================
FILE: typescript-sdk/integrations/agno/README.md
================================================
# @ag-ui/agno

Implementation of the AG-UI protocol for Agno.

Connects Agno agents to frontend applications via the AG-UI protocol using HTTP communication.

## Installation

```bash
npm install @ag-ui/agno
pnpm add @ag-ui/agno
yarn add @ag-ui/agno
```

## Usage

```ts
import { AgnoAgent } from "@ag-ui/agno";

// Create an AG-UI compatible agent
const agent = new AgnoAgent({
  url: "https://your-agno-server.com/agent",
  headers: { Authorization: "Bearer your-token" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Hello from Agno!" }],
});
```

## Features

- **HTTP connectivity** – Direct connection to Agno agent servers
- **Multi-agent support** – Works with Agno's multi-agent system architecture
- **Streaming responses** – Real-time communication with full AG-UI event support



================================================
FILE: typescript-sdk/integrations/agno/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/agno/package.json
================================================
{
  "name": "@ag-ui/agno",
  "author": "Manu Hortet <manu@agno.com>",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/agno/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/agno/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/agno/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/agno/examples/README.md
================================================
# Agno Finance Agent

An Agno Agent with Finance tools for AG-UI that researches stock prices, analyst recommendations, and stock fundamentals.

## Setup

This project uses [uv](https://github.com/astral-sh/uv) for dependency management.

### Prerequisites

1. Install uv: `pip install uv`
2. Set your OpenAI API key: `export OPENAI_API_KEY="your-api-key"`

### Installation

```bash
# Install dependencies
uv sync

# Activate the virtual environment
uv shell
```

### Running the Agent

```bash
# Run the agent
uv run python agent.py
```

The agent will be available at `http://localhost:9001` (or the port specified by the `PORT` environment variable).

## Development

```bash
# Install development dependencies
uv sync --extra dev

# Run tests
uv run pytest

# Format code
uv run black .
uv run isort .

# Lint code
uv run flake8 .
```

## Features

- Stock price lookup
- Analyst recommendations
- Stock fundamentals analysis
- AG-UI compatible interface


================================================
FILE: typescript-sdk/integrations/agno/examples/pyproject.toml
================================================
tool.uv.package = true

[project]
name = "server"
version = "0.1.0"
description = "Example usage of the AG-UI adapter for Agno"
license = "MIT"

readme = "README.md"
requires-python = ">=3.12,<4.0"
dependencies = [
    "agno>=1.7.7",
    "openai>=1.99.1",
    "yfinance>=0.2.63",
    "fastapi>=0.116.1",
    "uvicorn>=0.35.0",
    "ag-ui-protocol>=0.1.8",
    "dotenv (>=0.9.9,<0.10.0)",
]
authors = [
    {name = "AG-UI Team"}
]


[project.scripts]
dev = "server:main"


================================================
FILE: typescript-sdk/integrations/agno/examples/requirements.txt
================================================
agno>=1.6.3
openai>=1.88.0
yfinance>=0.2.63
fastapi>=0.115.13
uvicorn>=0.34.3
ag-ui-protocol>=0.1.5


================================================
FILE: typescript-sdk/integrations/agno/examples/server/__init__.py
================================================
"""Example usage of the AG-UI adapter for Agno.

This provides a FastAPI application that demonstrates how to use the
Agno agent with the AG-UI protocol. It includes examples for
AG-UI dojo features:
- Agentic Chat (Investment Analyst with Finance tools)
"""
from __future__ import annotations

from fastapi import FastAPI
import uvicorn
import os
from dotenv import load_dotenv
load_dotenv()

from .api import (
    agentic_chat_app,
    tool_based_generative_ui_app,
)

app = FastAPI(title='Agno AG-UI server')
app.mount('/agentic_chat', agentic_chat_app, 'Agentic Chat')
app.mount('/tool_based_generative_ui', tool_based_generative_ui_app, 'Tool-based Generative UI')

def main():
    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9001"))
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/__init__.py
================================================
"""Example API for a AG-UI compatible Agno Agent UI."""

from __future__ import annotations

from .agentic_chat import app as agentic_chat_app
from .tool_based_generative_ui import app as tool_based_generative_ui_app

__all__ = [
    'agentic_chat_app',
    'tool_based_generative_ui_app',
]


================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/agentic_chat.py
================================================
"""Example: Agno Agent with Finance tools

This example shows how to create an Agno Agent with tools (YFinanceTools) and expose it in an AG-UI compatible way.
"""
from agno.agent.agent import Agent
from agno.app.agui.app import AGUIApp
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from agno.tools import tool


@tool(external_execution=True)
def change_background(background: str) -> str: # pylint: disable=unused-argument
    """
    Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.

    Args:
        background: str: The background color to change to. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.
    """ # pylint: disable=line-too-long

agent = Agent(
  model=OpenAIChat(id="gpt-4o"),
  tools=[
    YFinanceTools(
      stock_price=True, analyst_recommendations=True, stock_fundamentals=True
    ),
    change_background,
  ],
  description="You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
  instructions="Format your response using markdown and use tables to display data where possible.",
)

agui_app = AGUIApp(
  agent=agent,
  name="Investment Analyst",
  app_id="agentic_chat",
  description="An investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
)

app = agui_app.get_app()


================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/tool_based_generative_ui.py
================================================
"""Example: Tool-based Generative UI Agent

This example shows how to create an Agno Agent with custom tools for haiku generation
and background changing, exposed in an AG-UI compatible way.
"""
from typing import List

from agno.agent.agent import Agent
from agno.app.agui.app import AGUIApp
from agno.models.openai import OpenAIChat
from agno.tools import tool


@tool(external_execution=True)
def generate_haiku(english: List[str], japanese: List[str], image_names: List[str]) -> str: # pylint: disable=unused-argument
    """

    Generate a haiku in Japanese and its English translation.
    YOU MUST PROVIDE THE ENGLISH HAIKU AND THE JAPANESE HAIKU AND THE IMAGE NAMES.
    When picking image names, pick them from the following list:
        - "Osaka_Castle_Turret_Stone_Wall_Pine_Trees_Daytime.jpg",
        - "Tokyo_Skyline_Night_Tokyo_Tower_Mount_Fuji_View.jpg",
        - "Itsukushima_Shrine_Miyajima_Floating_Torii_Gate_Sunset_Long_Exposure.jpg",
        - "Takachiho_Gorge_Waterfall_River_Lush_Greenery_Japan.jpg",
        - "Bonsai_Tree_Potted_Japanese_Art_Green_Foliage.jpeg",
        - "Shirakawa-go_Gassho-zukuri_Thatched_Roof_Village_Aerial_View.jpg",
        - "Ginkaku-ji_Silver_Pavilion_Kyoto_Japanese_Garden_Pond_Reflection.jpg",
        - "Senso-ji_Temple_Asakusa_Cherry_Blossoms_Kimono_Umbrella.jpg",
        - "Cherry_Blossoms_Sakura_Night_View_City_Lights_Japan.jpg",
        - "Mount_Fuji_Lake_Reflection_Cherry_Blossoms_Sakura_Spring.jpg"

    Args:
        english: List[str]: An array of three lines of the haiku in English. YOU MUST PROVIDE THE ENGLISH HAIKU.
        japanese: List[str]: An array of three lines of the haiku in Japanese. YOU MUST PROVIDE THE JAPANESE HAIKU.
        image_names: List[str]: An array of three image names. YOU MUST PROVIDE THE IMAGE NAMES.


    Returns:
        str: A confirmation message.
    """ # pylint: disable=line-too-long
    return "Haiku generated"

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[generate_haiku],
    description="Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user.",
    debug_mode=True,
)

agui_app = AGUIApp(
  agent=agent,
  name="Tool-based Generative UI Agent",
  app_id="tool_based_generative_ui",
  description="A tool-based generative UI agent with haiku generation and background changing capabilities.",
)

app = agui_app.get_app()


================================================
FILE: typescript-sdk/integrations/agno/src/index.ts
================================================
/**
 * Agno is a framework for building Multi-Agent Systems with memory, knowledge and reasoning.
 * Check more about using Agno: https://docs.agno.com/
 */

import { HttpAgent } from "@ag-ui/client";

export class AgnoAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/crewai/README.md
================================================
# @ag-ui/crewai

Implementation of the AG-UI protocol for CrewAI.

Connects CrewAI Flows and Crews to frontend applications via the AG-UI protocol. Supports both TypeScript HTTP clients and Python FastAPI server integration with streaming crew execution.

## Installation

```bash
npm install @ag-ui/crewai
pnpm add @ag-ui/crewai
yarn add @ag-ui/crewai
```

## Usage

```ts
import { CrewAIAgent } from "@ag-ui/crewai";

// Create an AG-UI compatible agent
const agent = new CrewAIAgent({
  url: "http://localhost:8000/crew-endpoint",
  headers: { "Content-Type": "application/json" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Execute the research crew" }],
});
```

## Features

- **HTTP connectivity** – Connect to CrewAI FastAPI servers
- **Flow & Crew support** – Works with both CrewAI Flows and traditional Crews
- **Step tracking** – Real-time crew execution progress
- **Python integration** – Full FastAPI server implementation included

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/crewai/python
poetry install && poetry run dev
```



================================================
FILE: typescript-sdk/integrations/crewai/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/crewai/package.json
================================================
{
  "name": "@ag-ui/crewai",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/crewai/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/crewai/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/crewai/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server
python



================================================
FILE: typescript-sdk/integrations/crewai/python/README.md
================================================
# ag-ui-crewai

Implementation of the AG-UI protocol for CrewAI.

Provides a complete Python integration for CrewAI flows and crews with the AG-UI protocol, including FastAPI endpoint creation and comprehensive event streaming.

## Installation

```bash
pip install ag-ui-crewai
```

## Usage

```python
from crewai.flow.flow import Flow, start
from litellm import completion
from ag_ui_crewai import (
    add_crewai_flow_fastapi_endpoint,
    copilotkit_stream,
    CopilotKitState
)
from fastapi import FastAPI

class MyFlow(Flow[CopilotKitState]):
    @start()
    async def chat(self):
        response = await copilotkit_stream(
            completion(
                model="openai/gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    *self.state.messages
                ],
                tools=self.state.copilotkit.actions,
                stream=True
            )
        )
        self.state.messages.append(response.choices[0].message)

# Add to FastAPI
app = FastAPI()
add_crewai_flow_fastapi_endpoint(app, MyFlow(), "/flow")
```

## Features

- **Native CrewAI integration** – Direct support for CrewAI flows, crews, and multi-agent systems
- **FastAPI endpoint creation** – Automatic HTTP endpoint generation with proper event streaming
- **Predictive state updates** – Real-time state synchronization between backend and frontend
- **Streaming tool calls** – Live streaming of LLM responses and tool execution to the UI

## To run the dojo examples

```bash
cd python/ag_ui_crewai
poetry install
poetry run dev
```



================================================
FILE: typescript-sdk/integrations/crewai/python/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-crewai"
version = "0.1.4"
description = "Implementation of the AG-UI protocol for CrewAI"
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"
exclude = [
    "ag_ui_crewai/dojo.py",
    "ag_ui_crewai/examples/**",
]

[tool.poetry.dependencies]
python = "<3.14,>=3.10"
ag-ui-protocol = "==0.1.5"
fastapi = "^0.115.12"
uvicorn = "^0.34.3"
crewai = "^0.130.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "ag_ui_crewai.dojo:main"


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/__init__.py
================================================
from .endpoint import add_crewai_flow_fastapi_endpoint
from .sdk import (
  CopilotKitState,
  copilotkit_predict_state,
  copilotkit_emit_state,
  copilotkit_stream
)
# from .enterprise import CrewEnterpriseEventListener

# CREW_ENTERPRISE_EVENT_LISTENER = CrewEnterpriseEventListener()

__all__ = [
  "add_crewai_flow_fastapi_endpoint",
  "CopilotKitState",
  "copilotkit_predict_state",
  "copilotkit_emit_state",
  "copilotkit_stream"
]



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/context.py
================================================
import contextvars
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from crewai.flow.flow import Flow

flow_context: contextvars.ContextVar['Flow'] = contextvars.ContextVar('flow')



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/crews.py
================================================
import uuid
import copy
import json
from typing import Any, cast
from crewai import Crew, Flow
from crewai.flow import start
from crewai.cli.crew_chat import (
  initialize_chat_llm as crew_chat_initialize_chat_llm,
  generate_crew_chat_inputs as crew_chat_generate_crew_chat_inputs,
  generate_crew_tool_schema as crew_chat_generate_crew_tool_schema,
  build_system_message as crew_chat_build_system_message,
  create_tool_function as crew_chat_create_tool_function
)
from litellm import completion
from .sdk import (
  copilotkit_stream,
  copilotkit_exit,
)

_CREW_INPUTS_CACHE = {}


CREW_EXIT_TOOL = {
    "type": "function",
    "function": {
        "name": "crew_exit",
        "description": "Call this when the user has indicated that they are done with the crew",
        "parameters": {
            "type": "object",
            "properties": {},
            "required": [],
        },
    },
}


class ChatWithCrewFlow(Flow):
    """Chat with crew"""

    def __init__(
            self, *,
            crew: Crew
        ):
        super().__init__()


        self.crew = copy.deepcopy(cast(Any, crew).crew())

        if self.crew.chat_llm is None:
            raise ValueError("Crew chat LLM is not set")

        self.crew_name = crew.name
        self.chat_llm = crew_chat_initialize_chat_llm(self.crew)

        if crew.name not in _CREW_INPUTS_CACHE:
            self.crew_chat_inputs = crew_chat_generate_crew_chat_inputs(
                self.crew,
                self.crew_name,
                self.chat_llm
            )
            _CREW_INPUTS_CACHE[ crew.name] = self.crew_chat_inputs
        else:
            self.crew_chat_inputs = _CREW_INPUTS_CACHE[ crew.name]

        self.crew_tool_schema = crew_chat_generate_crew_tool_schema(self.crew_chat_inputs)
        self.system_message = crew_chat_build_system_message(self.crew_chat_inputs)

        super().__init__()

    @start()
    async def chat(self):
        """Chat with the crew"""

        system_message = self.system_message
        if self.state.get("inputs"):
            system_message += "\n\nCurrent inputs: " + json.dumps(self.state["inputs"])

        messages = [
            {
                "role": "system",
                "content": system_message,
                "id": str(uuid.uuid4()) + "-system"
            },
            *self.state["messages"]
        ]

        tools = [action for action in self.state["copilotkit"]["actions"]
                 if action["function"]["name"] != self.crew_name]

        tools += [self.crew_tool_schema, CREW_EXIT_TOOL]

        response = await copilotkit_stream(
            completion(
                model=self.crew.chat_llm,
                messages=messages,
                tools=tools,
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = cast(Any, response).choices[0]["message"]
        self.state["messages"].append(message)

        if message.get("tool_calls"):
            if message["tool_calls"][0]["function"]["name"] == self.crew_name:
                # run the crew
                crew_function = crew_chat_create_tool_function(self.crew, messages)
                args = json.loads(message["tool_calls"][0]["function"]["arguments"])
                result = crew_function(**args)

                if isinstance(result, str):
                    self.state["outputs"] = result
                elif hasattr(result, "json_dict"):
                    self.state["outputs"] = result.json_dict
                elif hasattr(result, "raw"):
                    self.state["outputs"] = result.raw
                else:
                    raise ValueError("Unexpected result type", type(result))

                self.state["messages"].append({
                    "role": "tool",
                    "content": result,
                    "tool_call_id": message["tool_calls"][0]["id"]
                })
            elif message["tool_calls"][0]["function"]["name"] == CREW_EXIT_TOOL["function"]["name"]:
                await copilotkit_exit()
                self.state["messages"].append({
                    "role": "tool",
                    "content": "Crew exited",
                    "tool_call_id": message["tool_calls"][0]["id"]
                })

                response = await copilotkit_stream(
                    completion( # pylint: disable=too-many-arguments
                        model=self.crew.chat_llm,
                        messages = [
                            {
                                "role": "system",
                                "content": "Indicate to the user that the crew has exited",
                                "id": str(uuid.uuid4()) + "-system"
                            },
                            *self.state["messages"]
                        ],
                        tools=tools,
                        parallel_tool_calls=False,
                        stream=True,
                        tool_choice="none"
                    )
                )
                message = cast(Any, response).choices[0]["message"]
                self.state["messages"].append(message)



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/dojo.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from .endpoint import add_crewai_flow_fastapi_endpoint
from .examples.agentic_chat import AgenticChatFlow
from .examples.human_in_the_loop import HumanInTheLoopFlow
from .examples.tool_based_generative_ui import ToolBasedGenerativeUIFlow
from .examples.agentic_generative_ui import AgenticGenerativeUIFlow
from .examples.shared_state import SharedStateFlow
from .examples.predictive_state_updates import PredictiveStateUpdatesFlow

app = FastAPI(title="CrewAI Dojo Example Server")

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=AgenticChatFlow(),
    path="/agentic_chat",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=HumanInTheLoopFlow(),
    path="/human_in_the_loop",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=ToolBasedGenerativeUIFlow(),
    path="/tool_based_generative_ui",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=AgenticGenerativeUIFlow(),
    path="/agentic_generative_ui",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=SharedStateFlow(),
    path="/shared_state",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=PredictiveStateUpdatesFlow(),
    path="/predictive_state_updates",
)

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "ag_ui_crewai.dojo:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/endpoint.py
================================================
"""
AG-UI FastAPI server for CrewAI.
"""
import copy
import asyncio
from typing import List, Optional
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse

from crewai.utilities.events import (
    FlowStartedEvent,
    FlowFinishedEvent,
    MethodExecutionStartedEvent,
    MethodExecutionFinishedEvent,
)
from crewai.flow.flow import Flow
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai import Crew

from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    Message,
    Tool
)
from ag_ui.core.events import (
  TextMessageChunkEvent,
  ToolCallChunkEvent,
  StepStartedEvent,
  StepFinishedEvent,
  MessagesSnapshotEvent,
  StateSnapshotEvent,
  CustomEvent,
)
from ag_ui.encoder import EventEncoder

from .events import (
  BridgedTextMessageChunkEvent,
  BridgedToolCallChunkEvent,
  BridgedCustomEvent,
  BridgedStateSnapshotEvent
)
from .context import flow_context
from .sdk import litellm_messages_to_ag_ui_messages
from .crews import ChatWithCrewFlow

QUEUES = {}
QUEUES_LOCK = asyncio.Lock()


async def create_queue(flow: object) -> asyncio.Queue:
    """Create a queue for a flow."""
    queue_id = id(flow)
    async with QUEUES_LOCK:
        queue = asyncio.Queue()
        QUEUES[queue_id] = queue
        return queue


def get_queue(flow: object) -> Optional[asyncio.Queue]:
    """Get the queue for a flow."""
    queue_id = id(flow)
    # not using a lock here should be fine
    return QUEUES.get(queue_id)

async def delete_queue(flow: object) -> None:
    """Delete the queue for a flow."""
    queue_id = id(flow)
    async with QUEUES_LOCK:
        if queue_id in QUEUES:
            del QUEUES[queue_id]

GLOBAL_EVENT_LISTENER = None

class FastAPICrewFlowEventListener(BaseEventListener):
    """FastAPI CrewFlow event listener"""

    def setup_listeners(self, crewai_event_bus):
        """Setup listeners for the FastAPI CrewFlow event listener"""
        @crewai_event_bus.on(FlowStartedEvent)
        def _(source, event):  # pylint: disable=unused-argument
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    RunStartedEvent(
                        type=EventType.RUN_STARTED,
                         # will be replaced by the correct thread_id/run_id when sending the event
                        thread_id="?",
                        run_id="?",
                    ),
                )
        @crewai_event_bus.on(FlowFinishedEvent)
        def _(source, event):  # pylint: disable=unused-argument
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    RunFinishedEvent(
                        type=EventType.RUN_FINISHED,
                        thread_id="?",
                        run_id="?",
                    ),
                )
                queue.put_nowait(None)
        @crewai_event_bus.on(MethodExecutionStartedEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    StepStartedEvent(
                        type=EventType.STEP_STARTED,
                        step_name=event.method_name
                    )
                )
        @crewai_event_bus.on(MethodExecutionFinishedEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                messages = litellm_messages_to_ag_ui_messages(source.state.messages)

                queue.put_nowait(
                    MessagesSnapshotEvent(
                        type=EventType.MESSAGES_SNAPSHOT,
                        messages=messages
                    )
                )
                queue.put_nowait(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=source.state
                    )
                )
                queue.put_nowait(
                    StepFinishedEvent(
                        type=EventType.STEP_FINISHED,
                        step_name=event.method_name
                    )
                )
        @crewai_event_bus.on(BridgedTextMessageChunkEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    TextMessageChunkEvent(
                        type=EventType.TEXT_MESSAGE_CHUNK,
                        message_id=event.message_id,
                        role=event.role,
                        delta=event.delta,
                    )
                )
        @crewai_event_bus.on(BridgedToolCallChunkEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    ToolCallChunkEvent(
                        type=EventType.TOOL_CALL_CHUNK,
                        tool_call_id=event.tool_call_id,
                        tool_call_name=event.tool_call_name,
                        delta=event.delta,
                    )
                )
        @crewai_event_bus.on(BridgedCustomEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name=event.name,
                        value=event.value
                    )
                )
        @crewai_event_bus.on(BridgedStateSnapshotEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=event.snapshot
                    )
                )

def add_crewai_flow_fastapi_endpoint(app: FastAPI, flow: Flow, path: str = "/"):
    """Adds a CrewAI endpoint to the FastAPI app."""
    global GLOBAL_EVENT_LISTENER # pylint: disable=global-statement

    # Set up the global event listener singleton
    # we are doing this here because calling add_crewai_flow_fastapi_endpoint is a clear indicator
    # that we are not running on CrewAI enterprise
    if GLOBAL_EVENT_LISTENER is None:
        GLOBAL_EVENT_LISTENER = FastAPICrewFlowEventListener()

    @app.post(path)
    async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
        """Agentic chat endpoint"""

        flow_copy = copy.deepcopy(flow)

        # Get the accept header from the request
        accept_header = request.headers.get("accept")

        # Create an event encoder to properly format SSE events
        encoder = EventEncoder(accept=accept_header)

        inputs = crewai_prepare_inputs(
            state=input_data.state,
            messages=input_data.messages,
            tools=input_data.tools,
        )
        inputs["id"] = input_data.thread_id

        async def event_generator():
            queue = await create_queue(flow_copy)
            token = flow_context.set(flow_copy)
            try:
                asyncio.create_task(flow_copy.kickoff_async(inputs=inputs))

                while True:
                    item = await queue.get()
                    if item is None:
                        break

                    if item.type == EventType.RUN_STARTED or item.type == EventType.RUN_FINISHED:
                        item.thread_id = input_data.thread_id
                        item.run_id = input_data.run_id

                    yield encoder.encode(item)

            except Exception as e:  # pylint: disable=broad-exception-caught
                yield encoder.encode(
                    RunErrorEvent(
                        type=EventType.RUN_ERROR,
                        thread_id=input_data.thread_id,
                        run_id=input_data.run_id,
                        error=str(e),
                    )
                )
            finally:
                await delete_queue(flow_copy)
                flow_context.reset(token)

        return StreamingResponse(event_generator(), media_type=encoder.get_content_type())

def add_crewai_crew_fastapi_endpoint(app: FastAPI, crew: Crew, path: str = "/"):
    """Adds a CrewAI crew endpoint to the FastAPI app."""
    add_crewai_flow_fastapi_endpoint(app, ChatWithCrewFlow(crew=crew), path)


def crewai_prepare_inputs(  # pylint: disable=unused-argument, too-many-arguments
    *,
    state: dict,
    messages: List[Message],
    tools: List[Tool],
):
    """Default merge state for CrewAI"""
    messages = [message.model_dump() for message in messages]

    if len(messages) > 0:
        if "role" in messages[0] and messages[0]["role"] == "system":
            messages = messages[1:]

    actions = [{
        "type": "function",
        "function": {
            **tool.model_dump(),
        }
    } for tool in tools]

    new_state = {
        **state,
        "messages": messages,
        "copilotkit": {
            "actions": actions
        }
    }

    return new_state



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/enterprise.py
================================================
# from typing import Literal, List, Any
# from crewai.utilities.events import (
#     FlowStartedEvent,
#     FlowFinishedEvent,
#     MethodExecutionStartedEvent,
#     MethodExecutionFinishedEvent
# )
# from crewai.utilities.events.base_event_listener import BaseEventListener
# from crewai.utilities.events.base_events import BaseEvent

# from ag_ui.core import EventType, Message, State

# from .sdk import (
#     litellm_messages_to_ag_ui_messages,
#     BridgedTextMessageChunkEvent,
#     BridgedToolCallChunkEvent,
#     BridgedCustomEvent,
#     BridgedStateSnapshotEvent,
# )

# class EnterpriseRunStartedEvent(BaseEvent):
#     """Enterprise run started event"""
#     type: Literal[EventType.RUN_STARTED]

# class EnterpriseRunFinishedEvent(BaseEvent):
#     """Enterprise run finished event"""
#     type: Literal[EventType.RUN_FINISHED]

# class EnterpriseStepStartedEvent(BaseEvent):
#     """Enterprise step started event"""
#     type: Literal[EventType.STEP_STARTED]

# class EnterpriseStepFinishedEvent(BaseEvent):
#     """Enterprise step finished event"""
#     type: Literal[EventType.STEP_FINISHED]

# class EnterpriseMessagesSnapshotEvent(BaseEvent):
#     """Enterprise messages snapshot event"""
#     type: Literal[EventType.MESSAGES_SNAPSHOT]
#     messages: List[Message]

# class EnterpriseStateSnapshotEvent(BaseEvent):
#     """Enterprise state snapshot event"""
#     type: Literal[EventType.STATE_SNAPSHOT]
#     snapshot: State

# class EnterpriseTextMessageChunkEvent(BaseEvent):
#     """Enterprise text message chunk event"""
#     type: Literal[EventType.TEXT_MESSAGE_CHUNK]
#     message_id: str
#     role: Literal["assistant"]
#     delta: str

# class EnterpriseToolCallChunkEvent(BaseEvent):
#     """Enterprise tool call chunk event"""
#     type: Literal[EventType.TOOL_CALL_CHUNK]
#     tool_call_id: str
#     tool_call_name: str
#     delta: str

# class EnterpriseCustomEvent(BaseEvent):
#     """Enterprise custom event"""
#     type: Literal[EventType.CUSTOM]
#     name: str
#     value: Any

# class CrewEnterpriseEventListener(BaseEventListener):
#     """
#     This class is used to produce custom events when running a crewai flow on CrewAI Enterprise.
#     NOTE: These listeners only fire when the Flow is not run on enterprise.
#     """
#     def setup_listeners(self, crewai_event_bus):
#         @crewai_event_bus.on(FlowStartedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseRunStartedEvent(
#                   type=EventType.RUN_STARTED
#                 )
#             )

#         @crewai_event_bus.on(FlowFinishedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseRunFinishedEvent(
#                   type=EventType.RUN_FINISHED
#                 )
#             )

#         @crewai_event_bus.on(MethodExecutionStartedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStepStartedEvent(
#                   type=EventType.STEP_STARTED,
#                   step_name=event.method_name
#                 )
#             )

#         @crewai_event_bus.on(MethodExecutionFinishedEvent)
#         def _(source, event):
#             messages = litellm_messages_to_ag_ui_messages(source.state.messages)

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseMessagesSnapshotEvent(
#                   type=EventType.MESSAGES_SNAPSHOT,
#                   messages=messages
#                 )
#             )

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStateSnapshotEvent(
#                   type=EventType.STATE_SNAPSHOT,
#                   snapshot=source.state
#                 )
#             )

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStepFinishedEvent(
#                   type=EventType.STEP_FINISHED,
#                   step_name=event.method_name
#                 )
#             )

#         @crewai_event_bus.on(BridgedTextMessageChunkEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseTextMessageChunkEvent(
#                   type=EventType.TEXT_MESSAGE_CHUNK,
#                   message_id=event.message_id,
#                   role=event.role,
#                   delta=event.delta
#                 )
#             )

#         @crewai_event_bus.on(BridgedToolCallChunkEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseToolCallChunkEvent(
#                   type=EventType.TOOL_CALL_CHUNK,
#                   tool_call_id=event.tool_call_id,
#                   tool_call_name=event.tool_call_name,
#                   delta=event.delta
#                 )
#             )


#         @crewai_event_bus.on(BridgedCustomEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseCustomEvent(
#                   type=EventType.CUSTOM,
#                   name=event.name,
#                   value=event.value
#                 )
#             )

#         @crewai_event_bus.on(BridgedStateSnapshotEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStateSnapshotEvent(
#                   type=EventType.STATE_SNAPSHOT,
#                   snapshot=event.snapshot
#                 )
#             )



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/events.py
================================================
"""
This file is used to bridge the events from the crewai event bus to the ag-ui event bus.
"""

from crewai.utilities.events.base_events import BaseEvent
from ag_ui.core.events import (
  ToolCallChunkEvent,
  TextMessageChunkEvent,
  CustomEvent,
  StateSnapshotEvent
)

class BridgedToolCallChunkEvent(BaseEvent, ToolCallChunkEvent):
    """Bridged tool call chunk event"""

class BridgedTextMessageChunkEvent(BaseEvent, TextMessageChunkEvent):
    """Bridged text message chunk event"""

class BridgedCustomEvent(BaseEvent, CustomEvent):
    """Bridged custom event"""

class BridgedStateSnapshotEvent(BaseEvent, StateSnapshotEvent):
    """Bridged state snapshot event"""


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/sdk.py
================================================
"""
This is a placeholder for the copilotkit_stream function.
"""

import uuid
from typing import List, Any, Optional, Mapping, Dict, Literal, TypedDict
from litellm.types.utils import (
  ModelResponse,
  Choices,
  Message as LiteLLMMessage,
  ChatCompletionMessageToolCall,
  Function as LiteLLMFunction
)
from litellm.litellm_core_utils.streaming_handler import CustomStreamWrapper
from crewai.flow.flow import FlowState
from crewai.utilities.events import crewai_event_bus
from pydantic import BaseModel, Field, TypeAdapter
from ag_ui.core import EventType, Message
from .context import flow_context
from .events import (
  BridgedTextMessageChunkEvent,
  BridgedToolCallChunkEvent,
  BridgedCustomEvent,
  BridgedStateSnapshotEvent
)
from .utils import yield_control

class CopilotKitProperties(BaseModel):
    """CopilotKit properties"""
    actions: List[Any] = Field(default_factory=list)

class CopilotKitState(FlowState):
    """CopilotKit state"""
    messages: List[Any] = Field(default_factory=list)
    copilotkit: CopilotKitProperties = Field(default_factory=CopilotKitProperties)

class PredictStateConfig(TypedDict):
    """
    Predict State Config
    """
    tool_name: str
    tool_argument: Optional[str]

async def copilotkit_predict_state(
        config: Dict[str, PredictStateConfig]
    ) -> Literal[True]:
    """
    Stream tool calls as state to CopilotKit.

    To emit a tool call as streaming CrewAI state, pass the destination key in state,
    the tool name and optionally the tool argument. (If you don't pass the argument name,
    all arguments are emitted under the state key.)

    ```python
    from copilotkit.crewai import copilotkit_predict_state

    await copilotkit_predict_state(
        {
            "steps": {
                "tool": "SearchTool",
                "tool_argument": "steps",
            },
        }
    )
    ```

    Parameters
    ----------
    config : Dict[str, CopilotKitPredictStateConfig]
        The configuration to predict the state.

    Returns
    -------
    Awaitable[bool]
        Always return True.
    """
    flow = flow_context.get(None)

    value = [
        {
            "state_key": k,
            "tool": v["tool_name"],
            "tool_argument": v["tool_argument"]
        } for k, v in config.items()
    ]
    crewai_event_bus.emit(
        flow,
        BridgedCustomEvent(
            type=EventType.CUSTOM,
            name="PredictState",
            value=value
        )
    )

    await yield_control()

    return True

async def copilotkit_emit_state(state: Any) -> Literal[True]:
    """
    Emits intermediate state to CopilotKit.
    Useful if you have a longer running node and you want to update the user with the current state of the node.

    To install the CopilotKit SDK, run:

    ```bash
    pip install copilotkit[crewai]
    ```

    ### Examples

    ```python
    from copilotkit.crewai import copilotkit_emit_state

    for i in range(10):
        await some_long_running_operation(i)
        await copilotkit_emit_state({"progress": i})
    ```

    Parameters
    ----------
    state : Any
        The state to emit (Must be JSON serializable).

    Returns
    -------
    Awaitable[bool]
        Always return True.

    """
    flow = flow_context.get(None)
    crewai_event_bus.emit(
        flow,
        BridgedStateSnapshotEvent(
            type=EventType.STATE_SNAPSHOT,
            snapshot=state
        )
    )

    await yield_control()

    return True

async def copilotkit_stream(response):
    """
    Stream litellm responses token by token to CopilotKit.

    ```python
    response = await copilotkit_stream(
        completion(
            model="openai/gpt-4o",
            messages=messages,
            tools=tools,
            stream=True # this must be set to True for streaming
        )
    )
    ```
    """
    if isinstance(response, ModelResponse):
        return _copilotkit_stream_response(response)
    if isinstance(response, CustomStreamWrapper):
        return await _copilotkit_stream_custom_stream_wrapper(response)
    raise ValueError("Invalid response type")


async def _copilotkit_stream_custom_stream_wrapper(response: CustomStreamWrapper):
    flow = flow_context.get(None)

    message_id: Optional[str] = None
    tool_call_id: str = ""
    content = ""
    created = 0
    model = ""
    system_fingerprint = ""
    finish_reason=None
    all_tool_calls = []

    async for chunk in response:
        if message_id is None:
            message_id = chunk["id"]

        text_content = chunk["choices"][0]["delta"]["content"] or None

        # Stream text messages
        if text_content is not None:
            # add to the current text message
            content += text_content
            crewai_event_bus.emit(
                flow,
                BridgedTextMessageChunkEvent(
                    type=EventType.TEXT_MESSAGE_CHUNK,
                    message_id=message_id,
                    role="assistant",
                    delta=text_content,
                )
            )
            # yield control to the event loop
            await yield_control()

        # Stream tool calls
        tool_calls = chunk["choices"][0]["delta"]["tool_calls"] or None
        tool_call_id = tool_calls[0].id if tool_calls is not None else None
        tool_call_arguments = tool_calls[0].function["arguments"] if tool_calls is not None else None
        tool_call_name = tool_calls[0].function["name"] if tool_calls is not None else None

        if tool_call_id is not None:
            all_tool_calls.append(
                {
                    "id": tool_call_id,
                    "name": tool_call_name,
                    "arguments": "",
                }
            )

        if tool_call_arguments is not None:
            # add to the current tool call
            all_tool_calls[-1]["arguments"] += tool_call_arguments
            crewai_event_bus.emit(
                flow,
                BridgedToolCallChunkEvent(
                    type=EventType.TOOL_CALL_CHUNK,
                    tool_call_id=tool_call_id,
                    tool_call_name=tool_call_name,
                    delta=tool_call_arguments,
                )
            )
            # yield control to the event loop
            await yield_control()

        # Stream finish reason
        finish_reason = chunk["choices"][0]["finish_reason"]
        created = chunk["created"]
        model = chunk["model"]
        system_fingerprint = chunk["system_fingerprint"]

        if finish_reason is not None:
            break

    tool_calls = [
        ChatCompletionMessageToolCall(
            function=LiteLLMFunction(
                arguments=tool_call["arguments"],
                name=tool_call["name"]
            ),
            id=tool_call["id"],
            type="function"
        )
        for tool_call in all_tool_calls
    ]
    return ModelResponse(
        id=message_id,
        created=created,
        model=model,
        object='chat.completion',
        system_fingerprint=system_fingerprint,
        choices=[
            Choices(
                finish_reason=finish_reason,
                index=0,
                message=LiteLLMMessage(
                    content=content,
                    role='assistant',
                    tool_calls=tool_calls if len(tool_calls) > 0 else None,
                    function_call=None
                )
            )
        ]
    )

def _copilotkit_stream_response(response: ModelResponse):
    return response


message_adapter = TypeAdapter(Message)

def litellm_messages_to_ag_ui_messages(messages: List[LiteLLMMessage]) -> List[Message]:
    """
    Converts a list of LiteLLM messages to a list of ag_ui messages.
    """
    ag_ui_messages: List[Message] = []
    for message in messages:
        message_dict = message.model_dump() if not isinstance(message, Mapping) else message

        # whitelist the fields we want to keep
        whitelist = ["content", "role", "tool_calls", "id", "name", "tool_call_id"]
        message_dict = {k: v for k, v in message_dict.items() if k in whitelist}
        if not "id" in message_dict:
            message_dict["id"] = str(uuid.uuid4())
        # remove all None values
        message_dict = {k: v for k, v in message_dict.items() if v is not None}

        if "tool_calls" in message_dict:
            for tool_call in message_dict["tool_calls"]:
                if "type" not in tool_call:
                    tool_call["type"] = "function"

        ag_ui_message = message_adapter.validate_python(message_dict)
        ag_ui_messages.append(ag_ui_message)

    return ag_ui_messages


async def copilotkit_exit() -> Literal[True]:
    """
    Exits the current agent after the run completes. Calling copilotkit_exit() will
    not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
    the run completes.

    ### Examples

    ```python
    from copilotkit.crewai import copilotkit_exit

    def my_function():
        await copilotkit_exit()
        return state
    ```

    Returns
    -------
    Awaitable[bool]
        Always return True.
    """

    flow = flow_context.get(None)

    crewai_event_bus.emit(
        flow,
        BridgedCustomEvent(
            type=EventType.CUSTOM,
            name="Exit",
            value=""
        )
    )

    await yield_control()

    return True


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/utils.py
================================================
import asyncio

async def yield_control():
    """
    Yield control to the event loop.
    """
    loop = asyncio.get_running_loop()
    future = loop.create_future()
    loop.call_soon(future.set_result, None)
    await future



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/agentic_chat.py
================================================
"""
A simple agentic chat flow.
"""

from crewai.flow.flow import Flow, start
from litellm import completion
from ..sdk import copilotkit_stream, CopilotKitState

class AgenticChatFlow(Flow[CopilotKitState]):

    @start()
    async def chat(self):
        system_prompt = "You are a helpful assistant."

        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the available tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/agentic_generative_ui.py
================================================
"""
An example demonstrating agentic generative UI.
"""

import json
import asyncio
from crewai.flow.flow import Flow, start, router, listen, or_
from litellm import completion
from pydantic import BaseModel
from typing import Literal, List

from ..sdk import (
  copilotkit_stream,
  CopilotKitState,
  copilotkit_predict_state,
  copilotkit_emit_state
)

# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
PERFORM_TASK_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_task_steps",
        "description": "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in gerund form (i.e. Digging hole, opening door, ...)",
        "parameters": {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "description": {
                                "type": "string",
                                "description": "The text of the step in gerund form"
                            },
                            "status": {
                                "type": "string",
                                "enum": ["pending"],
                                "description": "The status of the step, always 'pending'"
                            }
                        },
                        "required": ["description", "status"]
                    },
                    "description": "An array of 10 step objects, each containing text and status"
                }
            },
            "required": ["steps"]
        }
    }
}

class TaskStep(BaseModel):
    description: str
    status: Literal["pending", "completed"]

class AgentState(CopilotKitState):
    """
    Here we define the state of the agent

    In this instance, we're inheriting from CopilotKitState, which will bring in
    the CopilotKitState fields. We're also adding a custom field, `steps`,
    which will be used to store the steps of the task.
    """
    steps: List[TaskStep] = []


class AgenticGenerativeUIFlow(Flow[AgentState]):
    """
    This is a sample flow that uses the CopilotKit framework to create a chat agent.
    """

    
    @start()
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """
        self.state.steps = []

    @router(or_(start_flow, "simulate_task"))
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = """
        You are a helpful assistant assisting with any task. 
        When asked to do something, you MUST call the function `generate_task_steps`
        that was provided to you.
        If you called the function, you MUST NOT repeat the steps in your next response to the user.
        Just give a very brief summary (one sentence) of what you did with some emojis. 
        Always say you actually did the steps, not merely generated them.
        """

        # 1. Here we specify that we want to stream the tool call to generate_task_steps
        #    to the frontend as state.
        await copilotkit_predict_state({
            "steps": {
                "tool_name": "generate_task_steps",
                "tool_argument": "steps"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    PERFORM_TASK_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "generate_task_steps":
                # Convert each step in the JSON array to a TaskStep instance
                self.state.steps = [TaskStep(**step) for step in tool_call_args["steps"]]

                # 4.1 Append the result to the messages in state
                self.state.messages.append({
                    "role": "tool",
                    "content": "Steps executed.",
                    "tool_call_id": tool_call_id
                })
                return "route_simulate_task"

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_simulate_task")
    async def simulate_task(self):
        """
        Simulate the task.
        """
        for step in self.state.steps:
            # simulate executing the step
            await asyncio.sleep(1)
            step.status = "completed"
            await copilotkit_emit_state(self.state)

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/human_in_the_loop.py
================================================
"""
An example demonstrating agentic generative UI.
"""

from crewai.flow.flow import Flow, start, router, listen
from litellm import completion
from pydantic import BaseModel
from typing import Literal, List
from ..sdk import (
  copilotkit_stream,
  CopilotKitState,
)

# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
DEFINE_TASK_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_task_steps",
        "description": "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in imperative form (i.e. Dig hole, Open door, ...)",
        "parameters": {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "description": {
                                "type": "string",
                                "description": "The text of the step in imperative form"
                            },
                            "status": {
                                "type": "string",
                                "enum": ["enabled"],
                                "description": "The status of the step, always 'enabled'"
                            }
                        },
                        "required": ["description", "status"]
                    },
                    "description": "An array of 10 step objects, each containing text and status"
                }
            },
            "required": ["steps"]
        }
    }
}

class TaskStep(BaseModel):
    description: str
    status: Literal["enabled", "disabled"]

class AgentState(CopilotKitState):
    """
    Here we define the state of the agent

    In this instance, we're inheriting from CopilotKitState, which will bring in
    the CopilotKitState fields. We're also adding a custom field, `steps`,
    which will be used to store the steps of the task.
    """
    steps: List[TaskStep] = []


class HumanInTheLoopFlow(Flow[AgentState]):
    """
    This is a sample flow that uses the CopilotKit framework to create a chat agent.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = """
        You are a helpful assistant that can perform any task.
        You MUST call the `generate_task_steps` function when the user asks you to perform a task.
        When the function `generate_task_steps` is called, the user will decide to enable or disable a step.
        After the user has decided which steps to perform, provide a textual description of how you are performing the task.
        If the user has disabled a step, you are not allowed to perform that step.
        However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
        some humor in the description of how you are performing the task.
        Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
        """

        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    DEFINE_TASK_TOOL
                ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)

        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/predictive_state_updates.py
================================================
"""
A demo of predictive state updates.
"""

import json
import uuid
from typing import Optional
from litellm import completion
from crewai.flow.flow import Flow, start, router, listen
from ..sdk import (
  copilotkit_stream, 
  copilotkit_predict_state,
  CopilotKitState
)

WRITE_DOCUMENT_TOOL = {
    "type": "function",
    "function": {
        "name": "write_document_local",
        "description": " ".join("""
            Write a document. Use markdown formatting to format the document.
            It's good to format the document extensively so it's easy to read.
            You can use all kinds of markdown.
            However, do not use italic or strike-through formatting, it's reserved for another purpose.
            You MUST write the full document, even when changing only a few words.
            When making edits to the document, try to make them minimal - do not change every word.
            Keep stories SHORT!
            """.split()),
        "parameters": {
            "type": "object",
            "properties": {
                "document": {
                    "type": "string",
                    "description": "The document to write"
                },
            },
        }
    }
}


class AgentState(CopilotKitState):
    """
    The state of the agent.
    """
    document: Optional[str] = None

class PredictiveStateUpdatesFlow(Flow[AgentState]):
    """
    This is a sample flow that demonstrates predictive state updates.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = f"""
        You are a helpful assistant for writing documents.
        To write the document, you MUST use the write_document_local tool.
        You MUST write the full document, even when changing only a few words.
        When you wrote the document, DO NOT repeat it as a message. 
        Just briefly summarize the changes you made. 2 sentences max.
        This is the current state of the document: ----\n {self.state.document}\n-----
        """

        # 1. Here we specify that we want to stream the tool call to write_document_local
        #    to the frontend as state.
        await copilotkit_predict_state({
            "document": {
                "tool_name": "write_document_local",
                "tool_argument": "document"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    WRITE_DOCUMENT_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "write_document_local":
                self.state.document = tool_call_args["document"]

                # 4.1 Append the result to the messages in state
                self.state.messages.append({
                    "role": "tool",
                    "content": "Document written.",
                    "tool_call_id": tool_call_id
                })

                # 4.2 Append a tool call to confirm changes
                self.state.messages.append({
                    "role": "assistant",
                    "content": "",
                    "tool_calls": [{
                        "id": str(uuid.uuid4()),
                        "function": {
                            "name": "confirm_changes",
                            "arguments": "{}"
                        }
                    }]
                })

                return "route_end"

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/shared_state.py
================================================
"""
A demo of shared state between the agent and CopilotKit.
"""

import json
from enum import Enum
from typing import List, Optional
from litellm import completion
from pydantic import BaseModel, Field
from crewai.flow.flow import Flow, start, router, listen
from ..sdk import (
  copilotkit_stream, 
  copilotkit_predict_state,
  CopilotKitState
)

class SkillLevel(str, Enum):
    """
    The level of skill required for the recipe.
    """
    BEGINNER = "Beginner"
    INTERMEDIATE = "Intermediate"
    ADVANCED = "Advanced"

class CookingTime(str, Enum):
    """
    The cooking time of the recipe.
    """
    FIVE_MIN = "5 min"
    FIFTEEN_MIN = "15 min"
    THIRTY_MIN = "30 min"
    FORTY_FIVE_MIN = "45 min"
    SIXTY_PLUS_MIN = "60+ min"

class Ingredient(BaseModel):
    """
    An ingredient with its details.
    """
    icon: str = Field(..., description="Emoji icon representing the ingredient.")
    name: str = Field(..., description="Name of the ingredient.")
    amount: str = Field(..., description="Amount or quantity of the ingredient.")

GENERATE_RECIPE_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_recipe",
        "description": " ".join("""Generate or modify an existing recipe. 
        When creating a new recipe, specify all fields. 
        When modifying, only fill optional fields if they need changes; 
        otherwise, leave them empty.""".split()),
        "parameters": {
            "type": "object",
            "properties": {
                "recipe": {
                    "description": "The recipe object containing all details.",
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "The title of the recipe."
                        },
                        "skill_level": {
                            "type": "string",
                            "enum": [level.value for level in SkillLevel],
                            "description": "The skill level required for the recipe."
                        },
                        "special_preferences": {
                            "type": "array",
                            "items": {
                                "type": "string"
                            },
                            "description": "A list of dietary preferences (e.g., Vegetarian, Gluten-free)."
                        },
                        "cooking_time": {
                            "type": "string",
                            "enum": [time.value for time in CookingTime],
                            "description": "The estimated cooking time for the recipe."
                        },
                        "ingredients": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "icon": {"type": "string", "description": "Emoji icon for the ingredient."},
                                    "name": {"type": "string", "description": "Name of the ingredient."},
                                    "amount": {"type": "string", "description": "Amount/quantity of the ingredient."}
                                },
                                "required": ["icon", "name", "amount"]
                            },
                            "description": "A list of ingredients required for the recipe."
                        },
                        "instructions": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Step-by-step instructions for preparing the recipe."
                        }
                    },
                    "required": ["title", "skill_level", "cooking_time", "special_preferences", "ingredients", "instructions"]
                }
            },
            "required": ["recipe"]
        }
    }
}

class Recipe(BaseModel):
    """
    A recipe.
    """
    title: str
    skill_level: SkillLevel
    special_preferences: List[str] = Field(default_factory=list)
    cooking_time: CookingTime
    ingredients: List[Ingredient] = Field(default_factory=list)
    instructions: List[str] = Field(default_factory=list)


class AgentState(CopilotKitState):
    """
    The state of the recipe.
    """
    recipe: Optional[Recipe] = None

class SharedStateFlow(Flow[AgentState]):
    """
    This is a sample flow that demonstrates shared state between the agent and CopilotKit.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """
        print(f"start_flow")
        print(f"self.state: {self.state}")

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
 
        system_prompt = f"""You are a helpful assistant for creating recipes. 
        This is the current state of the recipe: {self.state.model_dump_json(indent=2)}
        You can modify the recipe by calling the generate_recipe tool.
        If you have just created or modified the recipe, just answer in one sentence what you did.
        """

        # 1. Here we specify that we want to stream the tool call to generate_recipe
        #    to the frontend as state.
        await copilotkit_predict_state({
            "recipe": {
                "tool_name": "generate_recipe",
                "tool_argument": "recipe"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    GENERATE_RECIPE_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "generate_recipe":
                # Attempt to update the recipe state using the data from the tool call
                try:
                    updated_recipe_data = tool_call_args["recipe"]
                    # Validate and update the state. Pydantic will raise an error if the structure is wrong.
                    self.state.recipe = Recipe(**updated_recipe_data)

                    # 4.1 Append the result to the messages in state
                    self.state.messages.append({
                        "role": "tool",
                        "content": "Recipe updated.", # More accurate message
                        "tool_call_id": tool_call_id
                    })
                    return "route_follow_up"
                except Exception as e:
                    # Handle validation or other errors during update
                    print(f"Error updating recipe state: {e}") # Log the error server-side
                    # Optionally inform the user via a tool message, though it might be noisy
                    # self.state.messages.append({"role": "tool", "content": f"Error processing recipe update: {e}", "tool_call_id": tool_call_id})
                    return "route_end" # End the flow on error for now

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/tool_based_generative_ui.py
================================================
"""
An example demonstrating tool-based generative UI.
"""

from crewai.flow.flow import Flow, start
from litellm import completion
from ..sdk import copilotkit_stream, CopilotKitState


# This tool generates a haiku on the server.
# The tool call will be streamed to the frontend as it is being generated.
GENERATE_HAIKU_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_haiku",
        "description": "Generate a haiku in Japanese and its English translation",
        "parameters": {
            "type": "object",
            "properties": {
                "japanese": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "An array of three lines of the haiku in Japanese"
                },
                "english": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "An array of three lines of the haiku in English"
                },
                "image_names": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Names of 3 relevant images from the provided list"
                }
            },
            "required": ["japanese", "english", "image_names"]
        }
    }
}


class ToolBasedGenerativeUIFlow(Flow[CopilotKitState]):
    """
    A flow that demonstrates tool-based generative UI.
    """

    @start()
    async def chat(self):
        """
        The main function handling chat and tool calls.
        """
        system_prompt = "You assist the user in generating a haiku. When generating a haiku using the 'generate_haiku' tool, you MUST also select exactly 3 image filenames from the following list that are most relevant to the haiku's content or theme. Return the filenames in the 'image_names' parameter. Dont provide the relavent image names in your final response to the user. "


        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the available tools to the model
                tools=[ GENERATE_HAIKU_TOOL ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )
        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)

        # 3. If there are tool calls, append a tool message to the messages in state
        if message.tool_calls:
            self.state.messages.append(
                {
                    "tool_call_id": message.tool_calls[0].id,
                    "role": "tool",
                    "content": "Haiku generated."
                }
            )



================================================
FILE: typescript-sdk/integrations/crewai/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/crewai/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class CrewAIAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/langgraph/README.md
================================================
# @ag-ui/langgraph

Implementation of the AG-UI protocol for LangGraph.

Connects LangGraph graphs to frontend applications via the AG-UI protocol. Supports both local TypeScript graphs and remote LangGraph Cloud deployments with full state management and interrupt handling.

## Installation

```bash
npm install @ag-ui/langgraph
pnpm add @ag-ui/langgraph
yarn add @ag-ui/langgraph
```

## Usage

```ts
import { LangGraphAgent } from "@ag-ui/langgraph";

// Create an AG-UI compatible agent
const agent = new LangGraphAgent({
  graphId: "my-graph",
  deploymentUrl: "https://your-langgraph-deployment.com",
  langsmithApiKey: "your-api-key",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Start the workflow" }],
});
```

## Features

- **Cloud & local support** – Works with LangGraph Cloud and local graph instances
- **State management** – Bidirectional state synchronization with graph nodes
- **Interrupt handling** – Human-in-the-loop workflow support
- **Step tracking** – Real-time node execution progress

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/langgraph/examples
langgraph dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/langgraph/package.json
================================================
{
  "name": "@ag-ui/langgraph",
  "version": "0.0.12",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@langchain/core": "^0.3.66",
    "@langchain/langgraph-sdk": "^0.0.105",
    "partial-json": "^0.1.7",
    "rxjs": "7.8.1"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/langgraph/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/langgraph/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/langgraph/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
examples


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/README.md
================================================
# LangGraph examples

## How to run

First, make sure to create a new .env file from the .env.example and include the required keys.

To run the Python examples for langgraph platform, run:
```
cd typescript-sdk/integrations/langgraph/examples/python
pnpx @langchain/langgraph-cli@latest dev
```

To run the python examples using FastAPI, run:
```
cd typescript-sdk/integrations/langgraph/examples/python
poetry install
poetry run dev
```

Note that when running them both concurrently, poetry and the langgraph-cli will step on eachothers toes and install/uninstall eachothers dependencies.
You can fix this by running the poetry commands with virtualenvs.in-project set to false. You can set this permanently for the project using:
`poetry config virtualenvs.create false --local`, globally using `poetry config virtualenvs.create false`, or temporarily using an environment variable:

```
export POETRY_VIRTUALENVS_IN_PROJECT=false
poetry install
poetry run dev
```
or
```
POETRY_VIRTUALENVS_IN_PROJECT=false poetry install
POETRY_VIRTUALENVS_IN_PROJECT=false poetry run dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/langgraph.json
================================================
{
  "python_version": "3.12",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "agentic_chat": "./agents/agentic_chat/agent.py:graph",
    "agentic_generative_ui": "./agents/agentic_generative_ui/agent.py:graph",
    "human_in_the_loop": "./agents/human_in_the_loop/agent.py:graph",
    "predictive_state_updates": "./agents/predictive_state_updates/agent.py:graph",
    "shared_state": "./agents/shared_state/agent.py:graph",
    "tool_based_generative_ui": "./agents/tool_based_generative_ui/agent.py:graph",
    "agentic_chat_reasoning": "./agents/agentic_chat_reasoning/agent.py:graph",
    "subgraphs": "./agents/subgraphs/agent.py:graph"
  },
  "env": ".env"
}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/pyproject.toml
================================================
[tool.poetry]
name = "langgraph_agui_dojo"
version = "0.1.0"
description = ""
readme = "README.md"
packages = [{ include = "agents" }]

[project]
name = "agents"
version = "0.0.1"

[tool.poetry.dependencies]
python = ">=3.12,<3.14"
uvicorn = "^0.34.0"
dotenv = "^0.9.9"
langchain = ">=0.1.0"
langchain-anthropic = ">=0.3.18"
langchain-core = ">=0.1.5"
langchain-community = ">=0.0.1"
langchain-experimental = ">=0.0.11"
langchain-google-genai = ">=2.1.9"
langchain-openai = ">=0.0.1"
langgraph = "^0.6.1"
ag-ui-langgraph = { version = "0.0.10", extras = ["fastapi"] }
python-dotenv = "^1.0.0"
fastapi = "^0.115.12"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "agents.dojo:main"


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/.env.example
================================================
OPENAI_API_KEY=
LANGSMITH_API_KEY=



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/dojo.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from dotenv import load_dotenv
load_dotenv()

os.environ["LANGGRAPH_FAST_API"] = "true"

from ag_ui_langgraph import LangGraphAgent, add_langgraph_fastapi_endpoint
from .human_in_the_loop.agent import graph as human_in_the_loop_graph
from .predictive_state_updates.agent import graph as predictive_state_updates_graph
from .shared_state.agent import graph as shared_state_graph
from .tool_based_generative_ui.agent import graph as tool_based_generative_ui_graph
from .agentic_chat.agent import graph as agentic_chat_graph
from .agentic_generative_ui.agent import graph as agentic_generative_ui_graph
from .agentic_chat_reasoning.agent import graph as agentic_chat_reasoning_graph
from .subgraphs.agent import graph as subgraphs_graph

app = FastAPI(title="LangGraph Dojo Example Server")

agents = {
    # Register the LangGraph agent using the LangGraphAgent class
    "agentic_chat": LangGraphAgent(
        name="agentic_chat",
        description="An example for an agentic chat flow using LangGraph.",
        graph=agentic_chat_graph
    ),
    "tool_based_generative_ui": LangGraphAgent(
        name="tool_based_generative_ui",
        description="An example for a tool-based generative UI flow.",
        graph=tool_based_generative_ui_graph,
    ),
    "agentic_generative_ui": LangGraphAgent(
        name="agentic_generative_ui",
        description="An example for an agentic generative UI flow.",
        graph=agentic_generative_ui_graph,
    ),
    "human_in_the_loop": LangGraphAgent(
        name="human_in_the_loop",
        description="An example for a human in the loop flow.",
        graph=human_in_the_loop_graph,
    ),
    "shared_state": LangGraphAgent(
        name="shared_state",
        description="An example for a shared state flow.",
        graph=shared_state_graph,
    ),
    "predictive_state_updates": LangGraphAgent(
        name="predictive_state_updates",
        description="An example for a predictive state updates flow.",
        graph=predictive_state_updates_graph,
    ),
    "agentic_chat_reasoning": LangGraphAgent(
        name="agentic_chat_reasoning",
        description="An example for a reasoning chat.",
        graph=agentic_chat_reasoning_graph,
    ),
    "subgraphs": LangGraphAgent(
        name="subgraphs",
        description="A demo of LangGraph subgraphs using a Game Character Creator.",
        graph=subgraphs_graph,
    ),
}

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_chat"],
    path="/agent/agentic_chat"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["tool_based_generative_ui"],
    path="/agent/tool_based_generative_ui"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_generative_ui"],
    path="/agent/agentic_generative_ui"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["human_in_the_loop"],
    path="/agent/human_in_the_loop"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["shared_state"],
    path="/agent/shared_state"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["predictive_state_updates"],
    path="/agent/predictive_state_updates"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_chat_reasoning"],
    path="/agent/agentic_chat_reasoning"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["subgraphs"],
    path="/agent/subgraphs"
)

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "agents.dojo:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat/agent.py
================================================
"""
A simple agentic chat flow using LangGraph instead of CrewAI.
"""

from typing import List, Any, Optional
import os

# Updated imports for LangGraph
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.graph import MessagesState
from langgraph.types import Command

class AgentState(MessagesState):
    """
    State of our graph.
    """
    tools: List[Any]

async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see: 
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """

    # 1. Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # 2. Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            # your_tool_here
        ],

        # 2.1 Disable parallel tool calls to avoid race conditions,
        #     enable this for faster performance if you want to manage
        #     the complexity of running tool calls in parallel.
        parallel_tool_calls=False,
    )

    # 3. Define the system message by which the chat model will be run
    system_message = SystemMessage(
        content="You are a helpful assistant."
    )

    # 4. Run the model to generate a response
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    # 6. We've handled all tool calls, so we can end the graph.
    return Command(
        goto=END,
        update={
            "messages": response
        }
    )

# Define a new graph
workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("chat_node")

# Add explicit edges, matching the pattern in other examples
workflow.add_edge(START, "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat_reasoning/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat_reasoning/agent.py
================================================
"""
A simple agentic chat flow using LangGraph instead of CrewAI.
"""

from typing import List, Any, Optional
import os

from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START
from langgraph.graph import MessagesState
from langgraph.types import Command
from langgraph.checkpoint.memory import MemorySaver

class AgentState(MessagesState):
    """
    State of our graph.
    """
    tools: List[Any]
    model: str

async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see:
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """


    # 1. Define the model
    model = ChatOpenAI(model="o3")
    if state["model"] == "Anthropic":
        model = ChatAnthropic(
            model="claude-sonnet-4-20250514",
            thinking={"type": "enabled", "budget_tokens": 2000}
        )
    elif state["model"] == "Gemini":
        model = ChatGoogleGenerativeAI(model="gemini-2.5-pro", thinking_budget=1024)

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # 2. Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            # your_tool_here
        ],
    )

    # 3. Define the system message by which the chat model will be run
    system_message = SystemMessage(
        content="You are a helpful assistant."
    )

    # 4. Run the model to generate a response
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    # 6. We've handled all tool calls, so we can end the graph.
    return Command(
        goto=END,
        update={
            "messages": response
        }
    )

# Define a new graph
workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("chat_node")

# Add explicit edges, matching the pattern in other examples
workflow.add_edge(START, "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_generative_ui/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_generative_ui/agent.py
================================================
"""
An example demonstrating agentic generative UI using LangGraph.
"""

import asyncio
from typing import List, Any, Optional, Annotated
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks.manager import adispatch_custom_event
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from pydantic import BaseModel, Field

class Step(BaseModel):
    """
    A step in a task.
    """
    description: str = Field(description="The text of the step in gerund form")
    status: str = Field(description="The status of the step, always 'pending'")



# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
@tool
def generate_task_steps_generative_ui(
    steps: Annotated[ # pylint: disable=unused-argument
        List[Step],
        "An array of 10 step objects, each containing text and status"
    ]
):
    """
    Make up 10 steps (only a couple of words per step) that are required for a task.
    The step should be in gerund form (i.e. Digging hole, opening door, ...).
    """


class AgentState(MessagesState):
    """
    State of the agent.
    """
    steps: List[dict] = []
    tools: List[Any]


async def start_node(state: AgentState, config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """

    if "steps" not in state:
        state["steps"] = []

    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "steps": state["steps"]
        }
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node.
    """
    system_prompt = """
    You are a helpful assistant assisting with any task. 
    When asked to do something, you MUST call the function `generate_task_steps_generative_ui`
    that was provided to you.
    If you called the function, you MUST NOT repeat the steps in your next response to the user.
    Just give a very brief summary (one sentence) of what you did with some emojis. 
    Always say you actually did the steps, not merely generated them.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model with emit_intermediate_state to stream tool calls to frontend
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "steps",
        "tool": "generate_task_steps_generative_ui",
        "tool_argument": "steps",
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            generate_task_steps_generative_ui
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model to generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    messages = state["messages"] + [response]

    # Extract any tool calls from the response
    if hasattr(response, "tool_calls") and response.tool_calls and len(response.tool_calls) > 0:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        if tool_call["name"] == "generate_task_steps_generative_ui":
            steps = [
                {"description": step["description"], "status": step["status"]}
                for step in tool_call["args"]["steps"]
            ]

            # Add the tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Steps executed.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]
            state["steps"] = steps

            # Return Command to route to simulate_task_node
            for i, _ in enumerate(steps):
            # simulate executing the step
                await asyncio.sleep(1)
                steps[i]["status"] = "completed"
                # Update the state with the completed step using config
                await adispatch_custom_event(
                    "manually_emit_state",
                    state,
                    config=config,
                )

            return Command(
                goto='start_node',
                update={
                    "messages": messages,
                    "steps": state["steps"]
                }
            )

    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"]
        }
    )


# Define the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)

# Add edges
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/human_in_the_loop/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/human_in_the_loop/agent.py
================================================
"""
A LangGraph implementation of the human-in-the-loop agent.
"""

from typing import Dict, List, Any, Annotated, Optional
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command, interrupt
from langgraph.graph import MessagesState
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class Step(BaseModel):
    """
    A step in a task.
    """
    description: str = Field(description="The text of the step in imperative form")
    status: str = Field(description="The status of the step, always 'enabled'")

@tool
def plan_execution_steps(
    steps: Annotated[ # pylint: disable=unused-argument
        List[Step],
        "An array of 10 step objects, each containing text and status"
    ]
):
    """
    Make up 10 steps (only a couple of words per step) that are required for a task.
    The step should be in imperative form (i.e. Dig hole, Open door, ...).
    """

class AgentState(MessagesState):
    """
    State of the agent.
    """
    steps: List[Dict[str, str]] = []
    tools: List[Any]

async def start_node(state: Dict[str, Any], config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """

    # Initialize steps list if not exists
    if "steps" not in state:
        state["steps"] = []

    # Return command to route to chat_node
    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "steps": state["steps"],
        }
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node where the agent processes messages and generates responses.
    If task steps are defined, the user can enable/disable them using interrupts.
    """
    system_prompt = """
    You are a helpful assistant that can perform any task.
    You MUST call the `plan_execution_steps` function when the user asks you to perform a task.
    Always make sure you will provide tasks based on the user query
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o-mini")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "steps",
        "tool": "plan_execution_steps",
        "tool_argument": "steps"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            plan_execution_steps
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model and generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Handle tool calls
    if hasattr(response, "tool_calls") and response.tool_calls and len(response.tool_calls) > 0:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        if tool_call["name"] == "plan_execution_steps":
            # Get the steps from the tool call
            steps_raw = tool_call["args"]["steps"]

            # Set initial status to "enabled" for all steps
            steps_data = []

            # Handle different potential formats of steps data
            if isinstance(steps_raw, list):
                for step in steps_raw:
                    if isinstance(step, dict) and "description" in step:
                        steps_data.append({
                            "description": step["description"],
                            "status": "enabled"
                        })
                    elif isinstance(step, str):
                        steps_data.append({
                            "description": step,
                            "status": "enabled"
                        })

            # If no steps were processed correctly, return to END with the updated messages
            if not steps_data:
                return Command(
                    goto=END,
                    update={
                        "messages": messages,
                        "steps": state["steps"],
                    }
                )
            # Update steps in state and emit to frontend
            state["steps"] = steps_data

            # Add a tool response to satisfy OpenAI's requirements
            tool_response = {
                "role": "tool",
                "content": "Task steps generated.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]

            # Move to the process_steps_node which will handle the interrupt and final response
            return Command(
                goto="process_steps_node",
                update={
                    "messages": messages,
                    "steps": state["steps"],
                }
            )

    # If no tool calls or not plan_execution_steps, return to END with the updated messages
    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"],
        }
    )


async def process_steps_node(state: Dict[str, Any], config: RunnableConfig):
    """
    This node handles the user interrupt for step customization and generates the final response.
    """

    # Check if we already have a user_response in the state
    # This happens when the node restarts after an interrupt
    if "user_response" in state and state["user_response"]:
        user_response = state["user_response"]
    else:
        # Use LangGraph interrupt to get user input on steps
        # This will pause execution and wait for user input in the frontend
        user_response = interrupt({"steps": state["steps"]})
        # Store the user response in state for when the node restarts
        state["user_response"] = user_response

    # Generate the creative completion response
    final_prompt = """
    Provide a textual description of how you are performing the task.
    If the user has disabled a step, you are not allowed to perform that step.
    However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
    some humor in the description of how you are performing the task.
    Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
    """

    final_response = await ChatOpenAI(model="gpt-4o").ainvoke([
        SystemMessage(content=final_prompt),
        {"role": "user", "content": user_response}
    ], config)

    # Add the final response to messages
    messages = state["messages"] + [final_response]

    # Clear the user_response from state to prepare for future interactions
    if "user_response" in state:
        state.pop("user_response")

    # Return to END with the updated messages
    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"],
        }
    )


# Define the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.add_node("process_steps_node", process_steps_node)

# Add edges
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("process_steps_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/predictive_state_updates/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/predictive_state_updates/agent.py
================================================
"""
A demo of predictive state updates using LangGraph.
"""

import uuid
from typing import List, Any, Optional
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI

@tool
def write_document_local(document: str): # pylint: disable=unused-argument
    """
    Write a document. Use markdown formatting to format the document.
    It's good to format the document extensively so it's easy to read.
    You can use all kinds of markdown.
    However, do not use italic or strike-through formatting, it's reserved for another purpose.
    You MUST write the full document, even when changing only a few words.
    When making edits to the document, try to make them minimal - do not change every word.
    Keep stories SHORT!
    """
    return document

class AgentState(MessagesState):
    """
    The state of the agent.
    """
    document: Optional[str] = None
    tools: List[Any]


async def start_node(state: AgentState, config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """
    return Command(
        goto="chat_node"
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node.
    """

    system_prompt = f"""
    You are a helpful assistant for writing documents.
    To write the document, you MUST use the write_document_local tool.
    You MUST write the full document, even when changing only a few words.
    When you wrote the document, DO NOT repeat it as a message.
    Just briefly summarize the changes you made. 2 sentences max.
    This is the current state of the document: ----\n {state.get('document')}\n-----
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model with emit_intermediate_state to stream tool calls to frontend
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document_local tool
    config["metadata"]["predict_state"] = [{
        "state_key": "document",
        "tool": "write_document_local",
        "tool_argument": "document"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            write_document_local
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model to generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Extract any tool calls from the response
    if hasattr(response, "tool_calls") and response.tool_calls:
        tool_call = response.tool_calls[0]

        # Handle tool_call as a dictionary or an object
        if isinstance(tool_call, dict):
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["name"]
            tool_call_args = tool_call["args"]
        else:
            # Handle as an object (backward compatibility)
            tool_call_id = tool_call.id
            tool_call_name = tool_call.name
            tool_call_args = tool_call.args

        if tool_call_name == "write_document_local":
            # Add the tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Document written.",
                "tool_call_id": tool_call_id
            }

            # Add confirmation tool call
            confirm_tool_call = {
                "role": "assistant",
                "content": "",
                "tool_calls": [{
                    "id": str(uuid.uuid4()),
                    "function": {
                        "name": "confirm_changes",
                        "arguments": "{}"
                    }
                }]
            }

            messages = messages + [tool_response, confirm_tool_call]

            # Return Command to route to end
            return Command(
                goto=END,
                update={
                    "messages": messages,
                    "document": tool_call_args["document"]
                }
            )

    # If no tool was called, go to end
    return Command(
        goto=END,
        update={
            "messages": messages
        }
    )


# Define the graph
workflow = StateGraph(AgentState)
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()




================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/shared_state/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/shared_state/agent.py
================================================
"""
A demo of shared state between the agent and CopilotKit using LangGraph.
"""

import json
from enum import Enum
from typing import Dict, List, Any, Optional
import os

# LangGraph imports
from pydantic import BaseModel, Field
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks.manager import adispatch_custom_event
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.checkpoint.memory import MemorySaver

class SkillLevel(str, Enum):
    """
    The level of skill required for the recipe.
    """
    BEGINNER = "Beginner"
    INTERMEDIATE = "Intermediate"
    ADVANCED = "Advanced"

class SpecialPreferences(str, Enum):
    """
    Special preferences for the recipe.
    """
    HIGH_PROTEIN = "High Protein"
    LOW_CARB = "Low Carb"
    SPICY = "Spicy"
    BUDGET_FRIENDLY = "Budget-Friendly"
    ONE_POT_MEAL = "One-Pot Meal"
    VEGETARIAN = "Vegetarian"
    VEGAN = "Vegan"

class CookingTime(str, Enum):
    """
    The cooking time of the recipe.
    """
    FIVE_MIN = "5 min"
    FIFTEEN_MIN = "15 min"
    THIRTY_MIN = "30 min"
    FORTY_FIVE_MIN = "45 min"
    SIXTY_PLUS_MIN = "60+ min"

class Ingredient(BaseModel):
    """
    An ingredient.
    """
    icon: str = Field(
        description="Icon: the actual emoji like 🥕"
    )
    name: str = Field(description="The name of the ingredient")
    amount: str = Field(description="The amount of the ingredient")

class Recipe(BaseModel):
    """
    A recipe.
    """
    skill_level: SkillLevel = \
        Field(description="The skill level required for the recipe")
    special_preferences: List[SpecialPreferences] = \
        Field(description="A list of special preferences for the recipe")
    cooking_time: CookingTime = \
        Field(description="The cooking time of the recipe")
    ingredients: List[Ingredient] = \
        Field(description=
              """Entire list of ingredients for the recipe, including the new ingredients
              and the ones that are already in the recipe: Icon: the actual emoji like 🥕,
              name and amount.
              Like so: 🥕 Carrots (250g)"""
        )
    instructions: List[str] = \
        Field(description=
              """Entire list of instructions for the recipe,
              including the new instructions and the ones that are already there"""
        )
    changes: str = \
        Field(description="A description of the changes made to the recipe")

class GenerateRecipeArgs(BaseModel): # pylint: disable=missing-class-docstring
    recipe: Recipe

@tool(args_schema=GenerateRecipeArgs)
def generate_recipe(recipe: Recipe): # pylint: disable=unused-argument
    """
    Using the existing (if any) ingredients and instructions, proceed with the recipe to finish it.
    Make sure the recipe is complete. ALWAYS provide the entire recipe, not just the changes.
    """

class AgentState(MessagesState):
    """
    The state of the recipe.
    """
    recipe: Optional[Dict[str, Any]] = None
    tools: List[Any]


async def start_node(state: Dict[str, Any], config: RunnableConfig):
    """
    This is the entry point for the flow.
    """

    # Initialize recipe if not exists
    if "recipe" not in state or state["recipe"] is None:
        state["recipe"] = {
            "skill_level": SkillLevel.BEGINNER.value,
            "special_preferences": [],
            "cooking_time": CookingTime.FIFTEEN_MIN.value,
            "ingredients": [{"icon": "🍴", "name": "Sample Ingredient", "amount": "1 unit"}],
            "instructions": ["First step instruction"]
        }
        # Emit the initial state to ensure it's properly shared with the frontend
        await adispatch_custom_event(
            "manually_emit_intermediate_state",
            state,
            config=config,
        )

    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "recipe": state["recipe"]
        }
    )

async def chat_node(state: Dict[str, Any], config: RunnableConfig):
    """
    Standard chat node.
    """
    # Create a safer serialization of the recipe
    recipe_json = "No recipe yet"
    if "recipe" in state and state["recipe"] is not None:
        try:
            recipe_json = json.dumps(state["recipe"], indent=2)
        except Exception as e: # pylint: disable=broad-exception-caught
            recipe_json = f"Error serializing recipe: {str(e)}"

    system_prompt = f"""You are a helpful assistant for creating recipes. 
    This is the current state of the recipe: {recipe_json}
    You can improve the recipe by calling the generate_recipe tool.
    
    IMPORTANT:
    1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
    2. For ingredients, append new ingredients to the existing ones.
    3. For instructions, append new steps to the existing ones.
    4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
    5. 'instructions' is always an array of strings

    If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o-mini")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "recipe",
        "tool": "generate_recipe",
        "tool_argument": "recipe"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            generate_recipe
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model and generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Handle tool calls
    if hasattr(response, "tool_calls") and response.tool_calls:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        # Check if args is already a dict or needs to be parsed
        tool_call_args = (tool_call["args"]
                          if isinstance(tool_call["args"], dict)
                          else json.loads(tool_call["args"]))

        if tool_call["name"] == "generate_recipe":
            # Update recipe state with tool_call_args
            recipe_data = tool_call_args["recipe"]

            # If we have an existing recipe, update it
            if "recipe" in state and state["recipe"] is not None:
                recipe = state["recipe"]
                for key, value in recipe_data.items():
                    if value is not None:  # Only update fields that were provided
                        recipe[key] = value
            else:
                # Create a new recipe
                recipe = {
                    "skill_level": recipe_data.get("skill_level", SkillLevel.BEGINNER.value),
                    "special_preferences": recipe_data.get("special_preferences", []),
                    "cooking_time": recipe_data.get("cooking_time", CookingTime.FIFTEEN_MIN.value),
                    "ingredients": recipe_data.get("ingredients", []),
                    "instructions": recipe_data.get("instructions", [])
                }

            # Add tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Recipe generated.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]

            # Explicitly emit the updated state to ensure it's shared with frontend
            state["recipe"] = recipe
            await adispatch_custom_event(
                "manually_emit_intermediate_state",
                state,
                config=config,
            )

            # Return command with updated recipe
            return Command(
                goto="start_node",
                update={
                    "messages": messages,
                    "recipe": recipe
                }
            )

    return Command(
        goto=END,
        update={
            "messages": messages,
            "recipe": state["recipe"]
        }
    )


# Define the graph
workflow = StateGraph(AgentState)
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/subgraphs/__init__.py
================================================
# Subgraphs demo module


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/subgraphs/agent.py
================================================
"""
A travel agent supervisor demo showcasing multi-agent architecture with subgraphs.
The supervisor coordinates specialized agents: flights finder, hotels finder, and experiences finder.
"""

from typing import Dict, List, Any, Optional, Annotated, Union
from dataclasses import dataclass
import json
import os
from pydantic import BaseModel, Field

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command, interrupt
from langgraph.graph import MessagesState

# OpenAI imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage

def create_interrupt(message: str, options: List[Any], recommendation: Any, agent: str):
    return interrupt({
        "message": message,
        "options": options,
        "recommendation": recommendation,
        "agent": agent,
    })

# State schema for travel planning
@dataclass
class Flight:
    airline: str
    departure: str
    arrival: str
    price: str
    duration: str

@dataclass
class Hotel:
    name: str
    location: str
    price_per_night: str
    rating: str

@dataclass
class Experience:
    name: str
    type: str  # "restaurant" or "activity"
    description: str
    location: str

def merge_itinerary(left: Union[dict, None] = None, right: Union[dict, None] = None) -> dict:
    """Custom reducer to merge shopping cart updates."""
    if not left:
        left = {}
    if not right:
        right = {}

    return {**left, **right}

class TravelAgentState(MessagesState):
    """Shared state for the travel agent system"""
    # Travel request details
    origin: str = ""
    destination: str = ""

    # Results from each agent
    flights: List[Flight] = None
    hotels: List[Hotel] = None
    experiences: List[Experience] = None

    itinerary: Annotated[dict, merge_itinerary] = None

    # Tools available to all agents
    tools: List[Any] = None

    # Supervisor routing
    next_agent: Optional[str] = None

# Static data for demonstration
STATIC_FLIGHTS = [
    Flight("KLM", "Amsterdam (AMS)", "San Francisco (SFO)", "$650", "11h 30m"),
    Flight("United", "Amsterdam (AMS)", "San Francisco (SFO)", "$720", "12h 15m")
]

STATIC_HOTELS = [
    Hotel("Hotel Zephyr", "Fisherman's Wharf", "$280/night", "4.2 stars"),
    Hotel("The Ritz-Carlton", "Nob Hill", "$550/night", "4.8 stars"),
    Hotel("Hotel Zoe", "Union Square", "$320/night", "4.4 stars")
]

STATIC_EXPERIENCES = [
    Experience("Pier 39", "activity", "Iconic waterfront destination with shops and sea lions", "Fisherman's Wharf"),
    Experience("Golden Gate Bridge", "activity", "World-famous suspension bridge with stunning views", "Golden Gate"),
    Experience("Swan Oyster Depot", "restaurant", "Historic seafood counter serving fresh oysters", "Polk Street"),
    Experience("Tartine Bakery", "restaurant", "Artisanal bakery famous for bread and pastries", "Mission District")
]

# Flights finder subgraph
async def flights_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds flight options"""

    # Simulate flight search with static data
    flights = STATIC_FLIGHTS

    selected_flight = state.get('itinerary', {}).get('flight', None)
    if not selected_flight:
        selected_flight = create_interrupt(
            message=f"""
        Found {len(flights)} flight options from {state.get('origin', 'Amsterdam')} to {state.get('destination', 'San Francisco')}.
        I recommend choosing the flight by {flights[0].airline} since it's known to be on time and cheaper.
        """,
            options=flights,
            recommendation=flights[0],
            agent="flights"
        )

    if isinstance(selected_flight, str):
        selected_flight = json.loads(selected_flight)
    return Command(
        goto=END,
        update={
            "flights": flights,
            "itinerary": {
                "flight": selected_flight
            },
            "messages": state["messages"] + [{
                "role": "assistant",
                "content": f"Flights Agent: Great. I'll book you the {selected_flight["airline"]} flight from {selected_flight["departure"]} to {selected_flight["arrival"]}."
            }]
        }
    )

# Hotels finder subgraph
async def hotels_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds hotel options"""

    # Simulate hotel search with static data
    hotels = STATIC_HOTELS
    selected_hotel = state.get('itinerary', {}).get('hotel', None)
    if not selected_hotel:
        selected_hotel = create_interrupt(
            message=f"""
        Found {len(hotels)} accommodation options in {state.get('destination', 'San Francisco')}.
        I recommend choosing the {hotels[2].name} since it strikes the balance between rating, price, and location.
        """,
            options=hotels,
            recommendation=hotels[2],
            agent="hotels"
        )

    if isinstance(selected_hotel, str):
        selected_hotel = json.loads(selected_hotel)
    return Command(
            goto=END,
            update={
                "hotels": hotels,
                "itinerary": {
                    "hotel": selected_hotel
                },
                "messages": state["messages"] + [{
                    "role": "assistant",
                    "content": f"Hotels Agent: Excellent choice! You'll like {selected_hotel["name"]}."
                }]
            }
        )

# Experiences finder subgraph
async def experiences_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds restaurant and activity recommendations"""

    # Filter experiences (2 restaurants, 2 activities)
    restaurants = [exp for exp in STATIC_EXPERIENCES if exp.type == "restaurant"][:2]
    activities = [exp for exp in STATIC_EXPERIENCES if exp.type == "activity"][:2]
    experiences = restaurants + activities

    model = ChatOpenAI(model="gpt-4o")

    if config is None:
        config = RunnableConfig(recursion_limit=25)

    itinerary = state.get("itinerary", {})

    system_prompt = f"""
    You are the experiences agent. Your job is to find restaurants and activities for the user.
    You already went ahead and found a bunch of experiences. All you have to do now, is to let the user know of your findings.
    
    Current status:
    - Origin: {state.get('origin', 'Amsterdam')}
    - Destination: {state.get('destination', 'San Francisco')}
    - Flight chosen: {itinerary.get("hotel", None)}
    - Hotel chosen: {itinerary.get("hotel", None)}
    - activities found: {activities}
    - restaurants found: {restaurants}
    """

    # Get supervisor decision
    response = await model.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    return Command(
        goto=END,
        update={
            "experiences": experiences,
            "messages": state["messages"] + [response]
        }
    )

class SupervisorResponseFormatter(BaseModel):
    """Always use this tool to structure your response to the user."""
    answer: str = Field(description="The answer to the user")
    next_agent: str | None = Field(description="The agent to go to. Not required if you do not want to route to another agent.")

# Supervisor agent
async def supervisor_agent(state: TravelAgentState, config: RunnableConfig):
    """Main supervisor that coordinates all subgraphs"""

    itinerary = state.get("itinerary", {})

    # Check what's already completed
    has_flights = itinerary.get("flight", None) is not None
    has_hotels = itinerary.get("hotel", None) is not None
    has_experiences = state.get("experiences", None) is not None

    system_prompt = f"""
    You are a travel planning supervisor. Your job is to coordinate specialized agents to help plan a trip.
    
    Current status:
    - Origin: {state.get('origin', 'Amsterdam')}
    - Destination: {state.get('destination', 'San Francisco')}
    - Flights found: {has_flights}
    - Hotels found: {has_hotels}
    - Experiences found: {has_experiences}
    - Itinerary (Things that the user has already confirmed selection on): {json.dumps(itinerary, indent=2)}
    
    Available agents:
    - flights_agent: Finds flight options
    - hotels_agent: Finds hotel options  
    - experiences_agent: Finds restaurant and activity recommendations
    - {END}: Mark task as complete when all information is gathered
    
    You must route to the appropriate agent based on what's missing. Once all agents have completed their tasks, route to 'complete'.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Bind the routing tool
    model_with_tools = model.bind_tools(
        [SupervisorResponseFormatter],
        parallel_tool_calls=False,
    )

    # Get supervisor decision
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    messages = state["messages"] + [response]

    # Handle tool calls for routing
    if hasattr(response, "tool_calls") and response.tool_calls:
        tool_call = response.tool_calls[0]

        if isinstance(tool_call, dict):
            tool_call_args = tool_call["args"]
        else:
            tool_call_args = tool_call.args

        next_agent = tool_call_args["next_agent"]

        # Add tool response
        tool_response = {
            "role": "tool",
            "content": f"Routing to {next_agent} and providing the answer",
            "tool_call_id": tool_call.id if hasattr(tool_call, 'id') else tool_call["id"]
        }

        messages = messages + [tool_response, AIMessage(content=tool_call_args["answer"])]

        if next_agent is not None:
            return Command(goto=next_agent)

    # Fallback if no tool call
    return Command(
        goto=END,
        update={"messages": messages}
    )

# Create subgraphs
flights_graph = StateGraph(TravelAgentState)
flights_graph.add_node("flights_agent_chat_node", flights_finder)
flights_graph.set_entry_point("flights_agent_chat_node")
flights_graph.add_edge(START, "flights_agent_chat_node")
flights_graph.add_edge("flights_agent_chat_node", END)
flights_subgraph = flights_graph.compile()

hotels_graph = StateGraph(TravelAgentState)
hotels_graph.add_node("hotels_agent_chat_node", hotels_finder)
hotels_graph.set_entry_point("hotels_agent_chat_node")
hotels_graph.add_edge(START, "hotels_agent_chat_node")
hotels_graph.add_edge("hotels_agent_chat_node", END)
hotels_subgraph = hotels_graph.compile()

experiences_graph = StateGraph(TravelAgentState)
experiences_graph.add_node("experiences_agent_chat_node", experiences_finder)
experiences_graph.set_entry_point("experiences_agent_chat_node")
experiences_graph.add_edge(START, "experiences_agent_chat_node")
experiences_graph.add_edge("experiences_agent_chat_node", END)
experiences_subgraph = experiences_graph.compile()

# Main supervisor workflow
workflow = StateGraph(TravelAgentState)

# Add supervisor and subgraphs as nodes
workflow.add_node("supervisor", supervisor_agent)
workflow.add_node("flights_agent", flights_subgraph)
workflow.add_node("hotels_agent", hotels_subgraph)
workflow.add_node("experiences_agent", experiences_subgraph)

# Set entry point
workflow.set_entry_point("supervisor")
workflow.add_edge(START, "supervisor")

# Add edges back to supervisor after each subgraph
workflow.add_edge("flights_agent", "supervisor")
workflow.add_edge("hotels_agent", "supervisor")
workflow.add_edge("experiences_agent", "supervisor")

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/tool_based_generative_ui/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/tool_based_generative_ui/agent.py
================================================
"""
An example demonstrating tool-based generative UI using LangGraph.
"""

import os
from typing import Any, List
from typing_extensions import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.prebuilt import ToolNode


class AgentState(MessagesState):
    """
    State of the agent.
    """
    tools: List[Any]

async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["tool_node", "__end__"]]:
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see:
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """

    model = ChatOpenAI(model="gpt-4o")

    model_with_tools = model.bind_tools(
        [
            *state.get("tools", []), # bind tools defined by ag-ui
        ],
        parallel_tool_calls=False,
    )

    system_message = SystemMessage(
        content=f"Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user."
    )

    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    return Command(
        goto=END,
        update={
            "messages": [response],
        }
    )

workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
# This is required even though we don't have any backend tools to pass in.
workflow.add_node("tool_node", ToolNode(tools=[]))
workflow.set_entry_point("chat_node")
workflow.add_edge("chat_node", END)


# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/README.md
================================================
# LangGraph TypeScript Examples

This directory contains TypeScript versions of the LangGraph examples, providing the same functionality as the Python examples but implemented in TypeScript.

## How to run

First, make sure to create a new `.env` file from the `.env.example` and include the required keys:

```bash
cp .env.example .env
```

Then edit the `.env` file and add your API keys:
- `OPENAI_API_KEY`: Your OpenAI API key
- `TAVILY_API_KEY`: Your Tavily API key (if needed)

Install dependencies:

```bash
npm install
```

For TypeScript development, run:

```bash
npm run build
pnpx @langchain/langgraph-cli@latest dev
```

## Available Agents

This project includes TypeScript implementations of the following agents:

### 1. Agentic Chat (`agentic_chat`)
A simple agentic chat flow using LangGraph following the ReAct design pattern. Handles tool binding, system prompts, and model responses.

### 2. Agentic Generative UI (`agentic_generative_ui`)
Demonstrates agentic generative UI capabilities. Creates task steps and simulates their execution while streaming updates to the frontend.

### 3. Human in the Loop (`human_in_the_loop`)
Implements human-in-the-loop functionality where users can interact with and modify the agent's proposed steps before execution.

### 4. Predictive State Updates (`predictive_state_updates`)
Shows predictive state updates for document writing with streaming tool calls to the frontend.

### 5. Shared State (`shared_state`)
Demonstrates shared state management between the agent and CopilotKit, focusing on recipe creation and modification.

### 6. Tool-based Generative UI (`tool_based_generative_ui`)
Example of tool-based generative UI for haiku generation with image selection capabilities.

## Project Structure

```
typescript-sdk/integrations/langgraph/examples/typescript/
├── src/
│   └── agents/
│       ├── agentic_chat/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── agentic_generative_ui/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── human_in_the_loop/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── predictive_state_updates/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── shared_state/
│       │   ├── agent.ts
│       │   └── index.ts
│       └── tool_based_generative_ui/
│           ├── agent.ts
│           └── index.ts
├── package.json
├── tsconfig.json
├── langgraph.json
├── .env.example
└── README.md
```

## Dependencies

- `@langchain/core`: Core LangChain functionality
- `@langchain/openai`: OpenAI integration
- `@langchain/langgraph`: LangGraph for building stateful agents
- `dotenv`: Environment variable management
- `uuid`: UUID generation for tool calls
- `typescript`: TypeScript compiler

## Development

To build the project:

```bash
npm run build
```

To start development with LangGraph CLI:

```bash
npm run dev
```

## Notes

These TypeScript implementations maintain the same functionality as their Python counterparts while following TypeScript/JavaScript conventions and patterns. Each agent is fully typed and includes proper error handling and state management.


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/langgraph.json
================================================
{
  "dependencies": ["."],
  "graphs": {
    "agentic_chat": "./src/agents/agentic_chat/agent.ts:agenticChatGraph",
    "agentic_generative_ui": "./src/agents/agentic_generative_ui/agent.ts:agenticGenerativeUiGraph",
    "human_in_the_loop": "./src/agents/human_in_the_loop/agent.ts:humanInTheLoopGraph",
    "predictive_state_updates": "./src/agents/predictive_state_updates/agent.ts:predictiveStateUpdatesGraph",
    "shared_state": "./src/agents/shared_state/agent.ts:sharedStateGraph",
    "tool_based_generative_ui": "./src/agents/tool_based_generative_ui/agent.ts:toolBasedGenerativeUiGraph",
    "subgraphs": "./src/agents/subgraphs/agent.ts:subGraphsAgentGraph"
  },
  "env": ".env"
}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/package.json
================================================
{
  "name": "langgraph-agui-dojo-typescript",
  "version": "0.1.0",
  "description": "TypeScript examples for LangGraph agents with CopilotKit integration",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "dev": "pnpx @langchain/langgraph-cli@latest dev",
    "start": "node dist/index.js"
  },
  "dependencies": {
    "@langchain/core": "^0.3.66",
    "@langchain/openai": "^0.6.3",
    "@langchain/langgraph": "^0.2.65",
    "dotenv": "^16.4.5",
    "uuid": "^10.0.0"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "@types/uuid": "^10.0.0",
    "typescript": "^5.0.0"
  }
}


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/pnpm-lock.yaml
================================================
lockfileVersion: '9.0'

settings:
  autoInstallPeers: true
  excludeLinksFromLockfile: false

importers:

  .:
    dependencies:
      '@langchain/core':
        specifier: ^0.3.66
        version: 0.3.66(openai@5.10.2(zod@3.25.76))
      '@langchain/langgraph':
        specifier: ^0.2.65
        version: 0.2.74(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))(zod-to-json-schema@3.24.6(zod@3.25.76))
      '@langchain/openai':
        specifier: ^0.6.3
        version: 0.6.3(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      dotenv:
        specifier: ^16.4.5
        version: 16.6.1
      uuid:
        specifier: ^10.0.0
        version: 10.0.0
    devDependencies:
      '@types/node':
        specifier: ^20.0.0
        version: 20.19.9
      '@types/uuid':
        specifier: ^10.0.0
        version: 10.0.0
      typescript:
        specifier: ^5.0.0
        version: 5.8.3

packages:

  '@cfworker/json-schema@4.1.1':
    resolution: {integrity: sha512-gAmrUZSGtKc3AiBL71iNWxDsyUC5uMaKKGdvzYsBoTW/xi42JQHl7eKV2OYzCUqvc+D2RCcf7EXY2iCyFIk6og==}

  '@langchain/core@0.3.66':
    resolution: {integrity: sha512-d3SgSDOlgOjdIbReIXVQl9HaQzKqO/5+E+o3kJwoKXLGP9dxi7+lMyaII7yv7G8/aUxMWLwFES9zc1jFoeJEZw==}
    engines: {node: '>=18'}

  '@langchain/langgraph-checkpoint@0.0.18':
    resolution: {integrity: sha512-IS7zJj36VgY+4pf8ZjsVuUWef7oTwt1y9ylvwu0aLuOn1d0fg05Om9DLm3v2GZ2Df6bhLV1kfWAM0IAl9O5rQQ==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.2.31 <0.4.0'

  '@langchain/langgraph-sdk@0.0.104':
    resolution: {integrity: sha512-wUO6GMy65Y7DsWtjTJ3dA59enrZy2wN4o48AMYN7dF7u/PMXXYyBjBCKSzgVWqO6uWH2yNpyGDrcMwKuk5kQLA==}
    peerDependencies:
      '@langchain/core': '>=0.2.31 <0.4.0'
      react: ^18 || ^19
      react-dom: ^18 || ^19
    peerDependenciesMeta:
      '@langchain/core':
        optional: true
      react:
        optional: true
      react-dom:
        optional: true

  '@langchain/langgraph@0.2.74':
    resolution: {integrity: sha512-oHpEi5sTZTPaeZX1UnzfM2OAJ21QGQrwReTV6+QnX7h8nDCBzhtipAw1cK616S+X8zpcVOjgOtJuaJhXa4mN8w==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.2.36 <0.3.0 || >=0.3.40 < 0.4.0'
      zod-to-json-schema: ^3.x
    peerDependenciesMeta:
      zod-to-json-schema:
        optional: true

  '@langchain/openai@0.6.3':
    resolution: {integrity: sha512-dSNuXDTJitDzN8D2wFNqWVELDbBRhMpJiFeiWpHjfPuq7R6wSjzNNY/Uk6x+FLpvbOs/zKNWy5+0q0p3KrCjRQ==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.3.58 <0.4.0'

  '@types/json-schema@7.0.15':
    resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}

  '@types/node@20.19.9':
    resolution: {integrity: sha512-cuVNgarYWZqxRJDQHEB58GEONhOK79QVR/qYx4S7kcUObQvUwvFnYxJuuHUKm2aieN9X3yZB4LZsuYNU1Qphsw==}

  '@types/retry@0.12.0':
    resolution: {integrity: sha512-wWKOClTTiizcZhXnPY4wikVAwmdYHp8q6DmC+EJUzAMsycb7HB32Kh9RN4+0gExjmPmZSAQjgURXIGATPegAvA==}

  '@types/uuid@10.0.0':
    resolution: {integrity: sha512-7gqG38EyHgyP1S+7+xomFtL+ZNHcKv6DwNaCZmJmo1vgMugyF3TCnXVg4t1uk89mLNwnLtnY3TpOpCOyp1/xHQ==}

  ansi-styles@4.3.0:
    resolution: {integrity: sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==}
    engines: {node: '>=8'}

  ansi-styles@5.2.0:
    resolution: {integrity: sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==}
    engines: {node: '>=10'}

  base64-js@1.5.1:
    resolution: {integrity: sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==}

  camelcase@6.3.0:
    resolution: {integrity: sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==}
    engines: {node: '>=10'}

  chalk@4.1.2:
    resolution: {integrity: sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==}
    engines: {node: '>=10'}

  color-convert@2.0.1:
    resolution: {integrity: sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==}
    engines: {node: '>=7.0.0'}

  color-name@1.1.4:
    resolution: {integrity: sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==}

  console-table-printer@2.14.6:
    resolution: {integrity: sha512-MCBl5HNVaFuuHW6FGbL/4fB7N/ormCy+tQ+sxTrF6QtSbSNETvPuOVbkJBhzDgYhvjWGrTma4eYJa37ZuoQsPw==}

  decamelize@1.2.0:
    resolution: {integrity: sha512-z2S+W9X73hAUUki+N+9Za2lBlun89zigOyGrsax+KUQ6wKW4ZoWpEYBkGhQjwAjjDCkWxhY0VKEhk8wzY7F5cA==}
    engines: {node: '>=0.10.0'}

  dotenv@16.6.1:
    resolution: {integrity: sha512-uBq4egWHTcTt33a72vpSG0z3HnPuIl6NqYcTrKEg2azoEyl2hpW0zqlxysq2pK9HlDIHyHyakeYaYnSAwd8bow==}
    engines: {node: '>=12'}

  eventemitter3@4.0.7:
    resolution: {integrity: sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==}

  has-flag@4.0.0:
    resolution: {integrity: sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==}
    engines: {node: '>=8'}

  js-tiktoken@1.0.20:
    resolution: {integrity: sha512-Xlaqhhs8VfCd6Sh7a1cFkZHQbYTLCwVJJWiHVxBYzLPxW0XsoxBy1hitmjkdIjD3Aon5BXLHFwU5O8WUx6HH+A==}

  langsmith@0.3.49:
    resolution: {integrity: sha512-hVLpGzTDq4dFffScKuF9yIuwXqp6LJCsvxK4UjmLae+oEodfnFIQ6yVmNyhxFnm3QuRl1NY8qLFul3k+R1YnGQ==}
    peerDependencies:
      '@opentelemetry/api': '*'
      '@opentelemetry/exporter-trace-otlp-proto': '*'
      '@opentelemetry/sdk-trace-base': '*'
      openai: '*'
    peerDependenciesMeta:
      '@opentelemetry/api':
        optional: true
      '@opentelemetry/exporter-trace-otlp-proto':
        optional: true
      '@opentelemetry/sdk-trace-base':
        optional: true
      openai:
        optional: true

  mustache@4.2.0:
    resolution: {integrity: sha512-71ippSywq5Yb7/tVYyGbkBggbU8H3u5Rz56fH60jGFgr8uHwxs+aSKeqmluIVzM0m0kB7xQjKS6qPfd0b2ZoqQ==}
    hasBin: true

  openai@5.10.2:
    resolution: {integrity: sha512-n+vi74LzHtvlKcDPn9aApgELGiu5CwhaLG40zxLTlFQdoSJCLACORIPC2uVQ3JEYAbqapM+XyRKFy2Thej7bIw==}
    hasBin: true
    peerDependencies:
      ws: ^8.18.0
      zod: ^3.23.8
    peerDependenciesMeta:
      ws:
        optional: true
      zod:
        optional: true

  p-finally@1.0.0:
    resolution: {integrity: sha512-LICb2p9CB7FS+0eR1oqWnHhp0FljGLZCWBE9aix0Uye9W8LTQPwMTYVGWQWIw9RdQiDg4+epXQODwIYJtSJaow==}
    engines: {node: '>=4'}

  p-queue@6.6.2:
    resolution: {integrity: sha512-RwFpb72c/BhQLEXIZ5K2e+AhgNVmIejGlTgiB9MzZ0e93GRvqZ7uSi0dvRF7/XIXDeNkra2fNHBxTyPDGySpjQ==}
    engines: {node: '>=8'}

  p-retry@4.6.2:
    resolution: {integrity: sha512-312Id396EbJdvRONlngUx0NydfrIQ5lsYu0znKVUzVvArzEIt08V1qhtyESbGVd1FGX7UKtiFp5uwKZdM8wIuQ==}
    engines: {node: '>=8'}

  p-timeout@3.2.0:
    resolution: {integrity: sha512-rhIwUycgwwKcP9yTOOFK/AKsAopjjCakVqLHePO3CC6Mir1Z99xT+R63jZxAT5lFZLa2inS5h+ZS2GvR99/FBg==}
    engines: {node: '>=8'}

  retry@0.13.1:
    resolution: {integrity: sha512-XQBQ3I8W1Cge0Seh+6gjj03LbmRFWuoszgK9ooCpwYIrhhoO80pfq4cUkU5DkknwfOfFteRwlZ56PYOGYyFWdg==}
    engines: {node: '>= 4'}

  semver@7.7.2:
    resolution: {integrity: sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==}
    engines: {node: '>=10'}
    hasBin: true

  simple-wcswidth@1.1.2:
    resolution: {integrity: sha512-j7piyCjAeTDSjzTSQ7DokZtMNwNlEAyxqSZeCS+CXH7fJ4jx3FuJ/mTW3mE+6JLs4VJBbcll0Kjn+KXI5t21Iw==}

  supports-color@7.2.0:
    resolution: {integrity: sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==}
    engines: {node: '>=8'}

  typescript@5.8.3:
    resolution: {integrity: sha512-p1diW6TqL9L07nNxvRMM7hMMw4c5XOo/1ibL4aAIGmSAt9slTE1Xgw5KWuof2uTOvCg9BY7ZRi+GaF+7sfgPeQ==}
    engines: {node: '>=14.17'}
    hasBin: true

  undici-types@6.21.0:
    resolution: {integrity: sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==}

  uuid@10.0.0:
    resolution: {integrity: sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==}
    hasBin: true

  uuid@9.0.1:
    resolution: {integrity: sha512-b+1eJOlsR9K8HJpow9Ok3fiWOWSIcIzXodvv0rQjVoOVNpWMpxf1wZNpt4y9h10odCNrqnYp1OBzRktckBe3sA==}
    hasBin: true

  zod-to-json-schema@3.24.6:
    resolution: {integrity: sha512-h/z3PKvcTcTetyjl1fkj79MHNEjm+HpD6NXheWjzOekY7kV+lwDYnHw+ivHkijnCSMz1yJaWBD9vu/Fcmk+vEg==}
    peerDependencies:
      zod: ^3.24.1

  zod@3.25.76:
    resolution: {integrity: sha512-gzUt/qt81nXsFGKIFcC3YnfEAx5NkunCfnDlvuBSSFS02bcXu4Lmea0AFIUwbLWxWPx3d9p8S5QoaujKcNQxcQ==}

snapshots:

  '@cfworker/json-schema@4.1.1': {}

  '@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76))':
    dependencies:
      '@cfworker/json-schema': 4.1.1
      ansi-styles: 5.2.0
      camelcase: 6.3.0
      decamelize: 1.2.0
      js-tiktoken: 1.0.20
      langsmith: 0.3.49(openai@5.10.2(zod@3.25.76))
      mustache: 4.2.0
      p-queue: 6.6.2
      p-retry: 4.6.2
      uuid: 10.0.0
      zod: 3.25.76
      zod-to-json-schema: 3.24.6(zod@3.25.76)
    transitivePeerDependencies:
      - '@opentelemetry/api'
      - '@opentelemetry/exporter-trace-otlp-proto'
      - '@opentelemetry/sdk-trace-base'
      - openai

  '@langchain/langgraph-checkpoint@0.0.18(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      uuid: 10.0.0

  '@langchain/langgraph-sdk@0.0.104(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@types/json-schema': 7.0.15
      p-queue: 6.6.2
      p-retry: 4.6.2
      uuid: 9.0.1
    optionalDependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))

  '@langchain/langgraph@0.2.74(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))(zod-to-json-schema@3.24.6(zod@3.25.76))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      '@langchain/langgraph-checkpoint': 0.0.18(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      '@langchain/langgraph-sdk': 0.0.104(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      uuid: 10.0.0
      zod: 3.25.76
    optionalDependencies:
      zod-to-json-schema: 3.24.6(zod@3.25.76)
    transitivePeerDependencies:
      - react
      - react-dom

  '@langchain/openai@0.6.3(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      js-tiktoken: 1.0.20
      openai: 5.10.2(zod@3.25.76)
      zod: 3.25.76
    transitivePeerDependencies:
      - ws

  '@types/json-schema@7.0.15': {}

  '@types/node@20.19.9':
    dependencies:
      undici-types: 6.21.0

  '@types/retry@0.12.0': {}

  '@types/uuid@10.0.0': {}

  ansi-styles@4.3.0:
    dependencies:
      color-convert: 2.0.1

  ansi-styles@5.2.0: {}

  base64-js@1.5.1: {}

  camelcase@6.3.0: {}

  chalk@4.1.2:
    dependencies:
      ansi-styles: 4.3.0
      supports-color: 7.2.0

  color-convert@2.0.1:
    dependencies:
      color-name: 1.1.4

  color-name@1.1.4: {}

  console-table-printer@2.14.6:
    dependencies:
      simple-wcswidth: 1.1.2

  decamelize@1.2.0: {}

  dotenv@16.6.1: {}

  eventemitter3@4.0.7: {}

  has-flag@4.0.0: {}

  js-tiktoken@1.0.20:
    dependencies:
      base64-js: 1.5.1

  langsmith@0.3.49(openai@5.10.2(zod@3.25.76)):
    dependencies:
      '@types/uuid': 10.0.0
      chalk: 4.1.2
      console-table-printer: 2.14.6
      p-queue: 6.6.2
      p-retry: 4.6.2
      semver: 7.7.2
      uuid: 10.0.0
    optionalDependencies:
      openai: 5.10.2(zod@3.25.76)

  mustache@4.2.0: {}

  openai@5.10.2(zod@3.25.76):
    optionalDependencies:
      zod: 3.25.76

  p-finally@1.0.0: {}

  p-queue@6.6.2:
    dependencies:
      eventemitter3: 4.0.7
      p-timeout: 3.2.0

  p-retry@4.6.2:
    dependencies:
      '@types/retry': 0.12.0
      retry: 0.13.1

  p-timeout@3.2.0:
    dependencies:
      p-finally: 1.0.0

  retry@0.13.1: {}

  semver@7.7.2: {}

  simple-wcswidth@1.1.2: {}

  supports-color@7.2.0:
    dependencies:
      has-flag: 4.0.0

  typescript@5.8.3: {}

  undici-types@6.21.0: {}

  uuid@10.0.0: {}

  uuid@9.0.1: {}

  zod-to-json-schema@3.24.6(zod@3.25.76):
    dependencies:
      zod: 3.25.76

  zod@3.25.76: {}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/pnpm-workspace.yaml
================================================
packages:
  - '.'


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "node",
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/.env.example
================================================
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/agentic_chat/agent.ts
================================================
/**
 * A simple agentic chat flow using LangGraph instead of CrewAI.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Annotation, MessagesAnnotation, StateGraph, Command, START, END } from "@langchain/langgraph";

const AgentStateAnnotation = Annotation.Root({
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  ...MessagesAnnotation.spec,
});

type AgentState = typeof AgentStateAnnotation.State;

async function chatNode(state: AgentState, config?: RunnableConfig) {
  /**
   * Standard chat node based on the ReAct design pattern. It handles:
   * - The model to use (and binds in CopilotKit actions and the tools defined above)
   * - The system prompt
   * - Getting a response from the model
   * - Handling tool calls
   *
   * For more about the ReAct design pattern, see: 
   * https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
   */
  
  // 1. Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // 2. Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      // your_tool_here
    ],
    {
      // 2.1 Disable parallel tool calls to avoid race conditions,
      //     enable this for faster performance if you want to manage
      //     the complexity of running tool calls in parallel.
      parallel_tool_calls: false,
    }
  );

  // 3. Define the system message by which the chat model will be run
  const systemMessage = new SystemMessage({
    content: "You are a helpful assistant."
  });

  // 4. Run the model to generate a response
  const response = await modelWithTools.invoke([
    systemMessage,
    ...state.messages,
  ], config);

  // 6. We've handled all tool calls, so we can end the graph.
  return new Command({
    goto: END,
    update: {
      messages: [response]
    }
  })
}

// Define a new graph  
const workflow = new StateGraph(AgentStateAnnotation)
  .addNode("chat_node", chatNode)
  .addEdge(START, "chat_node");

// Compile the graph
export const agenticChatGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/agentic_generative_ui/agent.ts
================================================
/**
 * An example demonstrating agentic generative UI using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch";
import { Annotation, MessagesAnnotation, StateGraph } from "@langchain/langgraph";

// This tool simulates performing a task on the server.
// The tool call will be streamed to the frontend as it is being generated.
const PERFORM_TASK_TOOL = {
  type: "function",
  function: {
    name: "generate_task_steps_generative_ui",
    description: "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in gerund form (i.e. Digging hole, opening door, ...)",
    parameters: {
      type: "object",
      properties: {
        steps: {
          type: "array",
          items: {
            type: "object",
            properties: {
              description: {
                type: "string",
                description: "The text of the step in gerund form"
              },
              status: {
                type: "string",
                enum: ["pending"],
                description: "The status of the step, always 'pending'"
              }
            },
            required: ["description", "status"]
          },
          description: "An array of 10 step objects, each containing text and status"
        }
      },
      required: ["steps"]
    }
  }
};

const AgentStateAnnotation = Annotation.Root({
  steps: Annotation<Array<{ description: string; status: string }>>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  ...MessagesAnnotation.spec,
});

type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig) {
  /**
   * This is the entry point for the flow.
   */

  if (!state.steps) {
    state.steps = [];
  }

  return {
    steps: state.steps || []
  };
}

async function chatNode(state: AgentState, config?: RunnableConfig) {
  /**
   * Standard chat node.
   */
  const systemPrompt = `
    You are a helpful assistant assisting with any task. 
    When asked to do something, you MUST call the function \`generate_task_steps_generative_ui\`
    that was provided to you.
    If you called the function, you MUST NOT repeat the steps in your next response to the user.
    Just give a very brief summary (one sentence) of what you did with some emojis. 
    Always say you actually did the steps, not merely generated them.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });
  
  // Define config for the model with emit_intermediate_state to stream tool calls to frontend
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "steps",
    tool: "generate_task_steps_generative_ui",
    tool_argument: "steps",
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      PERFORM_TASK_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model to generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  const messages = [...state.messages, response];

  // Extract any tool calls from the response
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    
    if (toolCall.name === "generate_task_steps_generative_ui") {
      const steps = toolCall.args.steps.map((step: any) => ({
        description: step.description,
        status: step.status
      }));
      
      // Add the tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Steps executed.",
        tool_call_id: toolCall.id
      };

      const updatedMessages = [...messages, toolResponse];

      // Simulate executing the steps
      for (let i = 0; i < steps.length; i++) {
        // simulate executing the step
        await new Promise(resolve => setTimeout(resolve, 1000));
        steps[i].status = "completed";
        // Update the state with the completed step
        state.steps = steps;
        // Emit custom events to update the frontend
        await dispatchCustomEvent("manually_emit_state", state, config);
      }
      
      return {
        messages: updatedMessages,
        steps: state.steps
      };
    }
  }

  return {
    messages: messages,
    steps: state.steps
  };
}

// Define the graph
const workflow = new StateGraph(AgentStateAnnotation)
  .addNode("start_flow", startFlow)
  .addNode("chat_node", chatNode)
  .addEdge("__start__", "start_flow")
  .addEdge("start_flow", "chat_node")
  .addEdge("chat_node", "__end__");

// Compile the graph
export const agenticGenerativeUiGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/human_in_the_loop/agent.ts
================================================
/**
 * A LangGraph implementation of the human-in-the-loop agent.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, interrupt, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

const DEFINE_TASK_TOOL = {
  type: "function",
  function: {
    name: "plan_execution_steps",
    description: "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in imperative form (i.e. Dig hole, Open door, ...)",
    parameters: {
      type: "object",
      properties: {
        steps: {
          type: "array",
          items: {
            type: "object",
            properties: {
              description: {
                type: "string",
                description: "The text of the step in imperative form"
              },
              status: {
                type: "string",
                enum: ["enabled"],
                description: "The status of the step, always 'enabled'"
              }
            },
            required: ["description", "status"]
          },
          description: "An array of 10 step objects, each containing text and status"
        }
      },
      required: ["steps"]
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  steps: Annotation<Array<{ description: string; status: string }>>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  tools: Annotation<any[]>(),
  user_response: Annotation<string | undefined>({
    reducer: (x, y) => y ?? x,
    default: () => undefined
  }),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This is the entry point for the flow.
   */

  // Initialize steps list if not exists
  if (!state.steps) {
    state.steps = [];
  }

  return new Command({
    goto: "chat_node",
    update: {
      messages: state.messages,
      steps: state.steps,
    }
  });
}

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node where the agent processes messages and generates responses.
   * If task steps are defined, the user can enable/disable them using interrupts.
   */
  const systemPrompt = `
    You are a helpful assistant that can perform any task.
    You MUST call the \`plan_execution_steps\` function when the user asks you to perform a task.
    Always make sure you will provide tasks based on the user query
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o-mini" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "steps",
    tool: "plan_execution_steps",
    tool_argument: "steps"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      DEFINE_TASK_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model and generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];
  
  // Handle tool calls
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];

    if (toolCall.name === "plan_execution_steps") {
      // Get the steps from the tool call
      const stepsRaw = toolCall.args.steps || [];
      
      // Set initial status to "enabled" for all steps
      const stepsData: Array<{ description: string; status: string }> = [];
      
      // Handle different potential formats of steps data
      if (Array.isArray(stepsRaw)) {
        for (const step of stepsRaw) {
          if (typeof step === 'object' && step.description) {
            stepsData.push({
              description: step.description,
              status: "enabled"
            });
          } else if (typeof step === 'string') {
            stepsData.push({
              description: step,
              status: "enabled"
            });
          }
        }
      }
      
      // If no steps were processed correctly, return to END with the updated messages
      if (stepsData.length === 0) {
        return new Command({
          goto: END,
          update: {
            messages: messages,
            steps: state.steps,
          }
        });
      }

      // Update steps in state and emit to frontend
      state.steps = stepsData;
      
      // Add a tool response to satisfy OpenAI's requirements
      const toolResponse = {
        role: "tool" as const,
        content: "Task steps generated.",
        tool_call_id: toolCall.id
      };
      
      const updatedMessages = [...messages, toolResponse];

      // Move to the process_steps_node which will handle the interrupt and final response
      return new Command({
        goto: "process_steps_node",
        update: {
          messages: updatedMessages,
          steps: state.steps,
        }
      });
    }
  }
  
  // If no tool calls or not plan_execution_steps, return to END with the updated messages
  return new Command({
    goto: END,
    update: {
      messages: messages,
      steps: state.steps,
    }
  });
}

async function processStepsNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This node handles the user interrupt for step customization and generates the final response.
   */

  let userResponse: string;

  // Check if we already have a user_response in the state
  // This happens when the node restarts after an interrupt
  if (state.user_response) {
    userResponse = state.user_response;
  } else {
    // Use LangGraph interrupt to get user input on steps
    // This will pause execution and wait for user input in the frontend
    userResponse = interrupt({ steps: state.steps });
    // Store the user response in state for when the node restarts
    state.user_response = userResponse;
  }
  
  // Generate the creative completion response
  const finalPrompt = `
    Provide a textual description of how you are performing the task.
    If the user has disabled a step, you are not allowed to perform that step.
    However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
    some humor in the description of how you are performing the task.
    Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
    `;
  
  const finalResponse = await new ChatOpenAI({ model: "gpt-4o" }).invoke([
    new SystemMessage({ content: finalPrompt }),
    { role: "user", content: userResponse }
  ], config);

  // Add the final response to messages
  const messages = [...state.messages, finalResponse];
  
  // Clear the user_response from state to prepare for future interactions
  const newState = { ...state };
  delete newState.user_response;
  
  // Return to END with the updated messages
  return new Command({
    goto: END,
    update: {
      messages: messages,
      steps: state.steps,
    }
  });
}

// Define the graph
const workflow = new StateGraph(AgentStateAnnotation);

// Add nodes
workflow.addNode("start_flow", startFlow);
workflow.addNode("chat_node", chatNode);
workflow.addNode("process_steps_node", processStepsNode);

// Add edges
workflow.setEntryPoint("start_flow");
workflow.addEdge(START, "start_flow");
workflow.addEdge("start_flow", "chat_node");
workflow.addEdge("process_steps_node", END);

// Add conditional edges from chat_node
workflow.addConditionalEdges(
  "chat_node",
  (state: AgentState) => {
    // This would be determined by the Command returned from chat_node
    // For now, we'll assume the logic is handled in the Command's goto property
    return "continue";
  },
  {
    "process_steps_node": "process_steps_node",
    "continue": END,
  }
);

// Compile the graph
export const humanInTheLoopGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/predictive_state_updates/agent.ts
================================================
/**
 * A demo of predictive state updates using LangGraph.
 */

import { v4 as uuidv4 } from "uuid";
import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

const WRITE_DOCUMENT_TOOL = {
  type: "function",
  function: {
    name: "write_document_local",
    description: [
      "Write a document. Use markdown formatting to format the document.",
      "It's good to format the document extensively so it's easy to read.",
      "You can use all kinds of markdown.",
      "However, do not use italic or strike-through formatting, it's reserved for another purpose.",
      "You MUST write the full document, even when changing only a few words.",
      "When making edits to the document, try to make them minimal - do not change every word.",
      "Keep stories SHORT!"
    ].join(" "),
    parameters: {
      type: "object",
      properties: {
        document: {
          type: "string",
          description: "The document to write"
        },
      },
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  document: Annotation<string | undefined>({
    reducer: (x, y) => y ?? x,
    default: () => undefined
  }),
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This is the entry point for the flow.
   */
  return new Command({
    goto: "chat_node"
  });
}

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node.
   */

  const systemPrompt = `
    You are a helpful assistant for writing documents.
    To write the document, you MUST use the write_document_local tool.
    You MUST write the full document, even when changing only a few words.
    When you wrote the document, DO NOT repeat it as a message.
    Just briefly summarize the changes you made. 2 sentences max.
    This is the current state of the document: ----\n ${state.document || ''}\n-----
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });

  // Define config for the model with emit_intermediate_state to stream tool calls to frontend
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document_local tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "document",
    tool: "write_document_local",
    tool_argument: "document"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      WRITE_DOCUMENT_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model to generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];

  // Extract any tool calls from the response
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];

    if (toolCall.name === "write_document_local") {
      // Add the tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Document written.",
        tool_call_id: toolCall.id
      };

      // Add confirmation tool call
      const confirmToolCall = {
        role: "assistant" as const,
        content: "",
        tool_calls: [{
          id: uuidv4(),
          type: "function" as const,
          function: {
            name: "confirm_changes",
            arguments: "{}"
          }
        }]
      };

      const updatedMessages = [...messages, toolResponse, confirmToolCall];

      // Return Command to route to end
      return new Command({
        goto: END,
        update: {
          messages: updatedMessages,
          document: toolCall.args.document
        }
      });
    }
  }

  // If no tool was called, go to end
  return new Command({
    goto: END,
    update: {
      messages: messages
    }
  });
}

// Define the graph
const workflow = new StateGraph<AgentState>(AgentStateAnnotation);

// Add nodes
workflow.addNode("start_flow", startFlow);
workflow.addNode("chat_node", chatNode);

// Add edges
workflow.setEntryPoint("start_flow");
workflow.addEdge(START, "start_flow");
workflow.addEdge("start_flow", "chat_node");
workflow.addEdge("chat_node", END);

// Compile the graph
export const predictiveStateUpdatesGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/shared_state/agent.ts
================================================
/**
 * A demo of shared state between the agent and CopilotKit using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

enum SkillLevel {
  BEGINNER = "Beginner",
  INTERMEDIATE = "Intermediate",
  ADVANCED = "Advanced"
}

enum SpecialPreferences {
  HIGH_PROTEIN = "High Protein",
  LOW_CARB = "Low Carb",
  SPICY = "Spicy",
  BUDGET_FRIENDLY = "Budget-Friendly",
  ONE_POT_MEAL = "One-Pot Meal",
  VEGETARIAN = "Vegetarian",
  VEGAN = "Vegan"
}

enum CookingTime {
  FIVE_MIN = "5 min",
  FIFTEEN_MIN = "15 min",
  THIRTY_MIN = "30 min",
  FORTY_FIVE_MIN = "45 min",
  SIXTY_PLUS_MIN = "60+ min"
}

interface Ingredient {
  icon: string;
  name: string;
  amount: string;
}

interface Recipe {
  skill_level: SkillLevel;
  special_preferences: SpecialPreferences[];
  cooking_time: CookingTime;
  ingredients: Ingredient[];
  instructions: string[];
  changes?: string;
}

const GENERATE_RECIPE_TOOL = {
  type: "function",
  function: {
    name: "generate_recipe",
    description: "Using the existing (if any) ingredients and instructions, proceed with the recipe to finish it. Make sure the recipe is complete. ALWAYS provide the entire recipe, not just the changes.",
    parameters: {
      type: "object",
      properties: {
        recipe: {
          type: "object",
          properties: {
            skill_level: {
              type: "string",
              enum: Object.values(SkillLevel),
              description: "The skill level required for the recipe"
            },
            special_preferences: {
              type: "array",
              items: {
                type: "string",
                enum: Object.values(SpecialPreferences)
              },
              description: "A list of special preferences for the recipe"
            },
            cooking_time: {
              type: "string",
              enum: Object.values(CookingTime),
              description: "The cooking time of the recipe"
            },
            ingredients: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  icon: { type: "string", description: "The icon emoji (not emoji code like '\\u1f35e', but the actual emoji like 🥕) of the ingredient" },
                  name: { type: "string" },
                  amount: { type: "string" }
                }
              },
              description: "Entire list of ingredients for the recipe, including the new ingredients and the ones that are already in the recipe"
            },
            instructions: {
              type: "array",
              items: { type: "string" },
              description: "Entire list of instructions for the recipe, including the new instructions and the ones that are already there"
            },
            changes: {
              type: "string",
              description: "A description of the changes made to the recipe"
            }
          },
        }
      },
      required: ["recipe"]
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  recipe: Annotation<Recipe | undefined>(),
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This is the entry point for the flow.
   */

  // Initialize recipe if not exists
  if (!state.recipe) {
    state.recipe = {
      skill_level: SkillLevel.BEGINNER,
      special_preferences: [],
      cooking_time: CookingTime.FIFTEEN_MIN,
      ingredients: [{ icon: "🍴", name: "Sample Ingredient", amount: "1 unit" }],
      instructions: ["First step instruction"]
    };
    // Emit the initial state to ensure it's properly shared with the frontend
    await dispatchCustomEvent("manually_emit_intermediate_state", state, config);
  }
  
  return new Command({
    goto: "chat_node",
    update: {
      messages: state.messages,
      recipe: state.recipe
    }
  });
}

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node.
   */
  // Create a safer serialization of the recipe
  let recipeJson = "No recipe yet";
  if (state.recipe) {
    try {
      recipeJson = JSON.stringify(state.recipe, null, 2);
    } catch (e) {
      recipeJson = `Error serializing recipe: ${e}`;
    }
  }

  const systemPrompt = `You are a helpful assistant for creating recipes. 
    This is the current state of the recipe: ${recipeJson}
    You can improve the recipe by calling the generate_recipe tool.
    
    IMPORTANT:
    1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
    2. For ingredients, append new ingredients to the existing ones.
    3. For instructions, append new steps to the existing ones.
    4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
    5. 'instructions' is always an array of strings

    If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o-mini" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "recipe",
    tool: "generate_recipe",
    tool_argument: "recipe"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      GENERATE_RECIPE_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model and generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];
  
  // Handle tool calls
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    
    if (toolCall.name === "generate_recipe") {
      // Update recipe state with tool_call_args
      const recipeData = toolCall.args.recipe;
      let recipe: Recipe;
      // If we have an existing recipe, update it
      if (state.recipe) {
        recipe = { ...state.recipe };
        for (const [key, value] of Object.entries(recipeData)) {
          if (value !== null && value !== undefined) {  // Only update fields that were provided
            (recipe as any)[key] = value;
          }
        }
      } else {
        // Create a new recipe
        recipe = {
          skill_level: recipeData.skill_level || SkillLevel.BEGINNER,
          special_preferences: recipeData.special_preferences || [],
          cooking_time: recipeData.cooking_time || CookingTime.FIFTEEN_MIN,
          ingredients: recipeData.ingredients || [],
          instructions: recipeData.instructions || []
        };
      }
      
      // Add tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Recipe generated.",
        tool_call_id: toolCall.id
      };
      
      const updatedMessages = [...messages, toolResponse];
      
      // Explicitly emit the updated state to ensure it's shared with frontend
      state.recipe = recipe;
      await dispatchCustomEvent("manually_emit_intermediate_state", state, config);
      
      // Return command with updated recipe
      return new Command({
        goto: "start_flow",
        update: {
          messages: updatedMessages,
          recipe: recipe
        }
      });
    }
  }

  return new Command({
    goto: END,
    update: {
      messages: messages,
      recipe: state.recipe
    }
  });
}

// Define the graph
const workflow = new StateGraph<AgentState>(AgentStateAnnotation);

// Add nodes
workflow.addNode("start_flow", startFlow);
workflow.addNode("chat_node", chatNode);

// Add edges
workflow.setEntryPoint("start_flow");
workflow.addEdge(START, "start_flow");
workflow.addEdge("start_flow", "chat_node");
workflow.addEdge("chat_node", END);

// Compile the graph
export const sharedStateGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/subgraphs/agent.ts
================================================
/**
 * A travel agent supervisor demo showcasing multi-agent architecture with subgraphs.
 * The supervisor coordinates specialized agents: flights finder, hotels finder, and experiences finder.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, AIMessage, ToolMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { 
  Annotation, 
  MessagesAnnotation, 
  StateGraph, 
  Command, 
  START, 
  END, 
  interrupt 
} from "@langchain/langgraph";

// Travel data interfaces
interface Flight {
  airline: string;
  departure: string;
  arrival: string;
  price: string;
  duration: string;
}

interface Hotel {
  name: string;
  location: string;
  price_per_night: string;
  rating: string;
}

interface Experience {
  name: string;
  type: "restaurant" | "activity";
  description: string;
  location: string;
}

interface Itinerary {
  flight?: Flight;
  hotel?: Hotel;
}

// Custom reducer to merge itinerary updates
function mergeItinerary(left: Itinerary | null, right?: Itinerary | null): Itinerary {
  if (!left) left = {};
  if (!right) right = {};
  return { ...left, ...right };
}

// State annotation for travel agent system
export const TravelAgentStateAnnotation = Annotation.Root({
  origin: Annotation<string>(),
  destination: Annotation<string>(),
  flights: Annotation<Flight[] | null>(),
  hotels: Annotation<Hotel[] | null>(),
  experiences: Annotation<Experience[] | null>(),

  // Itinerary with custom merger
  itinerary: Annotation<Itinerary | null>({
    reducer: mergeItinerary,
    default: () => null
  }),

  // Tools available to all agents
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),

  // Supervisor routing
  next_agent: Annotation<string | null>(),
  ...MessagesAnnotation.spec,
});

export type TravelAgentState = typeof TravelAgentStateAnnotation.State;

// Static data for demonstration
const STATIC_FLIGHTS: Flight[] = [
  { airline: "KLM", departure: "Amsterdam (AMS)", arrival: "San Francisco (SFO)", price: "$650", duration: "11h 30m" },
  { airline: "United", departure: "Amsterdam (AMS)", arrival: "San Francisco (SFO)", price: "$720", duration: "12h 15m" }
];

const STATIC_HOTELS: Hotel[] = [
  { name: "Hotel Zephyr", location: "Fisherman's Wharf", price_per_night: "$280/night", rating: "4.2 stars" },
  { name: "The Ritz-Carlton", location: "Nob Hill", price_per_night: "$550/night", rating: "4.8 stars" },
  { name: "Hotel Zoe", location: "Union Square", price_per_night: "$320/night", rating: "4.4 stars" }
];

const STATIC_EXPERIENCES: Experience[] = [
  { name: "Pier 39", type: "activity", description: "Iconic waterfront destination with shops and sea lions", location: "Fisherman's Wharf" },
  { name: "Golden Gate Bridge", type: "activity", description: "World-famous suspension bridge with stunning views", location: "Golden Gate" },
  { name: "Swan Oyster Depot", type: "restaurant", description: "Historic seafood counter serving fresh oysters", location: "Polk Street" },
  { name: "Tartine Bakery", type: "restaurant", description: "Artisanal bakery famous for bread and pastries", location: "Mission District" }
];

function createInterrupt(message: string, options: any[], recommendation: any, agent: string) {
  return interrupt({
    message,
    options,
    recommendation,
    agent,
  });
}

// Flights finder subgraph
async function flightsFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Simulate flight search with static data
  const flights = STATIC_FLIGHTS;

  const selectedFlight = state.itinerary?.flight;
  
  let flightChoice: Flight;
  const message = `Found ${flights.length} flight options from ${state.origin || 'Amsterdam'} to ${state.destination || 'San Francisco'}.\n` +
    `I recommend choosing the flight by ${flights[0].airline} since it's known to be on time and cheaper.`
  if (!selectedFlight) {
    const interruptResult = createInterrupt(
      message,
      flights,
      flights[0],
      "flights"
    );
    
    // Parse the interrupt result if it's a string
    flightChoice = typeof interruptResult === 'string' ? JSON.parse(interruptResult) : interruptResult;
  } else {
    flightChoice = selectedFlight;
  }

  return new Command({
    goto: END,
    update: {
      flights: flights,
      itinerary: {
        flight: flightChoice
      },
      // Return all "messages" that the agent was sending
      messages: [
        ...state.messages,
        new AIMessage({
          content: message,
        }),
        new AIMessage({
          content: `Flights Agent: Great. I'll book you the ${flightChoice.airline} flight from ${flightChoice.departure} to ${flightChoice.arrival}.`,
        }),
      ]
    }
  });
}

// Hotels finder subgraph
async function hotelsFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Simulate hotel search with static data
  const hotels = STATIC_HOTELS;
  const selectedHotel = state.itinerary?.hotel;
  
  let hotelChoice: Hotel;
  const message = `Found ${hotels.length} accommodation options in ${state.destination || 'San Francisco'}.\n
    I recommend choosing the ${hotels[2].name} since it strikes the balance between rating, price, and location.`
  if (!selectedHotel) {
    const interruptResult = createInterrupt(
      message,
      hotels,
      hotels[2],
      "hotels"
    );
    
    // Parse the interrupt result if it's a string
    hotelChoice = typeof interruptResult === 'string' ? JSON.parse(interruptResult) : interruptResult;
  } else {
    hotelChoice = selectedHotel;
  }

  return new Command({
    goto: END,
    update: {
      hotels: hotels,
      itinerary: {
        hotel: hotelChoice
      },
      // Return all "messages" that the agent was sending
      messages: [
        ...state.messages,
        new AIMessage({
          content: message,
        }),
        new AIMessage({
          content: `Hotels Agent: Excellent choice! You'll like ${hotelChoice.name}.`
        }),
      ]
    }
  });
}

// Experiences finder subgraph
async function experiencesFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Filter experiences (2 restaurants, 2 activities)
  const restaurants = STATIC_EXPERIENCES.filter(exp => exp.type === "restaurant").slice(0, 2);
  const activities = STATIC_EXPERIENCES.filter(exp => exp.type === "activity").slice(0, 2);
  const experiences = [...restaurants, ...activities];

  const model = new ChatOpenAI({ model: "gpt-4o" });

  if (!config) {
    config = { recursionLimit: 25 };
  }

  const itinerary = state.itinerary || {};

  const systemPrompt = `
    You are the experiences agent. Your job is to find restaurants and activities for the user.
    You already went ahead and found a bunch of experiences. All you have to do now, is to let the user know of your findings.
    
    Current status:
    - Origin: ${state.origin || 'Amsterdam'}
    - Destination: ${state.destination || 'San Francisco'}
    - Flight chosen: ${JSON.stringify(itinerary.flight) || 'None'}
    - Hotel chosen: ${JSON.stringify(itinerary.hotel) || 'None'}
    - Activities found: ${JSON.stringify(activities)}
    - Restaurants found: ${JSON.stringify(restaurants)}
    `;

  // Get experiences response
  const response = await model.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  return new Command({
    goto: END,
    update: {
      experiences: experiences,
      messages: [...state.messages, response]
    }
  });
}

// Supervisor response tool
const SUPERVISOR_RESPONSE_TOOL = {
  type: "function" as const,
  function: {
    name: "supervisor_response",
    description: "Always use this tool to structure your response to the user.",
    parameters: {
      type: "object",
      properties: {
        answer: {
          type: "string",
          description: "The answer to the user"
        },
        next_agent: {
          type: "string",
          enum: ["flights_agent", "hotels_agent", "experiences_agent", "complete"],
          description: "The agent to go to. Not required if you do not want to route to another agent."
        }
      },
      required: ["answer"]
    }
  }
};

// Supervisor agent
async function supervisorAgent(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  const itinerary = state.itinerary || {};

  // Check what's already completed
  const hasFlights = itinerary.flight !== undefined;
  const hasHotels = itinerary.hotel !== undefined;
  const hasExperiences = state.experiences !== null;

  const systemPrompt = `
    You are a travel planning supervisor. Your job is to coordinate specialized agents to help plan a trip.
    
    Current status:
    - Origin: ${state.origin || 'Amsterdam'}
    - Destination: ${state.destination || 'San Francisco'}
    - Flights found: ${hasFlights}
    - Hotels found: ${hasHotels}
    - Experiences found: ${hasExperiences}
    - Itinerary (Things that the user has already confirmed selection on): ${JSON.stringify(itinerary, null, 2)}
    
    Available agents:
    - flights_agent: Finds flight options
    - hotels_agent: Finds hotel options  
    - experiences_agent: Finds restaurant and activity recommendations
    - complete: Mark task as complete when all information is gathered
    
    You must route to the appropriate agent based on what's missing. Once all agents have completed their tasks, route to 'complete'.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });

  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Bind the routing tool
  const modelWithTools = model.bindTools(
    [SUPERVISOR_RESPONSE_TOOL],
    {
      parallel_tool_calls: false,
    }
  );

  // Get supervisor decision
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  let messages = [...state.messages, response];

  // Handle tool calls for routing
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    const toolCallArgs = toolCall.args;
    const nextAgent = toolCallArgs.next_agent;

    const toolResponse = new ToolMessage({
      tool_call_id: toolCall.id!,
      content: `Routing to ${nextAgent} and providing the answer`,
    });

    messages = [
      ...messages, 
      toolResponse, 
      new AIMessage({ content: toolCallArgs.answer })
    ];

    if (nextAgent && nextAgent !== "complete") {
      return new Command({ goto: nextAgent });
    }
  }

  // Fallback if no tool call or complete
  return new Command({
    goto: END,
    update: { messages }
  });
}

// Create subgraphs
const flightsGraph = new StateGraph(TravelAgentStateAnnotation);
flightsGraph.addNode("flights_agent_chat_node", flightsFinder);
flightsGraph.setEntryPoint("flights_agent_chat_node");
flightsGraph.addEdge(START, "flights_agent_chat_node");
flightsGraph.addEdge("flights_agent_chat_node", END);
const flightsSubgraph = flightsGraph.compile();

const hotelsGraph = new StateGraph(TravelAgentStateAnnotation);
hotelsGraph.addNode("hotels_agent_chat_node", hotelsFinder);
hotelsGraph.setEntryPoint("hotels_agent_chat_node");
hotelsGraph.addEdge(START, "hotels_agent_chat_node");
hotelsGraph.addEdge("hotels_agent_chat_node", END);
const hotelsSubgraph = hotelsGraph.compile();

const experiencesGraph = new StateGraph(TravelAgentStateAnnotation);
experiencesGraph.addNode("experiences_agent_chat_node", experiencesFinder);
experiencesGraph.setEntryPoint("experiences_agent_chat_node");
experiencesGraph.addEdge(START, "experiences_agent_chat_node");
experiencesGraph.addEdge("experiences_agent_chat_node", END);
const experiencesSubgraph = experiencesGraph.compile();

// Main supervisor workflow
const workflow = new StateGraph(TravelAgentStateAnnotation);

// Add supervisor and subgraphs as nodes
workflow.addNode("supervisor", supervisorAgent, { ends: ['flights_agent', 'hotels_agent', 'experiences_agent', END] });
workflow.addNode("flights_agent", flightsSubgraph);
workflow.addNode("hotels_agent", hotelsSubgraph);
workflow.addNode("experiences_agent", experiencesSubgraph);

// Set entry point
workflow.setEntryPoint("supervisor");
workflow.addEdge(START, "supervisor");

// Add edges back to supervisor after each subgraph
workflow.addEdge("flights_agent", "supervisor");
workflow.addEdge("hotels_agent", "supervisor");
workflow.addEdge("experiences_agent", "supervisor");

// Compile the graph
export const subGraphsAgentGraph = workflow.compile();



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/tool_based_generative_ui/agent.ts
================================================
/**
 * An example demonstrating tool-based generative UI using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";


export const AgentStateAnnotation = Annotation.Root({
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  const model = new ChatOpenAI({ model: "gpt-4o" });

  const modelWithTools = model.bindTools(
    [
      ...state.tools || []
    ],
    { parallel_tool_calls: false }
  );

  const systemMessage = new SystemMessage({
     content: 'Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user.'
  });

  const response = await modelWithTools.invoke([
    systemMessage,
    ...state.messages,
  ], config);

  return new Command({
    goto: END,
    update: {
      messages: [response]
    }
  });
}

const workflow = new StateGraph<AgentState>(AgentStateAnnotation);
workflow.addNode("chat_node", chatNode);

workflow.addEdge(START, "chat_node");

export const toolBasedGenerativeUiGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/python/README.md
================================================
# ag-ui-langgraph

Implementation of the AG-UI protocol for LangGraph.

Provides a complete Python integration for LangGraph agents with the AG-UI protocol, including FastAPI endpoint creation and comprehensive event streaming.

## Installation

```bash
pip install ag-ui-langgraph
```

## Usage

```python
from langgraph.graph import StateGraph, MessagesState
from langchain_openai import ChatOpenAI
from ag_ui_langgraph import LangGraphAgent, add_langgraph_fastapi_endpoint
from fastapi import FastAPI
from my_langgraph_workflow import graph

# Add to FastAPI
app = FastAPI()
add_langgraph_fastapi_endpoint(app, graph, "/agent")
```

## Features

- **Native LangGraph integration** – Direct support for LangGraph workflows and state management
- **FastAPI endpoint creation** – Automatic HTTP endpoint generation with proper event streaming
- **Advanced event handling** – Comprehensive support for all AG-UI events including thinking, tool calls, and state updates
- **Message translation** – Seamless conversion between AG-UI and LangChain message formats

## To run the dojo examples

```bash
cd python/ag_ui_langgraph/examples
poetry install
poetry run dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/python/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-langgraph"
version = "0.0.10"
description = "Implementation of the AG-UI protocol for LangGraph."
authors = ["Ran Shem Tov <ran@copilotkit.ai>"]
readme = "README.md"
exclude = [
    "ag_ui_langgraph/examples/**",
]

[tool.poetry.dependencies]
python = "<3.14,>=3.10"
ag-ui-protocol = "==0.1.7"
fastapi = { version = "^0.115.12", optional = true }
langchain = ">=0.3.0"
langchain-core = ">=0.3.0"
langgraph = ">=0.3.25,<0.7.0"

[tool.poetry.extras]
fastapi = ["fastapi"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "ag_ui_langgraph.dojo:main"


================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/__init__.py
================================================
from .agent import LangGraphAgent
from .types import (
    LangGraphEventTypes,
    CustomEventNames,
    State,
    SchemaKeys,
    MessageInProgress,
    RunMetadata,
    MessagesInProgressRecord,
    ToolCall,
    BaseLangGraphPlatformMessage,
    LangGraphPlatformResultMessage,
    LangGraphPlatformActionExecutionMessage,
    LangGraphPlatformMessage,
    PredictStateTool
)
from .endpoint import add_langgraph_fastapi_endpoint

__all__ = [
    "LangGraphAgent",
    "LangGraphEventTypes",
    "CustomEventNames",
    "State",
    "SchemaKeys",
    "MessageInProgress",
    "RunMetadata",
    "MessagesInProgressRecord",
    "ToolCall",
    "BaseLangGraphPlatformMessage",
    "LangGraphPlatformResultMessage",
    "LangGraphPlatformActionExecutionMessage",
    "LangGraphPlatformMessage",
    "PredictStateTool",
    "add_langgraph_fastapi_endpoint"
]



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/agent.py
================================================
import uuid
import json
from typing import Optional, List, Any, Union, AsyncGenerator, Generator
from dataclasses import is_dataclass, asdict
from datetime import date, datetime

from langgraph.graph.state import CompiledStateGraph
from langchain.schema import BaseMessage, SystemMessage
from langchain_core.runnables import RunnableConfig, ensure_config
from langchain_core.messages import HumanMessage
from langgraph.types import Command

from .types import (
    State,
    LangGraphPlatformMessage,
    MessagesInProgressRecord,
    SchemaKeys,
    MessageInProgress,
    RunMetadata,
    LangGraphEventTypes,
    CustomEventNames,
    LangGraphReasoning
)
from .utils import (
    agui_messages_to_langchain,
    DEFAULT_SCHEMA_KEYS,
    filter_object_by_schema_keys,
    get_stream_payload_input,
    langchain_messages_to_agui,
    resolve_reasoning_content,
    resolve_message_content,
    camel_to_snake
)

from ag_ui.core import (
    EventType,
    CustomEvent,
    MessagesSnapshotEvent,
    RawEvent,
    RunAgentInput,
    RunErrorEvent,
    RunFinishedEvent,
    RunStartedEvent,
    StateDeltaEvent,
    StateSnapshotEvent,
    StepFinishedEvent,
    StepStartedEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    ToolCallStartEvent,
    ThinkingTextMessageStartEvent,
    ThinkingTextMessageContentEvent,
    ThinkingTextMessageEndEvent,
    ThinkingStartEvent,
    ThinkingEndEvent,
)
from ag_ui.encoder import EventEncoder

ProcessedEvents = Union[
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
]

class LangGraphAgent:
    def __init__(self, *, name: str, graph: CompiledStateGraph, description: Optional[str] = None, config:  Union[Optional[RunnableConfig], dict] = None):
        self.name = name
        self.description = description
        self.graph = graph
        self.config = config or {}
        self.messages_in_process: MessagesInProgressRecord = {}
        self.active_run: Optional[RunMetadata] = None
        self.constant_schema_keys = ['messages', 'tools']
        self.active_step = None

    def _dispatch_event(self, event: ProcessedEvents) -> str:
        return event  # Fallback if no encoder

    async def run(self, input: RunAgentInput) -> AsyncGenerator[str, None]:
        forwarded_props = {}
        if hasattr(input, "forwarded_props") and input.forwarded_props:
            forwarded_props = {
                camel_to_snake(k): v for k, v in input.forwarded_props.items()
            }
        async for event_str in self._handle_stream_events(input.copy(update={"forwarded_props": forwarded_props})):
            yield event_str

    async def _handle_stream_events(self, input: RunAgentInput) -> AsyncGenerator[str, None]:
        thread_id = input.thread_id or str(uuid.uuid4())
        INITIAL_ACTIVE_RUN = {
            "id": input.run_id,
            "thread_id": thread_id,
            "thinking_process": None,
            "node_name": None,
        }
        self.active_run = INITIAL_ACTIVE_RUN

        forwarded_props = input.forwarded_props
        node_name_input = forwarded_props.get('node_name', None) if forwarded_props else None

        self.active_run["manually_emitted_state"] = None
        self.active_run["node_name"] = node_name_input
        if self.active_run["node_name"] == "__end__":
            self.active_run["node_name"] = None

        config = ensure_config(self.config.copy() if self.config else {})
        config["configurable"] = {**(config.get('configurable', {})), "thread_id": thread_id}

        agent_state = await self.graph.aget_state(config)
        resume_input = forwarded_props.get('command', {}).get('resume', None)

        if resume_input is None and thread_id and self.active_run.get("node_name") != "__end__" and self.active_run.get("node_name"):
            self.active_run["mode"] = "continue"
        else:
            self.active_run["mode"] = "start"

        prepared_stream_response = await self.prepare_stream(input=input, agent_state=agent_state, config=config)

        yield self._dispatch_event(
            RunStartedEvent(type=EventType.RUN_STARTED, thread_id=thread_id, run_id=self.active_run["id"])
        )

        # In case of resume (interrupt), re-start resumed step
        if resume_input and self.active_run.get("node_name"):
            for ev in self.start_step(self.active_run.get("node_name")):
                yield ev

        state = prepared_stream_response["state"]
        stream = prepared_stream_response["stream"]
        config = prepared_stream_response["config"]
        events_to_dispatch = prepared_stream_response.get('events_to_dispatch', None)

        if events_to_dispatch is not None and len(events_to_dispatch) > 0:
            for event in events_to_dispatch:
                yield self._dispatch_event(event)
            return

        should_exit = False
        current_graph_state = state
        
        async for event in stream:
            subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False
            is_subgraph_stream = (subgraphs_stream_enabled and (
                event.get("event", "").startswith("events") or 
                event.get("event", "").startswith("values")
            ))
            if event["event"] == "error":
                yield self._dispatch_event(
                    RunErrorEvent(type=EventType.RUN_ERROR, message=event["data"]["message"], raw_event=event)
                )
                break

            current_node_name = event.get("metadata", {}).get("langgraph_node")
            event_type = event.get("event")
            self.active_run["id"] = event.get("run_id")
            exiting_node = False

            if event_type == "on_chain_end" and isinstance(
                    event.get("data", {}).get("output"), dict
            ):
                current_graph_state.update(event["data"]["output"])
                exiting_node = self.active_run["node_name"] == current_node_name

            should_exit = should_exit or (
                    event_type == "on_custom_event" and
                    event["name"] == "exit"
                )

            if current_node_name and current_node_name != self.active_run.get("node_name"):
                for ev in self.start_step(current_node_name):
                    yield ev

            updated_state = self.active_run.get("manually_emitted_state") or current_graph_state
            has_state_diff = updated_state != state
            if exiting_node or (has_state_diff and not self.get_message_in_progress(self.active_run["id"])):
                state = updated_state
                self.active_run["prev_node_name"] = self.active_run["node_name"]
                current_graph_state.update(updated_state)
                yield self._dispatch_event(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=self.get_state_snapshot(state),
                        raw_event=event,
                    )
                )

            yield self._dispatch_event(
                RawEvent(type=EventType.RAW, event=event)
            )

            async for single_event in self._handle_single_event(event, state):
                yield single_event

        state = await self.graph.aget_state(config)

        tasks = state.tasks if len(state.tasks) > 0 else None
        interrupts = tasks[0].interrupts if tasks else []

        writes = state.metadata.get("writes", {}) or {}
        node_name = self.active_run["node_name"] if interrupts else next(iter(writes), None)
        next_nodes = state.next or ()
        is_end_node = len(next_nodes) == 0 and not interrupts

        node_name = "__end__" if is_end_node else node_name

        for interrupt in interrupts:
            yield self._dispatch_event(
                CustomEvent(
                    type=EventType.CUSTOM,
                    name=LangGraphEventTypes.OnInterrupt.value,
                    value=json.dumps(interrupt.value, default=make_json_safe) if not isinstance(interrupt.value, str) else interrupt.value,
                    raw_event=interrupt,
                )
            )

        if self.active_run.get("node_name") != node_name:
            for ev in self.start_step(node_name):
                yield ev

        state_values = state.values if state.values else state
        yield self._dispatch_event(
            StateSnapshotEvent(type=EventType.STATE_SNAPSHOT, snapshot=self.get_state_snapshot(state_values))
        )

        yield self._dispatch_event(
            MessagesSnapshotEvent(
                type=EventType.MESSAGES_SNAPSHOT,
                messages=langchain_messages_to_agui(state_values.get("messages", [])),
            )
        )

        yield self.end_step()

        yield self._dispatch_event(
            RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id=thread_id, run_id=self.active_run["id"])
        )
        # Reset active run to how it was before the stream started
        self.active_run = INITIAL_ACTIVE_RUN


    async def prepare_stream(self, input: RunAgentInput, agent_state: State, config: RunnableConfig):
        state_input = input.state or {}
        messages = input.messages or []
        tools = input.tools or []
        forwarded_props = input.forwarded_props or {}
        thread_id = input.thread_id

        state_input["messages"] = agent_state.values.get("messages", [])
        self.active_run["current_graph_state"] = agent_state.values.copy()
        langchain_messages = agui_messages_to_langchain(messages)
        state = self.langgraph_default_merge_state(state_input, langchain_messages, tools)
        self.active_run["current_graph_state"].update(state)
        config["configurable"]["thread_id"] = thread_id
        interrupts = agent_state.tasks[0].interrupts if agent_state.tasks and len(agent_state.tasks) > 0 else []
        has_active_interrupts = len(interrupts) > 0
        resume_input = forwarded_props.get('command', {}).get('resume', None)

        self.active_run["schema_keys"] = self.get_schema_keys(config)

        non_system_messages = [msg for msg in langchain_messages if not isinstance(msg, SystemMessage)]
        if len(agent_state.values.get("messages", [])) > len(non_system_messages):
            # Find the last user message by working backwards from the last message
            last_user_message = None
            for i in range(len(langchain_messages) - 1, -1, -1):
                if isinstance(langchain_messages[i], HumanMessage):
                    last_user_message = langchain_messages[i]
                    break

            if last_user_message:
                return await self.prepare_regenerate_stream(
                    input=input,
                    message_checkpoint=last_user_message,
                    config=config
                )

        events_to_dispatch = []
        if has_active_interrupts and not resume_input:
            events_to_dispatch.append(
                RunStartedEvent(type=EventType.RUN_STARTED, thread_id=thread_id, run_id=self.active_run["id"])
            )

            for interrupt in interrupts:
                events_to_dispatch.append(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name=LangGraphEventTypes.OnInterrupt.value,
                        value=json.dumps(interrupt.value) if not isinstance(interrupt.value, str) else interrupt.value,
                        raw_event=interrupt,
                    )
                )

            events_to_dispatch.append(
                RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id=thread_id, run_id=self.active_run["id"])
            )
            return {
                "stream": None,
                "state": None,
                "config": None,
                "events_to_dispatch": events_to_dispatch,
            }

        if self.active_run["mode"] == "continue":
            await self.graph.aupdate_state(config, state, as_node=self.active_run.get("node_name"))

        if resume_input:
            stream_input = Command(resume=resume_input)
        else:
            payload_input = get_stream_payload_input(
                mode=self.active_run["mode"],
                state=state,
                schema_keys=self.active_run["schema_keys"],
            )
            stream_input = {**forwarded_props, **payload_input} if payload_input else None


        subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False

        stream = self.graph.astream_events(
            stream_input,
            config=config,
            subgraps=bool(subgraphs_stream_enabled),
            version="v2"
        )

        return {
            "stream": stream,
            "state": state,
            "config": config
        }

    async def prepare_regenerate_stream( # pylint: disable=too-many-arguments
            self,
            input: RunAgentInput,
            message_checkpoint: HumanMessage,
            config: RunnableConfig
    ):
        tools = input.tools or []
        thread_id = input.thread_id

        time_travel_checkpoint = await self.get_checkpoint_before_message(message_checkpoint.id, thread_id)
        if time_travel_checkpoint is None:
            return None

        fork = await self.graph.aupdate_state(
            time_travel_checkpoint.config,
            time_travel_checkpoint.values,
            as_node=time_travel_checkpoint.next[0] if time_travel_checkpoint.next else "__start__"
        )

        stream_input = self.langgraph_default_merge_state(time_travel_checkpoint.values, [message_checkpoint], tools)
        subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False
        stream = self.graph.astream_events(
            stream_input,
            fork,
            subgraps=bool(subgraphs_stream_enabled),
            version="v2"
        )

        return {
            "stream": stream,
            "state": time_travel_checkpoint.values,
            "config": config
        }

    def get_message_in_progress(self, run_id: str) -> Optional[MessageInProgress]:
        return self.messages_in_process.get(run_id)

    def set_message_in_progress(self, run_id: str, data: MessageInProgress):
        current_message_in_progress = self.messages_in_process.get(run_id, {})
        self.messages_in_process[run_id] = {
            **current_message_in_progress,
            **data,
        }

    def get_schema_keys(self, config) -> SchemaKeys:
        try:
            input_schema = self.graph.get_input_jsonschema(config)
            output_schema = self.graph.get_output_jsonschema(config)
            config_schema = self.graph.config_schema().schema()

            input_schema_keys = list(input_schema["properties"].keys()) if "properties" in input_schema else []
            output_schema_keys = list(output_schema["properties"].keys()) if "properties" in output_schema else []
            config_schema_keys = list(config_schema["properties"].keys()) if "properties" in config_schema else []

            return {
                "input": [*input_schema_keys, *self.constant_schema_keys],
                "output": [*output_schema_keys, *self.constant_schema_keys],
                "config": config_schema_keys,
            }
        except Exception:
            return {
                "input": self.constant_schema_keys,
                "output": self.constant_schema_keys,
                "config": [],
            }

    def langgraph_default_merge_state(self, state: State, messages: List[BaseMessage], tools: Any) -> State:
        if messages and isinstance(messages[0], SystemMessage):
            messages = messages[1:]

        existing_messages: List[LangGraphPlatformMessage] = state.get("messages", [])
        existing_message_ids = {msg.id for msg in existing_messages}

        new_messages = [msg for msg in messages if msg.id not in existing_message_ids]

        tools_as_dicts = []
        if tools:
            for tool in tools:
                if hasattr(tool, "model_dump"):
                    tools_as_dicts.append(tool.model_dump())
                elif hasattr(tool, "dict"):
                    tools_as_dicts.append(tool.dict())
                else:
                    tools_as_dicts.append(tool)

        return {
            **state,
            "messages": new_messages,
            "tools": [*state.get("tools", []), *tools_as_dicts],
        }

    def get_state_snapshot(self, state: State) -> State:
        schema_keys = self.active_run["schema_keys"]
        if schema_keys and schema_keys.get("output"):
            state = filter_object_by_schema_keys(state, [*DEFAULT_SCHEMA_KEYS, *schema_keys["output"]])
        return state

    async def _handle_single_event(self, event: Any, state: State) -> AsyncGenerator[str, None]:
        event_type = event.get("event")
        if event_type == LangGraphEventTypes.OnChatModelStream:
            should_emit_messages = event["metadata"].get("emit-messages", True)
            should_emit_tool_calls = event["metadata"].get("emit-tool-calls", True)

            if event["data"]["chunk"].response_metadata.get('finish_reason', None):
                return

            current_stream = self.get_message_in_progress(self.active_run["id"])
            has_current_stream = bool(current_stream and current_stream.get("id"))
            tool_call_data = event["data"]["chunk"].tool_call_chunks[0] if event["data"]["chunk"].tool_call_chunks else None
            predict_state_metadata = event["metadata"].get("predict_state", [])
            tool_call_used_to_predict_state = False
            if tool_call_data and tool_call_data.get("name") and predict_state_metadata:
                tool_call_used_to_predict_state = any(
                    predict_tool.get("tool") == tool_call_data["name"]
                    for predict_tool in predict_state_metadata
                )

            is_tool_call_start_event = not has_current_stream and tool_call_data and tool_call_data.get("name")
            is_tool_call_args_event = has_current_stream and current_stream.get("tool_call_id") and tool_call_data and tool_call_data.get("args")
            is_tool_call_end_event = has_current_stream and current_stream.get("tool_call_id") and not tool_call_data

            reasoning_data = resolve_reasoning_content(event["data"]["chunk"]) if event["data"]["chunk"] else None
            message_content = resolve_message_content(event["data"]["chunk"].content) if event["data"]["chunk"] and event["data"]["chunk"].content else None
            is_message_content_event = tool_call_data is None and message_content
            is_message_end_event = has_current_stream and not current_stream.get("tool_call_id") and not is_message_content_event

            if reasoning_data:
                self.handle_thinking_event(reasoning_data)
                return

            if reasoning_data is None and self.active_run.get('thinking_process', None) is not None:
                yield self._dispatch_event(
                    ThinkingTextMessageEndEvent(
                        type=EventType.THINKING_TEXT_MESSAGE_END,
                    )
                )
                yield self._dispatch_event(
                    ThinkingEndEvent(
                        type=EventType.THINKING_END,
                    )
                )
                self.active_run["thinking_process"] = None

            if tool_call_used_to_predict_state:
                yield self._dispatch_event(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name="PredictState",
                        value=predict_state_metadata,
                        raw_event=event
                    )
                )

            if is_tool_call_end_event:
                yield self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=current_stream["tool_call_id"], raw_event=event)
                )
                self.messages_in_process[self.active_run["id"]] = None
                return


            if is_message_end_event:
                yield self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=current_stream["id"], raw_event=event)
                )
                self.messages_in_process[self.active_run["id"]] = None
                return

            if is_tool_call_start_event and should_emit_tool_calls:
                yield self._dispatch_event(
                    ToolCallStartEvent(
                        type=EventType.TOOL_CALL_START,
                        tool_call_id=tool_call_data["id"],
                        tool_call_name=tool_call_data["name"],
                        parent_message_id=event["data"]["chunk"].id,
                        raw_event=event,
                    )
                )
                self.set_message_in_progress(
                    self.active_run["id"],
                    MessageInProgress(id=event["data"]["chunk"].id, tool_call_id=tool_call_data["id"], tool_call_name=tool_call_data["name"])
                )
                return

            if is_tool_call_args_event and should_emit_tool_calls:
                yield self._dispatch_event(
                    ToolCallArgsEvent(
                        type=EventType.TOOL_CALL_ARGS,
                        tool_call_id=current_stream["tool_call_id"],
                        delta=tool_call_data["args"],
                        raw_event=event
                    )
                )
                return

            if is_message_content_event and should_emit_messages:
                if bool(current_stream and current_stream.get("id")) == False:
                    yield self._dispatch_event(
                        TextMessageStartEvent(
                            type=EventType.TEXT_MESSAGE_START,
                            role="assistant",
                            message_id=event["data"]["chunk"].id,
                            raw_event=event,
                        )
                    )
                    self.set_message_in_progress(
                        self.active_run["id"],
                        MessageInProgress(
                            id=event["data"]["chunk"].id,
                            tool_call_id=None,
                            tool_call_name=None
                        )
                    )
                    current_stream = self.get_message_in_progress(self.active_run["id"])

                yield self._dispatch_event(
                    TextMessageContentEvent(
                        type=EventType.TEXT_MESSAGE_CONTENT,
                        message_id=current_stream["id"],
                        delta=message_content,
                        raw_event=event,
                    )
                )
                return

        elif event_type == LangGraphEventTypes.OnChatModelEnd:
            if self.get_message_in_progress(self.active_run["id"]) and self.get_message_in_progress(self.active_run["id"]).get("tool_call_id"):
                resolved = self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=self.get_message_in_progress(self.active_run["id"])["tool_call_id"], raw_event=event)
                )
                if resolved:
                    self.messages_in_process[self.active_run["id"]] = None
                yield resolved
            elif self.get_message_in_progress(self.active_run["id"]) and self.get_message_in_progress(self.active_run["id"]).get("id"):
                resolved = self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=self.get_message_in_progress(self.active_run["id"])["id"], raw_event=event)
                )
                if resolved:
                    self.messages_in_process[self.active_run["id"]] = None
                yield resolved

        elif event_type == LangGraphEventTypes.OnCustomEvent:
            if event["name"] == CustomEventNames.ManuallyEmitMessage:
                yield self._dispatch_event(
                    TextMessageStartEvent(type=EventType.TEXT_MESSAGE_START, role="assistant", message_id=event["data"]["message_id"], raw_event=event)
                )
                yield self._dispatch_event(
                    TextMessageContentEvent(
                        type=EventType.TEXT_MESSAGE_CONTENT,
                        message_id=event["data"]["message_id"],
                        delta=event["data"]["message"],
                        raw_event=event,
                    )
                )
                yield self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=event["data"]["message_id"], raw_event=event)
                )

            elif event["name"] == CustomEventNames.ManuallyEmitToolCall:
                yield self._dispatch_event(
                    ToolCallStartEvent(
                        type=EventType.TOOL_CALL_START,
                        tool_call_id=event["data"]["id"],
                        tool_call_name=event["data"]["name"],
                        parent_message_id=event["data"]["id"],
                        raw_event=event,
                    )
                )
                yield self._dispatch_event(
                    ToolCallArgsEvent(type=EventType.TOOL_CALL_ARGS, tool_call_id=event["data"]["id"], delta=event["data"]["args"], raw_event=event)
                )
                yield self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=event["data"]["id"], raw_event=event)
                )

            elif event["name"] == CustomEventNames.ManuallyEmitState:
                self.active_run["manually_emitted_state"] = event["data"]
                yield self._dispatch_event(
                    StateSnapshotEvent(type=EventType.STATE_SNAPSHOT, snapshot=self.get_state_snapshot(self.active_run["manually_emitted_state"]), raw_event=event)
                )
            
            yield self._dispatch_event(
                CustomEvent(type=EventType.CUSTOM, name=event["name"], value=event["data"], raw_event=event)
            )

    def handle_thinking_event(self, reasoning_data: LangGraphReasoning) -> Generator[str, Any, str | None]:
        if not reasoning_data or "type" not in reasoning_data or "text" not in reasoning_data:
            return ""

        thinking_step_index = reasoning_data.get("index")

        if (self.active_run.get("thinking_process") and
                self.active_run["thinking_process"].get("index") and
                self.active_run["thinking_process"]["index"] != thinking_step_index):

            if self.active_run["thinking_process"].get("type"):
                yield self._dispatch_event(
                    ThinkingTextMessageEndEvent(
                        type=EventType.THINKING_TEXT_MESSAGE_END,
                    )
                )
            yield self._dispatch_event(
                ThinkingEndEvent(
                    type=EventType.THINKING_END,
                )
            )
            self.active_run["thinking_process"] = None

        if not self.active_run.get("thinking_process"):
            yield self._dispatch_event(
                ThinkingStartEvent(
                    type=EventType.THINKING_START,
                )
            )
            self.active_run["thinking_process"] = {
                "index": thinking_step_index
            }

        if self.active_run["thinking_process"].get("type") != reasoning_data["type"]:
            yield self._dispatch_event(
                ThinkingTextMessageStartEvent(
                    type=EventType.THINKING_TEXT_MESSAGE_START,
                )
            )
            self.active_run["thinking_process"]["type"] = reasoning_data["type"]

        if self.active_run["thinking_process"].get("type"):
            yield self._dispatch_event(
                ThinkingTextMessageContentEvent(
                    type=EventType.THINKING_TEXT_MESSAGE_CONTENT,
                    delta=reasoning_data["text"]
                )
            )

    async def get_checkpoint_before_message(self, message_id: str, thread_id: str):
        if not thread_id:
            raise ValueError("Missing thread_id in config")

        history_list = []
        async for snapshot in self.graph.aget_state_history({"configurable": {"thread_id": thread_id}}):
            history_list.append(snapshot)

        history_list.reverse()
        for idx, snapshot in enumerate(history_list):
            messages = snapshot.values.get("messages", [])
            if any(getattr(m, "id", None) == message_id for m in messages):
                if idx == 0:
                    # No snapshot before this
                    # Return synthetic "empty before" version
                    empty_snapshot = snapshot
                    empty_snapshot.values["messages"] = []
                    return empty_snapshot

                snapshot_values_without_messages = snapshot.values.copy()
                del snapshot_values_without_messages["messages"]
                checkpoint = history_list[idx - 1]

                merged_values = {**checkpoint.values, **snapshot_values_without_messages}
                checkpoint = checkpoint._replace(values=merged_values)

                return checkpoint

        raise ValueError("Message ID not found in history")

    def start_step(self, step_name: str):
        if self.active_step:
            yield self.end_step()

        yield self._dispatch_event(
            StepStartedEvent(
                type=EventType.STEP_STARTED,
                step_name=step_name
            )
        )
        self.active_run["node_name"] = step_name
        self.active_step = step_name

    def end_step(self):
        if self.active_step is None:
            raise ValueError("No active step to end")

        dispatch = self._dispatch_event(
            StepFinishedEvent(
                type=EventType.STEP_FINISHED,
                step_name=self.active_run["node_name"] or self.active_step
            )
        )

        self.active_run["node_name"] = None
        self.active_step = None
        return dispatch

def make_json_safe(o):
    if is_dataclass(o):          # dataclasses like Flight(...)
        return asdict(o)
    if hasattr(o, "model_dump"): # pydantic v2
        return o.model_dump()
    if hasattr(o, "dict"):       # pydantic v1
        return o.dict()
    if hasattr(o, "__dict__"):   # plain objects
        return vars(o)
    if isinstance(o, (datetime, date)):
        return o.isoformat()
    return str(o)                # last resort



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/endpoint.py
================================================
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse

from ag_ui.core.types import RunAgentInput
from ag_ui.encoder import EventEncoder

from .agent import LangGraphAgent

def add_langgraph_fastapi_endpoint(app: FastAPI, agent: LangGraphAgent, path: str = "/"):
    """Adds an endpoint to the FastAPI app."""

    @app.post(path)
    async def langgraph_agent_endpoint(input_data: RunAgentInput, request: Request):
        # Get the accept header from the request
        accept_header = request.headers.get("accept")

        # Create an event encoder to properly format SSE events
        encoder = EventEncoder(accept=accept_header)

        async def event_generator():
            async for event in agent.run(input_data):
                yield encoder.encode(event)

        return StreamingResponse(
            event_generator(),
            media_type=encoder.get_content_type()
        )

    @app.get(f"{path}/health")
    def health():
        """Health check."""
        return {
            "status": "ok",
            "agent": {
                "name": agent.name,
            }
        }


================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/types.py
================================================
from typing import TypedDict, Optional, List, Any, Dict, Union, Literal
from typing_extensions import NotRequired
from enum import Enum

class LangGraphEventTypes(str, Enum):
    OnChainStart = "on_chain_start"
    OnChainStream = "on_chain_stream"
    OnChainEnd = "on_chain_end"
    OnChatModelStart = "on_chat_model_start"
    OnChatModelStream = "on_chat_model_stream"
    OnChatModelEnd = "on_chat_model_end"
    OnToolStart = "on_tool_start"
    OnToolEnd = "on_tool_end"
    OnCustomEvent = "on_custom_event"
    OnInterrupt = "on_interrupt"

class CustomEventNames(str, Enum):
    ManuallyEmitMessage = "manually_emit_message"
    ManuallyEmitToolCall = "manually_emit_tool_call"
    ManuallyEmitState = "manually_emit_state"
    Exit = "exit"

State = Dict[str, Any]

SchemaKeys = TypedDict("SchemaKeys", {
    "input": NotRequired[Optional[List[str]]],
    "output": NotRequired[Optional[List[str]]],
    "config": NotRequired[Optional[List[str]]]
})

ThinkingProcess = TypedDict("ThinkingProcess", {
    "index": int,
    "type": NotRequired[Optional[Literal['text']]],
})

MessageInProgress = TypedDict("MessageInProgress", {
    "id": str,
    "tool_call_id": NotRequired[Optional[str]],
    "tool_call_name": NotRequired[Optional[str]]
})

RunMetadata = TypedDict("RunMetadata", {
    "id": str,
    "schema_keys": NotRequired[Optional[SchemaKeys]],
    "node_name": NotRequired[Optional[str]],
    "prev_node_name": NotRequired[Optional[str]],
    "exiting_node": NotRequired[bool],
    "manually_emitted_state": NotRequired[Optional[State]],
    "thread_id": NotRequired[Optional[ThinkingProcess]],
    "thinking_process": NotRequired[Optional[str]]
})

MessagesInProgressRecord = Dict[str, Optional[MessageInProgress]]

ToolCall = TypedDict("ToolCall", {
    "id": str,
    "name": str,
    "args": Dict[str, Any]
})

class BaseLangGraphPlatformMessage(TypedDict):
    content: str
    role: str
    additional_kwargs: NotRequired[Dict[str, Any]]
    type: str
    id: str

class LangGraphPlatformResultMessage(BaseLangGraphPlatformMessage):
    tool_call_id: str
    name: str

class LangGraphPlatformActionExecutionMessage(BaseLangGraphPlatformMessage):
    tool_calls: List[ToolCall]

LangGraphPlatformMessage = Union[
    LangGraphPlatformActionExecutionMessage,
    LangGraphPlatformResultMessage,
    BaseLangGraphPlatformMessage,
]

PredictStateTool = TypedDict("PredictStateTool", {
    "tool": str,
    "state_key": str,
    "tool_argument": str
})

LangGraphReasoning = TypedDict("LangGraphReasoning", {
    "type": str,
    "text": str,
    "index": int
})



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/utils.py
================================================
import json
import re
from typing import List, Any, Dict, Union

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from ag_ui.core import (
    Message as AGUIMessage,
    UserMessage as AGUIUserMessage,
    AssistantMessage as AGUIAssistantMessage,
    SystemMessage as AGUISystemMessage,
    ToolMessage as AGUIToolMessage,
    ToolCall as AGUIToolCall,
    FunctionCall as AGUIFunctionCall,
)
from .types import State, SchemaKeys, LangGraphReasoning

DEFAULT_SCHEMA_KEYS = ["tools"]

def filter_object_by_schema_keys(obj: Dict[str, Any], schema_keys: List[str]) -> Dict[str, Any]:
    if not obj:
        return {}
    return {k: v for k, v in obj.items() if k in schema_keys}

def get_stream_payload_input(
    *,
    mode: str,
    state: State,
    schema_keys: SchemaKeys,
) -> Union[State, None]:
    input_payload = state if mode == "start" else None
    if input_payload and schema_keys and schema_keys.get("input"):
        input_payload = filter_object_by_schema_keys(input_payload, [*DEFAULT_SCHEMA_KEYS, *schema_keys["input"]])
    return input_payload

def stringify_if_needed(item: Any) -> str:
    if item is None:
        return ''
    if isinstance(item, str):
        return item
    return json.dumps(item)

def langchain_messages_to_agui(messages: List[BaseMessage]) -> List[AGUIMessage]:
    agui_messages: List[AGUIMessage] = []
    for message in messages:
        if isinstance(message, HumanMessage):
            agui_messages.append(AGUIUserMessage(
                id=str(message.id),
                role="user",
                content=stringify_if_needed(resolve_message_content(message.content)),
                name=message.name,
            ))
        elif isinstance(message, AIMessage):
            tool_calls = None
            if message.tool_calls:
                tool_calls = [
                    AGUIToolCall(
                        id=str(tc["id"]),
                        type="function",
                        function=AGUIFunctionCall(
                            name=tc["name"],
                            arguments=json.dumps(tc.get("args", {})),
                        ),
                    )
                    for tc in message.tool_calls
                ]

            agui_messages.append(AGUIAssistantMessage(
                id=str(message.id),
                role="assistant",
                content=stringify_if_needed(resolve_message_content(message.content)),
                tool_calls=tool_calls,
                name=message.name,
            ))
        elif isinstance(message, SystemMessage):
            agui_messages.append(AGUISystemMessage(
                id=str(message.id),
                role="system",
                content=stringify_if_needed(resolve_message_content(message.content)),
                name=message.name,
            ))
        elif isinstance(message, ToolMessage):
            agui_messages.append(AGUIToolMessage(
                id=str(message.id),
                role="tool",
                content=stringify_if_needed(resolve_message_content(message.content)),
                tool_call_id=message.tool_call_id,
            ))
        else:
            raise TypeError(f"Unsupported message type: {type(message)}")
    return agui_messages

def agui_messages_to_langchain(messages: List[AGUIMessage]) -> List[BaseMessage]:
    langchain_messages = []
    for message in messages:
        role = message.role
        if role == "user":
            langchain_messages.append(HumanMessage(
                id=message.id,
                content=message.content,
                name=message.name,
            ))
        elif role == "assistant":
            tool_calls = []
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tc in message.tool_calls:
                    tool_calls.append({
                        "id": tc.id,
                        "name": tc.function.name,
                        "args": json.loads(tc.function.arguments) if hasattr(tc, "function") and tc.function.arguments else {},
                        "type": "tool_call",
                    })
            langchain_messages.append(AIMessage(
                id=message.id,
                content=message.content or "",
                tool_calls=tool_calls,
                name=message.name,
            ))
        elif role == "system":
            langchain_messages.append(SystemMessage(
                id=message.id,
                content=message.content,
                name=message.name,
            ))
        elif role == "tool":
            langchain_messages.append(ToolMessage(
                id=message.id,
                content=message.content,
                tool_call_id=message.tool_call_id,
            ))
        else:
            raise ValueError(f"Unsupported message role: {role}")
    return langchain_messages

def resolve_reasoning_content(chunk: Any) -> LangGraphReasoning | None:
    content = chunk.content
    if not content:
        return None

    # Anthropic reasoning response
    if isinstance(content, list) and content and content[0]:
        if not content[0].get("thinking"):
            return None
        return LangGraphReasoning(
            text=content[0]["thinking"],
            type="text",
            index=content[0].get("index", 0)
        )

    # OpenAI reasoning response
    if hasattr(chunk, "additional_kwargs"):
        reasoning = chunk.additional_kwargs.get("reasoning", {})
        summary = reasoning.get("summary", [])
        if summary:
            data = summary[0]
            if not data or not data.get("text"):
                return None
            return LangGraphReasoning(
                type="text",
                text=data["text"],
                index=data.get("index", 0)
            )

    return None

def resolve_message_content(content: Any) -> str | None:
    if not content:
        return None

    if isinstance(content, str):
        return content

    if isinstance(content, list) and content:
        content_text = next((c.get("text") for c in content if isinstance(c, dict) and c.get("type") == "text"), None)
        return content_text

    return None

def camel_to_snake(name):
    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()



================================================
FILE: typescript-sdk/integrations/langgraph/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/src/agent.ts
================================================
import { Observable, Subscriber } from "rxjs";
import {
  Client as LangGraphClient,
  EventsStreamEvent,
  StreamMode,
  Config as LangGraphConfig,
  ThreadState,
  Assistant,
  Message as LangGraphMessage,
  Config,
  Interrupt,
  Thread,
} from "@langchain/langgraph-sdk";
import { randomUUID } from "node:crypto";
import {
  LangGraphPlatformMessage,
  CustomEventNames,
  LangGraphEventTypes,
  State,
  MessagesInProgressRecord,
  ThinkingInProgress,
  SchemaKeys,
  MessageInProgress,
  RunMetadata,
  PredictStateTool,
  LangGraphReasoning,
} from "./types";
import {
  AbstractAgent,
  AgentConfig,
  CustomEvent,
  EventType,
  MessagesSnapshotEvent,
  RawEvent,
  RunAgentInput,
  RunErrorEvent,
  RunFinishedEvent,
  RunStartedEvent,
  StateDeltaEvent,
  StateSnapshotEvent,
  StepFinishedEvent,
  StepStartedEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
  ThinkingTextMessageStartEvent,
  ThinkingTextMessageContentEvent,
  ThinkingTextMessageEndEvent,
  ThinkingStartEvent,
  ThinkingEndEvent,
  Message as AGUIMessage,
} from "@ag-ui/client";
import { RunsStreamPayload } from "@langchain/langgraph-sdk/dist/types";
import {
  aguiMessagesToLangChain,
  DEFAULT_SCHEMA_KEYS,
  filterObjectBySchemaKeys,
  getStreamPayloadInput,
  langchainMessagesToAgui,
  resolveMessageContent,
  resolveReasoningContent,
} from "@/utils";

export type ProcessedEvents =
  | TextMessageStartEvent
  | TextMessageContentEvent
  | TextMessageEndEvent
  | ThinkingTextMessageStartEvent
  | ThinkingTextMessageContentEvent
  | ThinkingTextMessageEndEvent
  | ToolCallStartEvent
  | ToolCallArgsEvent
  | ToolCallEndEvent
  | ThinkingStartEvent
  | ThinkingEndEvent
  | StateSnapshotEvent
  | StateDeltaEvent
  | MessagesSnapshotEvent
  | RawEvent
  | CustomEvent
  | RunStartedEvent
  | RunFinishedEvent
  | RunErrorEvent
  | StepStartedEvent
  | StepFinishedEvent;

type RunAgentExtendedInput<
  TStreamMode extends StreamMode | StreamMode[] = StreamMode,
  TSubgraphs extends boolean = false,
> = Omit<RunAgentInput, "forwardedProps"> & {
  forwardedProps?: Omit<RunsStreamPayload<TStreamMode, TSubgraphs>, "input"> & {
    nodeName?: string;
    threadMetadata?: Record<string, any>;
  };
};

interface RegenerateInput extends RunAgentExtendedInput {
  messageCheckpoint: LangGraphMessage;
}

export interface LangGraphAgentConfig extends AgentConfig {
  client?: LangGraphClient;
  deploymentUrl: string;
  langsmithApiKey?: string;
  propertyHeaders?: Record<string, string>;
  assistantConfig?: LangGraphConfig;
  agentName?: string;
  graphId: string;
}

export class LangGraphAgent extends AbstractAgent {
  client: LangGraphClient;
  assistantConfig?: LangGraphConfig;
  agentName?: string;
  graphId: string;
  assistant?: Assistant;
  messagesInProcess: MessagesInProgressRecord;
  thinkingProcess: null | ThinkingInProgress;
  activeRun?: RunMetadata;
  // @ts-expect-error no need to initialize subscriber right now
  subscriber: Subscriber<ProcessedEvents>;
  constantSchemaKeys: string[] = DEFAULT_SCHEMA_KEYS;
  activeStep?: string;
  config: LangGraphAgentConfig;

  constructor(config: LangGraphAgentConfig) {
    super(config);
    this.config = config;
    this.messagesInProcess = {};
    this.agentName = config.agentName;
    this.graphId = config.graphId;
    this.assistantConfig = config.assistantConfig;
    this.thinkingProcess = null;
    this.client =
      config?.client ??
      new LangGraphClient({
        apiUrl: config.deploymentUrl,
        apiKey: config.langsmithApiKey,
        defaultHeaders: { ...(config.propertyHeaders ?? {}) },
      });
  }

  public clone() {
    return new LangGraphAgent(this.config);
  }

  dispatchEvent(event: ProcessedEvents) {
    this.subscriber.next(event);
    return true;
  }

  run(input: RunAgentInput) {
    return new Observable<ProcessedEvents>((subscriber) => {
      this.runAgentStream(input, subscriber);
      return () => {};
    });
  }

  async runAgentStream(input: RunAgentExtendedInput, subscriber: Subscriber<ProcessedEvents>) {
    this.activeRun = {
      id: input.runId,
      threadId: input.threadId,
    };
    this.subscriber = subscriber;
    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }
    const threadId = input.threadId ?? randomUUID();
    const streamMode =
      input.forwardedProps?.streamMode ?? (["events", "values", "updates"] satisfies StreamMode[]);
    const preparedStream = await this.prepareStream({ ...input, threadId }, streamMode);

    if (!preparedStream) {
      return subscriber.error("No stream to regenerate");
    }

    await this.handleStreamEvents(preparedStream, threadId, subscriber, input, streamMode);
  }

  async prepareRegenerateStream(input: RegenerateInput, streamMode: StreamMode | StreamMode[]) {
    const { threadId, messageCheckpoint, tools } = input;

    const timeTravelCheckpoint = await this.getCheckpointByMessage(
      messageCheckpoint!.id!,
      threadId,
    );
    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }

    if (!timeTravelCheckpoint) {
      return this.subscriber.error("No checkpoint found for message");
    }

    const fork = await this.client.threads.updateState(threadId, {
      values: this.langGraphDefaultMergeState(timeTravelCheckpoint.values, [], tools),
      checkpointId: timeTravelCheckpoint.checkpoint.checkpoint_id!,
      asNode: timeTravelCheckpoint.next?.[0] ?? "__start__",
    });

    const payload = {
      ...(input.forwardedProps ?? {}),
      input: this.langGraphDefaultMergeState(
        timeTravelCheckpoint.values,
        [messageCheckpoint],
        tools,
      ),
      // @ts-ignore
      checkpointId: fork.checkpoint.checkpoint_id!,
      streamMode,
    };
    return {
      streamResponse: this.client.runs.stream(threadId, this.assistant.assistant_id, payload),
      state: timeTravelCheckpoint as ThreadState<State>,
      streamMode,
    };
  }

  async prepareStream(input: RunAgentExtendedInput, streamMode: StreamMode | StreamMode[]) {
    let {
      threadId: inputThreadId,
      state: inputState,
      messages,
      tools,
      context,
      forwardedProps,
    } = input;
    // If a manual emittance happens, it is the ultimate source of truth of state, unless a node has exited.
    // Therefore, this value should either hold null, or the only edition of state that should be used.
    this.activeRun!.manuallyEmittedState = null;

    const nodeNameInput = forwardedProps?.nodeName;
    this.activeRun!.nodeName = nodeNameInput;
    if (this.activeRun!.nodeName === "__end__") {
      this.activeRun!.nodeName = undefined;
    }

    const threadId = inputThreadId ?? randomUUID();

    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }

    const thread = await this.getOrCreateThread(threadId, forwardedProps?.threadMetadata);
    this.activeRun!.threadId = thread.thread_id;

    const agentState: ThreadState<State> =
      (await this.client.threads.getState(thread.thread_id)) ??
      ({ values: {} } as ThreadState<State>);
    const agentStateMessages = agentState.values.messages ?? [];
    const inputMessagesToLangchain = aguiMessagesToLangChain(messages);
    const stateValuesDiff = this.langGraphDefaultMergeState(
      { ...inputState, messages: agentStateMessages },
      inputMessagesToLangchain,
      tools,
    );
    // Messages are a combination of existing messages in state + everything that was newly sent
    let threadState = {
      ...agentState,
      values: {
        ...stateValuesDiff,
        messages: [...agentStateMessages, ...stateValuesDiff.messages],
      },
    };
    let stateValues = threadState.values;
    this.activeRun!.schemaKeys = await this.getSchemaKeys();

    if (
      (agentState.values.messages ?? []).length > messages.filter((m) => m.role !== "system").length
    ) {
      let lastUserMessage: LangGraphMessage | null = null;
      // Find the first user message by working backwards from the last message
      for (let i = messages.length - 1; i >= 0; i--) {
        if (messages[i].role === "user") {
          lastUserMessage = aguiMessagesToLangChain([messages[i]])[0];
          break;
        }
      }

      if (!lastUserMessage) {
        return this.subscriber.error("No user message found in messages to regenerate");
      }

      return this.prepareRegenerateStream(
        { ...input, messageCheckpoint: lastUserMessage },
        streamMode,
      );
    }
    this.activeRun!.graphInfo = await this.client.assistants.getGraph(this.assistant.assistant_id);

    const mode =
      !forwardedProps?.command?.resume &&
      threadId &&
      this.activeRun!.nodeName != "__end__" &&
      this.activeRun!.nodeName
        ? "continue"
        : "start";

    if (mode === "continue") {
      const nodeBefore = this.activeRun!.graphInfo.edges.find(
        (e) => e.target === this.activeRun!.nodeName,
      );
      await this.client.threads.updateState(threadId, {
        values: inputState,
        asNode: nodeBefore?.source,
      });
    }

    const payloadInput = getStreamPayloadInput({
      mode,
      state: stateValues,
      schemaKeys: this.activeRun!.schemaKeys,
    });

    let payloadConfig: LangGraphConfig | undefined;
    const configsToMerge = [this.assistantConfig, forwardedProps?.config].filter(
      Boolean,
    ) as LangGraphConfig[];
    if (configsToMerge.length) {
      payloadConfig = await this.mergeConfigs({
        configs: configsToMerge,
        assistant: this.assistant,
        schemaKeys: this.activeRun!.schemaKeys,
      });
    }
    const payload = {
      ...forwardedProps,
      streamMode,
      input: payloadInput,
      config: payloadConfig,
    };

    // If there are still outstanding unresolved interrupts, we must force resolution of them before moving forward
    const interrupts = (agentState.tasks?.[0]?.interrupts ?? []) as Interrupt[];
    if (interrupts?.length && !forwardedProps?.command?.resume) {
      this.dispatchEvent({
        type: EventType.RUN_STARTED,
        threadId,
        runId: input.runId,
      });

      interrupts.forEach((interrupt) => {
        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: LangGraphEventTypes.OnInterrupt,
          value:
            typeof interrupt.value === "string" ? interrupt.value : JSON.stringify(interrupt.value),
          rawEvent: interrupt,
        });
      });

      this.dispatchEvent({
        type: EventType.RUN_FINISHED,
        threadId,
        runId: input.runId,
      });
      return this.subscriber.complete();
    }

    return {
      // @ts-ignore
      streamResponse: this.client.runs.stream(threadId, this.assistant.assistant_id, payload),
      state: threadState as ThreadState<State>,
    };
  }

  async handleStreamEvents(
    stream: Awaited<
      ReturnType<typeof this.prepareStream> | ReturnType<typeof this.prepareRegenerateStream>
    >,
    threadId: string,
    subscriber: Subscriber<ProcessedEvents>,
    input: RunAgentExtendedInput,
    streamMode: StreamMode | StreamMode[],
  ) {
    const { forwardedProps } = input;
    const nodeNameInput = forwardedProps?.nodeName;
    this.subscriber = subscriber;
    let shouldExit = false;
    if (!stream) return;

    let { streamResponse, state } = stream;

    this.activeRun!.prevNodeName = null;
    let latestStateValues = {} as ThreadState<State>["values"];
    let updatedState = state;

    try {
      this.dispatchEvent({
        type: EventType.RUN_STARTED,
        threadId,
        runId: this.activeRun!.id,
      });

      // In case of resume (interrupt), re-start resumed step
      if (forwardedProps?.command?.resume && this.activeRun!.nodeName) {
        this.startStep(this.activeRun!.nodeName);
      }

      for await (let streamResponseChunk of streamResponse) {
        const subgraphsStreamEnabled = input.forwardedProps?.streamSubgraphs;
        const isSubgraphStream =
          subgraphsStreamEnabled &&
          (streamResponseChunk.event.startsWith("events") ||
            streamResponseChunk.event.startsWith("values"));

        // @ts-ignore
        if (!streamMode.includes(streamResponseChunk.event as StreamMode) && !isSubgraphStream) {
          continue;
        }

        // Force event type, as data is not properly defined on the LG side.
        type EventsChunkData = {
          __interrupt__?: any;
          metadata: Record<string, any>;
          event: string;
          data: any;
          [key: string]: unknown;
        };
        const chunk = streamResponseChunk as EventsStreamEvent & { data: EventsChunkData };

        if (streamResponseChunk.event === "error") {
          this.dispatchEvent({
            type: EventType.RUN_ERROR,
            message: streamResponseChunk.data.message,
            rawEvent: streamResponseChunk,
          });
          break;
        }

        if (streamResponseChunk.event === "updates") {
          continue;
        }

        if (streamResponseChunk.event === "values") {
          latestStateValues = chunk.data;
          continue;
        } else if (subgraphsStreamEnabled && chunk.event.startsWith("values|")) {
          latestStateValues = {
            ...latestStateValues,
            ...chunk.data,
          };
          continue;
        }

        const chunkData = chunk.data;
        const metadata = chunkData.metadata ?? {};
        const currentNodeName = metadata.langgraph_node;
        const eventType = chunkData.event;

        this.activeRun!.id = metadata.run_id;

        if (currentNodeName && currentNodeName !== this.activeRun!.nodeName) {
          if (this.activeRun!.nodeName && this.activeRun!.nodeName !== nodeNameInput) {
            this.endStep();
          }

          this.startStep(currentNodeName);
        }

        shouldExit =
          shouldExit ||
          (eventType === LangGraphEventTypes.OnCustomEvent &&
            chunkData.name === CustomEventNames.Exit);

        this.activeRun!.exitingNode =
          this.activeRun!.nodeName === currentNodeName &&
          eventType === LangGraphEventTypes.OnChainEnd;
        if (this.activeRun!.exitingNode) {
          this.activeRun!.manuallyEmittedState = null;
        }

        // we only want to update the node name under certain conditions
        // since we don't need any internal node names to be sent to the frontend
        if (this.activeRun!.graphInfo?.["nodes"].some((node) => node.id === currentNodeName)) {
          this.activeRun!.nodeName = currentNodeName;
        }

        updatedState.values = this.activeRun!.manuallyEmittedState ?? latestStateValues;

        if (!this.activeRun!.nodeName) {
          continue;
        }

        const hasStateDiff = JSON.stringify(updatedState) !== JSON.stringify(state);
        // We should not update snapshot while a message is in progress.
        if (
          (hasStateDiff ||
            this.activeRun!.prevNodeName != this.activeRun!.nodeName ||
            this.activeRun!.exitingNode) &&
          !Boolean(this.getMessageInProgress(this.activeRun!.id))
        ) {
          state = updatedState;
          this.activeRun!.prevNodeName = this.activeRun!.nodeName;

          this.dispatchEvent({
            type: EventType.STATE_SNAPSHOT,
            snapshot: this.getStateSnapshot(state),
            rawEvent: chunk,
          });
        }

        this.dispatchEvent({
          type: EventType.RAW,
          event: chunkData,
        });

        this.handleSingleEvent(chunkData);
      }

      state = await this.client.threads.getState(threadId);
      const tasks = state.tasks;
      const interrupts = (tasks?.[0]?.interrupts ?? []) as Interrupt[];
      const isEndNode = state.next.length === 0;
      const writes = state.metadata?.writes ?? {};

      let newNodeName = this.activeRun!.nodeName!;

      if (!interrupts?.length) {
        newNodeName = isEndNode ? "__end__" : (state.next[0] ?? Object.keys(writes)[0]);
      }

      interrupts.forEach((interrupt) => {
        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: LangGraphEventTypes.OnInterrupt,
          value:
            typeof interrupt.value === "string" ? interrupt.value : JSON.stringify(interrupt.value),
          rawEvent: interrupt,
        });
      });

      if (this.activeRun!.nodeName != newNodeName) {
        this.endStep();
        this.startStep(newNodeName);
      }

      this.endStep();
      this.dispatchEvent({
        type: EventType.STATE_SNAPSHOT,
        snapshot: this.getStateSnapshot(state),
      });
      this.dispatchEvent({
        type: EventType.MESSAGES_SNAPSHOT,
        messages: langchainMessagesToAgui((state.values as { messages: any[] }).messages ?? []),
      });

      this.dispatchEvent({
        type: EventType.RUN_FINISHED,
        threadId,
        runId: this.activeRun!.id,
      });
      this.activeRun = undefined;
      return subscriber.complete();
    } catch (e) {
      return subscriber.error(e);
    }
  }

  handleSingleEvent(event: any): void {
    switch (event.event) {
      case LangGraphEventTypes.OnChatModelStream:
        let shouldEmitMessages = event.metadata["emit-messages"] ?? true;
        let shouldEmitToolCalls = event.metadata["emit-tool-calls"] ?? true;

        if (event.data.chunk.response_metadata.finish_reason) return;
        let currentStream = this.getMessageInProgress(this.activeRun!.id);
        const hasCurrentStream = Boolean(currentStream?.id);
        const toolCallData = event.data.chunk.tool_call_chunks?.[0];
        const toolCallUsedToPredictState = event.metadata["predict_state"]?.some(
          (predictStateTool: PredictStateTool) => predictStateTool.tool === toolCallData?.name,
        );

        const isToolCallStartEvent = !hasCurrentStream && toolCallData?.name;
        const isToolCallArgsEvent =
          hasCurrentStream && currentStream?.toolCallId && toolCallData?.args;
        const isToolCallEndEvent = hasCurrentStream && currentStream?.toolCallId && !toolCallData;

        const reasoningData = resolveReasoningContent(event.data);
        const messageContent = resolveMessageContent(event.data.chunk.content);
        const isMessageContentEvent = Boolean(!toolCallData && messageContent);

        const isMessageEndEvent =
          hasCurrentStream && !currentStream?.toolCallId && !isMessageContentEvent;

        if (reasoningData) {
          this.handleThinkingEvent(reasoningData);
          break;
        }

        if (!reasoningData && this.thinkingProcess) {
          this.dispatchEvent({
            type: EventType.THINKING_TEXT_MESSAGE_END,
          });
          this.dispatchEvent({
            type: EventType.THINKING_END,
          });
          this.thinkingProcess = null;
        }

        if (toolCallUsedToPredictState) {
          this.dispatchEvent({
            type: EventType.CUSTOM,
            name: "PredictState",
            value: event.metadata["predict_state"],
          });
        }

        if (isToolCallEndEvent) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: currentStream?.toolCallId!,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }

        if (isMessageEndEvent) {
          const resolved = this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: currentStream!.id,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }

        if (isToolCallStartEvent && shouldEmitToolCalls) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_START,
            toolCallId: toolCallData.id,
            toolCallName: toolCallData.name,
            parentMessageId: event.data.chunk.id,
            rawEvent: event,
          });
          if (resolved) {
            this.setMessageInProgress(this.activeRun!.id, {
              id: event.data.chunk.id,
              toolCallId: toolCallData.id,
              toolCallName: toolCallData.name,
            });
          }
          break;
        }

        // Tool call args: emit ActionExecutionArgs
        if (isToolCallArgsEvent && shouldEmitToolCalls) {
          this.dispatchEvent({
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: currentStream?.toolCallId!,
            delta: toolCallData.args,
            rawEvent: event,
          });
          break;
        }

        // Message content: emit TextMessageContent
        if (isMessageContentEvent && shouldEmitMessages) {
          // No existing message yet, also init the message
          if (!currentStream) {
            this.dispatchEvent({
              type: EventType.TEXT_MESSAGE_START,
              role: "assistant",
              messageId: event.data.chunk.id,
              rawEvent: event,
            });
            this.setMessageInProgress(this.activeRun!.id, {
              id: event.data.chunk.id,
              toolCallId: null,
              toolCallName: null,
            });
            currentStream = this.getMessageInProgress(this.activeRun!.id);
          }

          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_CONTENT,
            messageId: currentStream!.id,
            delta: messageContent!,
            rawEvent: event,
          });
          break;
        }

        break;
      case LangGraphEventTypes.OnChatModelEnd:
        if (this.getMessageInProgress(this.activeRun!.id)?.toolCallId) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: this.getMessageInProgress(this.activeRun!.id)!.toolCallId!,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }
        if (this.getMessageInProgress(this.activeRun!.id)?.id) {
          const resolved = this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: this.getMessageInProgress(this.activeRun!.id)!.id,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }
        break;
      case LangGraphEventTypes.OnCustomEvent:
        if (event.name === CustomEventNames.ManuallyEmitMessage) {
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_START,
            role: "assistant",
            messageId: event.data.message_id,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_CONTENT,
            messageId: event.data.message_id,
            delta: event.data.message,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: event.data.message_id,
            rawEvent: event,
          });
          break;
        }

        if (event.name === CustomEventNames.ManuallyEmitToolCall) {
          this.dispatchEvent({
            type: EventType.TOOL_CALL_START,
            toolCallId: event.data.id,
            toolCallName: event.data.name,
            parentMessageId: event.data.id,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: event.data.id,
            delta: event.data.args,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: event.data.id,
            rawEvent: event,
          });
          break;
        }

        if (event.name === CustomEventNames.ManuallyEmitState) {
          this.activeRun!.manuallyEmittedState = event.data;
          this.dispatchEvent({
            type: EventType.STATE_SNAPSHOT,
            snapshot: this.getStateSnapshot({
              values: this.activeRun!.manuallyEmittedState!,
            } as ThreadState<State>),
            rawEvent: event,
          });
        }

        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: event.name,
          value: event.data,
          rawEvent: event,
        });
        break;
    }
  }

  handleThinkingEvent(reasoningData: LangGraphReasoning) {
    if (!reasoningData || !reasoningData.type || !reasoningData.text) {
      return;
    }

    const thinkingStepIndex = reasoningData.index;

    if (this.thinkingProcess?.index && this.thinkingProcess.index !== thinkingStepIndex) {
      if (this.thinkingProcess.type) {
        this.dispatchEvent({
          type: EventType.THINKING_TEXT_MESSAGE_END,
        });
      }
      this.dispatchEvent({
        type: EventType.THINKING_END,
      });
      this.thinkingProcess = null;
    }

    if (!this.thinkingProcess) {
      // No thinking step yet. Start a new one
      this.dispatchEvent({
        type: EventType.THINKING_START,
      });
      this.thinkingProcess = {
        index: thinkingStepIndex,
      };
    }

    if (this.thinkingProcess.type !== reasoningData.type) {
      this.dispatchEvent({
        type: EventType.THINKING_TEXT_MESSAGE_START,
      });
      this.thinkingProcess.type = reasoningData.type;
    }

    if (this.thinkingProcess.type) {
      this.dispatchEvent({
        type: EventType.THINKING_TEXT_MESSAGE_CONTENT,
        delta: reasoningData.text,
      });
    }
  }

  getStateSnapshot(threadState: ThreadState<State>) {
    let state = threadState.values;
    const schemaKeys = this.activeRun!.schemaKeys!;
    // Do not emit state keys that are not part of the output schema
    if (schemaKeys?.output) {
      state = filterObjectBySchemaKeys(state, [...this.constantSchemaKeys, ...schemaKeys.output]);
    }
    // return state
    return state;
  }

  async getOrCreateThread(threadId: string, threadMetadata?: Record<string, any>): Promise<Thread> {
    let thread: Thread;
    try {
      try {
        thread = await this.getThread(threadId);
      } catch (error) {
        thread = await this.createThread({
          threadId,
          metadata: threadMetadata,
        });
      }
    } catch (error: unknown) {
      throw new Error(`Failed to create thread: ${(error as Error).message}`);
    }

    return thread;
  }

  async getThread(threadId: string) {
    return this.client.threads.get(threadId);
  }

  async createThread(payload?: Parameters<typeof this.client.threads.create>[0]) {
    return this.client.threads.create(payload);
  }

  async mergeConfigs({
    configs,
    assistant,
    schemaKeys,
  }: {
    configs: Config[];
    assistant: Assistant;
    schemaKeys: SchemaKeys;
  }) {
    return configs.reduce((acc, cfg) => {
      let filteredConfigurable = acc.configurable;

      if (cfg.configurable) {
        filteredConfigurable = schemaKeys?.config
          ? filterObjectBySchemaKeys(cfg?.configurable, [
              ...this.constantSchemaKeys,
              ...(schemaKeys?.config ?? []),
            ])
          : cfg?.configurable;
      }

      const newConfig = {
        ...acc,
        ...cfg,
        configurable: filteredConfigurable,
      };

      // LG does not return recursion limit if it's the default, therefore we check: if no recursion limit is currently set, and the user asked for 25, there is no change.
      const isRecursionLimitSetToDefault =
        acc.recursion_limit == null && cfg.recursion_limit === 25;
      // Deep compare configs to avoid unnecessary update calls
      const configsAreDifferent = JSON.stringify(newConfig) !== JSON.stringify(acc);

      // Check if the only difference is the recursion_limit being set to default
      const isOnlyRecursionLimitDifferent =
        isRecursionLimitSetToDefault &&
        JSON.stringify({ ...newConfig, recursion_limit: null }) ===
          JSON.stringify({ ...acc, recursion_limit: null });

      if (configsAreDifferent && !isOnlyRecursionLimitDifferent) {
        return {
          ...acc,
          ...newConfig,
        };
      }

      return acc;
    }, assistant.config);
  }

  getMessageInProgress(runId: string) {
    return this.messagesInProcess[runId];
  }

  setMessageInProgress(runId: string, data: MessageInProgress) {
    this.messagesInProcess = {
      ...this.messagesInProcess,
      [runId]: {
        ...(this.messagesInProcess[runId] as MessageInProgress),
        ...data,
      },
    };
  }

  async getAssistant(): Promise<Assistant> {
    const assistants = await this.client.assistants.search();
    const retrievedAssistant = assistants.find(
      (searchResult) => searchResult.graph_id === this.graphId,
    );
    if (!retrievedAssistant) {
      console.error(`
      No agent found with graph ID ${this.graphId} found..\n
      
      These are the available agents: [${assistants.map((a) => `${a.graph_id} (ID: ${a.assistant_id})`).join(", ")}]
      `);
      throw new Error("No agent id found");
    }

    return retrievedAssistant;
  }

  async getSchemaKeys(): Promise<SchemaKeys> {
    try {
      const graphSchema = await this.client.assistants.getSchemas(this.assistant!.assistant_id);
      let configSchema = null;
      if (graphSchema.config_schema?.properties) {
        configSchema = Object.keys(graphSchema.config_schema.properties);
      }
      if (!graphSchema.input_schema?.properties || !graphSchema.output_schema?.properties) {
        return { config: [], input: null, output: null };
      }
      const inputSchema = Object.keys(graphSchema.input_schema.properties);
      const outputSchema = Object.keys(graphSchema.output_schema.properties);

      return {
        input:
          inputSchema && inputSchema.length ? [...inputSchema, ...this.constantSchemaKeys] : null,
        output:
          outputSchema && outputSchema.length
            ? [...outputSchema, ...this.constantSchemaKeys]
            : null,
        config: configSchema,
      };
    } catch (e) {
      return { config: [], input: this.constantSchemaKeys, output: this.constantSchemaKeys };
    }
  }

  langGraphDefaultMergeState(state: State, messages: LangGraphMessage[], tools: any): State {
    if (messages.length > 0 && "role" in messages[0] && messages[0].role === "system") {
      // remove system message
      messages = messages.slice(1);
    }

    // merge with existing messages
    const existingMessages: LangGraphPlatformMessage[] = state.messages || [];
    const existingMessageIds = new Set(existingMessages.map((message) => message.id));

    const newMessages = messages.filter((message) => !existingMessageIds.has(message.id));

    const langGraphTools = [...(state.tools ?? []), ...(tools ?? [])].map((tool) => {
      if (tool.type) {
        return tool;
      }

      return {
        type: "function",
        function: {
          name: tool.name,
          description: tool.description,
          parameters: tool.parameters,
        },
      };
    });

    return {
      ...state,
      messages: newMessages,
      tools: langGraphTools,
    };
  }

  startStep(nodeName: string) {
    if (this.activeStep) {
      this.endStep();
    }
    this.dispatchEvent({
      type: EventType.STEP_STARTED,
      stepName: nodeName,
    });
    this.activeRun!.nodeName = nodeName;
    this.activeStep = nodeName;
  }

  endStep() {
    if (!this.activeStep) {
      throw new Error("No active step to end");
    }
    this.dispatchEvent({
      type: EventType.STEP_FINISHED,
      stepName: this.activeRun!.nodeName! ?? this.activeStep,
    });
    this.activeRun!.nodeName = undefined;
    this.activeStep = undefined;
  }

  async getCheckpointByMessage(
    messageId: string,
    threadId: string,
    checkpoint?: null | {
      checkpoint_id?: null | string;
      checkpoint_ns: string;
    },
  ): Promise<ThreadState> {
    const options = checkpoint?.checkpoint_id
      ? {
          checkpoint: { checkpoint_id: checkpoint.checkpoint_id },
        }
      : undefined;
    const history = await this.client.threads.getHistory(threadId, options);
    const reversed = [...history].reverse(); // oldest → newest

    let targetState = reversed.find((state) =>
      (state.values as State).messages?.some((m: LangGraphPlatformMessage) => m.id === messageId),
    );

    if (!targetState) throw new Error("Message not found");

    const targetStateMessages = (targetState.values as State).messages ?? [];
    const messageIndex = targetStateMessages.findIndex(
      (m: LangGraphPlatformMessage) => m.id === messageId,
    );
    const messagesAfter = targetStateMessages.slice(messageIndex + 1);
    if (messagesAfter.length) {
      return this.getCheckpointByMessage(messageId, threadId, targetState.parent_checkpoint);
    }

    const targetStateIndex = reversed.indexOf(targetState);

    const { messages, ...targetStateValuesWithoutMessages } = targetState.values as State;
    const selectedCheckpoint = reversed[targetStateIndex - 1] ?? { ...targetState, values: {} };
    return {
      ...selectedCheckpoint,
      values: { ...selectedCheckpoint.values, ...targetStateValuesWithoutMessages },
    };
  }
}

export * from "./types";



================================================
FILE: typescript-sdk/integrations/langgraph/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export * from './agent'
export class LangGraphHttpAgent extends HttpAgent {}


================================================
FILE: typescript-sdk/integrations/langgraph/src/types.ts
================================================
import { AssistantGraph, Message } from "@langchain/langgraph-sdk";
import { MessageType } from "@langchain/core/messages";

export enum LangGraphEventTypes {
  OnChainStart = "on_chain_start",
  OnChainStream = "on_chain_stream",
  OnChainEnd = "on_chain_end",
  OnChatModelStart = "on_chat_model_start",
  OnChatModelStream = "on_chat_model_stream",
  OnChatModelEnd = "on_chat_model_end",
  OnToolStart = "on_tool_start",
  OnToolEnd = "on_tool_end",
  OnCustomEvent = "on_custom_event",
  OnInterrupt = "on_interrupt",
}

export type State = Record<string, any>;

export type SchemaKeys = {
  input: string[] | null;
  output: string[] | null;
  config: string[] | null;
} | null;

export type MessageInProgress = {
  id: string;
  toolCallId?: string | null;
  toolCallName?: string | null;
};

export type ThinkingInProgress = {
  index: number;
  type?: LangGraphReasoning['type'];
}

export interface RunMetadata {
  id: string;
  schemaKeys?: SchemaKeys;
  nodeName?: string;
  prevNodeName?: string | null;
  exitingNode?: boolean;
  manuallyEmittedState?: State | null;
  threadId?: string;
  graphInfo?: AssistantGraph
}

export type MessagesInProgressRecord = Record<string, MessageInProgress | null>;

// The following types are our own definition to the messages accepted by LangGraph Platform, enhanced with some of our extra data.
export interface ToolCall {
  id: string;
  name: string;
  args: Record<string, unknown>;
}

type BaseLangGraphPlatformMessage = Omit<
  Message,
  | "isResultMessage"
  | "isTextMessage"
  | "isImageMessage"
  | "isActionExecutionMessage"
  | "isAgentStateMessage"
  | "type"
  | "createdAt"
> & {
  content: string;
  role: string;
  additional_kwargs?: Record<string, unknown>;
  type: MessageType;
};

interface LangGraphPlatformResultMessage extends BaseLangGraphPlatformMessage {
  tool_call_id: string;
  name: string;
}

interface LangGraphPlatformActionExecutionMessage extends BaseLangGraphPlatformMessage {
  tool_calls: ToolCall[];
}

export type LangGraphPlatformMessage =
  | LangGraphPlatformActionExecutionMessage
  | LangGraphPlatformResultMessage
  | BaseLangGraphPlatformMessage;

export enum CustomEventNames {
  ManuallyEmitMessage = "manually_emit_message",
  ManuallyEmitToolCall = "manually_emit_tool_call",
  ManuallyEmitState = "manually_emit_state",
  Exit = "exit",
}

export interface PredictStateTool {
  tool: string;
  state_key: string;
  tool_argument: string;
}

export interface LangGraphReasoning {
  type: 'text';
  text: string;
  index: number
}



================================================
FILE: typescript-sdk/integrations/langgraph/src/utils.ts
================================================
import { Message as LangGraphMessage } from "@langchain/langgraph-sdk";
import { State, SchemaKeys, LangGraphReasoning } from "./types";
import { Message, ToolCall } from "@ag-ui/client";

export const DEFAULT_SCHEMA_KEYS = ["messages", "tools"];

export function filterObjectBySchemaKeys(obj: Record<string, any>, schemaKeys: string[]) {
  return Object.fromEntries(Object.entries(obj).filter(([key]) => schemaKeys.includes(key)));
}

export function getStreamPayloadInput({
  mode,
  state,
  schemaKeys,
}: {
  mode: "start" | "continue";
  state: State;
  schemaKeys: SchemaKeys;
}) {
  let input = mode === "start" ? state : null;
  // Do not input keys that are not part of the input schema
  if (input && schemaKeys?.input) {
    input = filterObjectBySchemaKeys(input, [...DEFAULT_SCHEMA_KEYS, ...schemaKeys.input]);
  }

  return input;
}

export function langchainMessagesToAgui(messages: LangGraphMessage[]): Message[] {
  return messages.map((message) => {
    switch (message.type) {
      case "human":
        return {
          id: message.id!,
          role: "user",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
        };
      case "ai":
        const content = resolveMessageContent(message.content)
        return {
          id: message.id!,
          role: "assistant",
          content: content ? stringifyIfNeeded(content) : '',
          toolCalls: message.tool_calls?.map((tc) => ({
            id: tc.id!,
            type: "function",
            function: {
              name: tc.name,
              arguments: JSON.stringify(tc.args),
            },
          })),
        };
      case "system":
        return {
          id: message.id!,
          role: "system",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
        };
      case "tool":
        return {
          id: message.id!,
          role: "tool",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
          toolCallId: message.tool_call_id,
        };
      default:
        throw new Error("message type returned from LangGraph is not supported.");
    }
  });
}

export function aguiMessagesToLangChain(messages: Message[]): LangGraphMessage[] {
  return messages.map((message, index) => {
    switch (message.role) {
      case "user":
        return {
          id: message.id,
          role: message.role,
          content: message.content,
          type: "human",
        };
      case "assistant":
        return {
          id: message.id,
          type: "ai",
          role: message.role,
          content: message.content ?? "",
          tool_calls: (message.toolCalls ?? []).map((tc: ToolCall) => ({
            id: tc.id,
            name: tc.function.name,
            args: JSON.parse(tc.function.arguments),
            type: "tool_call",
          })),
        };
      case "system":
        return {
          id: message.id,
          role: message.role,
          content: message.content,
          type: "system",
        };
      case "tool":
        return {
          content: message.content,
          role: message.role,
          type: message.role,
          tool_call_id: message.toolCallId,
          id: message.id,
        };
      default:
        console.error(`Message role ${message.role} is not implemented`);
        throw new Error("message role is not supported.");
    }
  });
}

function stringifyIfNeeded(item: any) {
  if (typeof item === "string") return item;
  return JSON.stringify(item);
}

export function resolveReasoningContent(eventData: any): LangGraphReasoning | null {
  const content = eventData.chunk?.content

  // Anthropic reasoning response
  if (content && Array.isArray(content) && content.length && content[0]) {
    if (!content[0].thinking) return null
    return {
      text: content[0].thinking,
      type: 'text',
      index: content[0].index,
    }
  }

  /// OpenAI reasoning response
  if (eventData.chunk.additional_kwargs?.reasoning?.summary?.[0]) {
    const data = eventData.chunk.additional_kwargs?.reasoning.summary[0]
    if (!data || !data.text) return null
    return {
      type: 'text',
      text: data.text,
      index: data.index,
    }
  }

  return null
}

export function resolveMessageContent(content?: LangGraphMessage['content']): string | null {
  if (!content) return null;

  if (typeof content === 'string') {
    return content;
  }

  if (Array.isArray(content) && content.length) {
    const contentText = content.find(c => c.type === 'text')?.text
    return contentText ?? null;
  }

  return null
}



================================================
FILE: typescript-sdk/integrations/llamaindex/README.md
================================================
# @ag-ui/llamaindex

Implementation of the AG-UI protocol for LlamaIndex.

Connects LlamaIndex workflows to frontend applications via the AG-UI protocol. Provides HTTP connectivity to LlamaIndex servers with support for RAG pipelines and workflow orchestration.

## Installation

```bash
npm install @ag-ui/llamaindex
pnpm add @ag-ui/llamaindex
yarn add @ag-ui/llamaindex
```

## Usage

```ts
import { LlamaIndexAgent } from "@ag-ui/llamaindex";

// Create an AG-UI compatible agent
const agent = new LlamaIndexAgent({
  url: "http://localhost:9000/agentic_chat",
  headers: { "Content-Type": "application/json" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Query my documents" }],
});
```

## Features

- **HTTP connectivity** – Connect to LlamaIndex FastAPI servers
- **Workflow support** – Full integration with LlamaIndex workflow orchestration
- **RAG capabilities** – Document retrieval and reasoning workflows
- **Python integration** – Complete FastAPI server implementation included

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/llamaindex/server-py
uv sync && uv run dev
```



================================================
FILE: typescript-sdk/integrations/llamaindex/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/llamaindex/package.json
================================================
{
  "name": "@ag-ui/llamaindex",
  "author": "Logan Markewich <logan@runllama.ai>",
  "version": "0.1.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/llamaindex/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/llamaindex/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/llamaindex/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/README.md
================================================
# LlamaIndex Python AG-UI Integration

This package provides a FastAPI server that is bootstrapped with several AG-UI+LlamaIndex endpoints. It can be used to communicate with AG-UI compatible frameworks like [CopilotKit](https://docs.copilotkit.ai/).

## Usage

Launch the server with:

```python
uv sync
uv run dev
```

Launch the frontend dojo with:

```bash
cd ../../
pnpm install
turbo run dev
```



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/pyproject.toml
================================================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "server"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.9, <3.14"
dependencies = [
    "llama-index-core>=0.12.41,<0.13",
    "llama-index-agent-openai>=0.4.9,<0.5",
    "llama-index-protocols-ag-ui>=0.1.2",
    "jsonpatch>=1.33",
    "uvicorn>=0.27.0",
    "fastapi>=0.100.0",
]
authors = [
    { name = "Logan Markewich", email = "logan@runllama.ai" },
]

[tool.hatch.build.targets.sdist]
include = ["server/"]

[tool.hatch.build.targets.wheel]
include = ["server/"]

[project.scripts]
dev = "server:main"



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/__init__.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from .routers.agentic_chat import agentic_chat_router
from .routers.human_in_the_loop import human_in_the_loop_router
from .routers.agentic_generative_ui import agentic_generative_ui_router
from .routers.shared_state import shared_state_router

app = FastAPI(title="AG-UI Llama-Index Endpoint")

app.include_router(agentic_chat_router, prefix="/agentic_chat")
app.include_router(human_in_the_loop_router, prefix="/human_in_the_loop")
app.include_router(agentic_generative_ui_router, prefix="/agentic_generative_ui")
app.include_router(shared_state_router, prefix="/shared_state")

def main():

    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9000"))

    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/agentic_chat.py
================================================
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
from typing import Annotated


# This tool has a client-side version that is actually called to change the background
def change_background(
    background: Annotated[str, "The background. Prefer gradients."],
) -> str:
    """Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc."""
    return f"Changing background to {background}"

agentic_chat_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[change_background],
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/agentic_generative_ui.py
================================================
import asyncio
import copy
import jsonpatch
from pydantic import BaseModel

from llama_index.core.workflow import Context
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
from llama_index.protocols.ag_ui.events import StateDeltaWorkflowEvent, StateSnapshotWorkflowEvent

class Step(BaseModel):
    description: str

class Task(BaseModel):
    steps: list[Step]

# Genrative UI demo
async def run_task(
    ctx: Context, task: Task,
) -> str:
    """Execute any list of steps needed to complete a task. Useful for anything the user wants to do."""
    state = await ctx.get("state", default={})
    task = Task.model_validate(task)

    state = {
        "steps": [
            {
                "description": step.description,
                "status": "pending"
            }
            for step in task.steps
        ]
    }

    # Send initial state snapshot
    ctx.write_event_to_stream(
        StateSnapshotWorkflowEvent(
            snapshot=state
        )
    )

    # Sleep for 1 second
    await asyncio.sleep(1.0)

    # Create a copy to track changes for JSON patches
    previous_state = copy.deepcopy(state)

    # Update each step and send deltas
    for i, step in enumerate(state["steps"]):
        step["status"] = "completed"
        
        # Generate JSON patch from previous state to current state
        patch = jsonpatch.make_patch(previous_state, state)
        
        # Send state delta event
        ctx.write_event_to_stream(
            StateDeltaWorkflowEvent(
                delta=patch.patch
            )
        )
        
        # Update previous state for next iteration
        previous_state = copy.deepcopy(state)
        
        # Sleep for 1 second
        await asyncio.sleep(1.0)

    # Optionally send a final snapshot to the client
    ctx.write_event_to_stream(
        StateSnapshotWorkflowEvent(
            snapshot=state
        )
    )

    return "Done!"


agentic_generative_ui_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[run_task],
    initial_state={},
    system_prompt=(
        "You are a helpful assistant that can help the user with their task. "
        "If the user asks you to do any task, use the run_task tool to do it. "
        "Use your best judgement to describe the steps."
    )
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/human_in_the_loop.py
================================================
from typing import Literal, List
from pydantic import BaseModel

from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router



class Step(BaseModel):
    description: str
    status: Literal["enabled", "disabled", "executing"]


def generate_task_steps(steps: List[Step]) -> str:
    return f"Generated {len(steps)} steps"


human_in_the_loop_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[generate_task_steps],
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/shared_state.py
================================================
from typing import Literal, List
from pydantic import BaseModel

from llama_index.core.workflow import Context
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.events import StateSnapshotWorkflowEvent
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router


class Ingredient(BaseModel):
    icon: str
    name: str
    amount: str

class Recipe(BaseModel):
    skill_level: str
    special_preferences: List[str]
    cooking_time: str
    ingredients: List[Ingredient]
    instructions: List[str]


async def update_recipe(ctx: Context, recipe: Recipe) -> str:
    """Useful for recording a recipe to shared state."""
    recipe = Recipe.model_validate(recipe)

    state = await ctx.get("state")
    if state is None:
        state = {}

    state["recipe"] = recipe.model_dump()

    ctx.write_event_to_stream(
        StateSnapshotWorkflowEvent(
            snapshot=state
        )
    )

    await ctx.set("state", state)

    return "Recipe updated!"


shared_state_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[update_recipe],
    initial_state={
        "recipe": None,
    }
)





================================================
FILE: typescript-sdk/integrations/llamaindex/src/index.ts
================================================
/**
 * LlamaIndex is a simple, flexible framework for building agentic generative AI applications that allow large language models to work with your data in any format.
 * Check more about using LlamaIndex: https://docs.llamaindex.ai/
 */

import { HttpAgent } from "@ag-ui/client";

export class LlamaIndexAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/mastra/README.md
================================================
# @ag-ui/mastra

Implementation of the AG-UI protocol for Mastra.

Connects Mastra agents (local and remote) to frontend applications via the AG-UI protocol. Supports streaming responses, memory management, and tool execution.

## Installation

```bash
npm install @ag-ui/mastra
pnpm add @ag-ui/mastra
yarn add @ag-ui/mastra
```

## Usage

```ts
import { MastraAgent } from "@ag-ui/mastra";
import { mastra } from "./mastra"; // Your Mastra instance

// Create an AG-UI compatible agent
const agent = new MastraAgent({
  agent: mastra.getAgent("weather-agent"),
  resourceId: "user-123",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "What's the weather like?" }],
});
```

## Features

- **Local & remote agents** – Works with in-process and network Mastra agents
- **Memory integration** – Automatic thread and working memory management
- **Tool streaming** – Real-time tool call execution and results
- **State management** – Bidirectional state synchronization

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/mastra/example
pnpm install
pnpm run dev
```



================================================
FILE: typescript-sdk/integrations/mastra/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/mastra/package.json
================================================
{
  "name": "@ag-ui/mastra",
  "version": "0.0.10",
  "license": "Apache-2.0",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ai-sdk/ui-utils": "^1.1.19",
    "@mastra/client-js": "^0.10.18",
    "rxjs": "7.8.1"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "@copilotkit/runtime": "^1.9.3",
    "@mastra/core": ">=0.11.1",
    "zod": "^3.25.67"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@mastra/core": "^0.13.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/mastra/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/mastra/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
example



================================================
FILE: typescript-sdk/integrations/mastra/example/package.json
================================================
{
  "name": "example",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "dev": "mastra dev",
    "build": "mastra build"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "",
  "type": "module",
  "engines": {
    "node": ">=20.9.0"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.3.24",
    "@mastra/client-js": "^0.10.20",
    "@mastra/core": "^0.13.1",
    "@mastra/libsql": "^0.13.1",
    "@mastra/loggers": "^0.10.6",
    "@mastra/memory": "^0.12.1",
    "zod": "^3.25.48"
  },
  "devDependencies": {
    "@types/node": "^22.15.29",
    "mastra": "^0.10.20",
    "typescript": "^5.8.3"
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/example/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "moduleResolution": "bundler",
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "skipLibCheck": true,
    "noEmit": true,
    "outDir": "dist"
  },
  "include": [
    "src/**/*"
  ]
}



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/index.ts
================================================
import { Mastra } from "@mastra/core/mastra";
import { PinoLogger } from "@mastra/loggers";
import { LibSQLStore } from "@mastra/libsql";

import { agenticChatAgent } from "./agents/agentic-chat";
import { toolBasedGenerativeUIAgent } from "./agents/tool-based-generative-ui";

export const mastra = new Mastra({
  server: {
    port: process.env.PORT ? parseInt(process.env.PORT) : 4111,
    host: "0.0.0.0",
  },
  agents: { agentic_chat: agenticChatAgent, tool_based_generative_ui: toolBasedGenerativeUIAgent },
  storage: new LibSQLStore({
    // stores telemetry, evals, ... into memory storage, if it needs to persist, change to file:../mastra.db
    url: ":memory:",
  }),
  logger: new PinoLogger({
    name: "Mastra",
    level: "info",
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/agents/agentic-chat.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { weatherTool } from "../tools/weather-tool";

export const agenticChatAgent = new Agent({
  name: "Weather Agent",
  instructions: `
      You are a helpful weather assistant that provides accurate weather information.

      Your primary function is to help users get weather details for specific locations. When responding:
      - Always ask for a location if none is provided
      - If the location name isn’t in English, please translate it
      - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
      - Include relevant details like humidity, wind conditions, and precipitation
      - Keep responses concise but informative

      Use the weatherTool to fetch current weather data.
`,
  model: openai("gpt-4o-mini"),
  tools: { weatherTool },
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db", // path is relative to the .mastra/output directory
    }),
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/agents/tool-based-generative-ui.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { createTool } from "@mastra/core";
import z from "zod";

export const toolBasedGenerativeUIAgent = new Agent({
  name: "Haiku Agent",
  instructions: `
      You are a helpful haiku assistant that provides the user with a haiku.
`,
  model: openai("gpt-4o-mini"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db", // path is relative to the .mastra/output directory
    }),
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/tools/weather-tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

interface GeocodingResponse {
  results: {
    latitude: number;
    longitude: number;
    name: string;
  }[];
}
interface WeatherResponse {
  current: {
    time: string;
    temperature_2m: number;
    apparent_temperature: number;
    relative_humidity_2m: number;
    wind_speed_10m: number;
    wind_gusts_10m: number;
    weather_code: number;
  };
}

export const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name"),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location);
  },
});

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;
  const geocodingResponse = await fetch(geocodingUrl);
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse;

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`);
  }

  const { latitude, longitude, name } = geocodingData.results[0];

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;

  const response = await fetch(weatherUrl);
  const data = (await response.json()) as WeatherResponse;

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name,
  };
};

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail",
  };
  return conditions[code] || "Unknown";
}



================================================
FILE: typescript-sdk/integrations/mastra/src/index.ts
================================================
export * from "./mastra";
export * from "./utils";



================================================
FILE: typescript-sdk/integrations/mastra/src/mastra.ts
================================================
import type {
  AgentConfig,
  BaseEvent,
  RunAgentInput,
  RunFinishedEvent,
  RunStartedEvent,
  StateSnapshotEvent,
  TextMessageChunkEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  ToolCallStartEvent,
} from "@ag-ui/client";
import { AbstractAgent, EventType } from "@ag-ui/client";
import { processDataStream } from "@ai-sdk/ui-utils";
import type { StorageThreadType } from "@mastra/core";
import { Agent as LocalMastraAgent } from "@mastra/core/agent";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { randomUUID } from "crypto";
import { Observable } from "rxjs";
import { MastraClient } from "@mastra/client-js";
type RemoteMastraAgent = ReturnType<MastraClient["getAgent"]>;
import {
  convertAGUIMessagesToMastra,
  GetLocalAgentsOptions,
  getLocalAgents,
  getRemoteAgents,
  GetRemoteAgentsOptions,
  GetLocalAgentOptions,
  getLocalAgent,
  GetNetworkOptions,
  getNetwork,
} from "./utils";

export interface MastraAgentConfig extends AgentConfig {
  agent: LocalMastraAgent | RemoteMastraAgent;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

interface MastraAgentStreamOptions {
  onTextPart?: (text: string) => void;
  onFinishMessagePart?: () => void;
  onToolCallPart?: (streamPart: { toolCallId: string; toolName: string; args: any }) => void;
  onToolResultPart?: (streamPart: { toolCallId: string; result: any }) => void;
  onError?: (error: Error) => void;
  onRunFinished?: () => Promise<void>;
}

export class MastraAgent extends AbstractAgent {
  agent: LocalMastraAgent | RemoteMastraAgent;
  resourceId?: string;
  runtimeContext?: RuntimeContext;

  constructor({ agent, resourceId, runtimeContext, ...rest }: MastraAgentConfig) {
    super(rest);
    this.agent = agent;
    this.resourceId = resourceId;
    this.runtimeContext = runtimeContext;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    let messageId = randomUUID();

    return new Observable<BaseEvent>((subscriber) => {
      const run = async () => {
        const runStartedEvent: RunStartedEvent = {
          type: EventType.RUN_STARTED,
          threadId: input.threadId,
          runId: input.runId,
        };

        subscriber.next(runStartedEvent);

        // Handle local agent memory management (from Mastra implementation)
        if (this.isLocalMastraAgent(this.agent)) {
          const memory = await this.agent.getMemory();

          if (memory && input.state && Object.keys(input.state || {}).length > 0) {
            let thread: StorageThreadType | null = await memory.getThreadById({
              threadId: input.threadId,
            });

            if (!thread) {
              thread = {
                id: input.threadId,
                title: "",
                metadata: {},
                resourceId: this.resourceId ?? input.threadId,
                createdAt: new Date(),
                updatedAt: new Date(),
              };
            }

            const existingMemory = JSON.parse((thread.metadata?.workingMemory as string) ?? "{}");
            const { messages, ...rest } = input.state;
            const workingMemory = JSON.stringify({ ...existingMemory, ...rest });

            // Update thread metadata with new working memory
            await memory.saveThread({
              thread: {
                ...thread,
                metadata: {
                  ...thread.metadata,
                  workingMemory,
                },
              },
            });
          }
        }

        try {
          await this.streamMastraAgent(input, {
            onTextPart: (text) => {
              const event: TextMessageChunkEvent = {
                type: EventType.TEXT_MESSAGE_CHUNK,
                role: "assistant",
                messageId,
                delta: text,
              };
              subscriber.next(event);
            },
            onToolCallPart: (streamPart) => {
              const startEvent: ToolCallStartEvent = {
                type: EventType.TOOL_CALL_START,
                parentMessageId: messageId,
                toolCallId: streamPart.toolCallId,
                toolCallName: streamPart.toolName,
              };
              subscriber.next(startEvent);

              const argsEvent: ToolCallArgsEvent = {
                type: EventType.TOOL_CALL_ARGS,
                toolCallId: streamPart.toolCallId,
                delta: JSON.stringify(streamPart.args),
              };
              subscriber.next(argsEvent);

              const endEvent: ToolCallEndEvent = {
                type: EventType.TOOL_CALL_END,
                toolCallId: streamPart.toolCallId,
              };
              subscriber.next(endEvent);
            },
            onToolResultPart(streamPart) {
              const toolCallResultEvent: ToolCallResultEvent = {
                type: EventType.TOOL_CALL_RESULT,
                toolCallId: streamPart.toolCallId,
                content: JSON.stringify(streamPart.result),
                messageId: randomUUID(),
                role: "tool",
              };

              subscriber.next(toolCallResultEvent);
            },
            onFinishMessagePart: async () => {
              messageId = randomUUID();
            },
            onError: (error) => {
              console.error("error", error);
              // Handle error
              subscriber.error(error);
            },
            onRunFinished: async () => {
              if (this.isLocalMastraAgent(this.agent)) {
                try {
                  const memory = await this.agent.getMemory();
                  if (memory) {
                    const workingMemory = await memory.getWorkingMemory({
                      threadId: input.threadId,
                      memoryConfig: {
                        workingMemory: {
                          enabled: true,
                        },
                      },
                    });

                    if (typeof workingMemory === "string") {
                      const snapshot = JSON.parse(workingMemory);

                      if (snapshot && !("$schema" in snapshot)) {
                        const stateSnapshotEvent: StateSnapshotEvent = {
                          type: EventType.STATE_SNAPSHOT,
                          snapshot,
                        };

                        subscriber.next(stateSnapshotEvent);
                      }
                    }
                  }
                } catch (error) {
                  console.error("Error sending state snapshot", error);
                }
              }

              // Emit run finished event
              subscriber.next({
                type: EventType.RUN_FINISHED,
                threadId: input.threadId,
                runId: input.runId,
              } as RunFinishedEvent);

              // Complete the observable
              subscriber.complete();
            },
          });
        } catch (error) {
          console.error("Stream error:", error);
          subscriber.error(error);
        }
      };

      run();

      return () => {};
    });
  }

  isLocalMastraAgent(agent: LocalMastraAgent | RemoteMastraAgent): agent is LocalMastraAgent {
    return "getMemory" in agent;
  }

  /**
   * Streams in process or remote mastra agent.
   * @param input - The input for the mastra agent.
   * @param options - The options for the mastra agent.
   * @returns The stream of the mastra agent.
   */
  private async streamMastraAgent(
    { threadId, runId, messages, tools }: RunAgentInput,
    {
      onTextPart,
      onFinishMessagePart,
      onToolCallPart,
      onToolResultPart,
      onError,
      onRunFinished,
    }: MastraAgentStreamOptions,
  ): Promise<void> {
    const clientTools = tools.reduce(
      (acc, tool) => {
        acc[tool.name as string] = {
          id: tool.name,
          description: tool.description,
          inputSchema: tool.parameters,
        };
        return acc;
      },
      {} as Record<string, any>,
    );
    const resourceId = this.resourceId ?? threadId;
    const convertedMessages = convertAGUIMessagesToMastra(messages);
    const runtimeContext = this.runtimeContext;

    if (this.isLocalMastraAgent(this.agent)) {
      // Local agent - use the agent's stream method directly
      try {
        const response = await this.agent.stream(convertedMessages, {
          threadId,
          resourceId,
          runId,
          clientTools,
          runtimeContext,
        });

        // For local agents, the response should already be a stream
        // Process it using the agent's built-in streaming mechanism
        if (response && typeof response === "object") {
          // If the response has a toDataStreamResponse method, use it
          if (
            "toDataStreamResponse" in response &&
            typeof response.toDataStreamResponse === "function"
          ) {
            const dataStreamResponse = response.toDataStreamResponse();
            if (dataStreamResponse && dataStreamResponse.body) {
              await processDataStream({
                stream: dataStreamResponse.body,
                onTextPart,
                onToolCallPart,
                onToolResultPart,
                onFinishMessagePart,
              });
              await onRunFinished?.();
            } else {
              throw new Error("Invalid data stream response from local agent");
            }
          } else {
            // If it's already a readable stream, process it directly
            await processDataStream({
              stream: response as any,
              onTextPart,
              onToolCallPart,
              onToolResultPart,
              onFinishMessagePart,
            });
            await onRunFinished?.();
          }
        } else {
          throw new Error("Invalid response from local agent");
        }
      } catch (error) {
        onError?.(error as Error);
      }
    } else {
      // Remote agent - use the remote agent's stream method
      try {
        const response = await this.agent.stream({
          threadId,
          resourceId,
          runId,
          messages: convertedMessages,
          clientTools,
        });

        // Remote agents should have a processDataStream method
        if (response && typeof response.processDataStream === "function") {
          await response.processDataStream({
            onTextPart,
            onToolCallPart,
            onToolResultPart,
            onFinishMessagePart,
          });
          await onRunFinished?.();
        } else {
          throw new Error("Invalid response from remote agent");
        }
      } catch (error) {
        onError?.(error as Error);
      }
    }
  }

  static async getRemoteAgents(
    options: GetRemoteAgentsOptions,
  ): Promise<Record<string, AbstractAgent>> {
    return getRemoteAgents(options);
  }

  static getLocalAgents(options: GetLocalAgentsOptions): Record<string, AbstractAgent> {
    return getLocalAgents(options);
  }

  static getLocalAgent(options: GetLocalAgentOptions) {
    return getLocalAgent(options);
  }

  static getNetwork(options: GetNetworkOptions) {
    return getNetwork(options);
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/src/utils.ts
================================================
import type { Message } from "@ag-ui/client";
import { AbstractAgent } from "@ag-ui/client";
import {
  CopilotRuntime,
  copilotRuntimeNodeHttpEndpoint,
  CopilotServiceAdapter,
  ExperimentalEmptyAdapter,
} from "@copilotkit/runtime";
import type { CoreMessage } from "@mastra/core";
import { registerApiRoute } from "@mastra/core/server";
import type { Mastra } from "@mastra/core";
import { Agent as LocalMastraAgent } from "@mastra/core/agent";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { MastraClient } from "@mastra/client-js";
import { MastraAgent } from "./mastra";

export function convertAGUIMessagesToMastra(messages: Message[]): CoreMessage[] {
  const result: CoreMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant") {
      const parts: any[] = message.content ? [{ type: "text", text: message.content }] : [];
      for (const toolCall of message.toolCalls ?? []) {
        parts.push({
          type: "tool-call",
          toolCallId: toolCall.id,
          toolName: toolCall.function.name,
          args: JSON.parse(toolCall.function.arguments),
        });
      }
      result.push({
        role: "assistant",
        content: parts,
      });
    } else if (message.role === "user") {
      result.push({
        role: "user",
        content: message.content || "",
      });
    } else if (message.role === "tool") {
      let toolName = "unknown";
      for (const msg of messages) {
        if (msg.role === "assistant") {
          for (const toolCall of msg.toolCalls ?? []) {
            if (toolCall.id === message.toolCallId) {
              toolName = toolCall.function.name;
              break;
            }
          }
        }
      }
      result.push({
        role: "tool",
        content: [
          {
            type: "tool-result",
            toolCallId: message.toolCallId,
            toolName: toolName,
            result: message.content,
          },
        ],
      });
    }
  }

  return result;
}

export function registerCopilotKit<T extends Record<string, any> | unknown = unknown>({
  path,
  resourceId,
  serviceAdapter = new ExperimentalEmptyAdapter(),
  agents,
  setContext,
}: {
  path: string;
  resourceId: string;
  serviceAdapter?: CopilotServiceAdapter;
  agents?: Record<string, AbstractAgent>;
  setContext?: (c: any, runtimeContext: RuntimeContext<T>) => void | Promise<void>;
}) {
  return registerApiRoute(path, {
    method: `ALL`,
    handler: async (c) => {
      const mastra = c.get("mastra");

      const runtimeContext = new RuntimeContext<T>();

      if (setContext) {
        await setContext(c, runtimeContext);
      }

      const aguiAgents =
        agents ||
        MastraAgent.getLocalAgents({
          resourceId,
          mastra,
          runtimeContext,
        });

      const runtime = new CopilotRuntime({
        agents: aguiAgents,
      });

      const handler = copilotRuntimeNodeHttpEndpoint({
        endpoint: path,
        runtime,
        serviceAdapter,
      });

      return handler.handle(c.req.raw, {});
    },
  });
}

export interface GetRemoteAgentsOptions {
  mastraClient: MastraClient;
  resourceId?: string;
}

export async function getRemoteAgents({
  mastraClient,
  resourceId,
}: GetRemoteAgentsOptions): Promise<Record<string, AbstractAgent>> {
  const agents = await mastraClient.getAgents();

  return Object.entries(agents).reduce(
    (acc, [agentId]) => {
      const agent = mastraClient.getAgent(agentId);

      acc[agentId] = new MastraAgent({
        agentId,
        agent,
        resourceId,
      });

      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );
}

export interface GetLocalAgentsOptions {
  mastra: Mastra;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getLocalAgents({
  mastra,
  resourceId,
  runtimeContext,
}: GetLocalAgentsOptions): Record<string, AbstractAgent> {
  const agents = mastra.getAgents() || {};
  const networks = mastra.getNetworks() || [];

  const networkAGUI = networks.reduce(
    (acc, network) => {
      acc[network.name!] = new MastraAgent({
        agentId: network.name!,
        agent: network as unknown as LocalMastraAgent,
        resourceId,
        runtimeContext,
      });
      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );

  const agentAGUI = Object.entries(agents).reduce(
    (acc, [agentId, agent]) => {
      acc[agentId] = new MastraAgent({
        agentId,
        agent,
        resourceId,
        runtimeContext,
      });
      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );

  return {
    ...agentAGUI,
    ...networkAGUI,
  };
}

export interface GetLocalAgentOptions {
  mastra: Mastra;
  agentId: string;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getLocalAgent({
  mastra,
  agentId,
  resourceId,
  runtimeContext,
}: GetLocalAgentOptions) {
  const agent = mastra.getAgent(agentId);
  if (!agent) {
    throw new Error(`Agent ${agentId} not found`);
  }
  return new MastraAgent({
    agentId,
    agent,
    resourceId,
    runtimeContext,
  }) as AbstractAgent;
}

export interface GetNetworkOptions {
  mastra: Mastra;
  networkId: string;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getNetwork({ mastra, networkId, resourceId, runtimeContext }: GetNetworkOptions) {
  const network = mastra.getNetwork(networkId);
  if (!network) {
    throw new Error(`Network ${networkId} not found`);
  }
  return new MastraAgent({
    agentId: network.name!,
    agent: network as unknown as LocalMastraAgent,
    resourceId,
    runtimeContext,
  }) as AbstractAgent;
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/README.md
================================================
# Middleware Starter

This starter kit demonstrates how to set up a middleware server that can be used to proxy events from the agent to the frontend.

## Tutorial

To learn how to set up your own middleware server, please refer to the [tutorial](https://docs.ag-ui.com/quickstart/middleware).



================================================
FILE: typescript-sdk/integrations/middleware-starter/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/middleware-starter/package.json
================================================
{
  "name": "@ag-ui/middleware-starter",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/middleware-starter/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/middleware-starter/src/index.ts
================================================
import { AbstractAgent, BaseEvent, EventType, RunAgentInput } from "@ag-ui/client";
import { Observable } from "rxjs";

export class MiddlewareStarterAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = Date.now().toString();
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
      } as any);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
      } as any);

      observer.complete();
    });
  }
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/README.md
================================================
# Pydantic AI

Implementation of the AG-UI protocol for [Pydantic AI](https://ai.pydantic.dev/).

For more information on the Pydantic AI implementation see
the [Pydantic AI AG-UI docs](https://ai.pydantic.dev/ag-ui/).

## Prerequisites

This example uses a Pydantic AI agent using an OpenAI model and the AG-UI dojo.

- An [OpenAI API key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)

## Running

To run this integration you need to:

1. Clone the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui)

    ```shell
    git clone https://github.com/ag-ui-protocol/ag-ui.git
    ```

2. Change into the `typescript-sdk/integrations/pydantic-ai` directory

    ```shell
    cd typescript-sdk/integrations/pydantic-ai
    ```

3. Install the `pydantic-ai-examples` package, for example:

    ```shell
    pip install pydantic-ai-examples
    ```

    or:

    ```shell
    uv venv
    uv pip install pydantic-ai-examples
    ```

4. Run the example dojo server

    ```shell
    export OPENAI_API_KEY=<your api key>
    python -m pydantic_ai_examples.ag_ui
    ```

    or:

    ```shell
    export OPENAI_API_KEY=<your api key>
    uv run python -m pydantic_ai_examples.ag_ui
    ```

5. Open another terminal in root directory of the `ag-ui` repository clone
6. Start the integration ag-ui dojo:

    ```shell
    cd typescript-sdk
    pnpm install && pnpm run dev
    ```

7. Visit [http://localhost:3000/pydantic-ai](http://localhost:3000/pydantic-ai)
8. Select View `Pydantic AI` from the sidebar


## Feature Examples

### Agentic Chat

This demonstrates a basic agent interaction including Pydantic AI server side
tools and AG-UI client side tools.

View the [Agentic Chat example](http://localhost:3000/pydantic-ai/feature/agentic_chat).

#### Agent Tools

- `time` - Pydantic AI tool to check the current time for a time zone
- `background` - AG-UI tool to set the background color of the client window

#### Agent Prompts

```text
What is the time in New York?
```

```text
Change the background to blue
```

A complex example which mixes both AG-UI and Pydantic AI tools:

```text
Perform the following steps, waiting for the response of each step before continuing:
1. Get the time
2. Set the background to red
3. Get the time
4. Report how long the background set took by diffing the two times
```

### Agentic Generative UI

Demonstrates a long running task where the agent sends updates to the frontend
to let the user know what's happening.

View the [Agentic Generative UI example](http://localhost:3000/pydantic-ai/feature/agentic_generative_ui).

#### Plan Prompts

```text
Create a plan for breakfast and execute it
```

### Human in the Loop

Demonstrates simple human in the loop workflow where the agent comes up with a
plan and the user can approve it using checkboxes.

#### Task Planning Tools

- `generate_task_steps` - AG-UI tool to generate and confirm steps

#### Task Planning Prompt

```text
Generate a list of steps for cleaning a car for me to review
```

### Predictive State Updates

Demonstrates how to use the predictive state updates feature to update the state
of the UI based on agent responses, including user interaction via user
confirmation.

View the [Predictive State Updates example](http://localhost:3000/pydantic-ai/feature/predictive_state_updates).

#### Story Tools

- `write_document` - AG-UI tool to write the document to a window
- `document_predict_state` - Pydantic AI tool that enables document state
  prediction for the `write_document` tool

This also shows how to use custom instructions based on shared state information.

#### Story Example

Starting document text

```markdown
Bruce was a good dog,
```

Agent prompt

```text
Help me complete my story about bruce the dog, is should be no longer than a sentence.
```

### Shared State

Demonstrates how to use the shared state between the UI and the agent.

State sent to the agent is detected by a function based instruction. This then
validates the data using a custom pydantic model before using to create the
instructions for the agent to follow and send to the client using a AG-UI tool.

View the [Shared State example](http://localhost:3000/pydantic-ai/feature/shared_state).

#### Recipe Tools

- `display_recipe` - AG-UI tool to display the recipe in a graphical format

#### Recipe Example

1. Customise the basic settings of your recipe
2. Click `Improve with AI`

### Tool Based Generative UI

Demonstrates customised rendering for tool output with used confirmation.

View the [Tool Based Generative UI example](http://localhost:3000/pydantic-ai/feature/tool_based_generative_ui).

#### Haiku Tools

- `generate_haiku` - AG-UI tool to display a haiku in English and Japanese

#### Haiku Prompt

```text
Generate a haiku about formula 1
```



================================================
FILE: typescript-sdk/integrations/pydantic-ai/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/pydantic-ai/package.json
================================================
{
  "name": "@ag-ui/pydantic-ai",
  "author": "Steven Hartland <steve@rocketscience.gg>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/pydantic-ai/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/README.md
================================================
# Pydantic AI AG-UI Examples

This directory contains example usage of the AG-UI adapter for Pydantic AI. It provides a FastAPI application that demonstrates how to use the Pydantic AI agent with the AG-UI protocol.

## Features

The examples include implementations for each of the AG-UI dojo features:
- Agentic Chat
- Human in the Loop
- Agentic Generative UI
- Tool Based Generative UI
- Shared State
- Predictive State Updates

## Setup

1. Install dependencies:
   ```bash
   uv sync
   ```

2. Run the development server:
   ```bash
   uv run dev
   ```

## Usage

Once the server is running, launch the frontend dojo with:

```bash
cd ../../../
pnpm install
turbo run dev
```

and view it at http://localhost:3000.

By default, the agents can be reached at:

- `http://localhost:9000/agentic_chat` - Agentic Chat
- `http://localhost:9000/agentic_generative_ui` - Agentic Generative UI
- `http://localhost:9000/human_in_the_loop` - Human in the Loop
- `http://localhost:9000/predictive_state_updates` - Predictive State Updates
- `http://localhost:9000/shared_state` - Shared State
- `http://localhost:9000/tool_based_generative_ui` - Tool Based Generative UI



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/pyproject.toml
================================================
tool.uv.package = true

[project]
name = "server"
version = "0.1.0"
description = "Example usage of the AG-UI adapter for Pydantic AI"
license = "MIT"

readme = "README.md"
requires-python = ">=3.9"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic-ai-slim[openai,ag-ui]>=0.1.0",
]
authors = []

[project.scripts]
dev = "server:main"




================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/__init__.py
================================================
"""Example usage of the AG-UI adapter for Pydantic AI.

This provides a FastAPI application that demonstrates how to use the
Pydantic AI agent with the AG-UI protocol. It includes examples for
each of the AG-UI dojo features:
- Agentic Chat
- Human in the Loop
- Agentic Generative UI
- Tool Based Generative UI
- Shared State
- Predictive State Updates
"""

from __future__ import annotations

from fastapi import FastAPI
import uvicorn
import os


from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

app = FastAPI(title='Pydantic AI AG-UI server')
app.mount('/agentic_chat', agentic_chat_app, 'Agentic Chat')
app.mount('/agentic_generative_ui', agentic_generative_ui_app, 'Agentic Generative UI')
app.mount('/human_in_the_loop', human_in_the_loop_app, 'Human in the Loop')
app.mount(
    '/predictive_state_updates',
    predictive_state_updates_app,
    'Predictive State Updates',
)
app.mount('/shared_state', shared_state_app, 'Shared State')
app.mount(
    '/tool_based_generative_ui',
    tool_based_generative_ui_app,
    'Tool Based Generative UI',
)


def main():
    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9000"))
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/__init__.py
================================================
"""Example API for a AG-UI compatible Pydantic AI Agent UI."""

from __future__ import annotations

from .agentic_chat import app as agentic_chat_app
from .agentic_generative_ui import app as agentic_generative_ui_app
from .human_in_the_loop import app as human_in_the_loop_app
from .predictive_state_updates import app as predictive_state_updates_app
from .shared_state import app as shared_state_app
from .tool_based_generative_ui import app as tool_based_generative_ui_app

__all__ = [
    'agentic_chat_app',
    'agentic_generative_ui_app',
    'human_in_the_loop_app',
    'predictive_state_updates_app',
    'shared_state_app',
    'tool_based_generative_ui_app',
]



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/agentic_chat.py
================================================
"""Agentic Chat feature."""

from __future__ import annotations

from datetime import datetime
from zoneinfo import ZoneInfo

from pydantic_ai import Agent

agent = Agent('openai:gpt-4o-mini')
app = agent.to_ag_ui()


@agent.tool_plain
async def current_time(timezone: str = 'UTC') -> str:
    """Get the current time in ISO format.

    Args:
        timezone: The timezone to use.

    Returns:
        The current time in ISO format string.
    """
    tz: ZoneInfo = ZoneInfo(timezone)
    return datetime.now(tz=tz).isoformat()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/agentic_generative_ui.py
================================================
"""Agentic Generative UI feature."""

from __future__ import annotations

from textwrap import dedent
from typing import Any, Literal

from pydantic import BaseModel, Field

from ag_ui.core import EventType, StateDeltaEvent, StateSnapshotEvent
from pydantic_ai import Agent

StepStatus = Literal['pending', 'completed']


class Step(BaseModel):
    """Represents a step in a plan."""

    description: str = Field(description='The description of the step')
    status: StepStatus = Field(
        default='pending',
        description='The status of the step (e.g., pending, completed)',
    )


class Plan(BaseModel):
    """Represents a plan with multiple steps."""

    steps: list[Step] = Field(default_factory=list, description='The steps in the plan')


class JSONPatchOp(BaseModel):
    """A class representing a JSON Patch operation (RFC 6902)."""

    op: Literal['add', 'remove', 'replace', 'move', 'copy', 'test'] = Field(
        description='The operation to perform: add, remove, replace, move, copy, or test',
    )
    path: str = Field(description='JSON Pointer (RFC 6901) to the target location')
    value: Any = Field(
        default=None,
        description='The value to apply (for add, replace operations)',
    )
    from_: str | None = Field(
        default=None,
        alias='from',
        description='Source path (for move, copy operations)',
    )


agent = Agent(
    'openai:gpt-4o-mini',
    instructions=dedent(
        """
        When planning use tools only, without any other messages.
        IMPORTANT:
        - Use the `create_plan` tool to set the initial state of the steps
        - Use the `update_plan_step` tool to update the status of each step
        - Do NOT repeat the plan or summarise it in a message
        - Do NOT confirm the creation or updates in a message
        - Do NOT ask the user for additional information or next steps

        Only one plan can be active at a time, so do not call the `create_plan` tool
        again until all the steps in current plan are completed.
        """
    ),
)


@agent.tool_plain
async def create_plan(steps: list[str]) -> StateSnapshotEvent:
    """Create a plan with multiple steps.

    Args:
        steps: List of step descriptions to create the plan.

    Returns:
        StateSnapshotEvent containing the initial state of the steps.
    """
    plan: Plan = Plan(
        steps=[Step(description=step) for step in steps],
    )
    return StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=plan.model_dump(),
    )


@agent.tool_plain
async def update_plan_step(
    index: int, description: str | None = None, status: StepStatus | None = None
) -> StateDeltaEvent:
    """Update the plan with new steps or changes.

    Args:
        index: The index of the step to update.
        description: The new description for the step.
        status: The new status for the step.

    Returns:
        StateDeltaEvent containing the changes made to the plan.
    """
    changes: list[JSONPatchOp] = []
    if description is not None:
        changes.append(
            JSONPatchOp(
                op='replace', path=f'/steps/{index}/description', value=description
            )
        )
    if status is not None:
        changes.append(
            JSONPatchOp(op='replace', path=f'/steps/{index}/status', value=status)
        )
    return StateDeltaEvent(
        type=EventType.STATE_DELTA,
        delta=changes,
    )


app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/human_in_the_loop.py
================================================
"""Human in the Loop Feature.

No special handling is required for this feature.
"""

from __future__ import annotations

from textwrap import dedent

from pydantic_ai import Agent

agent = Agent(
    'openai:gpt-4o-mini',
    instructions=dedent(
        """
        When planning tasks use tools only, without any other messages.
        IMPORTANT:
        - Use the `generate_task_steps` tool to display the suggested steps to the user
        - Never repeat the plan, or send a message detailing steps
        - If accepted, confirm the creation of the plan and the number of selected (enabled) steps only
        - If not accepted, ask the user for more information, DO NOT use the `generate_task_steps` tool again
        """
    ),
)

app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/predictive_state_updates.py
================================================
"""Predictive State feature."""

from __future__ import annotations

from textwrap import dedent

from pydantic import BaseModel

from ag_ui.core import CustomEvent, EventType
from pydantic_ai import Agent, RunContext
from pydantic_ai.ag_ui import StateDeps


class DocumentState(BaseModel):
    """State for the document being written."""

    document: str = ''


agent = Agent('openai:gpt-4o-mini', deps_type=StateDeps[DocumentState])


# Tools which return AG-UI events will be sent to the client as part of the
# event stream, single events and iterables of events are supported.
@agent.tool_plain
async def document_predict_state() -> list[CustomEvent]:
    """Enable document state prediction.

    Returns:
        CustomEvent containing the event to enable state prediction.
    """
    return [
        CustomEvent(
            type=EventType.CUSTOM,
            name='PredictState',
            value=[
                {
                    'state_key': 'document',
                    'tool': 'write_document',
                    'tool_argument': 'document',
                },
            ],
        ),
    ]


@agent.instructions()
async def story_instructions(ctx: RunContext[StateDeps[DocumentState]]) -> str:
    """Provide instructions for writing document if present.

    Args:
        ctx: The run context containing document state information.

    Returns:
        Instructions string for the document writing agent.
    """
    return dedent(
        f"""You are a helpful assistant for writing documents.

        Before you start writing, you MUST call the `document_predict_state`
        tool to enable state prediction.

        To present the document to the user for review, you MUST use the
        `write_document` tool.

        When you have written the document, DO NOT repeat it as a message.
        If accepted briefly summarize the changes you made, 2 sentences
        max, otherwise ask the user to clarify what they want to change.

        This is the current document:

        {ctx.deps.state.document}
        """
    )


app = agent.to_ag_ui(deps=StateDeps(DocumentState()))



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/shared_state.py
================================================
"""Shared State feature."""

from __future__ import annotations

from enum import StrEnum
from textwrap import dedent

from pydantic import BaseModel, Field

from ag_ui.core import EventType, StateSnapshotEvent
from pydantic_ai import Agent, RunContext
from pydantic_ai.ag_ui import StateDeps


class SkillLevel(StrEnum):
    """The level of skill required for the recipe."""

    BEGINNER = 'Beginner'
    INTERMEDIATE = 'Intermediate'
    ADVANCED = 'Advanced'


class SpecialPreferences(StrEnum):
    """Special preferences for the recipe."""

    HIGH_PROTEIN = 'High Protein'
    LOW_CARB = 'Low Carb'
    SPICY = 'Spicy'
    BUDGET_FRIENDLY = 'Budget-Friendly'
    ONE_POT_MEAL = 'One-Pot Meal'
    VEGETARIAN = 'Vegetarian'
    VEGAN = 'Vegan'


class CookingTime(StrEnum):
    """The cooking time of the recipe."""

    FIVE_MIN = '5 min'
    FIFTEEN_MIN = '15 min'
    THIRTY_MIN = '30 min'
    FORTY_FIVE_MIN = '45 min'
    SIXTY_PLUS_MIN = '60+ min'


class Ingredient(BaseModel):
    """A class representing an ingredient in a recipe."""

    icon: str = Field(
        default='ingredient',
        description="The icon emoji (not emoji code like '\x1f35e', but the actual emoji like 🥕) of the ingredient",
    )
    name: str
    amount: str


class Recipe(BaseModel):
    """A class representing a recipe."""

    skill_level: SkillLevel = Field(
        default=SkillLevel.BEGINNER,
        description='The skill level required for the recipe',
    )
    special_preferences: list[SpecialPreferences] = Field(
        default_factory=list,
        description='Any special preferences for the recipe',
    )
    cooking_time: CookingTime = Field(
        default=CookingTime.FIVE_MIN, description='The cooking time of the recipe'
    )
    ingredients: list[Ingredient] = Field(
        default_factory=list,
        description='Ingredients for the recipe',
    )
    instructions: list[str] = Field(
        default_factory=list, description='Instructions for the recipe'
    )


class RecipeSnapshot(BaseModel):
    """A class representing the state of the recipe."""

    recipe: Recipe = Field(
        default_factory=Recipe, description='The current state of the recipe'
    )


agent = Agent('openai:gpt-4o-mini', deps_type=StateDeps[RecipeSnapshot])


@agent.tool_plain
async def display_recipe(recipe: Recipe) -> StateSnapshotEvent:
    """Display the recipe to the user.

    Args:
        recipe: The recipe to display.

    Returns:
        StateSnapshotEvent containing the recipe snapshot.
    """
    return StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot={'recipe': recipe},
    )


@agent.instructions
async def recipe_instructions(ctx: RunContext[StateDeps[RecipeSnapshot]]) -> str:
    """Instructions for the recipe generation agent.

    Args:
        ctx: The run context containing recipe state information.

    Returns:
        Instructions string for the recipe generation agent.
    """
    return dedent(
        f"""
        You are a helpful assistant for creating recipes.

        IMPORTANT:
        - Create a complete recipe using the existing ingredients
        - Append new ingredients to the existing ones
        - Use the `display_recipe` tool to present the recipe to the user
        - Do NOT repeat the recipe in the message, use the tool instead
        - Do NOT run the `display_recipe` tool multiple times in a row

        Once you have created the updated recipe and displayed it to the user,
        summarise the changes in one sentence, don't describe the recipe in
        detail or send it as a message to the user.

        The current state of the recipe is:

        {ctx.deps.state.recipe.model_dump_json(indent=2)}
        """,
    )


app = agent.to_ag_ui(deps=StateDeps(RecipeSnapshot()))



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/tool_based_generative_ui.py
================================================
"""Tool Based Generative UI feature.

No special handling is required for this feature.
"""

from __future__ import annotations

from pydantic_ai import Agent

agent = Agent('openai:gpt-4o-mini')
app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class PydanticAIAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/server-starter/README.md
================================================
# Server Starter

This starter kit demonstrates sending the minimal set of events that are needed to stream data from the agent to the frontend.

## Running the server

To run the server:

```bash
cd typescript-sdk/integrations/server-starter/server/python

poetry install && poetry run dev
```



================================================
FILE: typescript-sdk/integrations/server-starter/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/server-starter/package.json
================================================
{
  "name": "@ag-ui/server-starter",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/server-starter/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/server-starter/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/server-starter/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server



================================================
FILE: typescript-sdk/integrations/server-starter/server/python/README.md
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter/server/python/pyproject.toml
================================================
[tool.poetry]
name = "example_server"
version = "0.1.0"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
ag-ui-protocol = "^0.1.5"
fastapi = "^0.115.12"
uvicorn = "^0.34.3"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "example_server:main"


================================================
FILE: typescript-sdk/integrations/server-starter/server/python/example_server/__init__.py
================================================
"""
Example server for the AG-UI protocol.
"""

import os
import uvicorn
import uuid
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
)
from ag_ui.encoder import EventEncoder

app = FastAPI(title="AG-UI Endpoint")

@app.post("/")
async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic chat endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():

        # Send run started event
        yield encoder.encode(
          RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

        message_id = str(uuid.uuid4())

        yield encoder.encode(
            TextMessageStartEvent(
                type=EventType.TEXT_MESSAGE_START,
                message_id=message_id,
                role="assistant"
            )
        )

        yield encoder.encode(
            TextMessageContentEvent(
                type=EventType.TEXT_MESSAGE_CONTENT,
                message_id=message_id,
                delta="Hello world!"
            )
        )

        yield encoder.encode(
            TextMessageEndEvent(
                type=EventType.TEXT_MESSAGE_END,
                message_id=message_id
            )
        )

        # Send run finished event
        yield encoder.encode(
          RunFinishedEvent(
            type=EventType.RUN_FINISHED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "example_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/server-starter/server/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class ServerStarterAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/README.md
================================================
# Server Starter (All Features)

This is a starter kit for demonstrating each feature of AG-UI by sending static events to the frontend.

## Running the server

To run the server:

```bash
cd typescript-sdk/integrations/server-starter-all-features/server/python

poetry install && poetry run dev
```

## Integrations

- **Agentic Chat**:

Demonstrates chatting with an agent and frontend tool calling. (send it a literal "tool" as a chat message to trigger the tool call)

Source: ➡️ [example_server/agentic_chat.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_chat.py)

- **Human in the Loop**:

A simple human in the loop workflow where the agent comes up with a plan and the user can approve it using checkboxes.

Source: ➡️ [example_server/human_in_the_loop.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/human_in_the_loop.py)

- **Agentic Generative UI**:

Simulates a long running task where the agent sends updates to the frontend to let the user know what's happening.

Source: ➡️ [example_server/agentic_generative_ui.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_generative_ui.py)

- **Tool Based Generative UI**:

Simulates a server tool call that is rendered in the frontend.

Source: ➡️ [example_server/tool_based_generative_ui.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/tool_based_generative_ui.py)

- **Shared State**:

Demonstrates how to use the shared state between the user and the agent.

Source: ➡️ [example_server/shared_state.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/shared_state.py)

- **Predictive State Updates**:

Demonstrates how to use the predictive state updates feature to update the state of the agent based on the user's input.

Source: ➡️ [example_server/predictive_state_updates.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/predictive_state_updates.py)



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/package.json
================================================
{
  "name": "@ag-ui/server-starter-all-features",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/README.md
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/pyproject.toml
================================================
[tool.poetry]
name = "example_server"
version = "0.1.0"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
ag-ui-protocol = {path = "../../../../../python-sdk/"}
fastapi = "^0.115.12"
uvicorn = "^0.34.3"
jsonpatch = "^1.33"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "example_server:main"


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/__init__.py
================================================
"""
Example server for the AG-UI protocol.
"""

import os
import uvicorn
from fastapi import FastAPI
from .agentic_chat import agentic_chat_endpoint
from .human_in_the_loop import human_in_the_loop_endpoint
from .agentic_generative_ui import agentic_generative_ui_endpoint
from .tool_based_generative_ui import tool_based_generative_ui_endpoint
from .shared_state import shared_state_endpoint
from .predictive_state_updates import predictive_state_updates_endpoint

app = FastAPI(title="AG-UI Endpoint")

# Register the agentic chat endpoint
app.post("/agentic_chat")(agentic_chat_endpoint)

# Register the human in the loop endpoint
app.post("/human_in_the_loop")(human_in_the_loop_endpoint)

# Register the agentic generative UI endpoint
app.post("/agentic_generative_ui")(agentic_generative_ui_endpoint)

# Register the tool-based generative UI endpoint
app.post("/tool_based_generative_ui")(tool_based_generative_ui_endpoint)

# Register the shared state endpoint
app.post("/shared_state")(shared_state_endpoint)

# Register the predictive state updates endpoint
app.post("/predictive_state_updates")(predictive_state_updates_endpoint)


def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "example_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_chat.py
================================================
"""
Agentic chat endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    MessagesSnapshotEvent,
    ToolMessage,
    ToolCall,
    AssistantMessage
)
from ag_ui.core.events import TextMessageChunkEvent
from ag_ui.encoder import EventEncoder

async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic chat endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message content for conditional logic
        last_message_content = None
        last_message_role = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]
            last_message_content = last_message.content
            last_message_role = getattr(last_message, 'role', None)

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message
        if last_message_role == "tool":
            async for event in send_tool_result_message_events():
                yield encoder.encode(event)
        elif last_message_content == "tool":
            async for event in send_tool_call_events():
                yield encoder.encode(event)
        elif last_message_content == "backend_tool":
            async for event in send_backend_tool_call_events(input_data.messages):
                yield encoder.encode(event)
        else:
            async for event in send_text_message_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_text_message_events():
    """Send text message events with countdown"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Initial content chunk
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="counting down: "
    )

    # Countdown from 10 to 1
    for count in range(10, 0, -1):
        yield TextMessageContentEvent(
            type=EventType.TEXT_MESSAGE_CONTENT,
            message_id=message_id,
            delta=f"{count}  "
        )
        # Sleep for 300ms
        await asyncio.sleep(0.3)

    # Final checkmark
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="✓"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )


async def send_tool_result_message_events():
    """Send message for tool result"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="background changed ✓"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )


async def send_tool_call_events():
    """Send tool call events"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "change_background"
    tool_call_args = {
        "background": "linear-gradient(135deg, #667eea 0%, #764ba2 100%)"
    }

    # Tool call start
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Tool call args
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta=json.dumps(tool_call_args)
    )

    # Tool call end
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )

async def send_backend_tool_call_events(messages):
    """Send backend tool call events"""
    tool_call_id = str(uuid.uuid4())

    new_message = AssistantMessage(
        id=str(uuid.uuid4()),
        role="assistant",
        tool_calls=[
            ToolCall(
                id=tool_call_id,
                type="function",
                function={
                    "name": "lookup_weather",
                    "arguments": json.dumps({"city": "San Francisco", "weather": "sunny"})
                }
            )
        ]
    )

    result_message = ToolMessage(
        id=str(uuid.uuid4()),
        role="tool",
        content="The weather in San Francisco is sunny.",
        tool_call_id=tool_call_id
    )

    all_messages = list(messages) + [new_message, result_message]

    # Send messages snapshot event
    yield MessagesSnapshotEvent(
        type=EventType.MESSAGES_SNAPSHOT,
        messages=all_messages
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_generative_ui.py
================================================
"""
Agentic generative UI endpoint for the AG-UI protocol.
"""

import asyncio
import copy
import jsonpatch
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    StateSnapshotEvent,
    StateDeltaEvent
)
from ag_ui.encoder import EventEncoder

async def agentic_generative_ui_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic generative UI endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Send state events
        async for event in send_state_events():
            yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_state_events():
    """Send state events with snapshots and deltas"""
    # Initialize state
    state = {
        "steps": [
            {
                "description": f"Step {i + 1}",
                "status": "pending"
            }
            for i in range(10)
        ]
    }

    # Send initial state snapshot
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )
    
    # Sleep for 1 second
    await asyncio.sleep(1.0)

    # Create a copy to track changes for JSON patches
    previous_state = copy.deepcopy(state)

    # Update each step and send deltas
    for i, step in enumerate(state["steps"]):
        step["status"] = "completed"
        
        # Generate JSON patch from previous state to current state
        patch = jsonpatch.make_patch(previous_state, state)
        
        # Send state delta event
        yield StateDeltaEvent(
            type=EventType.STATE_DELTA,
            delta=patch.patch
        )
        
        # Update previous state for next iteration
        previous_state = copy.deepcopy(state)
        
        # Sleep for 1 second
        await asyncio.sleep(1.0)

    # Optionally send a final snapshot to the client
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/human_in_the_loop.py
================================================
"""
Human in the loop endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent
)
from ag_ui.encoder import EventEncoder

async def human_in_the_loop_endpoint(input_data: RunAgentInput, request: Request):
    """Human in the loop endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message for conditional logic
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message role
        if last_message and getattr(last_message, 'role', None) == "tool":
            async for event in send_text_message_events():
                yield encoder.encode(event)
        else:
            async for event in send_tool_call_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_tool_call_events():
    """Send tool call events that generate task steps incrementally"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "generate_task_steps"

    # Tool call start
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Start building JSON - opening structure
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='{"steps":['
    )

    # Generate 10 steps incrementally
    for i in range(10):
        step_data = {
            "description": f"Step {i + 1}",
            "status": "enabled"
        }
        
        # Add comma separator except for the last item
        delta = json.dumps(step_data) + ("," if i != 9 else "")
        
        yield ToolCallArgsEvent(
            type=EventType.TOOL_CALL_ARGS,
            tool_call_id=tool_call_id,
            delta=delta
        )
        
        # Sleep for 200ms
        await asyncio.sleep(0.2)

    # Close JSON structure
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta="]}"
    )

    # Tool call end
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )


async def send_text_message_events():
    """Send text message events with simple response"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="Ok! I'm working on it."
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/predictive_state_updates.py
================================================
"""
Predictive state updates endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import random
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    CustomEvent
)
from ag_ui.encoder import EventEncoder

async def predictive_state_updates_endpoint(input_data: RunAgentInput, request: Request):
    """Predictive state updates endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message for conditional logic
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message role
        if last_message and getattr(last_message, 'role', None) == "tool":
            async for event in send_text_message_events():
                yield encoder.encode(event)
        else:
            async for event in send_tool_call_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


def make_story(name: str) -> str:
    """Generate a simple dog story"""
    return f"Once upon a time, there was a dog named {name}. {name} was a very good dog."


# List of dog names for random selection
dog_names = ["Rex", "Buddy", "Max", "Charlie", "Buddy", "Max", "Charlie"]


async def send_tool_call_events():
    """Send tool call events with predictive state and incremental story generation"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "write_document_local"

    # Generate a random story
    story = make_story(random.choice(dog_names))
    story_chunks = story.split(" ")

    # Send custom predict state event first
    yield CustomEvent(
        type=EventType.CUSTOM,
        name="PredictState",
        value=[
            {
                "state_key": "document",
                "tool": "write_document_local",
                "tool_argument": "document"
            }
        ]
    )

    # First tool call: write_document_local
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Start JSON arguments
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='{"document":"'
    )

    # Send story chunks incrementally
    for chunk in story_chunks:
        yield ToolCallArgsEvent(
            type=EventType.TOOL_CALL_ARGS,
            tool_call_id=tool_call_id,
            delta=chunk + " "
        )
        await asyncio.sleep(0.2)  # 200ms delay

    # Close JSON arguments
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='"}'
    )

    # End first tool call
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )

    # Second tool call: confirm_changes
    tool_call_id_2 = str(uuid.uuid4())
    tool_call_name_2 = "confirm_changes"

    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id_2,
        tool_call_name=tool_call_name_2
    )

    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id_2,
        delta="{}"
    )

    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id_2
    )


async def send_text_message_events():
    """Send simple text message events"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="Ok!"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/shared_state.py
================================================
"""
Shared state endpoint for the AG-UI protocol.
"""

from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    StateSnapshotEvent
)
from ag_ui.encoder import EventEncoder

async def shared_state_endpoint(input_data: RunAgentInput, request: Request):
    """Shared state endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Send state events
        async for event in send_state_events():
            yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_state_events():
    """Send state events with recipe data"""
    # Define the recipe state
    state = {
        "recipe": {
            "skill_level": "Advanced",
            "special_preferences": ["Low Carb", "Spicy"],
            "cooking_time": "15 min",
            "ingredients": [
                {
                    "icon": "🍗",
                    "name": "chicken breast",
                    "amount": "1",
                },
                {
                    "icon": "🌶️",
                    "name": "chili powder",
                    "amount": "1 tsp",
                },
                {
                    "icon": "🧂",
                    "name": "Salt",
                    "amount": "a pinch",
                },
                {
                    "icon": "🥬",
                    "name": "Lettuce leaves",
                    "amount": "handful",
                },
            ],
            "instructions": [
                "Season chicken with chili powder and salt.",
                "Sear until fully cooked.",
                "Slice and wrap in lettuce.",
            ]
        }
    }

    # Send state snapshot event
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/tool_based_generative_ui.py
================================================
"""
Tool-based generative UI endpoint for the AG-UI protocol.
"""

import uuid
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    MessagesSnapshotEvent
)
from ag_ui.encoder import EventEncoder

async def tool_based_generative_ui_endpoint(input_data: RunAgentInput, request: Request):
    """Tool-based generative UI endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Check if last message was a tool result
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        result_message = None

        # Determine what type of message to send
        if last_message and getattr(last_message, 'content', None) == "thanks":
            # Send text message for tool result
            message_id = str(uuid.uuid4())
            new_message = {
                "id": message_id,
                "role": "assistant",
                "content": "Haiku created"
            }
        else:
            # Send tool call message
            tool_call_id = str(uuid.uuid4())
            message_id = str(uuid.uuid4())

            # Prepare haiku arguments
            haiku_args = {
                "japanese": ["エーアイの", "橋つなぐ道", "コパキット"],
                "english": [
                    "From AI's realm",
                    "A bridge-road linking us—",
                    "CopilotKit."
                ]
            }

            # Create new assistant message with tool call
            new_message = {
                "id": message_id,
                "role": "assistant",
                "tool_calls": [
                    {
                        "id": tool_call_id,
                        "type": "function",
                        "function": {
                            "name": "generate_haiku",
                            "arguments": json.dumps(haiku_args)
                        }
                    }
                ]
            }

            result_message = {
                "id": str(uuid.uuid4()),
                "role": "tool",
                "tool_call_id": tool_call_id,
                "content": "Haiku created"
            }

        # Create messages list with input messages plus the new message
        all_messages = list(input_data.messages) + [new_message]

        if result_message:
            all_messages.append(result_message)

        # Send messages snapshot event
        yield encoder.encode(
            MessagesSnapshotEvent(
                type=EventType.MESSAGES_SNAPSHOT,
                messages=all_messages
            ),
        )

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class ServerStarterAllFeaturesAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/README.md
================================================
# @ag-ui/vercel-ai-sdk

Implementation of the AG-UI protocol for Vercel AI SDK.

Connects Vercel AI SDK models and tools to frontend applications via the AG-UI protocol. Provides native TypeScript integration with streamText, tool execution, and multi-step workflows.

## Installation

```bash
npm install @ag-ui/vercel-ai-sdk
pnpm add @ag-ui/vercel-ai-sdk
yarn add @ag-ui/vercel-ai-sdk
```

## Usage

```ts
import { VercelAISDKAgent } from "@ag-ui/vercel-ai-sdk";
import { openai } from "ai/openai";

// Create an AG-UI compatible agent
const agent = new VercelAISDKAgent({
  model: openai("gpt-4"),
  maxSteps: 3,
  toolChoice: "auto",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Help me with a task" }],
});
```

## Features

- **Native TypeScript** – Direct integration with Vercel AI SDK models
- **Streaming support** – Real-time text and tool call streaming
- **Multi-step workflows** – Automatic tool execution chains
- **Model flexibility** – Works with OpenAI, Anthropic, and other providers

## To run the example server in the dojo

```bash
# Use directly in TypeScript applications
# No separate server needed
```



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/package.json
================================================
{
  "name": "@ag-ui/vercel-ai-sdk",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  },
  "dependencies": {
    "ai": "^4.3.16",
    "zod": "^3.22.4"
  }
}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/src/index.ts
================================================
import {
  AgentConfig,
  AbstractAgent,
  EventType,
  BaseEvent,
  Message,
  AssistantMessage,
  RunAgentInput,
  MessagesSnapshotEvent,
  RunFinishedEvent,
  RunStartedEvent,
  TextMessageChunkEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
  ToolCall,
  ToolMessage,
} from "@ag-ui/client";
import { Observable } from "rxjs";
import {
  CoreMessage,
  LanguageModelV1,
  processDataStream,
  streamText,
  tool as createVercelAISDKTool,
  ToolChoice,
  ToolSet,
} from "ai";
import { randomUUID } from "crypto";
import { z } from "zod";

type ProcessedEvent =
  | MessagesSnapshotEvent
  | RunFinishedEvent
  | RunStartedEvent
  | TextMessageChunkEvent
  | ToolCallArgsEvent
  | ToolCallEndEvent
  | ToolCallStartEvent;

interface VercelAISDKAgentConfig extends AgentConfig {
  model: LanguageModelV1;
  maxSteps?: number;
  toolChoice?: ToolChoice<Record<string, unknown>>;
}

export class VercelAISDKAgent extends AbstractAgent {
  model: LanguageModelV1;
  maxSteps: number;
  toolChoice: ToolChoice<Record<string, unknown>>;
  constructor({ model, maxSteps, toolChoice, ...rest }: VercelAISDKAgentConfig) {
    super({ ...rest });
    this.model = model;
    this.maxSteps = maxSteps ?? 1;
    this.toolChoice = toolChoice ?? "auto";
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const finalMessages: Message[] = input.messages;

    return new Observable<ProcessedEvent>((subscriber) => {
      subscriber.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as RunStartedEvent);

      const response = streamText({
        model: this.model,
        messages: convertMessagesToVercelAISDKMessages(input.messages),
        tools: convertToolToVerlAISDKTools(input.tools),
        maxSteps: this.maxSteps,
        toolChoice: this.toolChoice,
      });

      let messageId = randomUUID();
      let assistantMessage: AssistantMessage = {
        id: messageId,
        role: "assistant",
        content: "",
        toolCalls: [],
      };
      finalMessages.push(assistantMessage);

      processDataStream({
        stream: response.toDataStreamResponse().body!,
        onTextPart: (text) => {
          assistantMessage.content += text;
          const event: TextMessageChunkEvent = {
            type: EventType.TEXT_MESSAGE_CHUNK,
            role: "assistant",
            messageId,
            delta: text,
          };
          subscriber.next(event);
        },
        onFinishMessagePart: () => {
          // Emit message snapshot
          const event: MessagesSnapshotEvent = {
            type: EventType.MESSAGES_SNAPSHOT,
            messages: finalMessages,
          };
          subscriber.next(event);

          // Emit run finished event
          subscriber.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
          } as RunFinishedEvent);

          // Complete the observable
          subscriber.complete();
        },
        onToolCallPart(streamPart) {
          let toolCall: ToolCall = {
            id: streamPart.toolCallId,
            type: "function",
            function: {
              name: streamPart.toolName,
              arguments: JSON.stringify(streamPart.args),
            },
          };
          assistantMessage.toolCalls!.push(toolCall);

          const startEvent: ToolCallStartEvent = {
            type: EventType.TOOL_CALL_START,
            parentMessageId: messageId,
            toolCallId: streamPart.toolCallId,
            toolCallName: streamPart.toolName,
          };
          subscriber.next(startEvent);

          const argsEvent: ToolCallArgsEvent = {
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: streamPart.toolCallId,
            delta: JSON.stringify(streamPart.args),
          };
          subscriber.next(argsEvent);

          const endEvent: ToolCallEndEvent = {
            type: EventType.TOOL_CALL_END,
            toolCallId: streamPart.toolCallId,
          };
          subscriber.next(endEvent);
        },
        onToolResultPart(streamPart) {
          const toolMessage: ToolMessage = {
            role: "tool",
            id: randomUUID(),
            toolCallId: streamPart.toolCallId,
            content: JSON.stringify(streamPart.result),
          };
          finalMessages.push(toolMessage);
        },
        onErrorPart(streamPart) {
          subscriber.error(streamPart);
        },
      }).catch((error) => {
        console.error("catch error", error);
        // Handle error
        subscriber.error(error);
      });

      return () => {};
    });
  }
}

export function convertMessagesToVercelAISDKMessages(messages: Message[]): CoreMessage[] {
  const result: CoreMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant") {
      const parts: any[] = message.content ? [{ type: "text", text: message.content }] : [];
      for (const toolCall of message.toolCalls ?? []) {
        parts.push({
          type: "tool-call",
          toolCallId: toolCall.id,
          toolName: toolCall.function.name,
          args: JSON.parse(toolCall.function.arguments),
        });
      }
      result.push({
        role: "assistant",
        content: parts,
      });
    } else if (message.role === "user") {
      result.push({
        role: "user",
        content: message.content || "",
      });
    } else if (message.role === "tool") {
      let toolName = "unknown";
      for (const msg of messages) {
        if (msg.role === "assistant") {
          for (const toolCall of msg.toolCalls ?? []) {
            if (toolCall.id === message.toolCallId) {
              toolName = toolCall.function.name;
              break;
            }
          }
        }
      }
      result.push({
        role: "tool",
        content: [
          {
            type: "tool-result",
            toolCallId: message.toolCallId,
            toolName: toolName,
            result: message.content,
          },
        ],
      });
    }
  }

  return result;
}

export function convertJsonSchemaToZodSchema(jsonSchema: any, required: boolean): z.ZodSchema {
  if (jsonSchema.type === "object") {
    const spec: { [key: string]: z.ZodSchema } = {};

    if (!jsonSchema.properties || !Object.keys(jsonSchema.properties).length) {
      return !required ? z.object(spec).optional() : z.object(spec);
    }

    for (const [key, value] of Object.entries(jsonSchema.properties)) {
      spec[key] = convertJsonSchemaToZodSchema(
        value,
        jsonSchema.required ? jsonSchema.required.includes(key) : false,
      );
    }
    let schema = z.object(spec).describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "string") {
    let schema = z.string().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "number") {
    let schema = z.number().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "boolean") {
    let schema = z.boolean().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "array") {
    let itemSchema = convertJsonSchemaToZodSchema(jsonSchema.items, true);
    let schema = z.array(itemSchema).describe(jsonSchema.description);
    return required ? schema : schema.optional();
  }
  throw new Error("Invalid JSON schema");
}

export function convertToolToVerlAISDKTools(tools: RunAgentInput["tools"]): ToolSet {
  return tools.reduce(
    (acc: ToolSet, tool: RunAgentInput["tools"][number]) => ({
      ...acc,
      [tool.name]: createVercelAISDKTool({
        description: tool.description,
        parameters: convertJsonSchemaToZodSchema(tool.parameters, true),
      }),
    }),
    {},
  );
}



================================================
FILE: typescript-sdk/packages/cli/README.md
================================================
# create-ag-ui-app

CLI tool for scaffolding **Agent-User Interaction (AG-UI) Protocol** applications.

`create-ag-ui-app` provides an interactive setup wizard to quickly bootstrap AG-UI projects with your preferred client framework and agent backend. 

Choose from CopilotKit/Next.js for web apps or CLI clients for terminal-based interactions.

## Usage

```bash
npx create-ag-ui-app@latest
pnpx create-ag-ui-app@latest
bunx create-ag-ui-app@latest
```

## Features

- 🎯 **Interactive setup** – Guided prompts for client and framework selection
- 🌐 **Multiple clients** – CopilotKit/Next.js web apps and CLI clients
- 🔧 **Framework integration** – Built-in support for LangGraph, CrewAI, Mastra, Agno, LlamaIndex, and more
- 📦 **Zero config** – Automatically sets up dependencies and project structure
- ⚡ **Quick start** – Get from idea to running app in minutes

## Quick example

```bash
# Interactive setup
npx create-ag-ui-app@latest

# With framework flags
npx create-ag-ui-app@latest --langgraph-py
npx create-ag-ui-app@latest --mastra

# See all options
npx create-ag-ui-app@latest --help
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/events`](https://docs.ag-ui.com/concepts/events)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://github.com/ag-ui-protocol/ag-ui/blob/main/CONTRIBUTING.md) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/cli/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/packages/cli/package.json
================================================
{
  "name": "create-ag-ui-app",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "bin": "./dist/index.mjs",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@types/inquirer": "^9.0.8",
    "commander": "^12.1.0",
    "inquirer": "^12.6.3",
    "giget": "2.0.0"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/packages/cli/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/cli/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/packages/cli/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/cli/src/index.ts
================================================
#!/usr/bin/env node
import { Command } from "commander";
import inquirer from "inquirer";
import { spawn } from "child_process";
import fs from "fs";
import path from "path";
import { downloadTemplate } from "giget";

const program = new Command();

// Dark purple color
const PURPLE = "\x1b[35m";
const RESET = "\x1b[0m";

function displayBanner() {
  const banner = `
${PURPLE}   █████╗  ██████╗       ██╗   ██╗ ██╗
  ██╔══██╗██╔════╝       ██║   ██║ ██║
  ███████║██║  ███╗█████╗██║   ██║ ██║
  ██╔══██║██║   ██║╚════╝██║   ██║ ██║
  ██║  ██║╚██████╔╝      ╚██████╔╝ ██║
  ╚═╝  ╚═╝ ╚═════╝        ╚═════╝  ╚═╝
${RESET}
  Agent User Interactivity Protocol
`;
  console.log(banner);
}

const description = `
Quickly scaffold AG-UI enabled applications for your favorite agent frameworks.
`

async function createProject() {
  displayBanner();

  console.log("\n~ Let's get started building an AG-UI powered user interactive agent ~");
  console.log("  Read more about AG-UI at https://ag-ui.com\n");

  const options = program.opts();
  const isFrameworkDefined = [
    "langgraphPy",
    "langgraphJs",
    "crewaiFlows",
    "mastra",
    "ag2",
    "llamaindex",
    "pydanticAi",
    "agno"
  ].some(flag => options[flag]);

  if (isFrameworkDefined) {
    await handleCopilotKitNextJs();
    return;
  } else {
    console.log("");
    console.log("To build an AG-UI app, you need to select a client.");
    console.log("");
  }

  const answers = await inquirer.prompt([
    {
      type: "list",
      name: "client",
      message: "What client do you want to use?",
      choices: [
        "CopilotKit/Next.js",
        "CLI client",
        new inquirer.Separator(" Other clients coming soon (SMS, Whatsapp, Slack ...)"),
      ],
    },
  ]);

  switch (answers.client) {
    case "CopilotKit/Next.js":
      await handleCopilotKitNextJs();
      break;
    case "CLI client":
      await handleCliClient();
      break;
    default:
      break;
  }
}

async function handleCopilotKitNextJs() {
  const options = program.opts();
  const frameworkArgs: string[] = [];

  const projectName = await inquirer.prompt([
    {
      type: "input",
      name: "name",
      message: "What would you like to name your project?",
      default: "my-ag-ui-app",
      validate: (input) => {
        if (!input.trim()) {
          return "Project name cannot be empty";
        }
        if (!/^[a-zA-Z0-9-_]+$/.test(input)) {
          return "Project name can only contain letters, numbers, hyphens, and underscores";
        }
        return true;
      },
    },
  ]);

  // Translate options to CopilotKit framework flags
  if (options.langgraphPy) {
    frameworkArgs.push("-f", "langgraph-py");
  } else if (options.langgraphJs) {
    frameworkArgs.push("-f", "langgraph-js");
  } else if (options.crewiAiFlows) {
    frameworkArgs.push("-f", "flows");
  } else if (options.mastra) {
    frameworkArgs.push("-f", "mastra");
  } else if (options.ag2) {
    frameworkArgs.push("-f", "ag2");
  } else if (options.llamaindex) {
    frameworkArgs.push("-f", "llamaindex");
  } else if (options.agno) {
    frameworkArgs.push("-f", "agno");
  } else if (options.pydanticAi) {
    frameworkArgs.push("-f", "pydantic-ai");
  }

  const copilotkit = spawn("npx", 
    [
      "copilotkit@latest",
      "create",
      "--no-banner",
      "-n", projectName.name,
      ...frameworkArgs,
    ],
    {
      stdio: "inherit",
      shell: true,
    },
  );

  copilotkit.on("close", (code) => {
    if (code !== 0) {
      console.log("\n❌ Project creation failed.");
    }
  });
}

async function handleCliClient() {
  console.log("🔧 Setting up CLI client...\n");

  // Get current package versions from the monorepo
  console.log("🔍 Reading current package versions...");
  const versions = await getCurrentPackageVersions();
  console.log(`📋 Found versions: ${Object.keys(versions).length} packages`);
  Object.entries(versions).forEach(([name, version]) => {
    console.log(`  - ${name}: ${version}`);
  });
  console.log("");

  const projectName = await inquirer.prompt([
    {
      type: "input",
      name: "name",
      message: "What would you like to name your CLI project?",
      default: "my-ag-ui-cli-app",
      validate: (input) => {
        if (!input.trim()) {
          return "Project name cannot be empty";
        }
        if (!/^[a-zA-Z0-9-_]+$/.test(input)) {
          return "Project name can only contain letters, numbers, hyphens, and underscores";
        }
        return true;
      },
    },
  ]);

  try {
    console.log(`📥 Downloading CLI client template: ${projectName.name}\n`);

    await downloadTemplate("gh:ag-ui-protocol/ag-ui/typescript-sdk/apps/client-cli-example", {
      dir: projectName.name,
      install: false,
    });

    console.log("✅ CLI client template downloaded successfully!");

    // Update workspace dependencies with actual versions
    console.log("\n🔄 Updating workspace dependencies...");
    await updateWorkspaceDependencies(projectName.name, versions);

    console.log(`\n📁 Project created in: ${projectName.name}`);
    console.log("\n🚀 Next steps:");
    console.log("   export OPENAI_API_KEY='your-openai-api-key'");
    console.log(`   cd ${projectName.name}`);
    console.log("   npm install");
    console.log("   npm run dev");
    console.log("\n💡 Check the README.md for more information on how to use your CLI client!");
  } catch (error) {
    console.log("❌ Failed to download CLI client template:", error);
    process.exit(1);
  }
}

// Metadata
program
  .name("create-ag-ui-app")
  .description(description)
  .version("0.0.36");

// Add framework flags
program
  .option("--langgraph-py", "Use the LangGraph framework with Python")
  .option("--langgraph-js", "Use the LangGraph framework with JavaScript")
  .option("--crewai-flows", "Use the CrewAI framework with Flows")
  .option("--mastra", "Use the Mastra framework")
  .option("--pydantic-ai", "Use the Pydantic AI framework")
  .option("--llamaindex", "Use the LlamaIndex framework")
  .option("--agno", "Use the Agno framework")
  .option("--ag2", "Use the AG2 framework")

program.action(async () => {
  await createProject();
});

program.parse();

// Utility functions

// Helper function to get package versions from npmjs
async function getCurrentPackageVersions(): Promise<{ [key: string]: string }> {
  const packages = ["@ag-ui/client", "@ag-ui/core", "@ag-ui/mastra"];
  const versions: { [key: string]: string } = {};

  for (const packageName of packages) {
    try {
      // Fetch package info from npm registry
      const response = await fetch(`https://registry.npmjs.org/${packageName}`);
      if (response.ok) {
        const packageInfo = await response.json();
        versions[packageName] = packageInfo["dist-tags"]?.latest || "latest";
        console.log(`  ✓ ${packageName}: ${versions[packageName]}`);
      } else {
        console.log(`  ⚠️  Could not fetch version for ${packageName}`);
        // Fallback to latest
        versions[packageName] = "latest";
      }
    } catch (error) {
      console.log(`  ⚠️  Error fetching ${packageName}: ${error}`);
      // Fallback to latest
      versions[packageName] = "latest";
    }
  }

  return versions;
}

// Function to update workspace dependencies in downloaded project
async function updateWorkspaceDependencies(
  projectPath: string,
  versions: { [key: string]: string },
) {
  const packageJsonPath = path.join(projectPath, "package.json");

  try {
    if (!fs.existsSync(packageJsonPath)) {
      console.log("⚠️  No package.json found in downloaded project");
      return;
    }

    const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, "utf-8"));
    let updated = false;

    // Update workspace dependencies with actual versions
    if (packageJson.dependencies) {
      for (const [depName, depVersion] of Object.entries(packageJson.dependencies)) {
        if (
          typeof depVersion === "string" &&
          depVersion.startsWith("workspace:") &&
          versions[depName]
        ) {
          packageJson.dependencies[depName] = `^${versions[depName]}`;
          updated = true;
          console.log(`  📦 Updated ${depName}: workspace:* → ^${versions[depName]}`);
        }
      }
    }

    if (updated) {
      fs.writeFileSync(packageJsonPath, JSON.stringify(packageJson, null, 2) + "\n");
      console.log("✅ Package.json updated with actual package versions!");
    } else {
      console.log("📄 No workspace dependencies found to update");
    }
  } catch (error) {
    console.log(`❌ Error updating package.json: ${error}`);
  }
}



================================================
FILE: typescript-sdk/packages/client/README.md
================================================
# @ag-ui/client

Client SDK for connecting to **Agent-User Interaction (AG-UI) Protocol** servers.

`@ag-ui/client` provides agent implementations that handle the full lifecycle of AG-UI communication: connecting to servers, processing streaming events, managing state mutations, and providing reactive subscriber hooks.

## Installation

```bash
npm install @ag-ui/client
pnpm add @ag-ui/client
yarn add @ag-ui/client
```

## Features

- 🔗 **HTTP connectivity** – `HttpAgent` for direct server connections with SSE/protobuf support
- 🏗️ **Custom agents** – `AbstractAgent` base class for building your own transport layer
- 📡 **Event streaming** – Full AG-UI event processing with validation and transformation
- 🔄 **State management** – Automatic message/state tracking with reactive updates
- 🪝 **Subscriber system** – Middleware-style hooks for logging, persistence, and custom logic

## Quick example

```ts
import { HttpAgent } from "@ag-ui/client";

const agent = new HttpAgent({
  url: "https://api.example.com/agent",
  headers: { Authorization: "Bearer token" },
});

const result = await agent.runAgent({
  messages: [{ role: "user", content: "Hello!" }],
});

console.log(result.newMessages);
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/client`](https://docs.ag-ui.com/sdk/js/client/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/client/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/packages/client/package.json
================================================
{
  "name": "@ag-ui/client",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.37",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/proto": "workspace:*",
    "@ag-ui/encoder": "workspace:*",
    "@types/uuid": "^10.0.0",
    "fast-json-patch": "^3.1.1",
    "rxjs": "7.8.1",
    "untruncate-json": "^0.0.1",
    "uuid": "^11.1.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/packages/client/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src", "../core/src/subscriber.ts"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/client/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
  minify: !options.watch, // Don't minify in watch mode for faster builds
}));



================================================
FILE: typescript-sdk/packages/client/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/client/src/index.ts
================================================
export * from "./apply";
export * from "./verify";
export * from "./transform";
export * from "./run";
export * from "./legacy";
export * from "./agent";
export * from "@ag-ui/core";



================================================
FILE: typescript-sdk/packages/client/src/utils.ts
================================================
export const structuredClone_ = <T>(obj: T): T => {
  if (typeof structuredClone === "function") {
    return structuredClone(obj);
  }

  try {
    return JSON.parse(JSON.stringify(obj));
  } catch (err) {
    return { ...obj } as T;
  }
};



================================================
FILE: typescript-sdk/packages/client/src/agent/agent.ts
================================================
import { defaultApplyEvents } from "@/apply/default";
import { Message, State, RunAgentInput, BaseEvent, ToolCall, AssistantMessage } from "@ag-ui/core";

import { AgentConfig, RunAgentParameters } from "./types";
import { v4 as uuidv4 } from "uuid";
import { structuredClone_ } from "@/utils";
import { catchError, map, tap } from "rxjs/operators";
import { finalize } from "rxjs/operators";
import { pipe, Observable, from, of } from "rxjs";
import { verifyEvents } from "@/verify";
import { convertToLegacyEvents } from "@/legacy/convert";
import { LegacyRuntimeProtocolEvent } from "@/legacy/types";
import { lastValueFrom } from "rxjs";
import { transformChunks } from "@/chunks";
import { AgentStateMutation, AgentSubscriber, runSubscribersWithMutation } from "./subscriber";

export interface RunAgentResult {
  result: any;
  newMessages: Message[];
}

export abstract class AbstractAgent {
  public agentId?: string;
  public description: string;
  public threadId: string;
  public messages: Message[];
  public state: State;
  public debug: boolean = false;
  public subscribers: AgentSubscriber[] = [];

  constructor({
    agentId,
    description,
    threadId,
    initialMessages,
    initialState,
    debug,
  }: AgentConfig = {}) {
    this.agentId = agentId;
    this.description = description ?? "";
    this.threadId = threadId ?? uuidv4();
    this.messages = structuredClone_(initialMessages ?? []);
    this.state = structuredClone_(initialState ?? {});
    this.debug = debug ?? false;
  }

  public subscribe(subscriber: AgentSubscriber) {
    this.subscribers.push(subscriber);
    return {
      unsubscribe: () => {
        this.subscribers = this.subscribers.filter((s) => s !== subscriber);
      },
    };
  }

  protected abstract run(input: RunAgentInput): Observable<BaseEvent>;

  public async runAgent(
    parameters?: RunAgentParameters,
    subscriber?: AgentSubscriber,
  ): Promise<RunAgentResult> {
    this.agentId = this.agentId ?? uuidv4();
    const input = this.prepareRunAgentInput(parameters);
    let result: any = undefined;
    const currentMessageIds = new Set(this.messages.map((message) => message.id));

    const subscribers: AgentSubscriber[] = [
      {
        onRunFinishedEvent: (params) => {
          result = params.result;
        },
      },
      ...this.subscribers,
      subscriber ?? {},
    ];

    await this.onInitialize(input, subscribers);

    const pipeline = pipe(
      () => this.run(input),
      transformChunks(this.debug),
      verifyEvents(this.debug),
      (source$) => this.apply(input, source$, subscribers),
      (source$) => this.processApplyEvents(input, source$, subscribers),
      catchError((error) => {
        return this.onError(input, error, subscribers);
      }),
      finalize(() => {
        void this.onFinalize(input, subscribers);
      }),
    );

    return lastValueFrom(pipeline(of(null))).then(() => {
      const newMessages = structuredClone_(this.messages).filter(
        (message: Message) => !currentMessageIds.has(message.id),
      );
      return { result, newMessages };
    });
  }

  public abortRun() {}

  protected apply(
    input: RunAgentInput,
    events$: Observable<BaseEvent>,
    subscribers: AgentSubscriber[],
  ): Observable<AgentStateMutation> {
    return defaultApplyEvents(input, events$, this, subscribers);
  }

  protected processApplyEvents(
    input: RunAgentInput,
    events$: Observable<AgentStateMutation>,
    subscribers: AgentSubscriber[],
  ): Observable<AgentStateMutation> {
    return events$.pipe(
      tap((event) => {
        if (event.messages) {
          this.messages = event.messages;
          subscribers.forEach((subscriber) => {
            subscriber.onMessagesChanged?.({
              messages: this.messages,
              state: this.state,
              agent: this,
              input,
            });
          });
        }
        if (event.state) {
          this.state = event.state;
          subscribers.forEach((subscriber) => {
            subscriber.onStateChanged?.({
              state: this.state,
              messages: this.messages,
              agent: this,
              input,
            });
          });
        }
      }),
    );
  }

  protected prepareRunAgentInput(parameters?: RunAgentParameters): RunAgentInput {
    return {
      threadId: this.threadId,
      runId: parameters?.runId || uuidv4(),
      tools: structuredClone_(parameters?.tools ?? []),
      context: structuredClone_(parameters?.context ?? []),
      forwardedProps: structuredClone_(parameters?.forwardedProps ?? {}),
      state: structuredClone_(this.state),
      messages: structuredClone_(this.messages),
    };
  }

  protected async onInitialize(input: RunAgentInput, subscribers: AgentSubscriber[]) {
    const onRunInitializedMutation = await runSubscribersWithMutation(
      subscribers,
      this.messages,
      this.state,
      (subscriber, messages, state) =>
        subscriber.onRunInitialized?.({ messages, state, agent: this, input }),
    );
    if (
      onRunInitializedMutation.messages !== undefined ||
      onRunInitializedMutation.state !== undefined
    ) {
      if (onRunInitializedMutation.messages) {
        this.messages = onRunInitializedMutation.messages;
        input.messages = onRunInitializedMutation.messages;
        subscribers.forEach((subscriber) => {
          subscriber.onMessagesChanged?.({
            messages: this.messages,
            state: this.state,
            agent: this,
            input,
          });
        });
      }
      if (onRunInitializedMutation.state) {
        this.state = onRunInitializedMutation.state;
        input.state = onRunInitializedMutation.state;
        subscribers.forEach((subscriber) => {
          subscriber.onStateChanged?.({
            state: this.state,
            messages: this.messages,
            agent: this,
            input,
          });
        });
      }
    }
  }

  protected onError(input: RunAgentInput, error: Error, subscribers: AgentSubscriber[]) {
    return from(
      runSubscribersWithMutation(
        subscribers,
        this.messages,
        this.state,
        (subscriber, messages, state) =>
          subscriber.onRunFailed?.({ error, messages, state, agent: this, input }),
      ),
    ).pipe(
      map((onRunFailedMutation) => {
        const mutation = onRunFailedMutation as AgentStateMutation;
        if (mutation.messages !== undefined || mutation.state !== undefined) {
          if (mutation.messages !== undefined) {
            this.messages = mutation.messages;
            subscribers.forEach((subscriber) => {
              subscriber.onMessagesChanged?.({
                messages: this.messages,
                state: this.state,
                agent: this,
                input,
              });
            });
          }
          if (mutation.state !== undefined) {
            this.state = mutation.state;
            subscribers.forEach((subscriber) => {
              subscriber.onStateChanged?.({
                state: this.state,
                messages: this.messages,
                agent: this,
                input,
              });
            });
          }
        }

        if (mutation.stopPropagation !== true) {
          console.error("Agent execution failed:", error);
          throw error;
        }

        // Return an empty mutation instead of null to prevent EmptyError
        return {} as AgentStateMutation;
      }),
    );
  }

  protected async onFinalize(input: RunAgentInput, subscribers: AgentSubscriber[]) {
    const onRunFinalizedMutation = await runSubscribersWithMutation(
      subscribers,
      this.messages,
      this.state,
      (subscriber, messages, state) =>
        subscriber.onRunFinalized?.({ messages, state, agent: this, input }),
    );

    if (
      onRunFinalizedMutation.messages !== undefined ||
      onRunFinalizedMutation.state !== undefined
    ) {
      if (onRunFinalizedMutation.messages !== undefined) {
        this.messages = onRunFinalizedMutation.messages;
        subscribers.forEach((subscriber) => {
          subscriber.onMessagesChanged?.({
            messages: this.messages,
            state: this.state,
            agent: this,
            input,
          });
        });
      }
      if (onRunFinalizedMutation.state !== undefined) {
        this.state = onRunFinalizedMutation.state;
        subscribers.forEach((subscriber) => {
          subscriber.onStateChanged?.({
            state: this.state,
            messages: this.messages,
            agent: this,
            input,
          });
        });
      }
    }
  }

  public clone() {
    const cloned = Object.create(Object.getPrototypeOf(this));

    for (const key of Object.getOwnPropertyNames(this)) {
      const value = (this as any)[key];
      if (typeof value !== "function") {
        cloned[key] = structuredClone_(value);
      }
    }

    return cloned;
  }

  public addMessage(message: Message) {
    // Add message to the messages array
    this.messages.push(message);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onNewMessage sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onNewMessage?.({
          message,
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }

      // Fire onNewToolCall if the message is from assistant and contains tool calls
      if (message.role === "assistant" && message.toolCalls) {
        for (const toolCall of message.toolCalls) {
          for (const subscriber of this.subscribers) {
            await subscriber.onNewToolCall?.({
              toolCall,
              messages: this.messages,
              state: this.state,
              agent: this,
            });
          }
        }
      }

      // Fire onMessagesChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public addMessages(messages: Message[]) {
    // Add all messages to the messages array
    this.messages.push(...messages);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onNewMessage and onNewToolCall for each message sequentially
      for (const message of messages) {
        // Fire onNewMessage sequentially
        for (const subscriber of this.subscribers) {
          await subscriber.onNewMessage?.({
            message,
            messages: this.messages,
            state: this.state,
            agent: this,
          });
        }

        // Fire onNewToolCall if the message is from assistant and contains tool calls
        if (message.role === "assistant" && message.toolCalls) {
          for (const toolCall of message.toolCalls) {
            for (const subscriber of this.subscribers) {
              await subscriber.onNewToolCall?.({
                toolCall,
                messages: this.messages,
                state: this.state,
                agent: this,
              });
            }
          }
        }
      }

      // Fire onMessagesChanged once at the end sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public setMessages(messages: Message[]) {
    // Replace the entire messages array
    this.messages = structuredClone_(messages);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onMessagesChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public setState(state: State) {
    // Replace the entire state
    this.state = structuredClone_(state);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onStateChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onStateChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public legacy_to_be_removed_runAgentBridged(
    config?: RunAgentParameters,
  ): Observable<LegacyRuntimeProtocolEvent> {
    this.agentId = this.agentId ?? uuidv4();
    const input = this.prepareRunAgentInput(config);

    return this.run(input).pipe(
      transformChunks(this.debug),
      verifyEvents(this.debug),
      convertToLegacyEvents(this.threadId, input.runId, this.agentId),
      (events$: Observable<LegacyRuntimeProtocolEvent>) => {
        return events$.pipe(
          map((event) => {
            if (this.debug) {
              console.debug("[LEGACY]:", JSON.stringify(event));
            }
            return event;
          }),
        );
      },
    );
  }
}



================================================
FILE: typescript-sdk/packages/client/src/agent/http.ts
================================================
import { AbstractAgent, RunAgentResult } from "./agent";
import { runHttpRequest } from "@/run/http-request";
import { HttpAgentConfig, RunAgentParameters } from "./types";
import { RunAgentInput, BaseEvent } from "@ag-ui/core";
import { structuredClone_ } from "@/utils";
import { transformHttpEventStream } from "@/transform/http";
import { Observable } from "rxjs";
import { AgentSubscriber } from "./subscriber";

interface RunHttpAgentConfig extends RunAgentParameters {
  abortController?: AbortController;
}

export class HttpAgent extends AbstractAgent {
  public url: string;
  public headers: Record<string, string>;
  public abortController: AbortController = new AbortController();

  /**
   * Returns the fetch config for the http request.
   * Override this to customize the request.
   *
   * @returns The fetch config for the http request.
   */
  protected requestInit(input: RunAgentInput): RequestInit {
    return {
      method: "POST",
      headers: {
        ...this.headers,
        "Content-Type": "application/json",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: this.abortController.signal,
    };
  }

  public runAgent(
    parameters?: RunHttpAgentConfig,
    subscriber?: AgentSubscriber,
  ): Promise<RunAgentResult> {
    this.abortController = parameters?.abortController ?? new AbortController();
    return super.runAgent(parameters, subscriber);
  }

  abortRun() {
    this.abortController.abort();
    super.abortRun();
  }

  constructor(config: HttpAgentConfig) {
    super(config);
    this.url = config.url;
    this.headers = structuredClone_(config.headers ?? {});
  }

  run(input: RunAgentInput): Observable<BaseEvent> {
    const httpEvents = runHttpRequest(this.url, this.requestInit(input));
    return transformHttpEventStream(httpEvents);
  }
}



================================================
FILE: typescript-sdk/packages/client/src/agent/index.ts
================================================
export { AbstractAgent } from "./agent";
export type { RunAgentResult } from "./agent";
export { HttpAgent } from "./http";
export type { AgentConfig, HttpAgentConfig, RunAgentParameters } from "./types";



================================================
FILE: typescript-sdk/packages/client/src/agent/subscriber.ts
================================================
import {
  BaseEvent,
  Message,
  RunAgentInput,
  RunErrorEvent,
  RunFinishedEvent,
  RunStartedEvent,
  State,
  StateDeltaEvent,
  StateSnapshotEvent,
  StepFinishedEvent,
  StepStartedEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  ToolCallStartEvent,
  MessagesSnapshotEvent,
  RawEvent,
  CustomEvent,
  ToolCall,
} from "@ag-ui/core";
import { AbstractAgent } from "./agent";
import { structuredClone_ } from "@/utils";

export interface AgentStateMutation {
  messages?: Message[];
  state?: State;
  stopPropagation?: boolean;
}

export interface AgentSubscriberParams {
  messages: Message[];
  state: State;
  agent: AbstractAgent;
  input: RunAgentInput;
}

// Utility type to allow callbacks to be implemented either synchronously or asynchronously.
export type MaybePromise<T> = T | Promise<T>;

export interface AgentSubscriber {
  // Request lifecycle
  onRunInitialized?(
    params: AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;
  onRunFailed?(
    params: { error: Error } & AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;
  onRunFinalized?(
    params: AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;

  // Events
  onEvent?(
    params: { event: BaseEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onRunStartedEvent?(
    params: { event: RunStartedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onRunFinishedEvent?(
    params: { event: RunFinishedEvent; result?: any } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onRunErrorEvent?(
    params: { event: RunErrorEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStepStartedEvent?(
    params: { event: StepStartedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onStepFinishedEvent?(
    params: { event: StepFinishedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onTextMessageStartEvent?(
    params: { event: TextMessageStartEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onTextMessageContentEvent?(
    params: {
      event: TextMessageContentEvent;
      textMessageBuffer: string;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onTextMessageEndEvent?(
    params: { event: TextMessageEndEvent; textMessageBuffer: string } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onToolCallStartEvent?(
    params: { event: ToolCallStartEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onToolCallArgsEvent?(
    params: {
      event: ToolCallArgsEvent;
      toolCallBuffer: string;
      toolCallName: string;
      partialToolCallArgs: Record<string, any>;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onToolCallEndEvent?(
    params: {
      event: ToolCallEndEvent;
      toolCallName: string;
      toolCallArgs: Record<string, any>;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onToolCallResultEvent?(
    params: { event: ToolCallResultEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStateSnapshotEvent?(
    params: { event: StateSnapshotEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStateDeltaEvent?(
    params: { event: StateDeltaEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onMessagesSnapshotEvent?(
    params: { event: MessagesSnapshotEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onRawEvent?(
    params: { event: RawEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onCustomEvent?(
    params: { event: CustomEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  // State changes
  onMessagesChanged?(
    params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput },
  ): MaybePromise<void>;
  onStateChanged?(
    params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput },
  ): MaybePromise<void>;
  onNewMessage?(
    params: { message: Message } & Omit<AgentSubscriberParams, "input"> & {
        input?: RunAgentInput;
      },
  ): MaybePromise<void>;
  onNewToolCall?(
    params: { toolCall: ToolCall } & Omit<AgentSubscriberParams, "input"> & {
        input?: RunAgentInput;
      },
  ): MaybePromise<void>;
}

export async function runSubscribersWithMutation(
  subscribers: AgentSubscriber[],
  initialMessages: Message[],
  initialState: State,
  executor: (
    subscriber: AgentSubscriber,
    messages: Message[],
    state: State,
  ) => MaybePromise<AgentStateMutation | void>,
): Promise<AgentStateMutation> {
  let messages: Message[] = initialMessages;
  let state: State = initialState;

  let stopPropagation: boolean | undefined = undefined;

  for (const subscriber of subscribers) {
    try {
      const mutation = await executor(
        subscriber,
        structuredClone_(messages),
        structuredClone_(state),
      );

      if (mutation === undefined) {
        // Nothing returned – keep going
        continue;
      }

      // Merge messages/state so next subscriber sees latest view
      if (mutation.messages !== undefined) {
        messages = mutation.messages;
      }

      if (mutation.state !== undefined) {
        state = mutation.state;
      }

      stopPropagation = mutation.stopPropagation;

      if (stopPropagation === true) {
        break;
      }
    } catch (error) {
      // Log subscriber errors but continue processing (silence during tests)
      const isTestEnvironment =
        process.env.NODE_ENV === "test" || process.env.JEST_WORKER_ID !== undefined;

      if (!isTestEnvironment) {
        console.error("Subscriber error:", error);
      }
      // Continue to next subscriber unless we want to stop propagation
      continue;
    }
  }

  return {
    ...(JSON.stringify(messages) !== JSON.stringify(initialMessages) ? { messages } : {}),
    ...(JSON.stringify(state) !== JSON.stringify(initialState) ? { state } : {}),
    ...(stopPropagation !== undefined ? { stopPropagation } : {}),
  };
}



================================================
FILE: typescript-sdk/packages/client/src/agent/types.ts
================================================
import { Message, RunAgentInput, State } from "@ag-ui/core";

export interface AgentConfig {
  agentId?: string;
  description?: string;
  threadId?: string;
  initialMessages?: Message[];
  initialState?: State;
  debug?: boolean;
}

export interface HttpAgentConfig extends AgentConfig {
  url: string;
  headers?: Record<string, string>;
}

export type RunAgentParameters = Partial<
  Pick<RunAgentInput, "runId" | "tools" | "context" | "forwardedProps">
>;



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-concurrent.test.ts
================================================
import { Observable, Subject } from "rxjs";
import { AbstractAgent } from "../agent";
import {
  BaseEvent,
  EventType,
  RunAgentInput,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  Message,
  AssistantMessage,
} from "@ag-ui/core";

// Mock agent implementation for testing concurrent events
class ConcurrentTestAgent extends AbstractAgent {
  public eventsToEmit: BaseEvent[] = [];
  public currentEventIndex = 0;

  constructor() {
    super();
    this.debug = false;
  }

  // Set the events this agent should emit
  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
    this.currentEventIndex = 0;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return new Observable((subscriber) => {
      // Emit all the pre-configured events
      for (const event of this.eventsToEmit) {
        subscriber.next(event);
      }
      subscriber.complete();
    });
  }
}

describe("Agent concurrent operations integration", () => {
  let agent: ConcurrentTestAgent;

  beforeEach(() => {
    agent = new ConcurrentTestAgent();
  });

  // Test: Concurrent text messages through full agent pipeline
  it("should handle concurrent text messages through full agent pipeline", async () => {
    // Configure events for concurrent text messages
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "First message ",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "Second message ",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "content",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "content",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg2" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg1" } as TextMessageEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify messages were created correctly
    expect(result.newMessages.length).toBe(2);

    const msg1 = result.newMessages.find((m) => m.id === "msg1");
    const msg2 = result.newMessages.find((m) => m.id === "msg2");

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.content).toBe("First message content");
    expect(msg2?.content).toBe("Second message content");
    expect(msg1?.role).toBe("assistant");
    expect(msg2?.role).toBe("assistant");
  });

  // Test: Concurrent tool calls through full agent pipeline
  it("should handle concurrent tool calls through full agent pipeline", async () => {
    // Configure events for concurrent tool calls
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '{"query":',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool2",
        delta: '{"expr":',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '"test"}',
      } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_ARGS, toolCallId: "tool2", delta: '"1+1"}' } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool1" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool2" } as ToolCallEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify tool call messages were created correctly
    expect(result.newMessages.length).toBe(2);

    const msg1 = result.newMessages.find((m) => m.id === "msg1") as AssistantMessage;
    const msg2 = result.newMessages.find((m) => m.id === "msg2") as AssistantMessage;

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.toolCalls?.length).toBe(1);
    expect(msg2?.toolCalls?.length).toBe(1);

    expect(msg1.toolCalls?.[0]?.id).toBe("tool1");
    expect(msg1.toolCalls?.[0]?.function.name).toBe("search");
    expect(msg1.toolCalls?.[0]?.function.arguments).toBe('{"query":"test"}');

    expect(msg2.toolCalls?.[0]?.id).toBe("tool2");
    expect(msg2.toolCalls?.[0]?.function.name).toBe("calculate");
    expect(msg2.toolCalls?.[0]?.function.arguments).toBe('{"expr":"1+1"}');
  });

  // Test: Mixed concurrent text messages and tool calls
  it("should handle mixed concurrent text messages and tool calls", async () => {
    // Configure events for mixed concurrent operations
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      { type: EventType.STEP_STARTED, stepName: "thinking" } as StepStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "thinking",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "search",
        toolCallName: "web_search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "Let me search ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search",
        delta: '{"query":"',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "for that...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search",
        delta: 'concurrent"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "status",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "status",
        delta: "Processing...",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "thinking" } as TextMessageEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "search" } as ToolCallEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "status" } as TextMessageEndEvent,
      { type: EventType.STEP_FINISHED, stepName: "thinking" } as StepFinishedEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages were created correctly
    expect(result.newMessages.length).toBe(3);

    const thinkingMsg = result.newMessages.find((m) => m.id === "thinking");
    const statusMsg = result.newMessages.find((m) => m.id === "status");
    const toolMsg = result.newMessages.find((m) => m.id === "tool_msg") as AssistantMessage;

    expect(thinkingMsg).toBeDefined();
    expect(statusMsg).toBeDefined();
    expect(toolMsg).toBeDefined();

    expect(thinkingMsg?.content).toBe("Let me search for that...");
    expect(statusMsg?.content).toBe("Processing...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("web_search");
    expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe('{"query":"concurrent"}');
  });

  // Test: Multiple tool calls on same message through full pipeline
  it("should handle multiple tool calls on same message through full pipeline", async () => {
    // Configure events for multiple tool calls on same message
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool3",
        toolCallName: "format",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '{"q":"a"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool2",
        delta: '{"e":"b"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool3",
        delta: '{"f":"c"}',
      } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool2" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool1" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool3" } as ToolCallEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify one message with three tool calls
    expect(result.newMessages.length).toBe(1);

    const sharedMsg = result.newMessages[0] as AssistantMessage;
    expect(sharedMsg.id).toBe("shared_msg");
    expect(sharedMsg.toolCalls?.length).toBe(3);

    const toolCallIds = sharedMsg.toolCalls?.map((tc) => tc.id).sort();
    expect(toolCallIds).toEqual(["tool1", "tool2", "tool3"]);

    const tool1 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool1");
    const tool2 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool2");
    const tool3 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool3");

    expect(tool1?.function.name).toBe("search");
    expect(tool2?.function.name).toBe("calculate");
    expect(tool3?.function.name).toBe("format");

    expect(tool1?.function.arguments).toBe('{"q":"a"}');
    expect(tool2?.function.arguments).toBe('{"e":"b"}');
    expect(tool3?.function.arguments).toBe('{"f":"c"}');
  });

  // Test: Event ordering is preserved in message creation
  it("should preserve event ordering in message creation", async () => {
    // Configure events to test ordering
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg3",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "First",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "Second",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg3",
        delta: "Third",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg3" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg1" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg2" } as TextMessageEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages exist with correct content
    expect(result.newMessages.length).toBe(3);

    // Messages should be in the order they were started
    expect(result.newMessages[0].id).toBe("msg1");
    expect(result.newMessages[1].id).toBe("msg2");
    expect(result.newMessages[2].id).toBe("msg3");

    expect(result.newMessages[0].content).toBe("First");
    expect(result.newMessages[1].content).toBe("Second");
    expect(result.newMessages[2].content).toBe("Third");
  });

  // Test: High-frequency concurrent events through full pipeline
  it("should handle high-frequency concurrent events through full pipeline", async () => {
    const numMessages = 5;
    const numToolCalls = 5;
    const events: BaseEvent[] = [];

    // Build event sequence
    events.push({
      type: EventType.RUN_STARTED,
      threadId: "test",
      runId: "test",
    } as RunStartedEvent);

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      events.push({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events.push({
        type: EventType.TOOL_CALL_START,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Add content to all messages
    for (let i = 0; i < numMessages; i++) {
      events.push({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg${i}`,
        delta: `Content ${i}`,
      } as TextMessageContentEvent);
    }

    // Add args to all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events.push({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: `tool${i}`,
        delta: `{"param":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all messages
    for (let i = numMessages - 1; i >= 0; i--) {
      events.push({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    // End all tool calls
    for (let i = numToolCalls - 1; i >= 0; i--) {
      events.push({
        type: EventType.TOOL_CALL_END,
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    events.push({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages and tool calls were processed
    expect(result.newMessages.length).toBe(numMessages + numToolCalls);

    // Verify text messages
    for (let i = 0; i < numMessages; i++) {
      const msg = result.newMessages.find((m) => m.id === `msg${i}`);
      expect(msg).toBeDefined();
      expect(msg?.content).toBe(`Content ${i}`);
    }

    // Verify tool call messages
    for (let i = 0; i < numToolCalls; i++) {
      const toolMsg = result.newMessages.find((m) => m.id === `tool_msg${i}`) as AssistantMessage;
      expect(toolMsg).toBeDefined();
      expect(toolMsg?.toolCalls?.length).toBe(1);
      expect(toolMsg.toolCalls?.[0]?.id).toBe(`tool${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe(`{"param":"value${i}"}`);
    }
  });

  // Test: Concurrent events with steps
  it("should handle concurrent events with lifecycle steps", async () => {
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      { type: EventType.STEP_STARTED, stepName: "analysis" } as StepStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "thinking",
        role: "assistant",
      } as TextMessageStartEvent,
      { type: EventType.STEP_STARTED, stepName: "search" } as StepStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "search_tool",
        toolCallName: "search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "Analyzing...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search_tool",
        delta: '{"query":"test"}',
      } as ToolCallArgsEvent,
      { type: EventType.STEP_FINISHED, stepName: "search" } as StepFinishedEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "thinking" } as TextMessageEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "search_tool" } as ToolCallEndEvent,
      { type: EventType.STEP_FINISHED, stepName: "analysis" } as StepFinishedEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify messages were created correctly even with concurrent steps
    expect(result.newMessages.length).toBe(2);

    const thinkingMsg = result.newMessages.find((m) => m.id === "thinking");
    const toolMsg = result.newMessages.find((m) => m.id === "tool_msg") as AssistantMessage;

    expect(thinkingMsg?.content).toBe("Analyzing...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("search");
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-multiple-runs.test.ts
================================================
import { AbstractAgent, RunAgentResult } from "../agent";
import { BaseEvent, EventType, Message, RunAgentInput, TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent, RunStartedEvent, RunFinishedEvent } from "@ag-ui/core";
import { Observable, of } from "rxjs";

describe("AbstractAgent multiple runs", () => {
  class TestAgent extends AbstractAgent {
    private events: BaseEvent[] = [];

    setEvents(events: BaseEvent[]) {
      this.events = events;
    }

    protected run(input: RunAgentInput): Observable<BaseEvent> {
      return of(...this.events);
    }
  }

  it("should accumulate messages across multiple sequential runs", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // First run events
    const firstRunEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Hello from run 1",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute first run
    agent.setEvents(firstRunEvents);
    const result1 = await agent.runAgent({ runId: "run-1" });

    // Verify first run results
    expect(result1.newMessages.length).toBe(1);
    expect(result1.newMessages[0].content).toBe("Hello from run 1");
    expect(agent.messages.length).toBe(1);
    expect(agent.messages[0].content).toBe("Hello from run 1");

    // Second run events
    const secondRunEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-2",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-2",
        delta: "Hello from run 2",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-2",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute second run
    agent.setEvents(secondRunEvents);
    const result2 = await agent.runAgent({ runId: "run-2" });

    // Verify second run results
    expect(result2.newMessages.length).toBe(1);
    expect(result2.newMessages[0].content).toBe("Hello from run 2");
    
    // Verify messages are accumulated
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Hello from run 1");
    expect(agent.messages[1].content).toBe("Hello from run 2");
  });

  it("should handle three sequential runs with message accumulation", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const messages = ["First message", "Second message", "Third message"];
    
    for (let i = 0; i < 3; i++) {
      const runEvents: BaseEvent[] = [
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: `run-${i + 1}`,
        } as RunStartedEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: `msg-${i + 1}`,
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: `msg-${i + 1}`,
          delta: messages[i],
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: `msg-${i + 1}`,
        } as TextMessageEndEvent,
        {
          type: EventType.RUN_FINISHED,
        } as RunFinishedEvent,
      ];

      agent.setEvents(runEvents);
      const result = await agent.runAgent({ runId: `run-${i + 1}` });

      // Verify new messages for this run
      expect(result.newMessages.length).toBe(1);
      expect(result.newMessages[0].content).toBe(messages[i]);

      // Verify total accumulated messages
      expect(agent.messages.length).toBe(i + 1);
      for (let j = 0; j <= i; j++) {
        expect(agent.messages[j].content).toBe(messages[j]);
      }
    }

    // Final verification
    expect(agent.messages.length).toBe(3);
    expect(agent.messages.map(m => m.content)).toEqual(messages);
  });

  it("should handle multiple runs in a single event stream", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // Create a single event stream with two runs
    const allEvents: BaseEvent[] = [
      // First run
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Message from run 1",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
      // Second run
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-2",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-2",
        delta: "Message from run 2",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-2",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute with the combined event stream
    agent.setEvents(allEvents);
    const result = await agent.runAgent({ runId: "combined-run" });

    // Verify results
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].content).toBe("Message from run 1");
    expect(result.newMessages[1].content).toBe("Message from run 2");

    // Verify all messages are accumulated
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Message from run 1");
    expect(agent.messages[1].content).toBe("Message from run 2");
  });

  it("should start with initial messages and accumulate new ones", async () => {
    const initialMessages: Message[] = [
      {
        id: "initial-1",
        role: "user",
        content: "Initial message",
      },
    ];

    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages,
    });

    // Run events
    const runEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Response message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(runEvents);
    const result = await agent.runAgent({ runId: "run-1" });

    // Verify new messages don't include initial messages
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].content).toBe("Response message");

    // Verify total messages include both initial and new
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Initial message");
    expect(agent.messages[1].content).toBe("Response message");
  });
});


================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-mutations.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  State,
  ToolCall,
  AssistantMessage,
} from "@ag-ui/core";
import { Observable, of } from "rxjs";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Helper function to wait for async notifications to complete
const waitForAsyncNotifications = async () => {
  // Wait for the next tick of the event loop to ensure async operations complete
  await new Promise((resolve) => setImmediate(resolve));
};

// Mock the verify and chunks modules
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Create a test agent implementation
class TestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of();
  }
}

describe("Agent Mutations", () => {
  let agent: TestAgent;
  let mockSubscriber: AgentSubscriber;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "initial-msg",
          role: "user",
          content: "Initial message",
        },
      ],
      initialState: { counter: 0 },
    });

    mockSubscriber = {
      onMessagesChanged: jest.fn(),
      onStateChanged: jest.fn(),
      onNewMessage: jest.fn(),
      onNewToolCall: jest.fn(),
    };

    agent.subscribe(mockSubscriber);
  });

  describe("addMessage", () => {
    it("should add a user message and fire appropriate events", async () => {
      const userMessage: Message = {
        id: "user-msg-1",
        role: "user",
        content: "Hello world",
      };

      agent.addMessage(userMessage);

      // Message should be added immediately
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages[1]).toBe(userMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should fire onNewMessage and onMessagesChanged
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: userMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewToolCall for user messages
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should add an assistant message without tool calls", async () => {
      const assistantMessage: Message = {
        id: "assistant-msg-1",
        role: "assistant",
        content: "How can I help you?",
      };

      agent.addMessage(assistantMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: assistantMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewToolCall when no tool calls
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should add an assistant message with tool calls and fire onNewToolCall", async () => {
      const toolCalls: ToolCall[] = [
        {
          id: "call-1",
          type: "function",
          function: {
            name: "get_weather",
            arguments: '{"location": "New York"}',
          },
        },
        {
          id: "call-2",
          type: "function",
          function: {
            name: "search_web",
            arguments: '{"query": "latest news"}',
          },
        },
      ];

      const assistantMessage: Message = {
        id: "assistant-msg-2",
        role: "assistant",
        content: "Let me help you with that.",
        toolCalls,
      };

      agent.addMessage(assistantMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: assistantMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should fire onNewToolCall for each tool call
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(2);

      expect(mockSubscriber.onNewToolCall).toHaveBeenNthCalledWith(1, {
        toolCall: toolCalls[0],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onNewToolCall).toHaveBeenNthCalledWith(2, {
        toolCall: toolCalls[1],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });
    });
  });

  describe("addMessages", () => {
    it("should add multiple messages and fire events correctly", async () => {
      const messages: Message[] = [
        {
          id: "msg-1",
          role: "user",
          content: "First message",
        },
        {
          id: "msg-2",
          role: "assistant",
          content: "Second message",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "test_tool",
                arguments: '{"param": "value"}',
              },
            },
          ],
        },
        {
          id: "msg-3",
          role: "user",
          content: "Third message",
        },
      ];

      const initialLength = agent.messages.length;
      agent.addMessages(messages);

      // Messages should be added immediately
      expect(agent.messages).toHaveLength(initialLength + 3);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should fire onNewMessage for each message
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledTimes(3);

      // Should fire onNewToolCall only for the assistant message with tool calls
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith({
        toolCall: (messages[1] as AssistantMessage).toolCalls![0],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should fire onMessagesChanged only once at the end
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });
    });

    it("should handle empty array gracefully", async () => {
      const initialLength = agent.messages.length;
      agent.addMessages([]);

      expect(agent.messages).toHaveLength(initialLength);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should still fire onMessagesChanged even for empty array
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });
  });

  describe("setMessages", () => {
    it("should replace messages and fire onMessagesChanged only", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New conversation start",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "Assistant response",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "some_tool",
                arguments: "{}",
              },
            },
          ],
        },
      ];

      const originalMessage = agent.messages[0];
      agent.setMessages(newMessages);

      // Messages should be replaced immediately
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages).not.toContain(originalMessage); // Original message should be gone
      expect(agent.messages[0]).toEqual(newMessages[0]);
      expect(agent.messages[1]).toEqual(newMessages[1]);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should ONLY fire onMessagesChanged
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewMessage or onNewToolCall
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should handle empty messages array", async () => {
      agent.setMessages([]);

      expect(agent.messages).toHaveLength(0);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });
  });

  describe("setState", () => {
    it("should replace state and fire onStateChanged only", async () => {
      const newState: State = {
        counter: 100,
        isActive: true,
        data: { key: "value" },
      };

      agent.setState(newState);

      // State should be replaced immediately
      expect(agent.state).toEqual(newState);
      expect(agent.state).not.toBe(newState); // Should be a clone

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should ONLY fire onStateChanged
      expect(mockSubscriber.onStateChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onStateChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire other events
      expect(mockSubscriber.onMessagesChanged).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should handle empty state object", async () => {
      agent.setState({});

      expect(agent.state).toEqual({});

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onStateChanged).toHaveBeenCalledTimes(1);
    });
  });

  describe("execution order", () => {
    it("should execute subscriber notifications in registration order", async () => {
      const callOrder: string[] = [];

      const firstSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn().mockImplementation(() => {
          callOrder.push("first-newMessage");
        }),
        onMessagesChanged: jest.fn().mockImplementation(() => {
          callOrder.push("first-messagesChanged");
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn().mockImplementation(() => {
          callOrder.push("second-newMessage");
        }),
        onMessagesChanged: jest.fn().mockImplementation(() => {
          callOrder.push("second-messagesChanged");
        }),
      };

      // Clear the default subscriber and add our test subscribers
      agent.subscribers = [];
      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      const message: Message = {
        id: "test-msg",
        role: "user",
        content: "Test message",
      };

      agent.addMessage(message);

      // Wait for all async operations to complete by polling until all calls are made
      while (callOrder.length < 4) {
        await waitForAsyncNotifications();
      }

      // Verify sequential execution order
      expect(callOrder).toEqual([
        "first-newMessage",
        "second-newMessage",
        "first-messagesChanged",
        "second-messagesChanged",
      ]);
    });
  });

  describe("multiple subscribers", () => {
    it("should notify all subscribers for each event", async () => {
      const subscriber2: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      const subscriber3: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
      };

      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      const message: Message = {
        id: "test-msg",
        role: "assistant",
        content: "Test",
        toolCalls: [
          {
            id: "call-1",
            type: "function",
            function: { name: "test", arguments: "{}" },
          },
        ],
      };

      agent.addMessage(message);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // All subscribers should receive notifications
      [mockSubscriber, subscriber2, subscriber3].forEach((sub) => {
        expect(sub.onNewMessage).toHaveBeenCalledWith(
          expect.objectContaining({
            message,
            agent,
          }),
        );
        expect(sub.onMessagesChanged).toHaveBeenCalled();
      });

      // Only subscribers with onNewToolCall should receive tool call events
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalled();
      expect(subscriber2.onNewToolCall).toHaveBeenCalled();
      // subscriber3 doesn't have onNewToolCall method, so it shouldn't be called
      expect(subscriber3.onNewToolCall).toBeUndefined();
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-result.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  State,
  MessagesSnapshotEvent,
  RunFinishedEvent,
  RunStartedEvent,
} from "@ag-ui/core";
import { Observable, of } from "rxjs";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Mock the verify and chunks modules
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Helper function to wait for async notifications to complete
const waitForAsyncNotifications = async () => {
  await new Promise((resolve) => setImmediate(resolve));
};

// Create a test agent implementation that can emit specific events
class TestAgent extends AbstractAgent {
  private eventsToEmit: BaseEvent[] = [];

  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of(...this.eventsToEmit);
  }
}

describe("Agent Result", () => {
  let agent: TestAgent;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "existing-msg-1",
          role: "user",
          content: "Existing message 1",
        },
        {
          id: "existing-msg-2",
          role: "assistant",
          content: "Existing message 2",
        },
      ],
      initialState: { counter: 0 },
    });
  });

  describe("result handling", () => {
    it("should return undefined result when no result is set", async () => {
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: "test-run",
        } as RunStartedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBeUndefined();
      expect(result.newMessages).toEqual([]);
    });

    it("should return result set by onRunFinishedEvent", async () => {
      const expectedResult = { success: true, data: "test-data", count: 42 };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: "test-run",
        } as RunStartedEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual([]);
    });

    it("should handle string result", async () => {
      const expectedResult = "Simple string result";

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBe(expectedResult);
    });

    it("should handle null result", async () => {
      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: null,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBeNull();
    });
  });

  describe("newMessages tracking", () => {
    it("should track new messages added during run", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New message 1",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "New message 2",
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: "success",
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBe("success");
      expect(result.newMessages).toEqual(newMessages);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should not include existing messages in newMessages", async () => {
      const newMessage: Message = {
        id: "new-msg-only",
        role: "assistant",
        content: "Only this is new",
      };

      // Include existing messages plus new one
      const allMessages = [...agent.messages, newMessage];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([newMessage]);
      expect(result.newMessages).toHaveLength(1);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should handle no new messages", async () => {
      // Keep same messages as initial
      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: agent.messages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([]);
      expect(agent.messages).toHaveLength(2); // Original messages
    });

    it("should handle multiple new messages with tool calls", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-user",
          role: "user",
          content: "User query",
        },
        {
          id: "new-msg-assistant",
          role: "assistant",
          content: "Let me help you",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "search_tool",
                arguments: '{"query": "test"}',
              },
            },
          ],
        },
        {
          id: "new-msg-tool",
          role: "tool",
          content: "Tool result",
          toolCallId: "call-1",
        },
        {
          id: "new-msg-final",
          role: "assistant",
          content: "Here's the answer",
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: { toolsUsed: 1, messagesAdded: 4 },
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      expect(result.newMessages).toHaveLength(4);
      expect(result.result).toEqual({ toolsUsed: 1, messagesAdded: 4 });
    });

    it("should preserve message order", async () => {
      const newMessages: Message[] = [
        { id: "new-1", role: "user", content: "First new" },
        { id: "new-2", role: "assistant", content: "Second new" },
        { id: "new-3", role: "user", content: "Third new" },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      // Verify order is preserved
      expect(result.newMessages[0].id).toBe("new-1");
      expect(result.newMessages[1].id).toBe("new-2");
      expect(result.newMessages[2].id).toBe("new-3");
    });
  });

  describe("combined result and newMessages", () => {
    it("should return both result and newMessages correctly", async () => {
      const newMessages: Message[] = [
        {
          id: "conversation-msg",
          role: "assistant",
          content: "Here's what I found",
        },
      ];

      const expectedResult = {
        status: "completed",
        messagesGenerated: 1,
        processingTime: 1500,
      };

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual(newMessages);
      expect(result.newMessages).toHaveLength(1);
    });

    it("should handle empty newMessages with valid result", async () => {
      const expectedResult = { error: false, processed: true };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual([]);
    });
  });

  describe("subscriber notifications integration", () => {
    it("should track newMessages without interfering with existing event processing", async () => {
      const mockSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      agent.subscribe(mockSubscriber);

      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New user message",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "New assistant message",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: { name: "test_tool", arguments: "{}" },
            },
          ],
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);

      // Note: Subscriber notifications are handled by the existing event processing pipeline
      // The newMessages tracking is separate from subscriber notification logic
    });

    it("should return empty newMessages when no messages are added", async () => {
      const mockSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      agent.subscribe(mockSubscriber);

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: "no new messages",
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([]);

      // Should not fire any new message events since no messages were added
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
      expect(mockSubscriber.onMessagesChanged).not.toHaveBeenCalled();
    });
  });

  describe("edge cases", () => {
    it("should handle agent with no initial messages", async () => {
      const emptyAgent = new TestAgent({
        threadId: "empty-thread",
        initialMessages: [],
      });

      const newMessages: Message[] = [{ id: "first-ever", role: "user", content: "First message" }];

      emptyAgent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: newMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await emptyAgent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      expect(emptyAgent.messages).toEqual(newMessages);
    });

    it("should handle messages with duplicate IDs correctly", async () => {
      // This tests that we're using Set correctly for ID tracking
      const messageWithSameId: Message = {
        id: "existing-msg-1", // Same ID as existing message
        role: "user",
        content: "Updated content",
      };

      const allMessages = [...agent.messages, messageWithSameId];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      // Should not include the duplicate ID in newMessages
      expect(result.newMessages).toEqual([]);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should handle complex result objects", async () => {
      const complexResult = {
        metadata: {
          timestamp: new Date().toISOString(),
          version: "1.0.0",
        },
        data: {
          results: [1, 2, 3],
          nested: {
            deep: {
              value: "test",
            },
          },
        },
        stats: {
          processingTime: 1000,
          tokensUsed: 150,
        },
      };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: complexResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(complexResult);
      expect(result.result).toMatchObject(complexResult);
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-text-roles.test.ts
================================================
import { AbstractAgent } from "../agent";
import { BaseEvent, EventType, Message, RunAgentInput, TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent, TextMessageChunkEvent, RunStartedEvent, RunFinishedEvent, Role } from "@ag-ui/core";
import { Observable, of } from "rxjs";

describe("AbstractAgent text message roles", () => {
  class TestAgent extends AbstractAgent {
    private events: BaseEvent[] = [];

    setEvents(events: BaseEvent[]) {
      this.events = events;
    }

    protected run(input: RunAgentInput): Observable<BaseEvent> {
      return of(...this.events);
    }
  }

  // Text messages can have any role except "tool"
  const textMessageRoles = ["developer", "system", "assistant", "user"] as const;

  it.each(textMessageRoles)("should handle text messages with role '%s'", async (role) => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg-${role}`,
        role: role,
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg-${role}`,
        delta: `Hello from ${role}`,
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg-${role}`,
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify message was created with correct role
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].role).toBe(role);
    expect(result.newMessages[0].content).toBe(`Hello from ${role}`);
    expect(agent.messages.length).toBe(1);
    expect(agent.messages[0].role).toBe(role);
  });

  it("should handle multiple messages with different roles in a single run", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
    ];

    // Add messages from different roles
    for (const role of textMessageRoles) {
      events.push(
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: `msg-${role}`,
          role: role,
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: `msg-${role}`,
          delta: `Message from ${role}`,
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: `msg-${role}`,
        } as TextMessageEndEvent
      );
    }

    events.push({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify all messages were created with correct roles
    expect(result.newMessages.length).toBe(textMessageRoles.length);
    expect(agent.messages.length).toBe(textMessageRoles.length);

    textMessageRoles.forEach((role, index) => {
      expect(result.newMessages[index].role).toBe(role);
      expect(result.newMessages[index].content).toBe(`Message from ${role}`);
      expect(agent.messages[index].role).toBe(role);
    });
  });

  it("should handle text message chunks with different roles", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // Test with chunks that specify role
    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-user",
        role: "user",
        delta: "User chunk message",
      } as TextMessageChunkEvent,
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-system",
        role: "system",
        delta: "System chunk message",
      } as TextMessageChunkEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify messages were created from chunks
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].role).toBe("user");
    expect(result.newMessages[0].content).toBe("User chunk message");
    expect(result.newMessages[1].role).toBe("system");
    expect(result.newMessages[1].content).toBe("System chunk message");
  });

  it("should default to 'assistant' role when not specified", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-default",
        // role not specified - should default to assistant
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-default",
        delta: "Default role message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-default",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify message was created with default 'assistant' role
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].role).toBe("assistant");
    expect(result.newMessages[0].content).toBe("Default role message");
  });

  it("should preserve role when mixing regular and chunk events", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      // Regular message with user role
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "user",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "User message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      // Chunk message with developer role
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-2",
        role: "developer",
        delta: "Developer chunk",
      } as TextMessageChunkEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify both message types preserved their roles
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].role).toBe("user");
    expect(result.newMessages[0].content).toBe("User message");
    expect(result.newMessages[1].role).toBe("developer");
    expect(result.newMessages[1].content).toBe("Developer chunk");
  });
});


================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/http.test.ts
================================================
import { HttpAgent } from "../http";
import { runHttpRequest, HttpEvent, HttpEventType } from "@/run/http-request";
import { v4 as uuidv4 } from "uuid";
import { Observable, of } from "rxjs";

// Mock the runHttpRequest module
jest.mock("@/run/http-request", () => ({
  runHttpRequest: jest.fn(),
  HttpEventType: {
    HEADERS: "headers",
    DATA: "data",
  },
}));

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-run-id"),
}));

// Mock transformHttpEventStream
jest.mock("@/transform/http", () => ({
  transformHttpEventStream: jest.fn((source$) => source$),
}));

describe("HttpAgent", () => {
  // Reset mocks before each test
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should configure and execute HTTP requests correctly", async () => {
    // Setup mock observable for the HTTP response
    const mockObservable = of({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers(),
    });

    // Mock the runHttpRequest function
    (runHttpRequest as jest.Mock).mockReturnValue(mockObservable);

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
    });

    // Setup input data for the agent
    agent.messages = [
      {
        id: uuidv4(),
        role: "user",
        content: "Hello",
      },
    ];

    // Prepare the input that would be used in runAgent
    const input = {
      threadId: agent.threadId,
      runId: "mock-run-id",
      tools: [],
      context: [],
      forwardedProps: {},
      state: agent.state,
      messages: agent.messages,
    };

    // Call run method directly, which should call runHttpRequest
    agent.run(input);

    // Verify runHttpRequest was called with correct config
    expect(runHttpRequest).toHaveBeenCalledWith("https://api.example.com/v1/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: expect.any(AbortSignal),
    });
  });

  it("should abort the request when abortRun is called", () => {
    // Setup mock implementation
    (runHttpRequest as jest.Mock).mockReturnValue(of());

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Spy on the abort method of AbortController
    const abortSpy = jest.spyOn(AbortController.prototype, "abort");

    // Trigger runAgent without actually calling it by checking the abortController
    expect(agent.abortController).toBeInstanceOf(AbortController);

    // Call abortRun directly
    agent.abortRun();

    // Verify abort was called
    expect(abortSpy).toHaveBeenCalled();

    // Clean up
    abortSpy.mockRestore();
  });

  it("should use a custom abort controller when provided", () => {
    // Setup mock implementation
    (runHttpRequest as jest.Mock).mockReturnValue(of());

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Create a custom abort controller
    const customController = new AbortController();
    const abortSpy = jest.spyOn(customController, "abort");

    // Set the custom controller
    agent.abortController = customController;

    // Call abortRun directly
    agent.abortRun();

    // Verify the custom controller was used
    expect(abortSpy).toHaveBeenCalled();

    // Clean up
    abortSpy.mockRestore();
  });

  it("should handle transformHttpEventStream correctly", () => {
    // Import the actual transformHttpEventStream function
    const { transformHttpEventStream } = require("../../transform/http");

    // Verify transformHttpEventStream is a function
    expect(typeof transformHttpEventStream).toBe("function");

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Verify that the HttpAgent's run method uses transformHttpEventStream
    // This is an indirect test of implementation details, but useful to verify the pipeline
    const mockObservable = of({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers(),
    });

    (runHttpRequest as jest.Mock).mockReturnValue(mockObservable);

    // Call run with mock input
    const input = {
      threadId: agent.threadId,
      runId: "test-run-id",
      state: {},
      messages: [],
      tools: [],
      context: [],
      forwardedProps: {},
    };

    // Execute the run function
    agent.run(input);

    // Verify that transformHttpEventStream was called with the mock observable
    expect(transformHttpEventStream).toHaveBeenCalledWith(mockObservable);
  });

  it("should process HTTP response data end-to-end", async () => {
    // Create mock headers
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "text/event-stream");

    // Create a mock response data
    const mockResponseObservable = of(
      {
        type: HttpEventType.HEADERS,
        status: 200,
        headers: mockHeaders,
      },
      {
        type: HttpEventType.DATA,
        data: new Uint8Array(
          new TextEncoder().encode(
            'data: {"type": "TEXT_MESSAGE_START", "messageId": "test-id"}\n\n',
          ),
        ),
      },
    );

    // Directly mock runHttpRequest
    (runHttpRequest as jest.Mock).mockReturnValue(mockResponseObservable);

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Prepare input for the agent
    const input = {
      threadId: agent.threadId,
      runId: "mock-run-id",
      tools: [],
      context: [],
      forwardedProps: {},
      state: agent.state,
      messages: agent.messages,
    };

    // Call run method directly
    agent.run(input);

    // Verify runHttpRequest was called with correct config
    expect(runHttpRequest).toHaveBeenCalledWith("https://api.example.com/v1/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: expect.any(AbortSignal),
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/legacy-bridged.test.ts
================================================
import { toArray } from "rxjs/operators";
import { EventType, BaseEvent, RunAgentInput } from "@ag-ui/core";
import { AbstractAgent } from "../../agent/agent";
import { Observable, lastValueFrom } from "rxjs";
import { RunAgentParameters } from "../../agent/types";

// Mock uuid
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Create a test agent that extends AbstractAgent
class TestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = "test-message-id";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

// Agent that emits text chunks instead of start/content/end events
class ChunkTestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = "test-chunk-id";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Emit a text message chunk instead of separate start/content/end events
      observer.next({
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId,
        delta: "Hello from chunks!",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

// Agent that emits tool call events with results
class ToolCallTestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const toolCallId = "test-tool-call-id";
    const toolCallName = "get_weather";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Start tool call
      observer.next({
        type: EventType.TOOL_CALL_START,
        toolCallId,
        toolCallName,
        timestamp: Date.now(),
      } as BaseEvent);

      // Tool call arguments
      observer.next({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId,
        delta: '{"location": "San Francisco"}',
        timestamp: Date.now(),
      } as BaseEvent);

      // End tool call
      observer.next({
        type: EventType.TOOL_CALL_END,
        toolCallId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Tool call result
      observer.next({
        messageId: "test-message-id",
        type: EventType.TOOL_CALL_RESULT,
        toolCallId,
        content: "The weather in San Francisco is 72°F and sunny.",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

describe("AbstractAgent.legacy_to_be_removed_runAgentBridged", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should correctly convert events to legacy format", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(3); // Start, Content, End

    // TextMessageStart
    expect(legacyEvents[0]).toMatchObject({
      type: "TextMessageStart",
      messageId: "test-message-id",
    });

    // TextMessageContent
    expect(legacyEvents[1]).toMatchObject({
      type: "TextMessageContent",
      messageId: "test-message-id",
      content: "Hello world!",
    });

    // TextMessageEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "TextMessageEnd",
      messageId: "test-message-id",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[3]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });

  it("should pass configuration to the underlying run method", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Spy on the run method
    const runSpy = jest.spyOn(agent as any, "run");

    // Create config with compatible tool format
    const config: RunAgentParameters = {
      tools: [],
      context: [{ value: "test context", description: "Test description" }],
      forwardedProps: { foo: "bar" },
    };

    // Call legacy bridged method with config
    agent.legacy_to_be_removed_runAgentBridged(config);

    // Verify run method was called with correct input
    expect(runSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        threadId: "test-thread-id",
        runId: "mock-uuid",
        tools: config.tools,
        context: config.context,
        forwardedProps: config.forwardedProps,
      }),
    );
  });

  it("should include agent ID in the legacy events when converting", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Set up a state snapshot to test agent state in legacy format
    const runWithStateSnapshot = jest
      .fn()
      .mockImplementation((input: RunAgentInput): Observable<BaseEvent> => {
        return new Observable<BaseEvent>((observer) => {
          observer.next({
            type: EventType.RUN_STARTED,
            threadId: input.threadId,
            runId: input.runId,
            timestamp: Date.now(),
          } as BaseEvent);

          // Add a state snapshot event
          observer.next({
            type: EventType.STATE_SNAPSHOT,
            snapshot: { test: "state" },
            timestamp: Date.now(),
          } as BaseEvent);

          observer.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
            timestamp: Date.now(),
          } as BaseEvent);

          observer.complete();
        });
      });

    // Override the run method for this test
    jest.spyOn(agent as any, "run").mockImplementation(runWithStateSnapshot);

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Find AgentStateMessage events
    const stateEvents = legacyEvents.filter((e) => e.type === "AgentStateMessage");

    // Should have at least one state event
    expect(stateEvents.length).toBeGreaterThan(0);

    // All state events should include the agent ID
    stateEvents.forEach((event) => {
      expect(event).toMatchObject({
        agentName: "test-agent-id",
        threadId: "test-thread-id",
        state: expect.any(String),
      });

      // Verify that state was correctly serialized
      if (event.state) {
        const parsedState = JSON.parse(event.state);
        expect(parsedState).toMatchObject({ test: "state" });
      }
    });
  });

  it("should transform text message chunks into legacy text message events", async () => {
    // Setup agent with mock IDs
    const agent = new ChunkTestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(3); // Start, Content, End

    // TextMessageStart
    expect(legacyEvents[0]).toMatchObject({
      type: "TextMessageStart",
      messageId: "test-chunk-id",
    });

    // TextMessageContent
    expect(legacyEvents[1]).toMatchObject({
      type: "TextMessageContent",
      messageId: "test-chunk-id",
      content: "Hello from chunks!",
    });

    // TextMessageEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "TextMessageEnd",
      messageId: "test-chunk-id",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[3]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });

  it("should transform tool call events with results into legacy events with correct tool name", async () => {
    // Setup agent with mock IDs
    const agent = new ToolCallTestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(4); // ActionExecutionStart, ActionExecutionArgs, ActionExecutionEnd, ActionExecutionResult

    // ActionExecutionStart
    expect(legacyEvents[0]).toMatchObject({
      type: "ActionExecutionStart",
      actionExecutionId: "test-tool-call-id",
      actionName: "get_weather",
    });

    // ActionExecutionArgs
    expect(legacyEvents[1]).toMatchObject({
      type: "ActionExecutionArgs",
      actionExecutionId: "test-tool-call-id",
      args: '{"location": "San Francisco"}',
    });

    // ActionExecutionEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "ActionExecutionEnd",
      actionExecutionId: "test-tool-call-id",
    });

    // ActionExecutionResult - this should include the tool name
    expect(legacyEvents[3]).toMatchObject({
      type: "ActionExecutionResult",
      actionExecutionId: "test-tool-call-id",
      actionName: "get_weather", // This verifies the tool name is correctly included
      result: "The weather in San Francisco is 72°F and sunny.",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[4]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/subscriber.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  StateSnapshotEvent,
  RunStartedEvent,
  RunFinishedEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  CustomEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { Observable, of, throwError, from } from "rxjs";
import { mergeMap } from "rxjs/operators";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils with handling for undefined values
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Mock the verify modules but NOT apply - we want to test against real defaultApplyEvents
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Create a test agent implementation
class TestAgent extends AbstractAgent {
  private eventsToEmit: BaseEvent[] = [];

  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of(...this.eventsToEmit);
  }
}

describe("AgentSubscriber", () => {
  let agent: TestAgent;
  let mockSubscriber: AgentSubscriber;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "msg-1",
          role: "user",
          content: "Hello",
        },
      ],
      initialState: { counter: 0 },
    });

    mockSubscriber = {
      onEvent: jest.fn(),
      onRunStartedEvent: jest.fn(),
      onRunFinishedEvent: jest.fn(),
      onTextMessageStartEvent: jest.fn(),
      onTextMessageContentEvent: jest.fn(),
      onTextMessageEndEvent: jest.fn(),
      onToolCallStartEvent: jest.fn(),
      onToolCallArgsEvent: jest.fn(),
      onToolCallEndEvent: jest.fn(),
      onToolCallResultEvent: jest.fn(),
      onCustomEvent: jest.fn(),
      onStateSnapshotEvent: jest.fn(),
      onMessagesChanged: jest.fn(),
      onStateChanged: jest.fn(),
      onNewMessage: jest.fn(),
      onNewToolCall: jest.fn(),
      onRunInitialized: jest.fn(),
      onRunFailed: jest.fn(),
      onRunFinalized: jest.fn(),
    };
  });

  describe("subscribe/unsubscribe functionality", () => {
    it("should allow subscribing and unsubscribing", () => {
      // Initially no subscribers
      expect(agent.subscribers).toHaveLength(0);

      // Subscribe
      const subscription = agent.subscribe(mockSubscriber);
      expect(agent.subscribers).toHaveLength(1);
      expect(agent.subscribers[0]).toBe(mockSubscriber);

      // Unsubscribe
      subscription.unsubscribe();
      expect(agent.subscribers).toHaveLength(0);
    });

    it("should support multiple subscribers", () => {
      const subscriber2: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      agent.subscribe(mockSubscriber);
      agent.subscribe(subscriber2);

      expect(agent.subscribers).toHaveLength(2);
      expect(agent.subscribers[0]).toBe(mockSubscriber);
      expect(agent.subscribers[1]).toBe(subscriber2);
    });

    it("should only remove the specific subscriber on unsubscribe", () => {
      const subscriber2: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      const subscription1 = agent.subscribe(mockSubscriber);
      const subscription2 = agent.subscribe(subscriber2);

      expect(agent.subscribers).toHaveLength(2);

      subscription1.unsubscribe();
      expect(agent.subscribers).toHaveLength(1);
      expect(agent.subscribers[0]).toBe(subscriber2);

      subscription2.unsubscribe();
      expect(agent.subscribers).toHaveLength(0);
    });
  });

  describe("temporary subscribers via runAgent", () => {
    it("should accept a temporary subscriber via runAgent parameter", async () => {
      const temporarySubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
        onRunFinishedEvent: jest.fn(),
      };

      const runStartedEvent: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      };

      const runFinishedEvent: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        threadId: "test-thread",
        runId: "test-run",
        result: "test-result",
      };

      agent.setEventsToEmit([runStartedEvent, runFinishedEvent]);

      await agent.runAgent({}, temporarySubscriber);

      // The temporary subscriber should have been called
      expect(temporarySubscriber.onRunStartedEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: runStartedEvent,
          messages: agent.messages,
          state: agent.state,
          agent,
        }),
      );

      expect(temporarySubscriber.onRunFinishedEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: runFinishedEvent,
          result: "test-result",
          messages: agent.messages,
          state: agent.state,
          agent,
        }),
      );
    });

    it("should combine permanent and temporary subscribers", async () => {
      const permanentSubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
      };

      const temporarySubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
      };

      agent.subscribe(permanentSubscriber);

      const runStartedEvent: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      };

      agent.setEventsToEmit([runStartedEvent]);

      await agent.runAgent({}, temporarySubscriber);

      // Both subscribers should have been called
      expect(permanentSubscriber.onRunStartedEvent).toHaveBeenCalled();
      expect(temporarySubscriber.onRunStartedEvent).toHaveBeenCalled();
    });
  });

  describe("mutation capabilities", () => {
    it("should allow subscribers to mutate messages", async () => {
      const newMessage: Message = {
        id: "new-msg",
        role: "assistant",
        content: "I was added by subscriber",
      };

      const mutatingSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          messages: [...agent.messages, newMessage],
        }),
        onMessagesChanged: jest.fn(),
      };

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({}, mutatingSubscriber);

      // Verify the subscriber was called with the initial messages
      expect(mutatingSubscriber.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          messages: [
            {
              id: "msg-1",
              role: "user",
              content: "Hello",
            },
          ],
        }),
      );

      // Verify the agent's messages were updated
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages[1]).toEqual(newMessage);

      // Verify onMessagesChanged was called
      expect(mutatingSubscriber.onMessagesChanged).toHaveBeenCalledWith(
        expect.objectContaining({
          messages: agent.messages,
        }),
      );
    });

    it("should allow subscribers to mutate state", async () => {
      const mutatingSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          state: { counter: 42, newField: "added" },
        }),
        onStateChanged: jest.fn(),
      };

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({}, mutatingSubscriber);

      // Verify the subscriber was called with the initial state
      expect(mutatingSubscriber.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { counter: 0 },
        }),
      );

      // Verify the agent's state was updated
      expect(agent.state).toEqual({ counter: 42, newField: "added" });

      // Verify onStateChanged was called
      expect(mutatingSubscriber.onStateChanged).toHaveBeenCalledWith(
        expect.objectContaining({
          state: agent.state,
        }),
      );
    });

    it("should allow mutations in event handlers", async () => {
      const stateEvent: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: { newCounter: 100 },
      };

      const mutatingSubscriber: AgentSubscriber = {
        onStateSnapshotEvent: jest.fn().mockReturnValue({
          state: { modifiedBySubscriber: true },
          stopPropagation: true, // Prevent the event from applying its snapshot
        }),
        onStateChanged: jest.fn(),
      };

      agent.setEventsToEmit([stateEvent]);

      await agent.runAgent({}, mutatingSubscriber);

      expect(mutatingSubscriber.onStateSnapshotEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: stateEvent,
        }),
      );

      // State should be updated by the subscriber
      expect(agent.state).toEqual({ modifiedBySubscriber: true });
      expect(mutatingSubscriber.onStateChanged).toHaveBeenCalled();
    });
  });

  describe("stopPropagation functionality", () => {
    it("should stop propagation to subsequent subscribers when stopPropagation is true", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          stopPropagation: true,
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // First subscriber should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();

      // Second subscriber should NOT be called due to stopPropagation
      expect(secondSubscriber.onRunInitialized).not.toHaveBeenCalled();
    });

    it("should continue to next subscriber when stopPropagation is false", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          stopPropagation: false,
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Both subscribers should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();
      expect(secondSubscriber.onRunInitialized).toHaveBeenCalled();
    });

    it("should continue to next subscriber when stopPropagation is undefined", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({}), // No stopPropagation field
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Both subscribers should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();
      expect(secondSubscriber.onRunInitialized).toHaveBeenCalled();
    });

    it("should stop default behavior on error when stopPropagation is true", async () => {
      const errorHandlingSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: true,
        }),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(errorHandlingSubscriber);

      // Mock console.error to check if it's called
      const consoleErrorSpy = jest.spyOn(console, "error").mockImplementation();

      // This should not throw because the subscriber handles the error
      await expect(errorAgent.runAgent({})).resolves.toBeDefined();

      expect(errorHandlingSubscriber.onRunFailed).toHaveBeenCalledWith(
        expect.objectContaining({
          error: expect.any(Error),
        }),
      );

      // Console.error should NOT be called because subscriber handled the error
      expect(consoleErrorSpy).not.toHaveBeenCalled();

      consoleErrorSpy.mockRestore();
    });

    it("should allow default error behavior when stopPropagation is false", async () => {
      const errorHandlingSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: false,
        }),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(errorHandlingSubscriber);

      // Mock console.error to check if it's called
      const consoleErrorSpy = jest.spyOn(console, "error").mockImplementation();

      // This should throw because the subscriber doesn't stop propagation
      await expect(errorAgent.runAgent({})).rejects.toThrow("Test error");

      expect(errorHandlingSubscriber.onRunFailed).toHaveBeenCalled();

      // Console.error should be called because error propagated
      expect(consoleErrorSpy).toHaveBeenCalledWith("Agent execution failed:", expect.any(Error));

      consoleErrorSpy.mockRestore();
    });
  });

  describe("subscriber order and chaining", () => {
    it("should call subscribers in the order they were added", async () => {
      const callOrder: string[] = [];

      const subscriber1: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber1");
        }),
      };

      const subscriber2: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber2");
        }),
      };

      const subscriber3: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber3");
        }),
      };

      agent.subscribe(subscriber1);
      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      expect(callOrder).toEqual(["subscriber1", "subscriber2", "subscriber3"]);
    });

    it("should pass mutations from one subscriber to the next", async () => {
      const subscriber1: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          state: { step: 1 },
        }),
      };

      const subscriber2: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation((params) => {
          // Should receive the state modified by subscriber1
          expect(params.state).toEqual({ step: 1 });
          return {
            state: { step: 2 },
          };
        }),
      };

      const subscriber3: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation((params) => {
          // Should receive the state modified by subscriber2
          expect(params.state).toEqual({ step: 2 });
          return {
            state: { step: 3 },
          };
        }),
      };

      agent.subscribe(subscriber1);
      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Final state should reflect all mutations
      expect(agent.state).toEqual({ step: 3 });

      expect(subscriber1.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { counter: 0 }, // Original state
        }),
      );

      expect(subscriber2.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { step: 1 }, // Modified by subscriber1
        }),
      );

      expect(subscriber3.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { step: 2 }, // Modified by subscriber2
        }),
      );
    });
  });

  describe("event-specific callbacks", () => {
    it("should call specific event callbacks with correct parameters", async () => {
      const textStartEvent: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "test-msg",
        role: "assistant",
      };

      const textContentEvent: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "test-msg",
        delta: "Hello",
      };

      const specificSubscriber: AgentSubscriber = {
        onTextMessageStartEvent: jest.fn(),
        onTextMessageContentEvent: jest.fn(),
      };

      agent.subscribe(specificSubscriber);
      agent.setEventsToEmit([textStartEvent, textContentEvent]);

      await agent.runAgent({});

      expect(specificSubscriber.onTextMessageStartEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: textStartEvent,
          messages: [{ content: "Hello", id: "msg-1", role: "user" }], // Pre-mutation state
          state: { counter: 0 }, // Pre-mutation state
          agent,
        }),
      );

      expect(specificSubscriber.onTextMessageContentEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: textContentEvent,
          textMessageBuffer: "", // Empty - buffer before current delta is applied
          messages: expect.arrayContaining([
            expect.objectContaining({ content: "Hello", id: "msg-1", role: "user" }),
            expect.objectContaining({ content: "", id: "test-msg", role: "assistant" }), // Message before delta applied
          ]),
          state: { counter: 0 },
          agent,
        }),
      );
    });

    it("should call generic onEvent callback for all events", async () => {
      const events: BaseEvent[] = [
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "test-msg",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.STATE_SNAPSHOT,
          snapshot: { test: true },
        } as StateSnapshotEvent,
      ];

      const genericSubscriber: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      agent.subscribe(genericSubscriber);
      agent.setEventsToEmit(events);

      await agent.runAgent({});

      expect(genericSubscriber.onEvent).toHaveBeenCalledTimes(2);
      expect(genericSubscriber.onEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          event: events[0],
        }),
      );
      expect(genericSubscriber.onEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          event: events[1],
        }),
      );
    });
  });

  describe("lifecycle callbacks", () => {
    it("should call lifecycle callbacks in correct order", async () => {
      const callOrder: string[] = [];

      const lifecycleSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("initialized");
        }),
        onRunFinalized: jest.fn().mockImplementation(() => {
          callOrder.push("finalized");
        }),
      };

      agent.subscribe(lifecycleSubscriber);
      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      expect(callOrder).toEqual(["initialized", "finalized"]);
    });

    it("should call onRunFinalized even after errors", async () => {
      const lifecycleSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: true, // Handle the error
        }),
        onRunFinalized: jest.fn(),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(lifecycleSubscriber);

      await errorAgent.runAgent({});

      expect(lifecycleSubscriber.onRunFailed).toHaveBeenCalled();
      expect(lifecycleSubscriber.onRunFinalized).toHaveBeenCalled();
    });
  });

  describe("Tool Call Tests", () => {
    test("should handle tool call events with proper buffer accumulation", async () => {
      // Create agent that emits tool call sequence
      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mockSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: '{"query": "te',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: 'st"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-123",
        } as ToolCallEndEvent,
      ]);

      await toolCallAgent.runAgent({});

      // Verify tool call events were called
      expect(mockSubscriber.onToolCallStartEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: expect.objectContaining({
            type: EventType.TOOL_CALL_START,
            toolCallId: "call-123",
            toolCallName: "search",
          }),
          messages: [],
          state: {},
          agent: toolCallAgent,
        }),
      );

      // Check buffer accumulation
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenCalledTimes(2);

      // First call should have empty buffer (before first delta applied)
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          toolCallBuffer: "",
          toolCallName: "search",
          partialToolCallArgs: "", // Empty string when buffer is empty
        }),
      );

      // Second call should have partial buffer (before second delta applied)
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          toolCallBuffer: '{"query": "te',
          toolCallName: "search",
          partialToolCallArgs: '{"query": "te"}', // untruncateJson returns truncated JSON string
        }),
      );

      expect(mockSubscriber.onToolCallEndEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCallName: "search",
          toolCallArgs: { query: "test" },
        }),
      );

      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCall: {
            id: "call-123",
            type: "function",
            function: {
              name: "search",
              arguments: '{"query": "test"}',
            },
          },
        }),
      );
    });
  });

  describe("Buffer Accumulation Tests", () => {
    test("should properly accumulate text message buffer", async () => {
      const textAgent = new TestAgent();
      textAgent.subscribe(mockSubscriber);
      textAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Hello",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: " ",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "World",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
      ]);

      await textAgent.runAgent({});

      // Verify buffer accumulation
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenCalledTimes(3);

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          textMessageBuffer: "", // First event: no content accumulated yet
        }),
      );

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          textMessageBuffer: "Hello", // Second event: content from first event
        }),
      );

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        3,
        expect.objectContaining({
          textMessageBuffer: "Hello ", // Third event: content from first + second events
        }),
      );

      expect(mockSubscriber.onTextMessageEndEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          textMessageBuffer: "Hello World",
        }),
      );
    });

    test("should reset text buffer on new message", async () => {
      const multiMessageAgent = new TestAgent();
      multiMessageAgent.subscribe(mockSubscriber);
      multiMessageAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "First",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-2",
          delta: "Second",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-2",
        } as TextMessageEndEvent,
      ]);

      await multiMessageAgent.runAgent({});

      // Check first message
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          textMessageBuffer: "", // First message, first content: no content accumulated yet
        }),
      );

      // Check second message (buffer should reset)
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          textMessageBuffer: "", // Second message, first content: buffer reset, no content accumulated yet
        }),
      );
    });
  });

  describe("Message and Tool Call Lifecycle Tests", () => {
    test("should call onNewMessage after text message completion", async () => {
      const textAgent = new TestAgent();
      textAgent.subscribe(mockSubscriber);
      textAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Test message",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
      ]);

      await textAgent.runAgent({});

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith(
        expect.objectContaining({
          message: expect.objectContaining({
            id: "msg-1",
            role: "assistant",
            content: "Test message",
          }),
        }),
      );
    });

    test("should call onNewToolCall after tool call completion", async () => {
      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mockSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: '{"query": "test"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-123",
        } as ToolCallEndEvent,
      ]);

      await toolCallAgent.runAgent({});

      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCall: {
            id: "call-123",
            type: "function",
            function: {
              name: "search",
              arguments: '{"query": "test"}',
            },
          },
        }),
      );
    });
  });

  describe("Custom Event Tests", () => {
    test("should handle custom events", async () => {
      const customAgent = new TestAgent();
      customAgent.subscribe(mockSubscriber);
      customAgent.setEventsToEmit([
        {
          type: EventType.CUSTOM,
          name: "user_interaction",
          data: { action: "click", target: "button" },
        } as CustomEvent,
      ]);

      await customAgent.runAgent({});

      expect(mockSubscriber.onCustomEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: expect.objectContaining({
            type: EventType.CUSTOM,
            name: "user_interaction",
            data: { action: "click", target: "button" },
          }),
          messages: [],
          state: {},
          agent: customAgent,
        }),
      );
    });
  });

  describe("Subscriber Error Handling", () => {
    test("should handle errors in subscriber callbacks gracefully", async () => {
      const errorSubscriber = {
        onEvent: jest.fn().mockImplementation(() => {
          // Return stopPropagation to handle the error gracefully
          throw new Error("Subscriber error");
        }),
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          throw new Error("Sync subscriber error");
        }),
      };

      // Add a working subscriber to ensure others still work
      const workingSubscriber = {
        onEvent: jest.fn(),
        onTextMessageStartEvent: jest.fn(),
      };

      const testAgent = new TestAgent();
      testAgent.subscribe(errorSubscriber);
      testAgent.subscribe(workingSubscriber);
      testAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
      ]);

      // Should not throw despite subscriber errors
      await expect(testAgent.runAgent({})).resolves.toBeDefined();

      expect(errorSubscriber.onEvent).toHaveBeenCalled();
      expect(errorSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
      expect(workingSubscriber.onEvent).toHaveBeenCalled();
      expect(workingSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
    });

    test("should continue processing other subscribers when one fails", async () => {
      const errorSubscriber = {
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          throw new Error("First subscriber error");
        }),
      };

      const workingSubscriber = {
        onTextMessageStartEvent: jest.fn().mockResolvedValue(undefined),
      };

      const testAgent = new TestAgent();
      testAgent.subscribe(errorSubscriber);
      testAgent.subscribe(workingSubscriber);
      testAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
      ]);

      await testAgent.runAgent({});

      expect(errorSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
      expect(workingSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
    });
  });

  describe("Realistic Event Sequences", () => {
    test("should handle a realistic conversation with mixed events", async () => {
      const realisticAgent = new TestAgent();
      realisticAgent.subscribe(mockSubscriber);
      realisticAgent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          runId: "run-123",
        } as RunStartedEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Let me search for that information.",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-1",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-1",
          delta: '{"query": "weather today"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-1",
        } as ToolCallEndEvent,
        {
          type: EventType.TOOL_CALL_RESULT,
          toolCallId: "call-1",
          content: "Sunny, 75°F",
          messageId: "result-1",
        } as ToolCallResultEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-2",
          delta: "The weather today is sunny and 75°F.",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-2",
        } as TextMessageEndEvent,
        {
          type: EventType.STATE_SNAPSHOT,
          state: { weather: "sunny" },
        } as StateSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          runId: "run-123",
          result: "success",
        } as RunFinishedEvent,
      ]);

      await realisticAgent.runAgent({});

      // Verify complete sequence was processed
      expect(mockSubscriber.onRunStartedEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onTextMessageStartEvent).toHaveBeenCalledTimes(2);
      expect(mockSubscriber.onTextMessageEndEvent).toHaveBeenCalledTimes(2);
      expect(mockSubscriber.onToolCallStartEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onToolCallEndEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onToolCallResultEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onStateSnapshotEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onRunFinishedEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledTimes(3); // 2 TEXT_MESSAGE_END + 1 TOOL_CALL_RESULT
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(1);
    });
  });

  describe("Advanced Mutation Tests", () => {
    test("should handle mutations with stopPropagation in tool call events", async () => {
      const mutatingSubscriber = {
        onToolCallStartEvent: jest.fn().mockResolvedValue({
          state: { toolCallBlocked: true },
          stopPropagation: true,
        }),
      };

      const secondSubscriber = {
        onToolCallStartEvent: jest.fn(),
      };

      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mutatingSubscriber);
      toolCallAgent.subscribe(secondSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
      ]);

      await toolCallAgent.runAgent({});

      expect(mutatingSubscriber.onToolCallStartEvent).toHaveBeenCalled();
      expect(secondSubscriber.onToolCallStartEvent).not.toHaveBeenCalled();
    });

    test("should accumulate mutations across multiple event types", async () => {
      let messageCount = 0;
      let stateUpdates = 0;

      const trackingSubscriber = {
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          messageCount++;
          return { state: { messageCount } };
        }),
        onToolCallStartEvent: jest.fn().mockImplementation(() => {
          stateUpdates++;
          return { state: { stateUpdates } };
        }),
      };

      const mixedAgent = new TestAgent();
      mixedAgent.subscribe(mockSubscriber);
      mixedAgent.subscribe(trackingSubscriber);
      mixedAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-1",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
        } as TextMessageStartEvent,
      ]);

      await mixedAgent.runAgent({});

      expect(trackingSubscriber.onTextMessageStartEvent).toHaveBeenCalledTimes(2);
      expect(trackingSubscriber.onToolCallStartEvent).toHaveBeenCalledTimes(1);
    });
  });

  describe("EmptyError Bug Reproduction", () => {
    test("should demonstrate EmptyError with STEP_STARTED/STEP_FINISHED events that cause no mutations", async () => {
      const emptyAgent = new TestAgent();

      // No subscribers that return mutations
      emptyAgent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          runId: "run-123",
        } as RunStartedEvent,
        {
          type: EventType.STEP_STARTED,
          stepName: "step-1",
        } as StepStartedEvent,
        {
          type: EventType.STEP_FINISHED,
          stepName: "step-1",
        } as StepFinishedEvent,
        {
          type: EventType.RUN_FINISHED,
          runId: "run-123",
        } as RunFinishedEvent,
      ]);

      // This should throw EmptyError because:
      // 1. STEP_STARTED and STEP_FINISHED have no default behavior (don't modify messages/state)
      // 2. No subscribers return mutations
      // 3. ALL calls to emitUpdates() return EMPTY
      // 4. Observable completes without emitting anything
      await expect(emptyAgent.runAgent({}));
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/default.ts
================================================
import {
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  Message,
  DeveloperMessage,
  SystemMessage,
  AssistantMessage,
  UserMessage,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
  CustomEvent,
  BaseEvent,
  ToolCallResultEvent,
  ToolMessage,
  RunAgentInput,
  TextMessageEndEvent,
  ToolCallEndEvent,
  RawEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { mergeMap, mergeAll, defaultIfEmpty, concatMap } from "rxjs/operators";
import { of, EMPTY } from "rxjs";
import { structuredClone_ } from "../utils";
import { applyPatch } from "fast-json-patch";
import {
  AgentStateMutation,
  AgentSubscriber,
  runSubscribersWithMutation,
} from "@/agent/subscriber";
import { Observable } from "rxjs";
import { AbstractAgent } from "@/agent/agent";
import untruncateJson from "untruncate-json";

export const defaultApplyEvents = (
  input: RunAgentInput,
  events$: Observable<BaseEvent>,
  agent: AbstractAgent,
  subscribers: AgentSubscriber[],
): Observable<AgentStateMutation> => {
  let messages = structuredClone_(input.messages);
  let state = structuredClone_(input.state);
  let currentMutation: AgentStateMutation = {};

  const applyMutation = (mutation: AgentStateMutation) => {
    if (mutation.messages !== undefined) {
      messages = mutation.messages;
      currentMutation.messages = mutation.messages;
    }
    if (mutation.state !== undefined) {
      state = mutation.state;
      currentMutation.state = mutation.state;
    }
  };

  const emitUpdates = () => {
    const result = structuredClone_(currentMutation) as AgentStateMutation;
    currentMutation = {};
    if (result.messages !== undefined || result.state !== undefined) {
      return of(result);
    }
    return EMPTY;
  };

  return events$.pipe(
    concatMap(async (event) => {
      const mutation = await runSubscribersWithMutation(
        subscribers,
        messages,
        state,
        (subscriber, messages, state) =>
          subscriber.onEvent?.({ event, agent, input, messages, state }),
      );
      applyMutation(mutation);

      if (mutation.stopPropagation === true) {
        return emitUpdates();
      }

      switch (event.type) {
        case EventType.TEXT_MESSAGE_START: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageStartEvent?.({
                event: event as TextMessageStartEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messageId, role = "assistant" } = event as TextMessageStartEvent;

            // Create a new message using properties from the event
            // Text messages can be developer, system, assistant, or user (not tool)
            const newMessage: Message = {
              id: messageId,
              role: role,
              content: "",
            };

            // Add the new message to the messages array
            messages.push(newMessage);
            applyMutation({ messages });
          }
          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_CONTENT: {
          const { messageId, delta } = event as TextMessageContentEvent;

          // Find the target message by ID
          const targetMessage = messages.find((m) => m.id === messageId);
          if (!targetMessage) {
            console.warn(`TEXT_MESSAGE_CONTENT: No message found with ID '${messageId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageContentEvent?.({
                event: event as TextMessageContentEvent,
                messages,
                state,
                agent,
                input,
                textMessageBuffer: targetMessage.content ?? "",
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            // Append content to the correct message by ID
            targetMessage.content = (targetMessage.content || "") + delta;
            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_END: {
          const { messageId } = event as TextMessageEndEvent;

          // Find the target message by ID
          const targetMessage = messages.find((m) => m.id === messageId);
          if (!targetMessage) {
            console.warn(`TEXT_MESSAGE_END: No message found with ID '${messageId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageEndEvent?.({
                event: event as TextMessageEndEvent,
                messages,
                state,
                agent,
                input,
                textMessageBuffer: targetMessage.content ?? "",
              }),
          );
          applyMutation(mutation);

          await Promise.all(
            subscribers.map((subscriber) => {
              subscriber.onNewMessage?.({
                message: targetMessage,
                messages,
                state,
                agent,
                input,
              });
            }),
          );

          return emitUpdates();
        }

        case EventType.TOOL_CALL_START: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onToolCallStartEvent?.({
                event: event as ToolCallStartEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { toolCallId, toolCallName, parentMessageId } = event as ToolCallStartEvent;

            let targetMessage: AssistantMessage;

            // Use last message if parentMessageId exists, we have messages, and the parentMessageId matches the last message's id
            if (
              parentMessageId &&
              messages.length > 0 &&
              messages[messages.length - 1].id === parentMessageId
            ) {
              targetMessage = messages[messages.length - 1] as AssistantMessage;
            } else {
              // Create a new message otherwise
              targetMessage = {
                id: parentMessageId || toolCallId,
                role: "assistant",
                toolCalls: [],
              };
              messages.push(targetMessage);
            }

            targetMessage.toolCalls ??= [];

            // Add the new tool call
            targetMessage.toolCalls.push({
              id: toolCallId,
              type: "function",
              function: {
                name: toolCallName,
                arguments: "",
              },
            });

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TOOL_CALL_ARGS: {
          const { toolCallId, delta } = event as ToolCallArgsEvent;

          // Find the message containing this tool call
          const targetMessage = messages.find((m) =>
            (m as AssistantMessage).toolCalls?.some((tc) => tc.id === toolCallId),
          ) as AssistantMessage;

          if (!targetMessage) {
            console.warn(
              `TOOL_CALL_ARGS: No message found containing tool call with ID '${toolCallId}'`,
            );
            return emitUpdates();
          }

          // Find the specific tool call
          const targetToolCall = targetMessage.toolCalls!.find((tc) => tc.id === toolCallId);
          if (!targetToolCall) {
            console.warn(`TOOL_CALL_ARGS: No tool call found with ID '${toolCallId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) => {
              const toolCallBuffer = targetToolCall.function.arguments;
              const toolCallName = targetToolCall.function.name;
              let partialToolCallArgs = {};
              try {
                // Parse from toolCallBuffer only (before current delta is applied)
                partialToolCallArgs = untruncateJson(toolCallBuffer);
              } catch (error) {}

              return subscriber.onToolCallArgsEvent?.({
                event: event as ToolCallArgsEvent,
                messages,
                state,
                agent,
                input,
                toolCallBuffer,
                toolCallName,
                partialToolCallArgs,
              });
            },
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            // Append the arguments to the correct tool call by ID
            targetToolCall.function.arguments += delta;
            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TOOL_CALL_END: {
          const { toolCallId } = event as ToolCallEndEvent;

          // Find the message containing this tool call
          const targetMessage = messages.find((m) =>
            (m as AssistantMessage).toolCalls?.some((tc) => tc.id === toolCallId),
          ) as AssistantMessage;

          if (!targetMessage) {
            console.warn(
              `TOOL_CALL_END: No message found containing tool call with ID '${toolCallId}'`,
            );
            return emitUpdates();
          }

          // Find the specific tool call
          const targetToolCall = targetMessage.toolCalls!.find((tc) => tc.id === toolCallId);
          if (!targetToolCall) {
            console.warn(`TOOL_CALL_END: No tool call found with ID '${toolCallId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) => {
              const toolCallArgsString = targetToolCall.function.arguments;
              const toolCallName = targetToolCall.function.name;
              let toolCallArgs = {};
              try {
                toolCallArgs = JSON.parse(toolCallArgsString);
              } catch (error) {}
              return subscriber.onToolCallEndEvent?.({
                event: event as ToolCallEndEvent,
                messages,
                state,
                agent,
                input,
                toolCallName,
                toolCallArgs,
              });
            },
          );
          applyMutation(mutation);

          await Promise.all(
            subscribers.map((subscriber) => {
              subscriber.onNewToolCall?.({
                toolCall: targetToolCall,
                messages,
                state,
                agent,
                input,
              });
            }),
          );

          return emitUpdates();
        }

        case EventType.TOOL_CALL_RESULT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onToolCallResultEvent?.({
                event: event as ToolCallResultEvent,
                messages,
                state,
                agent,
                input,
              }),
          );

          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messageId, toolCallId, content, role } = event as ToolCallResultEvent;

            const toolMessage: ToolMessage = {
              id: messageId,
              toolCallId,
              role: role || "tool",
              content: content,
            };

            messages.push(toolMessage);

            await Promise.all(
              subscribers.map((subscriber) => {
                subscriber.onNewMessage?.({
                  message: toolMessage,
                  messages,
                  state,
                  agent,
                  input,
                });
              }),
            );

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.STATE_SNAPSHOT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStateSnapshotEvent?.({
                event: event as StateSnapshotEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { snapshot } = event as StateSnapshotEvent;

            // Replace state with the literal snapshot
            state = snapshot;

            applyMutation({ state });
          }

          return emitUpdates();
        }

        case EventType.STATE_DELTA: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStateDeltaEvent?.({
                event: event as StateDeltaEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { delta } = event as StateDeltaEvent;

            try {
              // Apply the JSON Patch operations to the current state without mutating the original
              const result = applyPatch(state, delta, true, false);
              state = result.newDocument;
              applyMutation({ state });
            } catch (error: unknown) {
              const errorMessage = error instanceof Error ? error.message : String(error);
              console.warn(
                `Failed to apply state patch:\n` +
                  `Current state: ${JSON.stringify(state, null, 2)}\n` +
                  `Patch operations: ${JSON.stringify(delta, null, 2)}\n` +
                  `Error: ${errorMessage}`,
              );
              // If patch failed, only emit updates if there were subscriber mutations
              // This prevents emitting updates when both patch fails AND no subscriber mutations
            }
          }

          return emitUpdates();
        }

        case EventType.MESSAGES_SNAPSHOT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onMessagesSnapshotEvent?.({
                event: event as MessagesSnapshotEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messages: newMessages } = event as MessagesSnapshotEvent;

            // Replace messages with the snapshot
            messages = newMessages;

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.RAW: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRawEvent?.({
                event: event as RawEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.CUSTOM: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onCustomEvent?.({
                event: event as CustomEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_STARTED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunStartedEvent?.({
                event: event as RunStartedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_FINISHED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunFinishedEvent?.({
                event: event as RunFinishedEvent,
                messages,
                state,
                agent,
                input,
                result: (event as RunFinishedEvent).result,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_ERROR: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunErrorEvent?.({
                event: event as RunErrorEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.STEP_STARTED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStepStartedEvent?.({
                event: event as StepStartedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.STEP_FINISHED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStepFinishedEvent?.({
                event: event as StepFinishedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_CHUNK: {
          throw new Error("TEXT_MESSAGE_CHUNK must be tranformed before being applied");
        }

        case EventType.TOOL_CALL_CHUNK: {
          throw new Error("TOOL_CALL_CHUNK must be tranformed before being applied");
        }

        case EventType.THINKING_START: {
          return emitUpdates();
        }

        case EventType.THINKING_END: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_START: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_CONTENT: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_END: {
          return emitUpdates();
        }
      }

      // This makes TypeScript check that the switch is exhaustive
      // If a new EventType is added, this will cause a compile error
      const _exhaustiveCheck: never = event.type;
      return emitUpdates();
    }),
    mergeAll(),
    // Only use defaultIfEmpty when there are subscribers to avoid emitting empty updates
    // when patches fail and there are no subscribers (like in state patching test)
    subscribers.length > 0 ? defaultIfEmpty({} as AgentStateMutation) : (stream: any) => stream,
  );
};



================================================
FILE: typescript-sdk/packages/client/src/apply/index.ts
================================================
export { defaultApplyEvents } from "./default";



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.concurrent.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { defaultApplyEvents } from "../default";
import {
  BaseEvent,
  EventType,
  RunAgentInput,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  Message,
  AssistantMessage,
} from "@ag-ui/core";
import { AbstractAgent } from "../../agent";

// Mock agent for testing
const FAKE_AGENT = {
  messages: [],
  state: {},
  agentId: "test-agent",
} as unknown as AbstractAgent;

describe("defaultApplyEvents concurrent operations", () => {
  // Test: Concurrent text messages should create separate messages
  it("should handle concurrent text messages correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for concurrent text messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start two concurrent text messages
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
      role: "assistant",
    } as TextMessageStartEvent);

    // Send content for both messages
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "First message content",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Second message content",
    } as TextMessageContentEvent);

    // End messages in reverse order
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Verify we have the expected number of state updates
    expect(stateUpdates.length).toBeGreaterThan(0);

    // Check final state has both messages
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify messages have correct IDs and content
    const msg1 = finalState.messages?.find((m) => m.id === "msg1");
    const msg2 = finalState.messages?.find((m) => m.id === "msg2");

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.content).toBe("First message content");
    expect(msg2?.content).toBe("Second message content");
    expect(msg1?.role).toBe("assistant");
    expect(msg2?.role).toBe("assistant");
  });

  // Test: Concurrent tool calls should create separate tool calls
  it("should handle concurrent tool calls correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for concurrent tool calls
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start two concurrent tool calls
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: "msg1",
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
      parentMessageId: "msg2",
    } as ToolCallStartEvent);

    // Send args for both tool calls
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test search"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);

    // End tool calls in reverse order
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Verify we have the expected number of state updates
    expect(stateUpdates.length).toBeGreaterThan(0);

    // Check final state has both messages with tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify tool calls are properly attached to messages
    const msg1 = finalState.messages?.find((m) => m.id === "msg1") as AssistantMessage;
    const msg2 = finalState.messages?.find((m) => m.id === "msg2") as AssistantMessage;

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.toolCalls?.length).toBe(1);
    expect(msg2?.toolCalls?.length).toBe(1);

    // Verify tool call details
    expect(msg1.toolCalls?.[0]?.id).toBe("tool1");
    expect(msg1.toolCalls?.[0]?.function.name).toBe("search");
    expect(msg1.toolCalls?.[0]?.function.arguments).toBe('{"query":"test search"}');

    expect(msg2.toolCalls?.[0]?.id).toBe("tool2");
    expect(msg2.toolCalls?.[0]?.function.name).toBe("calculate");
    expect(msg2.toolCalls?.[0]?.function.arguments).toBe('{"expression":"1+1"}');
  });

  // Test: Mixed concurrent messages and tool calls
  it("should handle mixed concurrent text messages and tool calls", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send mixed concurrent events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start a text message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "thinking_msg",
      role: "assistant",
    } as TextMessageStartEvent);

    // Start a tool call while message is active
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "search_tool",
      toolCallName: "web_search",
      parentMessageId: "tool_msg",
    } as ToolCallStartEvent);

    // Add content to text message
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "thinking_msg",
      delta: "Let me search for that information...",
    } as TextMessageContentEvent);

    // Add args to tool call
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "search_tool",
      delta: '{"query":"concurrent events"}',
    } as ToolCallArgsEvent);

    // Start another text message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "status_msg",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "status_msg",
      delta: "Processing your request...",
    } as TextMessageContentEvent);

    // End everything in mixed order
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "thinking_msg",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "search_tool",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "status_msg",
    } as TextMessageEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(3);

    // Verify all messages are present
    const thinkingMsg = finalState.messages?.find((m) => m.id === "thinking_msg");
    const toolMsg = finalState.messages?.find((m) => m.id === "tool_msg") as AssistantMessage;
    const statusMsg = finalState.messages?.find((m) => m.id === "status_msg");

    expect(thinkingMsg).toBeDefined();
    expect(toolMsg).toBeDefined();
    expect(statusMsg).toBeDefined();

    expect(thinkingMsg?.content).toBe("Let me search for that information...");
    expect(statusMsg?.content).toBe("Processing your request...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("web_search");
  });

  // Test: Multiple tool calls on the same message
  it("should handle multiple tool calls on the same parent message", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();

    // Create initial state with an existing message
    const parentMessageId = "parent_msg";
    const initialState: RunAgentInput = {
      messages: [
        {
          id: parentMessageId,
          role: "assistant",
          content: "I'll help you with multiple tools.",
          toolCalls: [],
        },
      ],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for multiple tool calls on the same message
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start multiple tool calls concurrently with the same parent message
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool3",
      toolCallName: "format",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    // Send args for all tool calls
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"2*3"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool3",
      delta: '{"format":"json"}',
    } as ToolCallArgsEvent);

    // End all tool calls
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool3",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state - should still have only one message with 3 tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(1);

    const parentMsg = finalState.messages?.[0] as AssistantMessage;
    expect(parentMsg.id).toBe(parentMessageId);
    expect(parentMsg.toolCalls?.length).toBe(3);

    // Verify all tool calls are present
    const toolCallIds = parentMsg.toolCalls?.map((tc) => tc.id).sort();
    expect(toolCallIds).toEqual(["tool1", "tool2", "tool3"]);

    // Verify tool call details
    const searchTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool1");
    const calcTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool2");
    const formatTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool3");

    expect(searchTool?.function.name).toBe("search");
    expect(calcTool?.function.name).toBe("calculate");
    expect(formatTool?.function.name).toBe("format");

    expect(searchTool?.function.arguments).toBe('{"query":"test"}');
    expect(calcTool?.function.arguments).toBe('{"expression":"2*3"}');
    expect(formatTool?.function.arguments).toBe('{"format":"json"}');
  });

  // Test: High-frequency concurrent events
  it("should handle high-frequency concurrent events", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Create many concurrent messages and tool calls
    const numMessages = 10;
    const numToolCalls = 10;

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      events$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events$.next({
        type: EventType.TOOL_CALL_START,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Send content for all messages
    for (let i = 0; i < numMessages; i++) {
      events$.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg${i}`,
        delta: `Content for message ${i}`,
      } as TextMessageContentEvent);
    }

    // Send args for all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events$.next({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: `tool${i}`,
        delta: `{"param${i}":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all in reverse order
    for (let i = numMessages - 1; i >= 0; i--) {
      events$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    for (let i = numToolCalls - 1; i >= 0; i--) {
      events$.next({
        type: EventType.TOOL_CALL_END,
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];

    // Should have numMessages + numToolCalls messages total
    expect(finalState.messages?.length).toBe(numMessages + numToolCalls);

    // Verify all text messages are present with correct content
    for (let i = 0; i < numMessages; i++) {
      const msg = finalState.messages?.find((m) => m.id === `msg${i}`);
      expect(msg).toBeDefined();
      expect(msg?.content).toBe(`Content for message ${i}`);
      expect(msg?.role).toBe("assistant");
    }

    // Verify all tool call messages are present with correct tool calls
    for (let i = 0; i < numToolCalls; i++) {
      const toolMsg = finalState.messages?.find((m) => m.id === `tool_msg${i}`) as AssistantMessage;
      expect(toolMsg).toBeDefined();
      expect(toolMsg?.toolCalls?.length).toBe(1);
      expect(toolMsg.toolCalls?.[0]?.id).toBe(`tool${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.name).toBe(`tool_${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe(`{"param${i}":"value${i}"}`);
    }
  });

  // Test: Interleaved content and args updates
  it("should handle interleaved content and args updates correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start concurrent message and tool call
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: "tool_msg1",
    } as ToolCallStartEvent);

    // Interleave content and args updates
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Searching ",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"que',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "for ",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: 'ry":"',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "information...",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: 'test"}',
    } as ToolCallArgsEvent);

    // End both
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify text message content is assembled correctly
    const textMsg = finalState.messages?.find((m) => m.id === "msg1");
    expect(textMsg?.content).toBe("Searching for information...");

    // Verify tool call args are assembled correctly
    const toolMsg = finalState.messages?.find((m) => m.id === "tool_msg1") as AssistantMessage;
    expect(toolMsg?.toolCalls?.[0]?.function.arguments).toBe('{"query":"test"}');
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.state.test.ts
================================================
import { AbstractAgent } from "@/agent";
import { defaultApplyEvents } from "../default";
import { EventType, StateDeltaEvent } from "@ag-ui/core";
import { of } from "rxjs";
import { AgentStateMutation } from "@/agent/subscriber";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents - State Patching", () => {
  it("should apply state delta patch correctly", (done) => {
    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [
        { op: "replace", path: "/count", value: 1 },
        { op: "replace", path: "/text", value: "world" },
      ],
    };

    const events$ = of(stateDelta);

    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        count: 1,
        text: "world",
      });
      done();
    });
  });

  it("should handle nested state updates", (done) => {
    const initialState = {
      messages: [],
      state: {
        user: {
          name: "John",
          settings: {
            theme: "light",
          },
        },
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [{ op: "replace", path: "/user/settings/theme", value: "dark" }],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        user: {
          name: "John",
          settings: {
            theme: "dark",
          },
        },
      });
      done();
    });
  });

  it("should handle array updates", (done) => {
    const initialState = {
      messages: [],
      state: {
        items: ["a", "b", "c"],
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [
        { op: "add", path: "/items/-", value: "d" },
        { op: "replace", path: "/items/0", value: "x" },
      ],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        items: ["x", "b", "c", "d"],
      });
      done();
    });
  });

  it("should handle multiple patches in sequence", (done) => {
    const initialState = {
      messages: [],
      state: {
        counter: 0,
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDeltas: StateDeltaEvent[] = [
      {
        type: EventType.STATE_DELTA,
        delta: [{ op: "replace", path: "/counter", value: 1 }],
      },
      {
        type: EventType.STATE_DELTA,
        delta: [{ op: "replace", path: "/counter", value: 2 }],
      },
    ];

    const events$ = of(...stateDeltas);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    let updateCount = 0;
    result$.subscribe((update: AgentStateMutation) => {
      updateCount++;
      if (updateCount === 2) {
        expect(update.state).toEqual({
          counter: 2,
        });
        done();
      }
    });
  });

  it("should handle invalid patch operations gracefully", (done) => {
    // Suppress console.warn for this test
    const originalWarn = console.warn;
    console.warn = jest.fn();

    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Invalid patch: trying to replace a non-existent path
    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [{ op: "replace", path: "/nonexistent", value: 1 }],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    let updateCount = 0;
    result$.subscribe({
      next: (update: AgentStateMutation) => {
        updateCount++;
      },
      complete: () => {
        // When patch fails, no updates should be emitted
        expect(updateCount).toBe(0);
        // Restore original console.warn
        console.warn = originalWarn;
        done();
      },
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.text-message.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import {
  BaseEvent,
  EventType,
  RunStartedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunAgentInput,
} from "@ag-ui/core";
import { defaultApplyEvents } from "../default";
import { AbstractAgent } from "@/agent";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents with text messages", () => {
  it("should handle text message events correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Hello ",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "world!",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 3 state updates:
    // 1. After TEXT_MESSAGE_START
    // 2. After first TEXT_MESSAGE_CONTENT
    // 3. After second TEXT_MESSAGE_CONTENT
    // And NO update after TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(3);

    // First update: empty message added
    expect(stateUpdates[0]?.messages?.length).toBe(1);
    expect(stateUpdates[0]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[0]?.messages?.[0]?.content).toBe("");

    // Second update: first content chunk added
    expect(stateUpdates[1]?.messages?.length).toBe(1);
    expect(stateUpdates[1]?.messages?.[0]?.content).toBe("Hello ");

    // Third update: second content chunk appended
    expect(stateUpdates[2]?.messages?.length).toBe(1);
    expect(stateUpdates[2]?.messages?.[0]?.content).toBe("Hello world!");

    // Verify the last update came from TEXT_MESSAGE_CONTENT, not TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(3);
  });

  it("should handle multiple text messages correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for two different messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "First message",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Second message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
      role: "user",
    } as unknown as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Second message",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After first TEXT_MESSAGE_START
    // 2. After first TEXT_MESSAGE_CONTENT
    // 3. After second TEXT_MESSAGE_START
    // 4. After second TEXT_MESSAGE_CONTENT
    // And NO updates after either TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(4);

    // First update: first empty message added
    expect(stateUpdates[0]?.messages?.length).toBe(1);
    expect(stateUpdates[0]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[0]?.messages?.[0]?.role).toBe("assistant");
    expect(stateUpdates[0]?.messages?.[0]?.content).toBe("");

    // Second update: first message content added
    expect(stateUpdates[1]?.messages?.length).toBe(1);
    expect(stateUpdates[1]?.messages?.[0]?.content).toBe("First message");

    // Third update: second empty message added
    expect(stateUpdates[2]?.messages?.length).toBe(2);
    expect(stateUpdates[2]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[2]?.messages?.[0]?.content).toBe("First message");
    expect(stateUpdates[2]?.messages?.[1]?.id).toBe("msg2");
    expect(stateUpdates[2]?.messages?.[1]?.role).toBe("user");
    expect(stateUpdates[2]?.messages?.[1]?.content).toBe("");

    // Fourth update: second message content added
    expect(stateUpdates[3]?.messages?.length).toBe(2);
    expect(stateUpdates[3]?.messages?.[0]?.content).toBe("First message");
    expect(stateUpdates[3]?.messages?.[1]?.content).toBe("Second message");

    // Verify no additional updates after either TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(4);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.tool-calls.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import {
  BaseEvent,
  EventType,
  RunStartedEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  RunAgentInput,
  AssistantMessage,
} from "@ag-ui/core";
import { defaultApplyEvents } from "../default";
import { AbstractAgent } from "@/agent";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents with tool calls", () => {
  it("should handle a single tool call correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query": "',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: "test search",
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After TOOL_CALL_START
    // 2-4. After each TOOL_CALL_ARGS
    // And NO update after TOOL_CALL_END
    expect(stateUpdates.length).toBe(4);

    // First update: tool call created
    expect(stateUpdates[0].messages?.length).toBe(1);
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect(
      (stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe("");

    // Second update: first args chunk added
    expect(
      (stateUpdates[1].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "');

    // Third update: second args chunk appended
    expect(
      (stateUpdates[2].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "test search');

    // Fourth update: third args chunk appended
    expect(
      (stateUpdates[3].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "test search"}');
  });

  it("should handle multiple tool calls correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for two different tool calls
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Second tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After first TOOL_CALL_START
    // 2. After first TOOL_CALL_ARGS
    // 3. After second TOOL_CALL_START
    // 4. After second TOOL_CALL_ARGS
    expect(stateUpdates.length).toBe(4);

    // Check last state update for the correct tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // First message should have first tool call
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query":"test"}',
    );

    // Second message should have second tool call
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool2");
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "calculate",
    );
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"expression":"1+1"}',
    );
  });

  it("should handle tool calls with parent message ID correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();

    // Create initial state with an existing message
    const parentMessageId = "existing_message";
    const initialState: RunAgentInput = {
      messages: [
        {
          id: parentMessageId,
          role: "assistant",
          content: "I'll help you with that.",
          toolCalls: [],
        },
      ],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 2 state updates
    expect(stateUpdates.length).toBe(2);

    // Check that the tool call was added to the existing message
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(1);
    expect(finalState.messages?.[0]?.id).toBe(parentMessageId);
    expect(finalState.messages?.[0]?.content).toBe("I'll help you with that.");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query":"test"}',
    );
  });

  it("should handle errors and partial updates correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events with errors in the tool args JSON
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query',
    } as ToolCallArgsEvent); // Incomplete JSON
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: ':"test"}',
    } as ToolCallArgsEvent); // Completes the JSON
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should still have updates despite the JSON syntax error
    expect(stateUpdates.length).toBe(3);

    // Check the final JSON (should be valid now)
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query:"test"}',
    );
  });

  it("should handle advanced scenarios with multiple tools and text messages", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events with a mix of tool calls and text messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Second tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check for expected state updates
    expect(stateUpdates.length).toBe(4);

    // Check the final state for both tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify first tool call
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );

    // Verify second tool call
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool2");
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "calculate",
    );
  });
});



================================================
FILE: typescript-sdk/packages/client/src/chunks/index.ts
================================================
export * from "./transform";



================================================
FILE: typescript-sdk/packages/client/src/chunks/transform.ts
================================================
import { mergeMap, Observable, finalize } from "rxjs";
import {
  BaseEvent,
  TextMessageChunkEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallChunkEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
} from "@ag-ui/core";
import { EventType } from "@ag-ui/core";

interface TextMessageFields {
  messageId: string;
}

interface ToolCallFields {
  toolCallId: string;
  toolCallName: string;
  parentMessageId?: string;
}

export const transformChunks =
  (debug: boolean) =>
  (events$: Observable<BaseEvent>): Observable<BaseEvent> => {
    let textMessageFields: TextMessageFields | undefined;
    let toolCallFields: ToolCallFields | undefined;
    let mode: "text" | "tool" | undefined;

    const closeTextMessage = () => {
      if (!textMessageFields || mode !== "text") {
        throw new Error("No text message to close");
      }
      const event = {
        type: EventType.TEXT_MESSAGE_END,
        messageId: textMessageFields.messageId,
      } as TextMessageEndEvent;
      mode = undefined;
      textMessageFields = undefined;

      if (debug) {
        console.debug("[TRANSFORM]: TEXT_MESSAGE_END", JSON.stringify(event));
      }

      return event;
    };

    const closeToolCall = () => {
      if (!toolCallFields || mode !== "tool") {
        throw new Error("No tool call to close");
      }
      const event = {
        type: EventType.TOOL_CALL_END,
        toolCallId: toolCallFields.toolCallId,
      } as ToolCallEndEvent;
      mode = undefined;
      toolCallFields = undefined;

      if (debug) {
        console.debug("[TRANSFORM]: TOOL_CALL_END", JSON.stringify(event));
      }

      return event;
    };

    const closePendingEvent = () => {
      if (mode === "text") {
        return [closeTextMessage()];
      }
      if (mode === "tool") {
        return [closeToolCall()];
      }
      return [];
    };

    return events$.pipe(
      mergeMap((event) => {
        switch (event.type) {
          case EventType.TEXT_MESSAGE_START:
          case EventType.TEXT_MESSAGE_CONTENT:
          case EventType.TEXT_MESSAGE_END:
          case EventType.TOOL_CALL_START:
          case EventType.TOOL_CALL_ARGS:
          case EventType.TOOL_CALL_END:
          case EventType.TOOL_CALL_RESULT:
          case EventType.STATE_SNAPSHOT:
          case EventType.STATE_DELTA:
          case EventType.MESSAGES_SNAPSHOT:
          case EventType.CUSTOM:
          case EventType.RUN_STARTED:
          case EventType.RUN_FINISHED:
          case EventType.RUN_ERROR:
          case EventType.STEP_STARTED:
          case EventType.STEP_FINISHED:
          case EventType.THINKING_START:
          case EventType.THINKING_END:
          case EventType.THINKING_TEXT_MESSAGE_START:
          case EventType.THINKING_TEXT_MESSAGE_CONTENT:
          case EventType.THINKING_TEXT_MESSAGE_END:
            return [...closePendingEvent(), event];
          case EventType.RAW:
            return [event];
          case EventType.TEXT_MESSAGE_CHUNK:
            const messageChunkEvent = event as TextMessageChunkEvent;
            const textMessageResult = [];
            if (
              // we are not in a text message
              mode !== "text" ||
              // or the message id is different
              (messageChunkEvent.messageId !== undefined &&
                messageChunkEvent.messageId !== textMessageFields?.messageId)
            ) {
              // close the current message if any
              textMessageResult.push(...closePendingEvent());
            }

            // we are not in a text message, start a new one
            if (mode !== "text") {
              if (messageChunkEvent.messageId === undefined) {
                throw new Error("First TEXT_MESSAGE_CHUNK must have a messageId");
              }

              textMessageFields = {
                messageId: messageChunkEvent.messageId,
              };
              mode = "text";

              const textMessageStartEvent = {
                type: EventType.TEXT_MESSAGE_START,
                messageId: messageChunkEvent.messageId,
                role: messageChunkEvent.role || "assistant",
              } as TextMessageStartEvent;

              textMessageResult.push(textMessageStartEvent);

              if (debug) {
                console.debug(
                  "[TRANSFORM]: TEXT_MESSAGE_START",
                  JSON.stringify(textMessageStartEvent),
                );
              }
            }

            if (messageChunkEvent.delta !== undefined) {
              const textMessageContentEvent = {
                type: EventType.TEXT_MESSAGE_CONTENT,
                messageId: textMessageFields!.messageId,
                delta: messageChunkEvent.delta,
              } as TextMessageContentEvent;

              textMessageResult.push(textMessageContentEvent);

              if (debug) {
                console.debug(
                  "[TRANSFORM]: TEXT_MESSAGE_CONTENT",
                  JSON.stringify(textMessageContentEvent),
                );
              }
            }

            return textMessageResult;
          case EventType.TOOL_CALL_CHUNK:
            const toolCallChunkEvent = event as ToolCallChunkEvent;
            const toolMessageResult = [];
            if (
              // we are not in a text message
              mode !== "tool" ||
              // or the tool call id is different
              (toolCallChunkEvent.toolCallId !== undefined &&
                toolCallChunkEvent.toolCallId !== toolCallFields?.toolCallId)
            ) {
              // close the current message if any
              toolMessageResult.push(...closePendingEvent());
            }

            if (mode !== "tool") {
              if (toolCallChunkEvent.toolCallId === undefined) {
                throw new Error("First TOOL_CALL_CHUNK must have a toolCallId");
              }
              if (toolCallChunkEvent.toolCallName === undefined) {
                throw new Error("First TOOL_CALL_CHUNK must have a toolCallName");
              }
              toolCallFields = {
                toolCallId: toolCallChunkEvent.toolCallId,
                toolCallName: toolCallChunkEvent.toolCallName,
                parentMessageId: toolCallChunkEvent.parentMessageId,
              };
              mode = "tool";

              const toolCallStartEvent = {
                type: EventType.TOOL_CALL_START,
                toolCallId: toolCallChunkEvent.toolCallId,
                toolCallName: toolCallChunkEvent.toolCallName,
                parentMessageId: toolCallChunkEvent.parentMessageId,
              } as ToolCallStartEvent;

              toolMessageResult.push(toolCallStartEvent);

              if (debug) {
                console.debug("[TRANSFORM]: TOOL_CALL_START", JSON.stringify(toolCallStartEvent));
              }
            }

            if (toolCallChunkEvent.delta !== undefined) {
              const toolCallArgsEvent = {
                type: EventType.TOOL_CALL_ARGS,
                toolCallId: toolCallFields!.toolCallId,
                delta: toolCallChunkEvent.delta,
              } as ToolCallArgsEvent;

              toolMessageResult.push(toolCallArgsEvent);

              if (debug) {
                console.debug("[TRANSFORM]: TOOL_CALL_ARGS", JSON.stringify(toolCallArgsEvent));
              }
            }

            return toolMessageResult;
        }
        const _exhaustiveCheck: never = event.type;
      }),
      finalize(() => {
        // This ensures that we close any pending events when the source observable completes
        return closePendingEvent();
      }),
    );
  };



================================================
FILE: typescript-sdk/packages/client/src/chunks/__tests__/transform-roles.test.ts
================================================
import { from } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  EventType,
  TextMessageChunkEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunFinishedEvent,
  Role,
} from "@ag-ui/core";
import { transformChunks } from "../transform";

describe("transformChunks with roles", () => {
  const roles: Role[] = ["developer", "system", "assistant", "user", "tool"];

  it.each(roles)(
    "should preserve role '%s' when transforming text message chunks",
    (role, done) => {
      const chunk: TextMessageChunkEvent = {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: `msg-${role}`,
        role: role as unknown as any,
        delta: `Hello from ${role}`,
      };

      // Add a non-chunk event to close the sequence
      const closeEvent: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      };

      from([chunk, closeEvent])
        .pipe(transformChunks(false), toArray())
        .subscribe({
          next: (events) => {
            expect(events).toHaveLength(4); // start, content, end, run_finished

            const startEvent = events[0] as TextMessageStartEvent;
            expect(startEvent.type).toBe(EventType.TEXT_MESSAGE_START);
            expect(startEvent.messageId).toBe(`msg-${role}`);
            expect(startEvent.role).toBe(role);

            const contentEvent = events[1] as TextMessageContentEvent;
            expect(contentEvent.type).toBe(EventType.TEXT_MESSAGE_CONTENT);
            expect(contentEvent.delta).toBe(`Hello from ${role}`);

            const endEvent = events[2] as TextMessageEndEvent;
            expect(endEvent.type).toBe(EventType.TEXT_MESSAGE_END);

            done();
          },
          error: done,
        });
    },
  );

  it("should default to 'assistant' role when chunk has no role", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-default",
      delta: "Hello default",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    from([chunk, closeEvent])
      .pipe(transformChunks(false), toArray())
      .subscribe({
        next: (events) => {
          expect(events).toHaveLength(4);

          const startEvent = events[0] as TextMessageStartEvent;
          expect(startEvent.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(startEvent.messageId).toBe("msg-default");
          expect(startEvent.role).toBe("assistant"); // default role

          done();
        },
        error: done,
      });
  });

  it("should handle multiple chunks with different roles", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-user",
      role: "user",
      delta: "User message",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-system",
      role: "system",
      delta: "System message",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    from([chunk1, chunk2, closeEvent])
      .pipe(transformChunks(false), toArray())
      .subscribe({
        next: (events) => {
          // Should have: start1, content1, end1, start2, content2, end2, run_finished
          expect(events).toHaveLength(7);

          // First message
          const start1 = events[0] as TextMessageStartEvent;
          expect(start1.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(start1.messageId).toBe("msg-user");
          expect(start1.role).toBe("user");

          const content1 = events[1] as TextMessageContentEvent;
          expect(content1.delta).toBe("User message");

          // Second message
          const start2 = events[3] as TextMessageStartEvent;
          expect(start2.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(start2.messageId).toBe("msg-system");
          expect(start2.role).toBe("system");

          const content2 = events[4] as TextMessageContentEvent;
          expect(content2.delta).toBe("System message");

          done();
        },
        error: done,
      });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/chunks/__tests__/transform.test.ts
================================================
import { of, Observable, concat, EMPTY, throwError } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { transformChunks } from "../transform";
import {
  BaseEvent,
  EventType,
  TextMessageChunkEvent,
  ToolCallChunkEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  RunStartedEvent,
  RawEvent,
  RunFinishedEvent,
} from "@ag-ui/core";

describe("transformChunks", () => {
  it("should transform a single text message chunk into start, content, and end events", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello, world!",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: "Hello, world!",
      } as TextMessageContentEvent);

      expect(events[2]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should transform multiple text message chunks with the same ID", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: ", world!",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk1, chunk2), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(5);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: "Hello",
      } as TextMessageContentEvent);

      expect(events[2]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: ", world!",
      } as TextMessageContentEvent);

      expect(events[3]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[4]).toEqual(closeEvent);

      done();
    });
  });

  it("should transform a single tool call chunk into start, args, and end events", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
      } as ToolCallStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-123",
        delta: '{"arg1": "value1"}',
      } as ToolCallArgsEvent);

      expect(events[2]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should handle switching from text message to tool call", (done) => {
    const textChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const toolChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(textChunk, toolChunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7);

      // Text message events
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);

      // Tool call events
      expect(events[3].type).toBe(EventType.TOOL_CALL_START);
      expect(events[4].type).toBe(EventType.TOOL_CALL_ARGS);
      expect(events[5].type).toBe(EventType.TOOL_CALL_END);

      // Run finished event
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should pass through non-chunk events", (done) => {
    const runStartEvent: RunStartedEvent = {
      type: EventType.RUN_STARTED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = of(runStartEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(1);
      expect(events[0]).toEqual(runStartEvent);
      done();
    });
  });

  it("should close current message when encountering a non-chunk event", (done) => {
    const textChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const runStartEvent: RunStartedEvent = {
      type: EventType.RUN_STARTED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = of(textChunk, runStartEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);
      expect(events[3].type).toBe(EventType.RUN_STARTED);

      done();
    });
  });

  it("should handle text message chunks with different IDs", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-456",
      delta: "Different message",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk1, chunk2), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7);

      // First message
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect((events[0] as TextMessageStartEvent).messageId).toBe("msg-123");

      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect((events[1] as TextMessageContentEvent).messageId).toBe("msg-123");

      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);
      expect((events[2] as TextMessageEndEvent).messageId).toBe("msg-123");

      // Second message
      expect(events[3].type).toBe(EventType.TEXT_MESSAGE_START);
      expect((events[3] as TextMessageStartEvent).messageId).toBe("msg-456");

      expect(events[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect((events[4] as TextMessageContentEvent).messageId).toBe("msg-456");

      expect(events[5].type).toBe(EventType.TEXT_MESSAGE_END);
      expect((events[5] as TextMessageEndEvent).messageId).toBe("msg-456");

      // Run finished event
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle errors when first text message chunk has no ID", (done) => {
    const invalidChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TEXT_MESSAGE_CHUNK must have a messageId");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle errors when first tool call chunk has no ID", (done) => {
    const invalidChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TOOL_CALL_CHUNK must have a toolCallId");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle errors when first tool call chunk has no name", (done) => {
    const invalidChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TOOL_CALL_CHUNK must have a toolCallName");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle tool call chunks with parentMessageId", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      parentMessageId: "parent-msg-123",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
        parentMessageId: "parent-msg-123",
      } as ToolCallStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-123",
        delta: '{"arg1": "value1"}',
      } as ToolCallArgsEvent);

      expect(events[2]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should pass through RAW events without transformation", (done) => {
    const rawEvent: RawEvent = {
      type: EventType.RAW,
      event: { some: "data" },
      source: "test-source",
    };

    const events$ = of(rawEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(1);
      expect(events[0]).toEqual(rawEvent);
      done();
    });
  });

  it("should handle a complex sequence of mixed events", (done) => {
    const events: BaseEvent[] = [
      // Text message chunk
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Hello",
      } as TextMessageChunkEvent,

      // Tool call chunk
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-123",
        toolCallName: "testTool",
        delta: '{"arg1": "value1"}',
      } as ToolCallChunkEvent,

      // Another text message chunk
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-456",
        delta: "After tool call",
      } as TextMessageChunkEvent,

      // Non-chunk event to close the sequence
      {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      } as RunFinishedEvent,
    ];

    const events$ = of(...events);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((result) => {
      expect(result.length).toBe(10);

      // First text message (3 events)
      expect(result[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(result[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(result[2].type).toBe(EventType.TEXT_MESSAGE_END);

      // Tool call (3 events)
      expect(result[3].type).toBe(EventType.TOOL_CALL_START);
      expect(result[4].type).toBe(EventType.TOOL_CALL_ARGS);
      expect(result[5].type).toBe(EventType.TOOL_CALL_END);

      // Second text message (3 events)
      expect(result[6].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(result[7].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(result[8].type).toBe(EventType.TEXT_MESSAGE_END);

      // Final event
      expect(result[9].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle text message chunks without delta", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      // No delta property
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(3);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      // No content event because there was no delta

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[2]).toEqual(closeEvent);

      done();
    });
  });

  it("should handle tool call chunks without delta", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      // No delta property
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(3);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
      } as ToolCallStartEvent);

      // No args event because there was no delta

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[2]).toEqual(closeEvent);

      done();
    });
  });

  it("should generate exactly one start and one end event for multiple chunks with same ID", (done) => {
    // Create multiple chunks with the same message ID
    const chunks: TextMessageChunkEvent[] = [
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "First part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Second part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Third part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Fourth part",
      },
    ];

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(...chunks), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7); // 1 start + 4 content + 1 end + 1 close event

      // Count events by type
      const eventCounts = events.reduce(
        (counts, event) => {
          counts[event.type] = (counts[event.type] || 0) + 1;
          return counts;
        },
        {} as Record<EventType, number>,
      );

      // There should be exactly one start event
      expect(eventCounts[EventType.TEXT_MESSAGE_START]).toBe(1);

      // There should be exactly one end event
      expect(eventCounts[EventType.TEXT_MESSAGE_END]).toBe(1);

      // There should be exactly four content events (one for each chunk)
      expect(eventCounts[EventType.TEXT_MESSAGE_CONTENT]).toBe(4);

      // There should be exactly one run finished event
      expect(eventCounts[EventType.RUN_FINISHED]).toBe(1);

      // All content events should have the same message ID
      const contentEvents = events.filter(
        (e) => e.type === EventType.TEXT_MESSAGE_CONTENT,
      ) as TextMessageContentEvent[];

      contentEvents.forEach((e) => {
        expect(e.messageId).toBe("msg-123");
      });

      // Events should be in correct order: start, content*4, end, run_finished
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[3].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[5].type).toBe(EventType.TEXT_MESSAGE_END);
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle interleaved chunks with different message and tool call IDs", (done) => {
    // Create a complex sequence that alternates between different types of chunks
    const events: BaseEvent[] = [
      // First text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-1",
        delta: "First message part 1",
      } as TextMessageChunkEvent,

      // First tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-1",
        toolCallName: "firstTool",
        delta: '{"arg1": "value1"}',
      } as ToolCallChunkEvent,

      // Back to first text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-1",
        delta: "First message part 2",
      } as TextMessageChunkEvent,

      // Second text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-2",
        delta: "Second message",
      } as TextMessageChunkEvent,

      // Second tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-2",
        toolCallName: "secondTool",
        delta: '{"arg2": "value2"}',
      } as ToolCallChunkEvent,

      // Back to first tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-1",
        toolCallName: "firstTool",
        delta: ',"arg1_more": "more data"}',
      } as ToolCallChunkEvent,

      // Non-chunk event to close the sequence
      {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      } as RunFinishedEvent,
    ];

    const events$ = of(...events);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((results) => {
      // Count events by type
      const eventCounts = results.reduce(
        (counts, event) => {
          counts[event.type] = (counts[event.type] || 0) + 1;
          return counts;
        },
        {} as Record<EventType, number>,
      );

      // When switching between message types, the function creates new start events
      // even for previously seen message IDs
      expect(eventCounts[EventType.TEXT_MESSAGE_START]).toBe(3);
      expect(eventCounts[EventType.TOOL_CALL_START]).toBe(3);

      // There should be corresponding end events
      expect(eventCounts[EventType.TEXT_MESSAGE_END]).toBe(3);
      expect(eventCounts[EventType.TOOL_CALL_END]).toBe(3);

      // There should be 3 content events (for the text messages)
      expect(eventCounts[EventType.TEXT_MESSAGE_CONTENT]).toBe(3);

      // There should be 3 args events (for the tool calls)
      expect(eventCounts[EventType.TOOL_CALL_ARGS]).toBe(3);

      // There should be exactly one run finished event
      expect(eventCounts[EventType.RUN_FINISHED]).toBe(1);

      // Verify the total number of events
      expect(results.length).toBe(19); // 6 starts + 6 contents/args + 6 ends + 1 run finished

      // Get all messageId pairs to see start/content/end sequences
      const messageEventsById: Record<string, EventType[]> = {};

      results.forEach((event) => {
        if (
          event.type === EventType.TEXT_MESSAGE_START ||
          event.type === EventType.TEXT_MESSAGE_CONTENT ||
          event.type === EventType.TEXT_MESSAGE_END
        ) {
          const msgEvent = event as
            | TextMessageStartEvent
            | TextMessageContentEvent
            | TextMessageEndEvent;
          if (!messageEventsById[msgEvent.messageId]) {
            messageEventsById[msgEvent.messageId] = [];
          }
          messageEventsById[msgEvent.messageId].push(event.type);
        }
      });

      // Check that the first message ID appears twice
      expect(
        messageEventsById["msg-1"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_START)
          .length,
      ).toBe(2);
      expect(
        messageEventsById["msg-1"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_END)
          .length,
      ).toBe(2);

      // The second message ID appears only once
      expect(
        messageEventsById["msg-2"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_START)
          .length,
      ).toBe(1);
      expect(
        messageEventsById["msg-2"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_END)
          .length,
      ).toBe(1);

      done();
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/convert.ts
================================================
import { mergeMap } from "rxjs/operators";
import { applyPatch } from "fast-json-patch";

import {
  BaseEvent,
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  CustomEvent,
  StateSnapshotEvent,
  StepStartedEvent,
  Message,
  StateDeltaEvent,
  MessagesSnapshotEvent,
  ToolCall,
  RunErrorEvent,
} from "@ag-ui/core";
import { Observable } from "rxjs";
import {
  LegacyTextMessageStart,
  LegacyTextMessageContent,
  LegacyTextMessageEnd,
  LegacyActionExecutionStart,
  LegacyActionExecutionArgs,
  LegacyActionExecutionEnd,
  LegacyRuntimeEventTypes,
  LegacyRuntimeProtocolEvent,
  LegacyMetaEvent,
  LegacyAgentStateMessage,
  LegacyMessage,
  LegacyTextMessage,
  LegacyActionExecutionMessage,
  LegacyResultMessage,
  LegacyActionExecutionResult,
  LegacyRunError
} from "./types";
import untruncateJson from "untruncate-json";

interface PredictStateValue {
  state_key: string;
  tool: string;
  tool_argument: string;
}

export const convertToLegacyEvents =
  (threadId: string, runId: string, agentName: string) =>
  (events$: Observable<BaseEvent>): Observable<LegacyRuntimeProtocolEvent> => {
    let currentState: any = {};
    let running = true;
    let active = true;
    let nodeName = "";
    let syncedMessages: Message[] | null = null;
    let predictState: PredictStateValue[] | null = null;
    let currentToolCalls: ToolCall[] = [];
    let toolCallNames: Record<string, string> = {};

    const updateCurrentState = (newState: any) => {
      // the legacy protocol will only support object state
      if (typeof newState === "object" && newState !== null) {
        if ("messages" in newState) {
          delete newState.messages;
        }
        currentState = newState;
      }
    };

    return events$.pipe(
      mergeMap((event) => {
        switch (event.type) {
          case EventType.TEXT_MESSAGE_START: {
            const startEvent = event as TextMessageStartEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageStart,
                messageId: startEvent.messageId,
                role: startEvent.role,
              } as LegacyTextMessageStart,
            ];
          }
          case EventType.TEXT_MESSAGE_CONTENT: {
            const contentEvent = event as TextMessageContentEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageContent,
                messageId: contentEvent.messageId,
                content: contentEvent.delta,
              } as LegacyTextMessageContent,
            ];
          }
          case EventType.TEXT_MESSAGE_END: {
            const endEvent = event as TextMessageEndEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageEnd,
                messageId: endEvent.messageId,
              } as LegacyTextMessageEnd,
            ];
          }
          case EventType.TOOL_CALL_START: {
            const startEvent = event as ToolCallStartEvent;

            currentToolCalls.push({
              id: startEvent.toolCallId,
              type: "function",
              function: {
                name: startEvent.toolCallName,
                arguments: "",
              },
            });

            active = true;
            toolCallNames[startEvent.toolCallId] = startEvent.toolCallName;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionStart,
                actionExecutionId: startEvent.toolCallId,
                actionName: startEvent.toolCallName,
                parentMessageId: startEvent.parentMessageId,
              } as LegacyActionExecutionStart,
            ];
          }
          case EventType.TOOL_CALL_ARGS: {
            const argsEvent = event as ToolCallArgsEvent;

            // Find the tool call by ID instead of using the last one
            const currentToolCall = currentToolCalls.find((tc) => tc.id === argsEvent.toolCallId);
            if (!currentToolCall) {
              console.warn(`TOOL_CALL_ARGS: No tool call found with ID '${argsEvent.toolCallId}'`);
              return [];
            }

            currentToolCall.function.arguments += argsEvent.delta;
            let didUpdateState = false;

            if (predictState) {
              let currentPredictState = predictState.find(
                (s) => s.tool == currentToolCall.function.name,
              );

              if (currentPredictState) {
                try {
                  const currentArgs = JSON.parse(
                    untruncateJson(currentToolCall.function.arguments),
                  );
                  if (
                    currentPredictState.tool_argument &&
                    currentPredictState.tool_argument in currentArgs
                  ) {
                    updateCurrentState({
                      ...currentState,
                      [currentPredictState.state_key]:
                        currentArgs[currentPredictState.tool_argument],
                    });
                    didUpdateState = true;
                  } else if (!currentPredictState.tool_argument) {
                    updateCurrentState({
                      ...currentState,
                      [currentPredictState.state_key]: currentArgs,
                    });
                    didUpdateState = true;
                  }
                } catch (e) {}
              }
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionArgs,
                actionExecutionId: argsEvent.toolCallId,
                args: argsEvent.delta,
              } as LegacyActionExecutionArgs,
              ...(didUpdateState
                ? [
                    {
                      type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                      threadId,
                      agentName,
                      nodeName,
                      runId,
                      running,
                      role: "assistant",
                      state: JSON.stringify(currentState),
                      active,
                    },
                  ]
                : []),
            ];
          }
          case EventType.TOOL_CALL_END: {
            const endEvent = event as ToolCallEndEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionEnd,
                actionExecutionId: endEvent.toolCallId,
              } as LegacyActionExecutionEnd,
            ];
          }
          case EventType.TOOL_CALL_RESULT: {
            const resultEvent = event as ToolCallResultEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionResult,
                actionExecutionId: resultEvent.toolCallId,
                result: resultEvent.content,
                actionName: toolCallNames[resultEvent.toolCallId] || "unknown",
              } as LegacyActionExecutionResult,
            ];
          }
          case EventType.RAW: {
            // The legacy protocol doesn't support raw events
            return [];
          }
          case EventType.CUSTOM: {
            const customEvent = event as CustomEvent;
            switch (customEvent.name) {
              case "Exit":
                running = false;
                break;
              case "PredictState":
                predictState = customEvent.value as PredictStateValue[];
                break;
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.MetaEvent,
                name: customEvent.name,
                value: customEvent.value,
              } as LegacyMetaEvent,
            ];
          }
          case EventType.STATE_SNAPSHOT: {
            const stateEvent = event as StateSnapshotEvent;
            updateCurrentState(stateEvent.snapshot);

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.STATE_DELTA: {
            const deltaEvent = event as StateDeltaEvent;
            const result = applyPatch(currentState, deltaEvent.delta, true, false);
            if (!result) {
              return [];
            }
            updateCurrentState(result.newDocument);

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.MESSAGES_SNAPSHOT: {
            const messagesSnapshot = event as MessagesSnapshotEvent;
            syncedMessages = messagesSnapshot.messages;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify({
                  ...currentState,
                  ...(syncedMessages ? { messages: syncedMessages } : {}),
                }),
                active: true,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.RUN_STARTED: {
            // There is nothing to do in the legacy protocol
            return [];
          }
          case EventType.RUN_FINISHED: {
            if (syncedMessages) {
              currentState.messages = syncedMessages;
            }

            // Only do an update if state is not empty
            if (Object.keys(currentState).length === 0) {
              return [];
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify({
                  ...currentState,
                  ...(syncedMessages
                    ? {
                        messages: convertMessagesToLegacyFormat(syncedMessages),
                      }
                    : {}),
                }),
                active: false,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.RUN_ERROR: {
            const errorEvent = event as RunErrorEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.RunError,
                message: errorEvent.message,
                code: errorEvent.code,
              } as LegacyRunError,
            ];
          }
          case EventType.STEP_STARTED: {
            const stepStarted = event as StepStartedEvent;
            nodeName = stepStarted.stepName;

            currentToolCalls = [];
            predictState = null;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active: true,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.STEP_FINISHED: {
            currentToolCalls = [];
            predictState = null;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active: false,
              } as LegacyAgentStateMessage,
            ];
          }
          default: {
            return [];
          }
        }
      }),
    );
  };

export function convertMessagesToLegacyFormat(messages: Message[]): LegacyMessage[] {
  const result: LegacyMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant" || message.role === "user" || message.role === "system") {
      if (message.content) {
        const textMessage: LegacyTextMessage = {
          id: message.id,
          role: message.role,
          content: message.content,
        };
        result.push(textMessage);
      }
      if (message.role === "assistant" && message.toolCalls && message.toolCalls.length > 0) {
        for (const toolCall of message.toolCalls) {
          const actionExecutionMessage: LegacyActionExecutionMessage = {
            id: toolCall.id,
            name: toolCall.function.name,
            arguments: JSON.parse(toolCall.function.arguments),
            parentMessageId: message.id,
          };
          result.push(actionExecutionMessage);
        }
      }
    } else if (message.role === "tool") {
      let actionName = "unknown";
      for (const m of messages) {
        if (m.role === "assistant" && m.toolCalls?.length) {
          for (const toolCall of m.toolCalls) {
            if (toolCall.id === message.toolCallId) {
              actionName = toolCall.function.name;
              break;
            }
          }
        }
      }
      const toolMessage: LegacyResultMessage = {
        id: message.id,
        result: message.content,
        actionExecutionId: message.toolCallId,
        actionName,
      };
      result.push(toolMessage);
    }
  }

  return result;
}



================================================
FILE: typescript-sdk/packages/client/src/legacy/index.ts
================================================
export { convertToLegacyEvents } from "./convert";



================================================
FILE: typescript-sdk/packages/client/src/legacy/types.ts
================================================
import { z } from "zod";

// Protocol Events
export const LegacyRuntimeEventTypes = z.enum([
  "TextMessageStart",
  "TextMessageContent",
  "TextMessageEnd",
  "ActionExecutionStart",
  "ActionExecutionArgs",
  "ActionExecutionEnd",
  "ActionExecutionResult",
  "AgentStateMessage",
  "MetaEvent",
  "RunStarted",
  "RunFinished",
  "RunError",
  "NodeStarted",
  "NodeFinished",
]);

export const LegacyRuntimeMetaEventName = z.enum([
  "LangGraphInterruptEvent",
  "PredictState",
  "Exit",
]);

export const LegacyTextMessageStart = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageStart),
  messageId: z.string(),
  parentMessageId: z.string().optional(),
  role: z.string().optional(),
});

export const LegacyTextMessageContent = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageContent),
  messageId: z.string(),
  content: z.string(),
});

export const LegacyTextMessageEnd = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageEnd),
  messageId: z.string(),
});

export const LegacyActionExecutionStart = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionStart),
  actionExecutionId: z.string(),
  actionName: z.string(),
  parentMessageId: z.string().optional(),
});

export const LegacyActionExecutionArgs = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionArgs),
  actionExecutionId: z.string(),
  args: z.string(),
});

export const LegacyActionExecutionEnd = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionEnd),
  actionExecutionId: z.string(),
});

export const LegacyActionExecutionResult = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionResult),
  actionName: z.string(),
  actionExecutionId: z.string(),
  result: z.string(),
});

export const LegacyAgentStateMessage = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.AgentStateMessage),
  threadId: z.string(),
  agentName: z.string(),
  nodeName: z.string(),
  runId: z.string(),
  active: z.boolean(),
  role: z.string(),
  state: z.string(),
  running: z.boolean(),
});

export const LegacyMetaEvent = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.MetaEvent),
  name: LegacyRuntimeMetaEventName,
  value: z.any(),
});


export const LegacyRunError = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.RunError),
  message: z.string(),
  code: z.string().optional(),
});

export const LegacyRuntimeProtocolEvent = z.discriminatedUnion("type", [
  LegacyTextMessageStart,
  LegacyTextMessageContent,
  LegacyTextMessageEnd,
  LegacyActionExecutionStart,
  LegacyActionExecutionArgs,
  LegacyActionExecutionEnd,
  LegacyActionExecutionResult,
  LegacyAgentStateMessage,
  LegacyMetaEvent,
  LegacyRunError,
]);

// Protocol Event type exports
export type RuntimeEventTypes = z.infer<typeof LegacyRuntimeEventTypes>;
export type RuntimeMetaEventName = z.infer<typeof LegacyRuntimeMetaEventName>;
export type LegacyTextMessageStart = z.infer<typeof LegacyTextMessageStart>;
export type LegacyTextMessageContent = z.infer<typeof LegacyTextMessageContent>;
export type LegacyTextMessageEnd = z.infer<typeof LegacyTextMessageEnd>;
export type LegacyActionExecutionStart = z.infer<typeof LegacyActionExecutionStart>;
export type LegacyActionExecutionArgs = z.infer<typeof LegacyActionExecutionArgs>;
export type LegacyActionExecutionEnd = z.infer<typeof LegacyActionExecutionEnd>;
export type LegacyActionExecutionResult = z.infer<typeof LegacyActionExecutionResult>;
export type LegacyAgentStateMessage = z.infer<typeof LegacyAgentStateMessage>;
export type LegacyMetaEvent = z.infer<typeof LegacyMetaEvent>;
export type LegacyRuntimeProtocolEvent = z.infer<typeof LegacyRuntimeProtocolEvent>;
export type LegacyRunError = z.infer<typeof LegacyRunError>;

// Message schemas (with kind discriminator)
export const LegacyTextMessageSchema = z.object({
  id: z.string(),
  role: z.string(),
  content: z.string(),
  parentMessageId: z.string().optional(),
});

export const LegacyActionExecutionMessageSchema = z.object({
  id: z.string(),
  name: z.string(),
  arguments: z.any(),
  parentMessageId: z.string().optional(),
});

export const LegacyResultMessageSchema = z.object({
  id: z.string(),
  result: z.any(),
  actionExecutionId: z.string(),
  actionName: z.string(),
});

// Message type exports
export type LegacyTextMessage = z.infer<typeof LegacyTextMessageSchema>;
export type LegacyActionExecutionMessage = z.infer<typeof LegacyActionExecutionMessageSchema>;
export type LegacyResultMessage = z.infer<typeof LegacyResultMessageSchema>;
export type LegacyMessage = LegacyTextMessage | LegacyActionExecutionMessage | LegacyResultMessage;



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.concurrent.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  CustomEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - Concurrent Operations", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle concurrent text messages correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start two concurrent text messages
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,

      // Send content for both messages
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "First message content",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg2",
        delta: "Second message content",
      } as TextMessageContentEvent,

      // End messages in reverse order
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg2",
      } as TextMessageEndEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg1",
      } as TextMessageEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify message starts
    expect(events[0].type).toBe("TextMessageStart");
    expect(events[1].type).toBe("TextMessageStart");
    if (events[0].type === "TextMessageStart" && events[1].type === "TextMessageStart") {
      expect(events[0].messageId).toBe("msg1");
      expect(events[1].messageId).toBe("msg2");
    }

    // Verify message content
    expect(events[2].type).toBe("TextMessageContent");
    expect(events[3].type).toBe("TextMessageContent");
    if (events[2].type === "TextMessageContent" && events[3].type === "TextMessageContent") {
      expect(events[2].messageId).toBe("msg1");
      expect(events[2].content).toBe("First message content");
      expect(events[3].messageId).toBe("msg2");
      expect(events[3].content).toBe("Second message content");
    }

    // Verify message ends (in reverse order)
    expect(events[4].type).toBe("TextMessageEnd");
    expect(events[5].type).toBe("TextMessageEnd");
    if (events[4].type === "TextMessageEnd" && events[5].type === "TextMessageEnd") {
      expect(events[4].messageId).toBe("msg2");
      expect(events[5].messageId).toBe("msg1");
    }
  });

  it("should handle concurrent tool calls correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start two concurrent tool calls
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,

      // Send args for both tool calls
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: '{"query":"test search"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool2",
        delta: '{"expression":"2+2"}',
      } as ToolCallArgsEvent,

      // End tool calls in reverse order
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool2",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify tool call starts
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[0].type === "ActionExecutionStart" && events[1].type === "ActionExecutionStart") {
      expect(events[0].actionExecutionId).toBe("tool1");
      expect(events[0].actionName).toBe("search");
      expect(events[0].parentMessageId).toBe("msg1");
      expect(events[1].actionExecutionId).toBe("tool2");
      expect(events[1].actionName).toBe("calculate");
      expect(events[1].parentMessageId).toBe("msg2");
    }

    // Verify tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs" && events[3].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("tool1");
      expect(events[2].args).toBe('{"query":"test search"}');
      expect(events[3].actionExecutionId).toBe("tool2");
      expect(events[3].args).toBe('{"expression":"2+2"}');
    }

    // Verify tool call ends (in reverse order)
    expect(events[4].type).toBe("ActionExecutionEnd");
    expect(events[5].type).toBe("ActionExecutionEnd");
    if (events[4].type === "ActionExecutionEnd" && events[5].type === "ActionExecutionEnd") {
      expect(events[4].actionExecutionId).toBe("tool2");
      expect(events[5].actionExecutionId).toBe("tool1");
    }
  });

  it("should handle mixed concurrent text messages and tool calls", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a text message
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        role: "assistant",
      } as TextMessageStartEvent,

      // Start a tool call while message is active
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        toolCallName: "web_search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,

      // Add content to text message
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        delta: "Let me search for that...",
      } as TextMessageContentEvent,

      // Add args to tool call
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        delta: '{"query":"concurrent events"}',
      } as ToolCallArgsEvent,

      // Start another text message
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "status_msg",
        role: "assistant",
      } as TextMessageStartEvent,

      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "status_msg",
        delta: "Processing...",
      } as TextMessageContentEvent,

      // End everything
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "thinking_msg",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search_tool",
      } as ToolCallEndEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "status_msg",
      } as TextMessageEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(9);

    // Check the sequence matches expected pattern
    const expectedTypes = [
      "TextMessageStart", // thinking_msg start
      "ActionExecutionStart", // search_tool start
      "TextMessageContent", // thinking_msg content
      "ActionExecutionArgs", // search_tool args
      "TextMessageStart", // status_msg start
      "TextMessageContent", // status_msg content
      "TextMessageEnd", // thinking_msg end
      "ActionExecutionEnd", // search_tool end
      "TextMessageEnd", // status_msg end
    ];

    for (let i = 0; i < expectedTypes.length; i++) {
      expect(events[i].type).toBe(expectedTypes[i]);
    }

    // Verify specific content
    const thinkingContent = events.find(
      (e) => e.type === "TextMessageContent" && (e as any).messageId === "thinking_msg",
    );
    expect(thinkingContent).toBeDefined();
    if (thinkingContent?.type === "TextMessageContent") {
      expect(thinkingContent.content).toBe("Let me search for that...");
    }

    const toolArgs = events.find(
      (e) => e.type === "ActionExecutionArgs" && (e as any).actionExecutionId === "search_tool",
    );
    expect(toolArgs).toBeDefined();
    if (toolArgs?.type === "ActionExecutionArgs") {
      expect(toolArgs.args).toBe('{"query":"concurrent events"}');
    }
  });

  it("should handle multiple tool calls on same parent message", async () => {
    const mockEvents: BaseEvent[] = [
      // Start multiple tool calls with same parent
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search1",
        toolCallName: "search",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "calc1",
        toolCallName: "calculate",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "format1",
        toolCallName: "format",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,

      // Send args for all tool calls
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search1",
        delta: '{"query":"test"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "calc1",
        delta: '{"expression":"2*3"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "format1",
        delta: '{"format":"json"}',
      } as ToolCallArgsEvent,

      // End all tool calls
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "calc1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "format1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(9);

    // Verify all start events have same parent
    const startEvents = events.filter((e) => e.type === "ActionExecutionStart");
    expect(startEvents).toHaveLength(3);
    for (const event of startEvents) {
      if (event.type === "ActionExecutionStart") {
        expect(event.parentMessageId).toBe("agent_msg");
      }
    }

    // Verify args events match correct tool calls
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents).toHaveLength(3);

    const searchArgs = argsEvents.find((e) => (e as any).actionExecutionId === "search1");
    expect(searchArgs).toBeDefined();
    if (searchArgs?.type === "ActionExecutionArgs") {
      expect(searchArgs.args).toBe('{"query":"test"}');
    }

    const calcArgs = argsEvents.find((e) => (e as any).actionExecutionId === "calc1");
    expect(calcArgs).toBeDefined();
    if (calcArgs?.type === "ActionExecutionArgs") {
      expect(calcArgs.args).toBe('{"expression":"2*3"}');
    }

    const formatArgs = argsEvents.find((e) => (e as any).actionExecutionId === "format1");
    expect(formatArgs).toBeDefined();
    if (formatArgs?.type === "ActionExecutionArgs") {
      expect(formatArgs.args).toBe('{"format":"json"}');
    }
  });

  it("should handle high-frequency concurrent events", async () => {
    const mockEvents: BaseEvent[] = [];

    // Create many concurrent messages and tool calls
    const numMessages = 5;
    const numToolCalls = 5;

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now() + i,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      mockEvents.push({
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now() + numMessages + i,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Send content for all messages
    for (let i = 0; i < numMessages; i++) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now() + numMessages + numToolCalls + i,
        messageId: `msg${i}`,
        delta: `Content for message ${i}`,
      } as TextMessageContentEvent);
    }

    // Send args for all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      mockEvents.push({
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now() + numMessages * 2 + numToolCalls + i,
        toolCallId: `tool${i}`,
        delta: `{"param${i}":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all in reverse order
    for (let i = numMessages - 1; i >= 0; i--) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now() + numMessages * 2 + numToolCalls * 2 + (numMessages - 1 - i),
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    for (let i = numToolCalls - 1; i >= 0; i--) {
      mockEvents.push({
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now() + numMessages * 3 + numToolCalls * 2 + (numToolCalls - 1 - i),
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Should have: numMessages starts + numToolCalls starts + numMessages content + numToolCalls args + numMessages ends + numToolCalls ends
    const expectedLength = numMessages * 3 + numToolCalls * 3;
    expect(events).toHaveLength(expectedLength);

    // Verify all message starts are present
    const messageStarts = events.filter((e) => e.type === "TextMessageStart");
    expect(messageStarts).toHaveLength(numMessages);
    for (let i = 0; i < numMessages; i++) {
      const start = messageStarts.find((e) => (e as any).messageId === `msg${i}`);
      expect(start).toBeDefined();
    }

    // Verify all tool call starts are present
    const toolStarts = events.filter((e) => e.type === "ActionExecutionStart");
    expect(toolStarts).toHaveLength(numToolCalls);
    for (let i = 0; i < numToolCalls; i++) {
      const start = toolStarts.find((e) => (e as any).actionExecutionId === `tool${i}`);
      expect(start).toBeDefined();
      if (start?.type === "ActionExecutionStart") {
        expect(start.actionName).toBe(`tool_${i}`);
      }
    }

    // Verify all message content is present
    const messageContent = events.filter((e) => e.type === "TextMessageContent");
    expect(messageContent).toHaveLength(numMessages);
    for (let i = 0; i < numMessages; i++) {
      const content = messageContent.find((e) => (e as any).messageId === `msg${i}`);
      expect(content).toBeDefined();
      if (content?.type === "TextMessageContent") {
        expect(content.content).toBe(`Content for message ${i}`);
      }
    }

    // Verify all tool call args are present
    const toolArgs = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(toolArgs).toHaveLength(numToolCalls);
    for (let i = 0; i < numToolCalls; i++) {
      const args = toolArgs.find((e) => (e as any).actionExecutionId === `tool${i}`);
      expect(args).toBeDefined();
      if (args?.type === "ActionExecutionArgs") {
        expect(args.args).toBe(`{"param${i}":"value${i}"}`);
      }
    }
  });

  it("should handle interleaved content and args updates correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start concurrent message and tool call
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "tool_msg1",
      } as ToolCallStartEvent,

      // Interleave content and args updates
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "Searching ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: '{"que',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "for ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: 'ry":"',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "information...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: 'test"}',
      } as ToolCallArgsEvent,

      // End both
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg1",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(10);

    // Verify the interleaved pattern
    expect(events[0].type).toBe("TextMessageStart");
    expect(events[1].type).toBe("ActionExecutionStart");
    expect(events[2].type).toBe("TextMessageContent");
    expect(events[3].type).toBe("ActionExecutionArgs");
    expect(events[4].type).toBe("TextMessageContent");
    expect(events[5].type).toBe("ActionExecutionArgs");
    expect(events[6].type).toBe("TextMessageContent");
    expect(events[7].type).toBe("ActionExecutionArgs");
    expect(events[8].type).toBe("TextMessageEnd");
    expect(events[9].type).toBe("ActionExecutionEnd");

    // Verify content chunks
    const contentEvents = events.filter((e) => e.type === "TextMessageContent");
    expect(contentEvents).toHaveLength(3);
    if (contentEvents[0]?.type === "TextMessageContent") {
      expect(contentEvents[0].content).toBe("Searching ");
    }
    if (contentEvents[1]?.type === "TextMessageContent") {
      expect(contentEvents[1].content).toBe("for ");
    }
    if (contentEvents[2]?.type === "TextMessageContent") {
      expect(contentEvents[2].content).toBe("information...");
    }

    // Verify args chunks
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents).toHaveLength(3);
    if (argsEvents[0]?.type === "ActionExecutionArgs") {
      expect(argsEvents[0].args).toBe('{"que');
    }
    if (argsEvents[1]?.type === "ActionExecutionArgs") {
      expect(argsEvents[1].args).toBe('ry":"');
    }
    if (argsEvents[2]?.type === "ActionExecutionArgs") {
      expect(argsEvents[2].args).toBe('test"}');
    }
  });

  it("should handle concurrent operations with predictive state updates", async () => {
    const mockEvents: BaseEvent[] = [
      // Set up predictive state
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "search_results",
            tool: "search",
            tool_argument: "query",
          },
          {
            state_key: "calculation",
            tool: "calculate",
            tool_argument: "expression",
          },
        ],
      } as CustomEvent,

      // Start concurrent tool calls
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "calc1",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,

      // Send args that should trigger state updates
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search1",
        delta: '{"query":"concurrent test"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "calc1",
        delta: '{"expression":"5*5"}',
      } as ToolCallArgsEvent,

      // End tool calls
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "calc1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Should have: PredictState + 2 starts + 2 args + 2 state updates + 2 ends = 9 events
    expect(events).toHaveLength(9);

    // First event should be the meta event
    expect(events[0].type).toBe("MetaEvent");

    // Should have state update events triggered by the tool call args
    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);

    // Verify first state update (from search)
    if (stateEvents[0]?.type === "AgentStateMessage") {
      const state = JSON.parse(stateEvents[0].state);
      expect(state.search_results).toBe("concurrent test");
    }

    // Verify second state update (from calculation)
    if (stateEvents[1]?.type === "AgentStateMessage") {
      const state = JSON.parse(stateEvents[1].state);
      expect(state.calculation).toBe("5*5");
    }
  });

  it("should handle concurrent operations with lifecycle steps", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a step
      {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "processing",
      } as StepStartedEvent,

      // Start concurrent operations during the step
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        toolCallName: "search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,

      // Add content and args
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        delta: "Analyzing...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        delta: '{"query":"analysis"}',
      } as ToolCallArgsEvent,

      // End operations
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "thinking_msg",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search_tool",
      } as ToolCallEndEvent,

      // End the step
      {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "processing",
      } as StepFinishedEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(8);

    // Verify the sequence includes step lifecycle and concurrent operations
    expect(events[0].type).toBe("AgentStateMessage"); // Step start
    expect(events[1].type).toBe("TextMessageStart");
    expect(events[2].type).toBe("ActionExecutionStart");
    expect(events[3].type).toBe("TextMessageContent");
    expect(events[4].type).toBe("ActionExecutionArgs");
    expect(events[5].type).toBe("TextMessageEnd");
    expect(events[6].type).toBe("ActionExecutionEnd");
    expect(events[7].type).toBe("AgentStateMessage"); // Step end

    // Verify step states
    const stepStates = events.filter((e) => e.type === "AgentStateMessage");
    expect(stepStates).toHaveLength(2);
    if (stepStates[0]?.type === "AgentStateMessage") {
      expect(stepStates[0].active).toBe(true);
    }
    if (stepStates[1]?.type === "AgentStateMessage") {
      expect(stepStates[1].active).toBe(false);
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.predictive.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import {
  BaseEvent,
  EventType,
  CustomEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  StateSnapshotEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";
import { toArray } from "rxjs/operators";

describe("convertToLegacyEvents", () => {
  it("should handle predictive state and tool call events", async () => {
    const mockEvents: BaseEvent[] = [
      // First, send a predict state event
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "greeting",
            tool: "make_greeting",
            tool_argument: "message",
          },
        ],
      } as CustomEvent,
      // Then, send the tool call start event
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        toolCallName: "make_greeting",
      } as ToolCallStartEvent,
      // Send partial JSON arguments in multiple deltas
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        delta: '{"message": "Hello',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        delta: ' world!"}',
      } as ToolCallArgsEvent,
      // Finally, end the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(7);

    // First event should be the predict state meta event
    expect(events[0].type).toBe("MetaEvent");
    if (events[0].type === "MetaEvent") {
      expect(events[0].name).toBe("PredictState");
      expect(events[0].value).toEqual([
        {
          state_key: "greeting",
          tool: "make_greeting",
          tool_argument: "message",
        },
      ]);
    }

    // Second event should be the tool call start
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[1].type === "ActionExecutionStart") {
      expect(events[1].actionName).toBe("make_greeting");
      expect(events[1].actionExecutionId).toBe("greeting-1");
    }

    // Third event should be the first tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("greeting-1");
      expect(events[2].args).toBe('{"message": "Hello');
    }

    // Fourth event should be the agent state message (after first delta)
    expect(events[3].type).toBe("AgentStateMessage");
    if (events[3].type === "AgentStateMessage") {
      expect(events[3].threadId).toBe("test-thread");
      expect(events[3].agentName).toBe("test-agent");
      expect(events[3].runId).toBe("test-run");
      expect(events[3].active).toBe(true);
      expect(events[3].role).toBe("assistant");
      expect(JSON.parse(events[3].state)).toEqual({ greeting: "Hello" });
      expect(events[3].running).toBe(true);
    }

    // Fifth event should be the second tool call args
    expect(events[4].type).toBe("ActionExecutionArgs");
    if (events[4].type === "ActionExecutionArgs") {
      expect(events[4].actionExecutionId).toBe("greeting-1");
      expect(events[4].args).toBe(' world!"}');
    }

    // Sixth event should be the agent state message (after complete JSON)
    expect(events[5].type).toBe("AgentStateMessage");
    if (events[5].type === "AgentStateMessage") {
      expect(events[5].threadId).toBe("test-thread");
      expect(events[5].agentName).toBe("test-agent");
      expect(events[5].runId).toBe("test-run");
      expect(events[5].active).toBe(true);
      expect(events[5].role).toBe("assistant");
      expect(JSON.parse(events[5].state)).toEqual({ greeting: "Hello world!" });
      expect(events[5].running).toBe(true);
    }

    // Seventh event should be the tool call end
    expect(events[6].type).toBe("ActionExecutionEnd");
    if (events[6].type === "ActionExecutionEnd") {
      expect(events[6].actionExecutionId).toBe("greeting-1");
    }
  });

  it("should handle predictive state without tool_argument, including all args in state", async () => {
    const mockEvents: BaseEvent[] = [
      // First, send a predict state event without tool_argument
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "user_preferences",
            tool: "update_preferences",
          },
        ],
      } as CustomEvent,
      // Then, send the tool call start event
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        toolCallName: "update_preferences",
      } as ToolCallStartEvent,
      // Send partial JSON arguments in multiple deltas
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        delta: '{"theme": "dark", "language": "en',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        delta: '", "notifications": true}',
      } as ToolCallArgsEvent,
      // Finally, end the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(7);

    // First event should be the predict state meta event
    expect(events[0].type).toBe("MetaEvent");
    if (events[0].type === "MetaEvent") {
      expect(events[0].name).toBe("PredictState");
      expect(events[0].value).toEqual([
        {
          state_key: "user_preferences",
          tool: "update_preferences",
        },
      ]);
    }

    // Second event should be the tool call start
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[1].type === "ActionExecutionStart") {
      expect(events[1].actionName).toBe("update_preferences");
      expect(events[1].actionExecutionId).toBe("prefs-1");
    }

    // Third event should be the first tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("prefs-1");
      expect(events[2].args).toBe('{"theme": "dark", "language": "en');
    }

    // Fourth event should be the agent state message (after first delta)
    expect(events[3].type).toBe("AgentStateMessage");
    if (events[3].type === "AgentStateMessage") {
      expect(events[3].threadId).toBe("test-thread");
      expect(events[3].agentName).toBe("test-agent");
      expect(events[3].runId).toBe("test-run");
      expect(events[3].active).toBe(true);
      expect(events[3].role).toBe("assistant");
      expect(JSON.parse(events[3].state)).toEqual({
        user_preferences: { theme: "dark", language: "en" },
      });
      expect(events[3].running).toBe(true);
    }

    // Fifth event should be the second tool call args
    expect(events[4].type).toBe("ActionExecutionArgs");
    if (events[4].type === "ActionExecutionArgs") {
      expect(events[4].actionExecutionId).toBe("prefs-1");
      expect(events[4].args).toBe('", "notifications": true}');
    }

    // Sixth event should be the agent state message (after complete JSON)
    expect(events[5].type).toBe("AgentStateMessage");
    if (events[5].type === "AgentStateMessage") {
      expect(events[5].threadId).toBe("test-thread");
      expect(events[5].agentName).toBe("test-agent");
      expect(events[5].runId).toBe("test-run");
      expect(events[5].active).toBe(true);
      expect(events[5].role).toBe("assistant");
      expect(JSON.parse(events[5].state)).toEqual({
        user_preferences: {
          theme: "dark",
          language: "en",
          notifications: true,
        },
      });
      expect(events[5].running).toBe(true);
    }

    // Seventh event should be the tool call end
    expect(events[6].type).toBe("ActionExecutionEnd");
    if (events[6].type === "ActionExecutionEnd") {
      expect(events[6].actionExecutionId).toBe("prefs-1");
    }
  });

  it("should handle step events and state snapshots correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a step
      {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "process_task",
      } as StepStartedEvent,
      // Send a predict state event
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "current_task",
            tool: "update_task",
          },
        ],
      } as CustomEvent,
      // Start a tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "task-1",
        toolCallName: "update_task",
      } as ToolCallStartEvent,
      // Send tool call args
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "task-1",
        delta: '{"status": "in_progress", "progress": 50, "details": "Processing data"}',
      } as ToolCallArgsEvent,
      // End the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "task-1",
      } as ToolCallEndEvent,
      // End the step
      {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "process_task",
      } as StepFinishedEvent,
      // Send a state snapshot
      {
        type: EventType.STATE_SNAPSHOT,
        timestamp: Date.now(),
        snapshot: {
          current_task: {
            status: "completed",
            progress: 100,
            details: "Task finished",
          },
        },
      } as StateSnapshotEvent,
      // Start another tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "task-2",
        toolCallName: "update_task",
      } as ToolCallStartEvent,
      // Send tool call args
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "task-2",
        delta: '{"status": "new_task", "progress": 0}',
      } as ToolCallArgsEvent,
      // End the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "task-2",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(11);

    // First event should be the agent state message (after step start)
    expect(events[0].type).toBe("AgentStateMessage");
    if (events[0].type === "AgentStateMessage") {
      expect(events[0].threadId).toBe("test-thread");
      expect(events[0].agentName).toBe("test-agent");
      expect(events[0].runId).toBe("test-run");
      expect(events[0].active).toBe(true);
      expect(events[0].role).toBe("assistant");
      expect(JSON.parse(events[0].state)).toEqual({});
      expect(events[0].running).toBe(true);
    }

    // Second event should be the predict state meta event
    expect(events[1].type).toBe("MetaEvent");
    if (events[1].type === "MetaEvent") {
      expect(events[1].name).toBe("PredictState");
      expect(events[1].value).toEqual([
        {
          state_key: "current_task",
          tool: "update_task",
        },
      ]);
    }

    // Third event should be the tool call start
    expect(events[2].type).toBe("ActionExecutionStart");
    if (events[2].type === "ActionExecutionStart") {
      expect(events[2].actionName).toBe("update_task");
      expect(events[2].actionExecutionId).toBe("task-1");
    }

    // Fourth event should be the first tool call args
    expect(events[3].type).toBe("ActionExecutionArgs");
    if (events[3].type === "ActionExecutionArgs") {
      expect(events[3].actionExecutionId).toBe("task-1");
      expect(events[3].args).toBe(
        '{"status": "in_progress", "progress": 50, "details": "Processing data"}',
      );
    }

    // Fifth event should be the agent state message (after tool call args)
    expect(events[4].type).toBe("AgentStateMessage");
    if (events[4].type === "AgentStateMessage") {
      expect(events[4].threadId).toBe("test-thread");
      expect(events[4].agentName).toBe("test-agent");
      expect(events[4].runId).toBe("test-run");
      expect(events[4].active).toBe(true);
      expect(events[4].role).toBe("assistant");
      expect(JSON.parse(events[4].state)).toEqual({
        current_task: {
          status: "in_progress",
          progress: 50,
          details: "Processing data",
        },
      });
      expect(events[4].running).toBe(true);
    }

    // Sixth event should be the tool call end
    expect(events[5].type).toBe("ActionExecutionEnd");
    if (events[5].type === "ActionExecutionEnd") {
      expect(events[5].actionExecutionId).toBe("task-1");
    }

    // Seventh event should be the agent state message (after step finished)
    expect(events[6].type).toBe("AgentStateMessage");
    if (events[6].type === "AgentStateMessage") {
      expect(events[6].threadId).toBe("test-thread");
      expect(events[6].agentName).toBe("test-agent");
      expect(events[6].runId).toBe("test-run");
      expect(events[6].active).toBe(false);
      expect(events[6].role).toBe("assistant");
      expect(JSON.parse(events[6].state)).toEqual({
        current_task: {
          status: "in_progress",
          progress: 50,
          details: "Processing data",
        },
      });
      expect(events[6].running).toBe(true);
    }

    // Eighth event should be the agent state message (after state snapshot)
    expect(events[7].type).toBe("AgentStateMessage");
    if (events[7].type === "AgentStateMessage") {
      expect(events[7].threadId).toBe("test-thread");
      expect(events[7].agentName).toBe("test-agent");
      expect(events[7].runId).toBe("test-run");
      expect(events[7].active).toBe(true);
      expect(events[7].role).toBe("assistant");
      expect(JSON.parse(events[7].state)).toEqual({
        current_task: {
          status: "completed",
          progress: 100,
          details: "Task finished",
        },
      });
      expect(events[7].running).toBe(true);
    }

    // Ninth event should be the second tool call start
    expect(events[8].type).toBe("ActionExecutionStart");
    if (events[8].type === "ActionExecutionStart") {
      expect(events[8].actionName).toBe("update_task");
      expect(events[8].actionExecutionId).toBe("task-2");
    }

    // Tenth event should be the second tool call args
    expect(events[9].type).toBe("ActionExecutionArgs");
    if (events[9].type === "ActionExecutionArgs") {
      expect(events[9].actionExecutionId).toBe("task-2");
      expect(events[9].args).toBe('{"status": "new_task", "progress": 0}');
    }

    // Eleventh event should be the second tool call end
    expect(events[10].type).toBe("ActionExecutionEnd");
    if (events[10].type === "ActionExecutionEnd") {
      expect(events[10].actionExecutionId).toBe("task-2");
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.state.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  CustomEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - State Management", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle state updates from complete tool call arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "user",
            tool: "update_user",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-1",
        toolCallName: "update_user",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-1",
        delta: '{"data": {"name": "John", "age": 30}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(5);
    expect(events[0].type).toBe("MetaEvent");
    expect(events[1].type).toBe("ActionExecutionStart");
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("AgentStateMessage");
    expect(events[4].type).toBe("ActionExecutionEnd");

    // Verify state update
    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        user: { name: "John", age: 30 },
      });
    }
  });

  it("should handle partial state updates from incomplete JSON", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "settings",
            tool: "update_settings",
            tool_argument: "config",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-2",
        toolCallName: "update_settings",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '{"config": {"theme": "dark", "fontSize": 14',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: ', "notifications": true}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-2",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Verify intermediate state update
    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);
    if (stateEvents[0]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[0].state)).toEqual({
        settings: { theme: "dark", fontSize: 14 },
      });
    }
    if (stateEvents[1]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[1].state)).toEqual({
        settings: { theme: "dark", fontSize: 14, notifications: true },
      });
    }
  });

  it("should handle state updates with nested objects", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "profile",
            tool: "update_profile",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-3",
        toolCallName: "update_profile",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-3",
        delta:
          '{"data": {"personal": {"name": "Alice", "age": 25}, "preferences": {"theme": "light"}}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-3",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        profile: {
          personal: { name: "Alice", age: 25 },
          preferences: { theme: "light" },
        },
      });
    }
  });

  it("should handle state updates with arrays", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "tasks",
            tool: "update_tasks",
            tool_argument: "list",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-4",
        toolCallName: "update_tasks",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-4",
        delta: '{"list": {"items": ["task1", "task2", "task3"]}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-4",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        tasks: { items: ["task1", "task2", "task3"] },
      });
    }
  });

  it("should handle empty state updates", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "empty",
            tool: "clear_state",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-5",
        toolCallName: "clear_state",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-5",
        delta: '{"data": {}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-5",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        empty: {},
      });
    }
  });

  it("should handle invalid state updates (malformed JSON)", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "invalid",
            tool: "update_invalid",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-6",
        toolCallName: "update_invalid",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-6",
        delta: '{"data": {"invalid": "json"', // Incomplete JSON
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-6",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        invalid: { invalid: "json" }, // The JSON is actually valid when wrapped in data object
      });
    }
  });

  it("should handle state rollback scenarios", async () => {
    const mockEvents: BaseEvent[] = [
      // First update
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "counter",
            tool: "increment",
            tool_argument: "value",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-7",
        toolCallName: "increment",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-7",
        delta: '{"value": 1}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-7",
      } as ToolCallEndEvent,
      // Second update (rollback)
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "counter",
            tool: "decrement",
            tool_argument: "value",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-8",
        toolCallName: "decrement",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-8",
        delta: '{"value": 0}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-8",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);
    if (stateEvents[0]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[0].state)).toEqual({
        counter: 1, // The value is directly assigned
      });
    }
    if (stateEvents[1]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[1].state)).toEqual({
        counter: 0, // The value is directly assigned
      });
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.tool-calls.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - Tool Call Sequences", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle basic tool call lifecycle (start → args → end)", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-1",
        toolCallName: "test_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-1",
        delta: '{"key": "value"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(3);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionEnd");
  });

  it("should handle partial/chunked tool call arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-2",
        toolCallName: "test_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '{"complex',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '": "object",',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '"value": 123}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-2",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(5);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("ActionExecutionArgs");
    expect(events[4].type).toBe("ActionExecutionEnd");

    // Verify the chunked arguments
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents[0].args).toBe('{"complex');
    expect(argsEvents[1].args).toBe('": "object",');
    expect(argsEvents[2].args).toBe('"value": 123}');
  });

  it("should handle multiple tool calls in sequence", async () => {
    const mockEvents: BaseEvent[] = [
      // First tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-3",
        toolCallName: "first_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-3",
        delta: '{"first": true}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-3",
      } as ToolCallEndEvent,
      // Second tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-4",
        toolCallName: "second_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-4",
        delta: '{"second": true}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-4",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify first tool call
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionEnd");

    // Verify second tool call
    expect(events[3].type).toBe("ActionExecutionStart");
    expect(events[4].type).toBe("ActionExecutionArgs");
    expect(events[5].type).toBe("ActionExecutionEnd");
  });

  it("should handle tool calls without arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-5",
        toolCallName: "no_args_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-5",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(2);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionEnd");
  });

  it("should handle tool calls with invalid/malformed arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-6",
        toolCallName: "invalid_args_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-6",
        delta: '{"invalid": "json"', // Incomplete JSON
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-6",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(3);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    if (events[1].type === "ActionExecutionArgs") {
      expect(events[1].args).toBe('{"invalid": "json"'); // Should pass through invalid JSON as-is
    }
    expect(events[2].type).toBe("ActionExecutionEnd");
  });
});



================================================
FILE: typescript-sdk/packages/client/src/run/http-request.ts
================================================
import { Observable, from, defer, throwError } from "rxjs";
import { switchMap } from "rxjs/operators";

export enum HttpEventType {
  HEADERS = "headers",
  DATA = "data",
}

export interface HttpDataEvent {
  type: HttpEventType.DATA;
  data?: Uint8Array;
}

export interface HttpHeadersEvent {
  type: HttpEventType.HEADERS;
  status: number;
  headers: Headers;
}

export type HttpEvent = HttpDataEvent | HttpHeadersEvent;

export const runHttpRequest = (url: string, requestInit: RequestInit): Observable<HttpEvent> => {
  // Defer the fetch so that it's executed when subscribed to
  return defer(() => from(fetch(url, requestInit))).pipe(
    switchMap((response) => {
      // Emit headers event first
      const headersEvent: HttpHeadersEvent = {
        type: HttpEventType.HEADERS,
        status: response.status,
        headers: response.headers,
      };

      const reader = response.body?.getReader();
      if (!reader) {
        return throwError(() => new Error("Failed to getReader() from response"));
      }

      return new Observable<HttpEvent>((subscriber) => {
        // Emit headers event first
        subscriber.next(headersEvent);

        (async () => {
          try {
            while (true) {
              const { done, value } = await reader.read();
              if (done) break;
              // Emit data event instead of raw Uint8Array
              const dataEvent: HttpDataEvent = {
                type: HttpEventType.DATA,
                data: value,
              };
              subscriber.next(dataEvent);
            }
            subscriber.complete();
          } catch (error) {
            subscriber.error(error);
          }
        })();

        return () => {
          reader.cancel();
        };
      });
    }),
  );
};



================================================
FILE: typescript-sdk/packages/client/src/run/index.ts
================================================
export { runHttpRequest as runHttpRequest } from "./http-request";



================================================
FILE: typescript-sdk/packages/client/src/run/__tests__/http-request.test.ts
================================================
import { runHttpRequest, HttpEventType } from "../http-request";

describe("runHttpRequest", () => {
  let originalFetch: any;
  let fetchMock: jest.Mock;

  beforeEach(() => {
    // Save original fetch
    originalFetch = global.fetch;

    // Create a mock fetch function with proper response structure
    fetchMock = jest.fn();
    global.fetch = fetchMock;
  });

  afterEach(() => {
    // Restore original fetch
    global.fetch = originalFetch;
  });

  it("should call fetch with the provided configuration", async () => {
    // Set up test configuration
    const config = {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
      body: JSON.stringify({ key: "value" }),
    };

    // Mock a proper response
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue({
          read: jest.fn().mockResolvedValue({ done: true }),
          cancel: jest.fn(),
        }),
      },
    };

    fetchMock.mockResolvedValue(mockResponse);

    // Create the run agent function

    // Execute the function which should trigger a fetch call
    const observable = runHttpRequest("https://example.com/api", config);

    // Subscribe to trigger the fetch
    const subscription = observable.subscribe({
      next: () => {},
      error: () => {},
      complete: () => {},
    });

    // Give time for async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Verify fetch was called with the expected parameters
    expect(fetchMock).toHaveBeenCalledWith("https://example.com/api", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
      body: JSON.stringify({ key: "value" }),
    });

    // Clean up subscription
    subscription.unsubscribe();
  });

  it("should pass an abort signal when provided", async () => {
    // Create an abort controller
    const abortController = new AbortController();

    // Set up test configuration with abort signal
    const config = {
      method: "GET",
      abortSignal: abortController.signal,
    };

    // Mock a proper response
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue({
          read: jest.fn().mockResolvedValue({ done: true }),
          cancel: jest.fn(),
        }),
      },
    };

    fetchMock.mockResolvedValue(mockResponse);

    // Create the run agent function
    const observable = runHttpRequest("https://example.com/api", config);

    // Subscribe to trigger the fetch
    const subscription = observable.subscribe();

    // Give time for async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Verify fetch was called with the expected configuration
    // The implementation passes the config directly, including abortSignal property
    expect(fetchMock).toHaveBeenCalledWith("https://example.com/api", {
      method: "GET",
      abortSignal: abortController.signal,
    });

    // Clean up subscription
    subscription.unsubscribe();
  });

  it("should emit headers and data events from the response", async () => {
    // Create mock chunks to be returned by the reader
    const chunk1 = new Uint8Array([1, 2, 3]);
    const chunk2 = new Uint8Array([4, 5, 6]);

    // Mock reader that returns multiple chunks before completing
    const mockReader = {
      read: jest
        .fn()
        .mockResolvedValueOnce({ done: false, value: chunk1 })
        .mockResolvedValueOnce({ done: false, value: chunk2 })
        .mockResolvedValueOnce({ done: true }),
      cancel: jest.fn(),
    };

    // Mock response with our custom reader and headers
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue(mockReader),
      },
    };

    // Override the fetch mock for this specific test
    fetchMock.mockResolvedValue(mockResponse);

    // Set up test configuration
    const config = {
      method: "GET",
    };

    // Create and execute the run agent function
    const observable = runHttpRequest("https://example.com/api", config);

    // Collect the emitted events
    const emittedEvents: any[] = [];
    const subscription = observable.subscribe({
      next: (event) => emittedEvents.push(event),
      error: (err) => fail(`Should not have errored: ${err}`),
      complete: () => {},
    });

    // Wait for all async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify we received the expected events
    expect(emittedEvents.length).toBe(3);

    // First event should be headers
    expect(emittedEvents[0].type).toBe(HttpEventType.HEADERS);
    expect(emittedEvents[0].status).toBe(200);
    expect(emittedEvents[0].headers).toBe(mockHeaders);

    // Second and third events should be data
    expect(emittedEvents[1].type).toBe(HttpEventType.DATA);
    expect(emittedEvents[1].data).toBe(chunk1);

    expect(emittedEvents[2].type).toBe(HttpEventType.DATA);
    expect(emittedEvents[2].data).toBe(chunk2);

    // Verify reader.read was called the expected number of times
    expect(mockReader.read).toHaveBeenCalledTimes(3);

    // Clean up
    subscription.unsubscribe();
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/http.ts
================================================
import { BaseEvent, EventSchemas } from "@ag-ui/core";
import { Subject, ReplaySubject, Observable } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";
import { parseSSEStream } from "./sse";
import { parseProtoStream } from "./proto";
import * as proto from "@ag-ui/proto";

/**
 * Transforms HTTP events into BaseEvents using the appropriate format parser based on content type.
 */
export const transformHttpEventStream = (source$: Observable<HttpEvent>): Observable<BaseEvent> => {
  const eventSubject = new Subject<BaseEvent>();

  // Use ReplaySubject to buffer events until we decide on the parser
  const bufferSubject = new ReplaySubject<HttpEvent>();

  // Flag to track whether we've set up the parser
  let parserInitialized = false;

  // Subscribe to source and buffer events while we determine the content type
  source$.subscribe({
    next: (event: HttpEvent) => {
      // Forward event to buffer
      bufferSubject.next(event);

      // If we get headers and haven't initialized a parser yet, check content type
      if (event.type === HttpEventType.HEADERS && !parserInitialized) {
        parserInitialized = true;
        const contentType = event.headers.get("content-type");

        // Choose parser based on content type
        if (contentType === proto.AGUI_MEDIA_TYPE) {
          // Use protocol buffer parser
          parseProtoStream(bufferSubject).subscribe({
            next: (event) => eventSubject.next(event),
            error: (err) => eventSubject.error(err),
            complete: () => eventSubject.complete(),
          });
        } else {
          // Use SSE JSON parser for all other cases
          parseSSEStream(bufferSubject).subscribe({
            next: (json) => {
              try {
                const parsedEvent = EventSchemas.parse(json);
                eventSubject.next(parsedEvent as BaseEvent);
              } catch (err) {
                eventSubject.error(err);
              }
            },
            error: (err) => eventSubject.error(err),
            complete: () => eventSubject.complete(),
          });
        }
      } else if (!parserInitialized) {
        eventSubject.error(new Error("No headers event received before data events"));
      }
    },
    error: (err) => {
      bufferSubject.error(err);
      eventSubject.error(err);
    },
    complete: () => {
      bufferSubject.complete();
    },
  });

  return eventSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/index.ts
================================================
export { transformHttpEventStream } from "./http";
export { parseSSEStream } from "./sse";
export { parseProtoStream } from "./proto";



================================================
FILE: typescript-sdk/packages/client/src/transform/proto.ts
================================================
import { Observable, Subject } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";
import { BaseEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";

/**
 * Parses a stream of HTTP events into a stream of BaseEvent objects using Protocol Buffer format.
 * Each message is prefixed with a 4-byte length header (uint32 in big-endian format)
 * followed by the protocol buffer encoded message.
 */
export const parseProtoStream = (source$: Observable<HttpEvent>): Observable<BaseEvent> => {
  const eventSubject = new Subject<BaseEvent>();
  let buffer = new Uint8Array(0);

  source$.subscribe({
    next: (event: HttpEvent) => {
      if (event.type === HttpEventType.HEADERS) {
        return;
      }

      if (event.type === HttpEventType.DATA && event.data) {
        // Append the new data to our buffer
        const newBuffer = new Uint8Array(buffer.length + event.data.length);
        newBuffer.set(buffer, 0);
        newBuffer.set(event.data, buffer.length);
        buffer = newBuffer;

        // Process as many complete messages as possible
        processBuffer();
      }
    },
    error: (err) => eventSubject.error(err),
    complete: () => {
      // Try to process any remaining data in the buffer
      if (buffer.length > 0) {
        try {
          processBuffer();
        } catch (error: unknown) {
          console.warn("Incomplete or invalid protocol buffer data at stream end");
        }
      }
      eventSubject.complete();
    },
  });

  /**
   * Process as many complete messages as possible from the buffer
   */
  function processBuffer() {
    // Keep processing while we have enough data for at least a header (4 bytes)
    while (buffer.length >= 4) {
      // Read message length from the first 4 bytes (big-endian uint32)
      const view = new DataView(buffer.buffer, buffer.byteOffset, 4);
      const messageLength = view.getUint32(0, false); // false = big-endian

      // Check if we have the complete message (header + message body)
      const totalLength = 4 + messageLength;
      if (buffer.length < totalLength) {
        // Not enough data yet, wait for more
        break;
      }

      try {
        // Extract the message (skipping the 4-byte header)
        const message = buffer.slice(4, totalLength);

        // Decode the protocol buffer message using the imported decode function
        const event = proto.decode(message);

        // Emit the parsed event
        eventSubject.next(event);

        // Remove the processed message from the buffer
        buffer = buffer.slice(totalLength);
      } catch (error: unknown) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        eventSubject.error(new Error(`Failed to decode protocol buffer message: ${errorMessage}`));
        return;
      }
    }
  }

  return eventSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/sse.ts
================================================
import { Observable, Subject } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";

/**
 * Parses a stream of HTTP events into a stream of JSON objects using Server-Sent Events (SSE) format.
 * Strictly follows the SSE standard where:
 * - Events are separated by double newlines ('\n\n')
 * - Only 'data:' prefixed lines are processed
 * - Multi-line data events are supported and joined
 * - Non-data fields (event, id, retry) are ignored
 */
export const parseSSEStream = (source$: Observable<HttpEvent>): Observable<any> => {
  const jsonSubject = new Subject<any>();
  // Create TextDecoder with stream option set to true to handle split UTF-8 characters
  const decoder = new TextDecoder("utf-8", { fatal: false });
  let buffer = "";

  // Subscribe to the source once and multicast to all subscribers
  source$.subscribe({
    next: (event: HttpEvent) => {
      if (event.type === HttpEventType.HEADERS) {
        return;
      }

      if (event.type === HttpEventType.DATA && event.data) {
        // Decode chunk carefully to handle UTF-8
        const text = decoder.decode(event.data, { stream: true });
        buffer += text;

        // Process complete events (separated by double newlines)
        const events = buffer.split(/\n\n/);
        // Keep the last potentially incomplete event in buffer
        buffer = events.pop() || "";

        for (const event of events) {
          processSSEEvent(event);
        }
      }
    },
    error: (err) => jsonSubject.error(err),
    complete: () => {
      // Use the final call to decoder.decode() to flush any remaining bytes
      if (buffer) {
        buffer += decoder.decode();
        // Process any remaining SSE event data
        processSSEEvent(buffer);
      }
      jsonSubject.complete();
    },
  });

  /**
   * Helper function to process an SSE event.
   * Extracts and joins data lines, then parses the result as JSON.
   * Follows the SSE spec by only processing 'data:' prefixed lines.
   * @param eventText The raw event text to process
   */
  function processSSEEvent(eventText: string) {
    const lines = eventText.split("\n");
    const dataLines: string[] = [];

    for (const line of lines) {
      if (line.startsWith("data: ")) {
        // Extract data content (remove 'data: ' prefix)
        dataLines.push(line.slice(6));
      }
    }

    // Only process if we have data lines
    if (dataLines.length > 0) {
      try {
        // Join multi-line data and parse JSON
        const jsonStr = dataLines.join("\n");
        const json = JSON.parse(jsonStr);
        jsonSubject.next(json);
      } catch (err) {
        jsonSubject.error(err);
      }
    }
  }

  return jsonSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/http.test.ts
================================================
import { transformHttpEventStream } from "../http";
import { HttpEvent, HttpEventType } from "../../run/http-request";
import { parseProtoStream } from "../proto";
import * as proto from "@ag-ui/proto";
import { BaseEvent, EventType } from "@ag-ui/core";
import { Subject, of, throwError } from "rxjs";

// Mock dependencies
jest.mock("../proto", () => ({
  parseProtoStream: jest.fn(),
}));

describe("transformHttpEventStream", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  test("should correctly transform protocol buffer events", () => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();
    const mockBaseEvent: BaseEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      timestamp: Date.now(),
    };

    // Mock parseProtoStream to return our test event
    (parseProtoStream as jest.Mock).mockReturnValue(of(mockBaseEvent));

    // Create a list to collect emitted events
    const receivedEvents: BaseEvent[] = [];

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe((event) => receivedEvents.push(event));

    // Send a HEADERS event with protocol buffer content type
    mockHttpSource.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers([["content-type", proto.AGUI_MEDIA_TYPE]]),
    });

    // Send a DATA event
    mockHttpSource.next({
      type: HttpEventType.DATA,
      data: new Uint8Array([1, 2, 3, 4]),
    });

    // Complete the stream
    mockHttpSource.complete();

    // Then
    expect(parseProtoStream).toHaveBeenCalled();
    expect(receivedEvents).toEqual([mockBaseEvent]);
  });

  test("should handle parseProtoStream errors", (done) => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();
    const testError = new Error("Test proto parsing error");

    // Mock parseProtoStream to throw an error
    (parseProtoStream as jest.Mock).mockReturnValue(throwError(() => testError));

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe({
      next: () => {
        // Should not emit any events
        fail("Should not emit events when parseProtoStream errors");
      },
      error: (err) => {
        // Then
        expect(err).toBe(testError);
        done();
      },
    });

    // Send a HEADERS event with protocol buffer content type
    mockHttpSource.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers([["content-type", proto.AGUI_MEDIA_TYPE]]),
    });
  });

  test("should error if DATA received before HEADERS", (done) => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe({
      next: () => {
        // Should not emit any events
        fail("Should not emit events when DATA received before HEADERS");
      },
      error: (err) => {
        // Then
        expect(err.message).toContain("No headers event received before data events");
        done();
      },
    });

    // Send a DATA event before HEADERS
    mockHttpSource.next({
      type: HttpEventType.DATA,
      data: new Uint8Array([1, 2, 3, 4]),
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/proto.test.ts
================================================
import { HttpEvent, HttpEventType } from "../../run/http-request";
import { firstValueFrom, Subject, take } from "rxjs";
import {
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";
import * as proto from "@ag-ui/proto";
import { transformHttpEventStream } from "../http";
import * as encoder from "@ag-ui/encoder";

const eventEncoder = new encoder.EventEncoder({
  accept: proto.AGUI_MEDIA_TYPE,
});

// Don't mock the proto package so we can use real encoding/decoding
jest.unmock("@ag-ui/proto");

describe("parseProtoStream", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should correctly decode protocol buffer events", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the first event before emitting
    const firstEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a test event
    const originalEvent = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg123",
      role: "assistant",
      timestamp: Date.now(),
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(originalEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await firstEventPromise) as TextMessageStartEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(originalEvent.type);
    expect(receivedEvent.timestamp).toEqual(originalEvent.timestamp);
    expect(receivedEvent.messageId).toEqual(originalEvent.messageId);
    expect(receivedEvent.role).toEqual(originalEvent.role);
    // Complete the stream
    chunk$.complete();
  });

  it("should handle multiple protobuf events in a single chunk", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that resolves after receiving 2 events
    const eventsPromise = new Promise<any[]>((resolve) => {
      const events: any[] = [];
      event$.subscribe({
        next: (event) => {
          events.push(event);
          if (events.length === 2) {
            resolve(events);
          }
        },
        error: (err) => {
          throw new Error(`Unexpected error: ${err}`);
        },
      });
    });

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create two test events
    const startEvent = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg123",
      role: "assistant",
      timestamp: Date.now(),
    };

    const contentEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg123",
      delta: "Hello world",
      timestamp: Date.now(),
    };

    // Encode both events and concatenate them
    const encodedStart = eventEncoder.encodeBinary(startEvent);
    const encodedContent = eventEncoder.encodeBinary(contentEvent);

    // Concatenate the two encoded events
    const combinedData = new Uint8Array(encodedStart.length + encodedContent.length);
    combinedData.set(encodedStart, 0);
    combinedData.set(encodedContent, encodedStart.length);

    // Send the combined data as a single chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: combinedData,
    });

    // Wait for both events to be emitted
    const events = await eventsPromise;

    // Verify we received both events correctly
    expect(events.length).toBe(2);
    expect(events[0].type).toEqual(startEvent.type);
    expect(events[0].messageId).toEqual(startEvent.messageId);
    expect(events[0].role).toEqual(startEvent.role);
    expect(events[1].type).toEqual(contentEvent.type);
    expect(events[1].messageId).toEqual(contentEvent.messageId);
    expect(events[1].delta).toEqual(contentEvent.delta);

    // Complete the stream
    chunk$.complete();
  });

  it("should handle split protobuf event across multiple chunks", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a test event
    const originalEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg123",
      delta: "This is a message that will be split across chunks",
      timestamp: Date.now(),
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(originalEvent);

    // Split the encoded event into three parts
    const firstPart = encodedEvent.slice(0, Math.floor(encodedEvent.length / 3));
    const secondPart = encodedEvent.slice(
      Math.floor(encodedEvent.length / 3),
      Math.floor((2 * encodedEvent.length) / 3),
    );
    const thirdPart = encodedEvent.slice(Math.floor((2 * encodedEvent.length) / 3));

    // Send the parts as separate chunks
    chunk$.next({
      type: HttpEventType.DATA,
      data: firstPart,
    });

    chunk$.next({
      type: HttpEventType.DATA,
      data: secondPart,
    });

    chunk$.next({
      type: HttpEventType.DATA,
      data: thirdPart,
    });

    // Complete the stream
    chunk$.complete();

    // Await the received event
    const receivedEvent = (await eventPromise) as TextMessageContentEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(originalEvent.type);
    expect(receivedEvent.messageId).toEqual(originalEvent.messageId);
    expect(receivedEvent.delta).toEqual(originalEvent.delta);
  });

  it("should emit error when invalid protobuf data is received", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    let receivedEvent = false;
    let receivedError = false;
    let errorReceived: any = null;

    // Set up a subscription with shorter timeout
    const subscription = event$.subscribe({
      next: () => {
        receivedEvent = true;
      },
      error: (err) => {
        receivedError = true;
        errorReceived = err;
      },
      complete: () => {
        // This is fine if it completes
      },
    });

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send invalid protobuf data (just random bytes)
    const invalidData = new Uint8Array([0x01, 0x02, 0x03, 0xff, 0xee, 0xdd]);

    chunk$.next({
      type: HttpEventType.DATA,
      data: invalidData,
    });

    // Give it a moment to process
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Force completion
    chunk$.complete();

    // Clean up subscription
    subscription.unsubscribe();

    // Here we're just verifying we didn't get an event from invalid data
    // The implementation could either emit an error or just ignore bad data
    expect(receivedEvent).toBe(false);
  }, 3000);

  it("should correctly encode and decode a STATE_DELTA event with JSON patch operations", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a state delta event with JSON patch operations
    const stateDeltaEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: Date.now(),
      delta: [
        { op: "add", path: "/counter", value: 42 },
        { op: "add", path: "/items", value: ["apple", "banana", "cherry"] },
        { op: "replace", path: "/users/123/name", value: "Jane Doe" },
        { op: "remove", path: "/outdated" },
        { op: "move", from: "/oldPath", path: "/newPath" },
        { op: "copy", from: "/source", path: "/destination" },
      ],
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(stateDeltaEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await eventPromise) as StateDeltaEvent;

    // Verify we got back the same event with all patch operations intact
    expect(receivedEvent.type).toEqual(stateDeltaEvent.type);
    expect(receivedEvent.timestamp).toEqual(stateDeltaEvent.timestamp);

    // Check the JSON patch operations were correctly preserved
    expect(receivedEvent.delta.length).toEqual(stateDeltaEvent.delta.length);

    // Verify each patch operation
    receivedEvent.delta.forEach((operation, index) => {
      expect(operation.op).toEqual(stateDeltaEvent.delta[index].op);
      expect(operation.path).toEqual(stateDeltaEvent.delta[index].path);

      if ("from" in operation) {
        expect(operation.from).toEqual(stateDeltaEvent.delta[index].from);
      }

      if ("value" in operation) {
        expect(operation.value).toEqual(stateDeltaEvent.delta[index].value);
      }
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should correctly encode and decode a MESSAGES_SNAPSHOT event", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a messages snapshot event with complex message objects
    const messagesSnapshotEvent: MessagesSnapshotEvent = {
      type: EventType.MESSAGES_SNAPSHOT,
      timestamp: Date.now(),
      messages: [
        {
          id: "msg1",
          role: "user",
          content: "Hello, can you help me with something?",
        },
        {
          id: "msg2",
          role: "assistant",
          content: "Of course! How can I assist you today?",
        },
        {
          id: "msg3",
          role: "user",
          content: "I need help with coding",
        },
        {
          id: "msg4",
          role: "assistant",
          content: undefined,
          toolCalls: [
            {
              id: "tool1",
              type: "function",
              function: {
                name: "write_code",
                arguments: JSON.stringify({
                  language: "python",
                  task: "sorting algorithm",
                }),
              },
            },
          ],
        },
      ],
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(messagesSnapshotEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await eventPromise) as MessagesSnapshotEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(messagesSnapshotEvent.type);
    expect(receivedEvent.timestamp).toEqual(messagesSnapshotEvent.timestamp);

    // Check the messages array was correctly preserved
    expect(receivedEvent.messages.length).toEqual(messagesSnapshotEvent.messages.length);

    // Verify each message
    receivedEvent.messages.forEach((message, index) => {
      expect(message.id).toEqual(messagesSnapshotEvent.messages[index].id);
      expect(message.role).toEqual(messagesSnapshotEvent.messages[index].role);
      expect(message.content).toEqual(messagesSnapshotEvent.messages[index].content);

      // Check tool calls if present
      if ((messagesSnapshotEvent.messages[index] as any).toolCalls) {
        expect((message as any).toolCalls).toBeDefined();
        expect((message as any).toolCalls!.length).toEqual(
          (messagesSnapshotEvent.messages[index] as any).toolCalls!.length,
        );

        (message as any).toolCalls!.forEach((toolCall: any, toolIndex: number) => {
          const originalToolCall = (messagesSnapshotEvent.messages[index] as any).toolCalls![
            toolIndex
          ];
          expect(toolCall.id).toEqual(originalToolCall.id);
          expect(toolCall.type).toEqual(originalToolCall.type);
          expect(toolCall.function.name).toEqual(originalToolCall.function.name);
          expect(JSON.parse(toolCall.function.arguments)).toEqual(
            JSON.parse(originalToolCall.function.arguments),
          );
        });
      }
    });

    // Complete the stream
    chunk$.complete();
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/sse.test.ts
================================================
import { Subject } from "rxjs";
import { firstValueFrom } from "rxjs";
import { take } from "rxjs/operators";
import { transformHttpEventStream } from "../http";
import { EventType } from "@ag-ui/core";
import { HttpEvent, HttpEventType } from "../../run/http-request";

describe("transformHttpEventStream", () => {
  it("should emit events as soon as complete SSE events are encountered", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the first event before emitting
    const firstEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send first chunk with a complete SSE event
    const firstChunkData = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_START", "messageId": "1", "role": "assistant"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: firstChunkData,
    });

    // Await the first event
    const firstEvent = await firstEventPromise;
    expect(firstEvent).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });

    // Set up subscription promise for the second event before emitting
    const secondEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send second chunk with another complete SSE event
    const secondChunkData = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1", "delta": "Hello"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: secondChunkData,
    });

    // Await the second event
    const secondEvent = await secondEventPromise;
    expect(secondEvent).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle multiple complete SSE events in a single chunk", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that resolves after receiving 2 events
    const eventsPromise = new Promise<any[]>((resolve) => {
      const events: any[] = [];
      event$.subscribe({
        next: (event) => {
          events.push(event);
          if (events.length === 2) {
            resolve(events);
          }
        },
        error: (err) => fail(err),
      });
    });

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send a single chunk with multiple complete SSE events
    const multilineJson = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_START", "messageId": "1", "role": "assistant"}\n\n' +
        'data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1", "delta": "Hello"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: multilineJson,
    });

    // Wait for both events to be emitted
    const events = await eventsPromise;

    // Verify we received both events in the correct order
    expect(events.length).toBe(2);
    expect(events[0]).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });
    expect(events[1]).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle split SSE event across multiple chunks", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send first part of an SSE event
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE'),
    });

    // Send middle part
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('_START", "messageId": '),
    });

    // Send final part with double newline to complete the SSE event
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('"1", "role": "assistant"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });
  });

  it("should emit error when invalid JSON is received in SSE format", async () => {
    const chunk$ = new Subject<HttpEvent>();
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that will resolve when an error occurs
    const errorPromise = new Promise<any>((resolve) => {
      event$.subscribe({
        next: () => {
          // This should not be called
          fail("Should not emit events for invalid JSON");
        },
        error: (err) => {
          resolve(err);
        },
        complete: () => {
          fail("Stream should not complete successfully with invalid JSON");
        },
      });
    });

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send invalid JSON (missing closing bracket) in SSE format
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE_START", "messageId": "1"\n\n'),
    });

    // Wait for the error to be caught
    const error = await errorPromise;

    // Verify we got a JSON parsing error
    expect(error).toBeDefined();
    expect(error instanceof SyntaxError || error.message.includes("JSON")).toBeTruthy();
  });

  it("should handle Server-Sent Events (SSE) format with multiple data lines", async () => {
    const chunk$ = new Subject<HttpEvent>();
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send an SSE formatted event with multi-line data
    const sseData = new TextEncoder().encode(
      "event: message\n" +
        "id: 123\n" +
        "data: {\n" +
        'data: "type": "TEXT_MESSAGE_CONTENT",\n' +
        'data: "messageId": "1",\n' +
        'data: "delta": "Hello World"\n' +
        "data: }\n\n",
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: sseData,
    });

    // Await the event
    const event = await eventPromise;

    // Verify we received the correct event with the multi-line data properly joined
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello World",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle JSON split between HTTP chunks in a single SSE event", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send the start of the SSE event with first part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1"'),
    });

    // Send the middle part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(', "delta": "Hello '),
    });

    // Send the end of the JSON with the closing SSE event markers
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('World"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello World",
    });
  });

  it("should handle SSE with 'data:' prefix split from JSON content", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send the first chunk with just the SSE prefix
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode("data: "),
    });

    // Send the start of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('{"type": "TEXT_MESSAGE_CONTENT"'),
    });

    // Send the middle part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(', "messageId": "1", "delta":'),
    });

    // Send the end of the JSON with the closing SSE event markers
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(' "Split JSON Test"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Split JSON Test",
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/index.ts
================================================
export { verifyEvents } from "./verify";



================================================
FILE: typescript-sdk/packages/client/src/verify/verify.ts
================================================
import { BaseEvent, EventType, AGUIError } from "@ag-ui/core";
import { Observable, throwError, of } from "rxjs";
import { mergeMap } from "rxjs/operators";

export const verifyEvents =
  (debug: boolean) =>
  (source$: Observable<BaseEvent>): Observable<BaseEvent> => {
    // Declare variables in closure to maintain state across events
    let activeMessages = new Map<string, boolean>(); // Map of message ID -> active status
    let activeToolCalls = new Map<string, boolean>(); // Map of tool call ID -> active status
    let runFinished = false;
    let runError = false; // New flag to track if RUN_ERROR has been sent
    // New flags to track first/last event requirements
    let firstEventReceived = false;
    // Track active steps
    let activeSteps = new Map<string, boolean>(); // Map of step name -> active status
    let activeThinkingStep = false;
    let activeThinkingStepMessage = false;
    let runStarted = false; // Track if a run has started

    // Function to reset state for a new run
    const resetRunState = () => {
      activeMessages.clear();
      activeToolCalls.clear();
      activeSteps.clear();
      activeThinkingStep = false;
      activeThinkingStepMessage = false;
      runFinished = false;
      runError = false;
      runStarted = true;
    };

    return source$.pipe(
      // Process each event through our state machine
      mergeMap((event) => {
        const eventType = event.type;

        if (debug) {
          console.debug("[VERIFY]:", JSON.stringify(event));
        }

        // Check if run has errored
        if (runError) {
          return throwError(
            () =>
              new AGUIError(
                `Cannot send event type '${eventType}': The run has already errored with 'RUN_ERROR'. No further events can be sent.`,
              ),
          );
        }

        // Check if run has already finished (but allow new RUN_STARTED to start a new run)
        if (runFinished && eventType !== EventType.RUN_ERROR && eventType !== EventType.RUN_STARTED) {
          return throwError(
            () =>
              new AGUIError(
                `Cannot send event type '${eventType}': The run has already finished with 'RUN_FINISHED'. Start a new run with 'RUN_STARTED'.`,
              ),
          );
        }

        // Handle first event requirement and sequential RUN_STARTED
        if (!firstEventReceived) {
          firstEventReceived = true;
          if (eventType !== EventType.RUN_STARTED && eventType !== EventType.RUN_ERROR) {
            return throwError(() => new AGUIError(`First event must be 'RUN_STARTED'`));
          }
        } else if (eventType === EventType.RUN_STARTED) {
          // Allow RUN_STARTED after RUN_FINISHED (new run), but not during an active run
          if (runStarted && !runFinished) {
            return throwError(
              () =>
                new AGUIError(
                  `Cannot send 'RUN_STARTED' while a run is still active. The previous run must be finished with 'RUN_FINISHED' before starting a new run.`,
                ),
            );
          }
          // If we're here, it's either the first RUN_STARTED or a new run after RUN_FINISHED
          if (runFinished) {
            // This is a new run after the previous one finished, reset state
            resetRunState();
          }
        }

        // Validate event based on type and current state
        switch (eventType) {
          // Text message flow
          case EventType.TEXT_MESSAGE_START: {
            const messageId = (event as any).messageId;

            // Check if this message is already in progress
            if (activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_START' event: A text message with ID '${messageId}' is already in progress. Complete it with 'TEXT_MESSAGE_END' first.`,
                  ),
              );
            }

            activeMessages.set(messageId, true);
            return of(event);
          }

          case EventType.TEXT_MESSAGE_CONTENT: {
            const messageId = (event as any).messageId;

            // Must be in a message with this ID
            if (!activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID '${messageId}'. Start a text message with 'TEXT_MESSAGE_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.TEXT_MESSAGE_END: {
            const messageId = (event as any).messageId;

            // Must be in a message with this ID
            if (!activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID '${messageId}'. A 'TEXT_MESSAGE_START' event must be sent first.`,
                  ),
              );
            }

            // Remove message from active set
            activeMessages.delete(messageId);
            return of(event);
          }

          // Tool call flow
          case EventType.TOOL_CALL_START: {
            const toolCallId = (event as any).toolCallId;

            // Check if this tool call is already in progress
            if (activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_START' event: A tool call with ID '${toolCallId}' is already in progress. Complete it with 'TOOL_CALL_END' first.`,
                  ),
              );
            }

            activeToolCalls.set(toolCallId, true);
            return of(event);
          }

          case EventType.TOOL_CALL_ARGS: {
            const toolCallId = (event as any).toolCallId;

            // Must be in a tool call with this ID
            if (!activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID '${toolCallId}'. Start a tool call with 'TOOL_CALL_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.TOOL_CALL_END: {
            const toolCallId = (event as any).toolCallId;

            // Must be in a tool call with this ID
            if (!activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID '${toolCallId}'. A 'TOOL_CALL_START' event must be sent first.`,
                  ),
              );
            }

            // Remove tool call from active set
            activeToolCalls.delete(toolCallId);
            return of(event);
          }

          // Step flow
          case EventType.STEP_STARTED: {
            const stepName = (event as any).stepName;
            if (activeSteps.has(stepName)) {
              return throwError(
                () => new AGUIError(`Step "${stepName}" is already active for 'STEP_STARTED'`),
              );
            }
            activeSteps.set(stepName, true);
            return of(event);
          }

          case EventType.STEP_FINISHED: {
            const stepName = (event as any).stepName;
            if (!activeSteps.has(stepName)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'STEP_FINISHED' for step "${stepName}" that was not started`,
                  ),
              );
            }
            activeSteps.delete(stepName);
            return of(event);
          }

          // Run flow
          case EventType.RUN_STARTED: {
            // We've already validated this above
            runStarted = true;
            return of(event);
          }

          case EventType.RUN_FINISHED: {
            // Can't be the first event (already checked)
            // and can't happen after already being finished (already checked)

            // Check that all steps are finished before run ends
            if (activeSteps.size > 0) {
              const unfinishedSteps = Array.from(activeSteps.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while steps are still active: ${unfinishedSteps}`,
                  ),
              );
            }

            // Check that all messages are finished before run ends
            if (activeMessages.size > 0) {
              const unfinishedMessages = Array.from(activeMessages.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while text messages are still active: ${unfinishedMessages}`,
                  ),
              );
            }

            // Check that all tool calls are finished before run ends
            if (activeToolCalls.size > 0) {
              const unfinishedToolCalls = Array.from(activeToolCalls.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while tool calls are still active: ${unfinishedToolCalls}`,
                  ),
              );
            }

            runFinished = true;
            return of(event);
          }

          case EventType.RUN_ERROR: {
            // RUN_ERROR can happen at any time
            runError = true; // Set flag to prevent any further events
            return of(event);
          }

          case EventType.CUSTOM: {
            return of(event);
          }

          // Text message flow
          case EventType.THINKING_TEXT_MESSAGE_START: {
            if (!activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_START' event: A thinking step is not in progress. Create one with 'THINKING_START' first.`,
                  ),
              );
            }
            // Can't start a message if one is already in progress
            if (activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_START' event: A thinking message is already in progress. Complete it with 'THINKING_TEXT_MESSAGE_END' first.`,
                  ),
              );
            }

            activeThinkingStepMessage = true;
            return of(event);
          }

          case EventType.THINKING_TEXT_MESSAGE_CONTENT: {
            // Must be in a message and IDs must match
            if (!activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_CONTENT' event: No active thinking message found. Start a message with 'THINKING_TEXT_MESSAGE_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.THINKING_TEXT_MESSAGE_END: {
            // Must be in a message and IDs must match
            if (!activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_END' event: No active thinking message found. A 'THINKING_TEXT_MESSAGE_START' event must be sent first.`,
                  ),
              );
            }

            // Reset message state
            activeThinkingStepMessage = false;
            return of(event);
          }

          case EventType.THINKING_START: {
            if (activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_START' event: A thinking step is already in progress. End it with 'THINKING_END' first.`,
                  ),
              );
            }

            activeThinkingStep = true;
            return of(event);
          }

          case EventType.THINKING_END: {
            // Must be in a message and IDs must match
            if (!activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_END' event: No active thinking step found. A 'THINKING_START' event must be sent first.`,
                  ),
              );
            }

            // Reset message state
            activeThinkingStep = false;
            return of(event);
          }

          default: {
            return of(event);
          }
        }
      }),
    );
  };



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.concurrent.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents concurrent operations", () => {
  // Test: Concurrent text messages with different IDs should be allowed
  it("should allow concurrent text messages with different IDs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send concurrent text messages
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start first message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Start second message before first one ends
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // Content for both messages
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Content for message 1",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Content for message 2",
    } as TextMessageContentEvent);

    // End messages in different order
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Concurrent tool calls with different IDs should be allowed
  it("should allow concurrent tool calls with different IDs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send concurrent tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start first tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Start second tool call before first one ends
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Args for both tool calls
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);

    // End tool calls in different order
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_START);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Overlapping text messages and tool calls should be allowed
  it("should allow overlapping text messages and tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send overlapping text messages and tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start a text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Start a tool call while message is active
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Send content for both
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Thinking...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    // Start another message while tool call is active
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // End in various orders
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Based on the search...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(11);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[10].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Steps and other lifecycle events should be allowed during concurrent messages/tool calls
  it("should allow lifecycle events during concurrent messages and tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start a step
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "search_step",
    } as StepStartedEvent);

    // Start messages and tool calls within the step
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Lifecycle events should be allowed
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "analysis_step",
    } as StepStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Searching...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    // End everything
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "analysis_step",
    } as StepFinishedEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "search_step",
    } as StepFinishedEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(12);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[11].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Should reject duplicate message ID starts
  it("should reject starting a text message with an ID already in progress", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_START' event: A text message with ID 'msg1' is already in progress`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Try to start the same message ID again
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
  });

  // Test: Should reject duplicate tool call ID starts
  it("should reject starting a tool call with an ID already in progress", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_START' event: A tool call with ID 'tool1' is already in progress`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Try to start the same tool call ID again
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
  });

  // Test: Should reject content for non-existent message ID
  it("should reject content for non-existent message ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'nonexistent'`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send content for a message that was never started
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "nonexistent",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
  });

  // Test: Should reject args for non-existent tool call ID
  it("should reject args for non-existent tool call ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'nonexistent'`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send args for a tool call that was never started
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "nonexistent",
      delta: '{"test":"value"}',
    } as ToolCallArgsEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
  });

  // Test: Should reject RUN_FINISHED while messages are still active
  it("should reject RUN_FINISHED while text messages are still active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'RUN_FINISHED' while text messages are still active: msg1, msg2`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // Try to finish run while messages are still active
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(3);
  });

  // Test: Should reject RUN_FINISHED while tool calls are still active
  it("should reject RUN_FINISHED while tool calls are still active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'RUN_FINISHED' while tool calls are still active: tool1, tool2`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Try to finish run while tool calls are still active
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(3);
  });

  // Test: Complex concurrent scenario with high frequency events
  it("should handle complex concurrent scenario with many overlapping events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start multiple concurrent messages and tool calls
    const messageIds = ["msg1", "msg2", "msg3", "msg4", "msg5"];
    const toolCallIds = ["tool1", "tool2", "tool3", "tool4", "tool5"];

    // Start all messages
    for (const msgId of messageIds) {
      source$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: msgId,
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (const toolId of toolCallIds) {
      source$.next({
        type: EventType.TOOL_CALL_START,
        toolCallId: toolId,
        toolCallName: "test_tool",
      } as ToolCallStartEvent);
    }

    // Send content/args in random order
    for (let i = 0; i < 3; i++) {
      for (const msgId of messageIds) {
        source$.next({
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: msgId,
          delta: `Content ${i} for ${msgId}`,
        } as TextMessageContentEvent);
      }

      for (const toolId of toolCallIds) {
        source$.next({
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: toolId,
          delta: `{"step":${i}}`,
        } as ToolCallArgsEvent);
      }
    }

    // End all in reverse order
    for (const msgId of [...messageIds].reverse()) {
      source$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: msgId,
      } as TextMessageEndEvent);
    }

    for (const toolId of [...toolCallIds].reverse()) {
      source$.next({
        type: EventType.TOOL_CALL_END,
        toolCallId: toolId,
      } as ToolCallEndEvent);
    }

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify we have the expected number of events:
    // 1 RUN_STARTED + 5 MSG_START + 5 TOOL_START + 15 MSG_CONTENT + 15 TOOL_ARGS + 5 MSG_END + 5 TOOL_END + 1 RUN_FINISHED = 52
    expect(result.length).toBe(52);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[51].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.events.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents general validation", () => {
  // Test: Event IDs must match their parent events (e.g. TEXT_MESSAGE_CONTENT must have same ID as TEXT_MESSAGE_START)
  it("should ensure message content has the same ID as message start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'different-id'. Start a text message with 'TEXT_MESSAGE_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a message start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Send message content with different ID
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "different-id",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TEXT_MESSAGE_START);
  });

  // Test: Cannot end a message that wasn't started
  it("should not allow ending a message that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID 'msg1'. A 'TEXT_MESSAGE_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a message start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send message end without a start
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: TOOL_CALL_ARGS must have matching ID with TOOL_CALL_START
  it("should ensure tool call args has the same ID as tool call start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'different-id'. Start a tool call with 'TOOL_CALL_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a tool call start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Send tool call args with different ID
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "different-id",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TOOL_CALL_START);
  });

  // Test: Cannot end a tool call that wasn't started
  it("should not allow ending a tool call that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'. A 'TOOL_CALL_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a tool call start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send tool call end without a start
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Properly handle CUSTOM and RAW in any context
  it("should allow CUSTOM and RAW in any context", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a sequence with meta and raw events at different places
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "Exit",
      value: undefined,
    } as CustomEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "test_rawEvent",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.CUSTOM);
    expect(result[2].type).toBe(EventType.RAW);
  });

  // Test: Properly handle STATE_SNAPSHOT, STATE_DELTA, and MESSAGES_SNAPSHOT
  it("should allow state-related events in appropriate contexts", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a sequence with state events at different places
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "initial",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[1].type).toBe(EventType.STATE_SNAPSHOT);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
    expect(result[5].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Complex valid sequence with multiple message types
  it("should allow complex valid sequences with multiple message types", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a complex but valid sequence
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "msg1 content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "t1 args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "msg2 content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(13);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[12].type).toBe(EventType.RUN_FINISHED);
  });
});

describe("verifyEvents events", () => {
  // Test: TEXT_MESSAGE_CONTENT requires TEXT_MESSAGE_START with matching ID
  it("should require TEXT_MESSAGE_START before TEXT_MESSAGE_CONTENT with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'different-id'. Start a text message with 'TEXT_MESSAGE_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run and open a message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Try to send a message content event with a different message ID
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "different-id",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TEXT_MESSAGE_START);
  });

  // Test: TEXT_MESSAGE_END requires TEXT_MESSAGE_START with matching ID
  it("should require TEXT_MESSAGE_START before TEXT_MESSAGE_END with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID 'msg1'. A 'TEXT_MESSAGE_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run without starting a message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send a message end event without a matching start
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: TOOL_CALL_ARGS requires TOOL_CALL_START with matching ID
  it("should require TOOL_CALL_START before TOOL_CALL_ARGS with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'different-id'. Start a tool call with 'TOOL_CALL_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run and open a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Try to send a tool args event with a different tool ID
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "different-id",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TOOL_CALL_START);
  });

  // Test: TOOL_CALL_END requires TOOL_CALL_START with matching ID
  it("should require TOOL_CALL_START before TOOL_CALL_END with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'. A 'TOOL_CALL_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run without starting a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a tool call without a matching start
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Special events (RAW, CUSTOM, etc.) are allowed outside of tool calls
  it("should allow special events outside of tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with special events
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Meta event
    source$.next({
      type: EventType.CUSTOM,
      name: "Exit",
      value: undefined,
    } as CustomEvent);

    // Raw event
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.CUSTOM);
    expect(result[2].type).toBe(EventType.RAW);
  });

  // Test: STATE_SNAPSHOT is allowed
  it("should allow STATE_SNAPSHOT events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify both events were processed
    expect(result.length).toBe(2);
    expect(result[1].type).toBe(EventType.STATE_SNAPSHOT);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.lifecycle.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents lifecycle", () => {
  // Test: RUN_STARTED must be the first event
  it("should require RUN_STARTED as the first event", async () => {
    const source$ = new Subject<BaseEvent>();
    const result$ = verifyEvents(false)(source$).pipe(
      catchError((err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        throw err;
      }),
    );

    // Set up subscription
    const promise = firstValueFrom(result$).catch((e) => e);

    // Send an event that is not RUN_STARTED
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect it to be an error
    const result = await promise;
    expect(result).toBeInstanceOf(AGUIError);
  });

  // Test: Multiple RUN_STARTED events are not allowed
  it("should not allow multiple RUN_STARTED events", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("Cannot send 'RUN_STARTED' while a run is still active");
        subscription.unsubscribe();
      },
    });

    // Send first RUN_STARTED (should be accepted)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send second RUN_STARTED (should be rejected)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify one event was processed before the error
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: No events should be allowed after RUN_FINISHED (except RUN_ERROR)
  it("should not allow events after RUN_FINISHED (except RUN_ERROR)", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send event type 'TEXT_MESSAGE_START': The run has already finished with 'RUN_FINISHED'",
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence then RUN_FINISHED
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Send another event after RUN_FINISHED (should be rejected)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "2",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify the events before RUN_FINISHED were processed
    expect(events.length).toBe(4);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[3].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: RUN_ERROR is allowed after RUN_FINISHED
  it("should allow RUN_ERROR after RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send valid sequence ending with RUN_FINISHED followed by RUN_ERROR
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed including the RUN_ERROR after RUN_FINISHED
    expect(result.length).toBe(5);
    expect(result[4].type).toBe(EventType.RUN_ERROR);
  });

  // Test: RUN_ERROR can happen at any time (even as the first event)
  it("should allow RUN_ERROR at any time (even as first event)", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send RUN_ERROR as the first event
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify the RUN_ERROR was accepted as first event
    expect(result.length).toBe(1);
    expect(result[0].type).toBe(EventType.RUN_ERROR);
  });

  // Test: No events should be allowed after RUN_ERROR
  it("should not allow any events after RUN_ERROR", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send event type 'TEXT_MESSAGE_START': The run has already errored with 'RUN_ERROR'. No further events can be sent.",
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence then RUN_ERROR
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Send another event after RUN_ERROR (should be rejected)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify the events before RUN_ERROR were processed
    expect(events.length).toBe(2);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.RUN_ERROR);
  });

  // Test: Valid sequence of events is allowed
  it("should allow a valid sequence of events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.multiple-runs.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents multiple runs", () => {
  // Test: Basic multiple sequential runs
  it("should allow multiple sequential runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg-1",
      delta: "Hello from run 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg-2",
      delta: "Hello from run 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(10);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect((result[0] as RunStartedEvent).runId).toBe("test-run-1");
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
    expect(result[5].type).toBe(EventType.RUN_STARTED);
    expect((result[5] as RunStartedEvent).runId).toBe("test-run-2");
    expect(result[9].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Multiple runs with different message IDs
  it("should allow reusing message IDs across different runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with message ID "msg-1"
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run reusing message ID "msg-1" (should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
  });

  // Test: Multiple runs with tool calls
  it("should allow multiple runs with tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "calculator",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool-1",
      delta: '{"a": 1, "b": 2}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run with tool call (reusing toolCallId should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "weather",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool-1",
      delta: '{"city": "NYC"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(10);
  });

  // Test: Multiple runs with steps
  it("should allow multiple runs with steps", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "planning",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "planning",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run reusing step name (should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "planning",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "planning",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
  });

  // Test: Cannot start new run while current run is active
  it("should not allow new RUN_STARTED while run is active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send 'RUN_STARTED' while a run is still active",
        );
        subscription.unsubscribe();
      },
    });

    // Start first run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);

    // Try to start second run without finishing first (should fail)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only first RUN_STARTED was processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Three sequential runs
  it("should allow three sequential runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Three sequential runs
    for (let i = 1; i <= 3; i++) {
      source$.next({
        type: EventType.RUN_STARTED,
        threadId: "test-thread-1",
        runId: `test-run-${i}`,
      } as RunStartedEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg-${i}`,
      } as TextMessageStartEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg-${i}`,
        delta: `Message from run ${i}`,
      } as TextMessageContentEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg-${i}`,
      } as TextMessageEndEvent);
      source$.next({
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent);
    }

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed (5 events per run * 3 runs = 15 events)
    expect(result.length).toBe(15);

    // Verify run IDs are correct
    expect((result[0] as RunStartedEvent).runId).toBe("test-run-1");
    expect((result[5] as RunStartedEvent).runId).toBe("test-run-2");
    expect((result[10] as RunStartedEvent).runId).toBe("test-run-3");
  });

  // Test: RUN_ERROR still blocks subsequent events in the same run
  it("should still block events after RUN_ERROR within the same run", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "The run has already errored with 'RUN_ERROR'",
        );
        subscription.unsubscribe();
      },
    });

    // Start run and send error
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Try to send another event (should fail)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify events before error were processed
    expect(events.length).toBe(2);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.RUN_ERROR);
  });

  // Test: Complex scenario with mixed events across runs
  it("should handle complex scenario with multiple runs and various event types", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run: message + tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run: step + message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "analysis",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "analysis",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(12);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[5].type).toBe(EventType.RUN_FINISHED);
    expect(result[6].type).toBe(EventType.RUN_STARTED);
    expect(result[11].type).toBe(EventType.RUN_FINISHED);
  });
});


================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.steps.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents steps", () => {
  // Test: STEP_FINISHED must have matching name with STEP_STARTED
  it("should ensure step end has the same name as step start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'STEP_FINISHED' for step "different-name" that was not started`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Send step end with different name
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "different-name",
    } as StepFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
  });

  // Test: Cannot end a step that wasn't started
  it("should not allow ending a step that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'STEP_FINISHED' for step "test-step" that was not started`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send step end without a start
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot start a step with a name that's already active
  it("should not allow starting a step with a name that's already active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(`Step "test-step" is already active for 'STEP_STARTED'`);
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Send another step start with the same name
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
  });

  // Test: All steps must be ended before RUN_FINISHED
  it("should require all steps to be ended before run ends", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(`Cannot send 'RUN_FINISHED' while steps are still active`);
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with multiple steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step2",
    } as StepStartedEvent);
    // Intentionally not finishing step2

    // Try to end the run with active steps
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(4);
    expect(events[3].type).toBe(EventType.STEP_STARTED);
  });

  // Test: Valid sequence with properly nested steps
  it("should allow properly nested steps", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const events: BaseEvent[] = [];
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        fail(`Should not have errored: ${err.message}`);
      },
    });

    // Send a valid sequence with nested steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);

    source$.next({
      type: EventType.RUN_FINISHED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));
    subscription.unsubscribe();

    // Verify events were processed correctly
    expect(events.length).toBe(4);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
    expect(events[2].type).toBe(EventType.STEP_FINISHED);
    expect(events[3].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.text-messages.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents text messages", () => {
  // Test: Cannot send TEXT_MESSAGE_CONTENT before TEXT_MESSAGE_START
  it("should not allow TEXT_MESSAGE_CONTENT before TEXT_MESSAGE_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID '1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send content without starting a text message
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot send TEXT_MESSAGE_END before TEXT_MESSAGE_START
  it("should not allow TEXT_MESSAGE_END before TEXT_MESSAGE_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID '1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a text message without starting it
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Should allow TEXT_MESSAGE_CONTENT inside a text message
  it("should allow TEXT_MESSAGE_CONTENT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with text message content
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Should allow RAW inside a text message
  it("should allow RAW inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a raw event inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.RAW);
  });

  // Test: Should allow CUSTOM inside a text message
  it("should allow CUSTOM inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a custom event inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "test_event",
      value: "test_value",
    } as CustomEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.CUSTOM);
  });

  // Test: Should allow STATE_SNAPSHOT inside a text message
  it("should allow STATE_SNAPSHOT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_SNAPSHOT);
  });

  // Test: Should allow STATE_DELTA inside a text message
  it("should allow STATE_DELTA inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state delta inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Should allow MESSAGES_SNAPSHOT inside a text message
  it("should allow MESSAGES_SNAPSHOT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a messages snapshot inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test", id: "test-id" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
  });

  // Test: Should allow lifecycle events (STEP_STARTED/STEP_FINISHED) during text messages
  it("should allow lifecycle events during text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with lifecycle events inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[2].type).toBe(EventType.STEP_STARTED);
    expect(result[4].type).toBe(EventType.STEP_FINISHED);
  });

  // Test: Should allow tool calls to start during text messages
  it("should allow tool calls to start during text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with tool calls inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Starting search...",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Search completed.",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(9);
    expect(result[3].type).toBe(EventType.TOOL_CALL_START);
    expect(result[4].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[5].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Sequential text messages
  it("should allow multiple sequential text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with multiple text messages
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // First text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);

    // Second text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "2",
      delta: "content 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "2",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_END);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[5].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[6].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Text message at run boundaries
  it("should allow text messages immediately after RUN_STARTED and before RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send text message immediately after run start and before run end
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(5);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_END);
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Starting text message before RUN_STARTED
  it("should not allow starting a text message before RUN_STARTED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        subscription.unsubscribe();
      },
    });

    // Try to start a text message before RUN_STARTED
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify no events were processed
    expect(events.length).toBe(0);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.tool-calls.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents tool calls", () => {
  // Test: Cannot send TOOL_CALL_ARGS before TOOL_CALL_START
  it("should not allow TOOL_CALL_ARGS before TOOL_CALL_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 't1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send args without starting a tool call
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot send TOOL_CALL_END before TOOL_CALL_START
  it("should not allow TOOL_CALL_END before TOOL_CALL_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a tool call without starting it
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Should allow TOOL_CALL_ARGS and TOOL_CALL_END inside a tool call
  it("should allow TOOL_CALL_ARGS and TOOL_CALL_END inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with tool call events
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args 1",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args 2",
    } as ToolCallArgsEvent); // Multiple args allowed
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[3].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[4].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Should allow RAW inside a tool call
  it("should allow RAW inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a raw event inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.RAW);
  });

  // Test: Should allow CUSTOM inside a tool call
  it("should allow CUSTOM inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a custom event inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "test_event",
      value: "test_value",
    } as CustomEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.CUSTOM);
  });

  // Test: Should allow STATE_SNAPSHOT inside a tool call
  it("should allow STATE_SNAPSHOT inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_SNAPSHOT);
  });

  // Test: Should allow STATE_DELTA inside a tool call
  it("should allow STATE_DELTA inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state delta inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Should allow MESSAGES_SNAPSHOT inside a tool call
  it("should allow MESSAGES_SNAPSHOT inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a messages snapshot inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test", id: "test-id" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
  });

  // Test: Should allow lifecycle events (STEP_STARTED/STEP_FINISHED) during tool calls
  it("should allow lifecycle events during tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with lifecycle events inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[2].type).toBe(EventType.STEP_STARTED);
    expect(result[4].type).toBe(EventType.STEP_FINISHED);
  });

  // Test: Should allow text messages to start during tool calls
  it("should allow text messages to start during tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with text messages inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "Preparing...",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Tool is processing...",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "Completed.",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(9);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[5].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Sequential tool calls
  it("should allow multiple sequential tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with multiple tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // First tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Second tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t2",
    } as ToolCallEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[3].type).toBe(EventType.TOOL_CALL_END);
    expect(result[4].type).toBe(EventType.TOOL_CALL_START);
    expect(result[5].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[6].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Tool call at run boundaries
  it("should allow tool calls immediately after RUN_STARTED and before RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send tool call immediately after run start and before run end
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(5);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[3].type).toBe(EventType.TOOL_CALL_END);
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Starting tool call before RUN_STARTED
  it("should not allow starting a tool call before RUN_STARTED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        subscription.unsubscribe();
      },
    });

    // Try to start a tool call before RUN_STARTED
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify no events were processed
    expect(events.length).toBe(0);
  });
});



================================================
FILE: typescript-sdk/packages/core/README.md
================================================
# @ag-ui/core

TypeScript definitions & runtime schemas for the **Agent-User Interaction (AG-UI) Protocol**.

`@ag-ui/core` delivers the strongly-typed building blocks that every other AG-UI package is built on: message & state models, run inputs and the full set of streaming event types.

## Installation

```bash
npm install @ag-ui/core
pnpm add @ag-ui/core
yarn add @ag-ui/core
```

## Features

- 🧩 **Typed data models** – `Message`, `Tool`, `Context`, `RunAgentInput`, `State` …
- 🔄 **Streaming events** – 16 core event kinds covering assistant messages, tool calls, state updates and run lifecycle.
- ✅ **Runtime validation** – schemas catch malformed payloads early.
- 🚀 **Framework-agnostic** – works in Node.js, browsers and any agent framework that can emit JSON.

## Quick example

```ts
import { EventSchemas, EventType } from "@ag-ui/core";

// Validate an incoming event
EventSchemas.parse({
  type: EventType.TEXT_MESSAGE_CONTENT,
  messageId: "msg_123",
  delta: "Hello, world!",
});
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/core`](https://docs.ag-ui.com/sdk/js/core/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/core/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/core/package.json
================================================
{
  "name": "@ag-ui/core",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.37",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "rxjs": "7.8.1",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/jest": "^29.5.12",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/core/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/core/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/core/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/core/src/events.ts
================================================
import { z } from "zod";
import { MessageSchema, StateSchema } from "./types";

// Text messages can have any role except "tool"
const TextMessageRoleSchema = z.union([
  z.literal("developer"),
  z.literal("system"),
  z.literal("assistant"),
  z.literal("user"),
]);

export enum EventType {
  TEXT_MESSAGE_START = "TEXT_MESSAGE_START",
  TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT",
  TEXT_MESSAGE_END = "TEXT_MESSAGE_END",
  TEXT_MESSAGE_CHUNK = "TEXT_MESSAGE_CHUNK",
  THINKING_TEXT_MESSAGE_START = "THINKING_TEXT_MESSAGE_START",
  THINKING_TEXT_MESSAGE_CONTENT = "THINKING_TEXT_MESSAGE_CONTENT",
  THINKING_TEXT_MESSAGE_END = "THINKING_TEXT_MESSAGE_END",
  TOOL_CALL_START = "TOOL_CALL_START",
  TOOL_CALL_ARGS = "TOOL_CALL_ARGS",
  TOOL_CALL_END = "TOOL_CALL_END",
  TOOL_CALL_CHUNK = "TOOL_CALL_CHUNK",
  TOOL_CALL_RESULT = "TOOL_CALL_RESULT",
  THINKING_START = "THINKING_START",
  THINKING_END = "THINKING_END",
  STATE_SNAPSHOT = "STATE_SNAPSHOT",
  STATE_DELTA = "STATE_DELTA",
  MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT",
  RAW = "RAW",
  CUSTOM = "CUSTOM",
  RUN_STARTED = "RUN_STARTED",
  RUN_FINISHED = "RUN_FINISHED",
  RUN_ERROR = "RUN_ERROR",
  STEP_STARTED = "STEP_STARTED",
  STEP_FINISHED = "STEP_FINISHED",
}

export const BaseEventSchema = z.object({
  type: z.nativeEnum(EventType),
  timestamp: z.number().optional(),
  rawEvent: z.any().optional(),
});

export const TextMessageStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_START),
  messageId: z.string(),
  role: TextMessageRoleSchema.default("assistant"),
});

export const TextMessageContentEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_CONTENT),
  messageId: z.string(),
  delta: z.string().refine((s) => s.length > 0, "Delta must not be an empty string"),
});

export const TextMessageEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_END),
  messageId: z.string(),
});

export const TextMessageChunkEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_CHUNK),
  messageId: z.string().optional(),
  role: TextMessageRoleSchema.optional(),
  delta: z.string().optional(),
});

export const ThinkingTextMessageStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_START),
});

export const ThinkingTextMessageContentEventSchema = TextMessageContentEventSchema.omit({
  messageId: true,
  type: true,
}).extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_CONTENT),
});

export const ThinkingTextMessageEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_END),
});

export const ToolCallStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_START),
  toolCallId: z.string(),
  toolCallName: z.string(),
  parentMessageId: z.string().optional(),
});

export const ToolCallArgsEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_ARGS),
  toolCallId: z.string(),
  delta: z.string(),
});

export const ToolCallEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_END),
  toolCallId: z.string(),
});

export const ToolCallResultEventSchema = BaseEventSchema.extend({
  messageId: z.string(),
  type: z.literal(EventType.TOOL_CALL_RESULT),
  toolCallId: z.string(),
  content: z.string(),
  role: z.literal("tool").optional(),
});

export const ToolCallChunkEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_CHUNK),
  toolCallId: z.string().optional(),
  toolCallName: z.string().optional(),
  parentMessageId: z.string().optional(),
  delta: z.string().optional(),
});

export const ThinkingStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_START),
  title: z.string().optional(),
});

export const ThinkingEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_END),
});

export const StateSnapshotEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STATE_SNAPSHOT),
  snapshot: StateSchema,
});

export const StateDeltaEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STATE_DELTA),
  delta: z.array(z.any()), // JSON Patch (RFC 6902)
});

export const MessagesSnapshotEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.MESSAGES_SNAPSHOT),
  messages: z.array(MessageSchema),
});

export const RawEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RAW),
  event: z.any(),
  source: z.string().optional(),
});

export const CustomEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.CUSTOM),
  name: z.string(),
  value: z.any(),
});

export const RunStartedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_STARTED),
  threadId: z.string(),
  runId: z.string(),
});

export const RunFinishedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_FINISHED),
  threadId: z.string(),
  runId: z.string(),
  result: z.any().optional(),
});

export const RunErrorEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_ERROR),
  message: z.string(),
  code: z.string().optional(),
});

export const StepStartedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STEP_STARTED),
  stepName: z.string(),
});

export const StepFinishedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STEP_FINISHED),
  stepName: z.string(),
});

export const EventSchemas = z.discriminatedUnion("type", [
  TextMessageStartEventSchema,
  TextMessageContentEventSchema,
  TextMessageEndEventSchema,
  TextMessageChunkEventSchema,
  ThinkingStartEventSchema,
  ThinkingEndEventSchema,
  ThinkingTextMessageStartEventSchema,
  ThinkingTextMessageContentEventSchema,
  ThinkingTextMessageEndEventSchema,
  ToolCallStartEventSchema,
  ToolCallArgsEventSchema,
  ToolCallEndEventSchema,
  ToolCallChunkEventSchema,
  ToolCallResultEventSchema,
  StateSnapshotEventSchema,
  StateDeltaEventSchema,
  MessagesSnapshotEventSchema,
  RawEventSchema,
  CustomEventSchema,
  RunStartedEventSchema,
  RunFinishedEventSchema,
  RunErrorEventSchema,
  StepStartedEventSchema,
  StepFinishedEventSchema,
]);

export type BaseEvent = z.infer<typeof BaseEventSchema>;
export type TextMessageStartEvent = z.infer<typeof TextMessageStartEventSchema>;
export type TextMessageContentEvent = z.infer<typeof TextMessageContentEventSchema>;
export type TextMessageEndEvent = z.infer<typeof TextMessageEndEventSchema>;
export type TextMessageChunkEvent = z.infer<typeof TextMessageChunkEventSchema>;
export type ThinkingTextMessageStartEvent = z.infer<typeof ThinkingTextMessageStartEventSchema>;
export type ThinkingTextMessageContentEvent = z.infer<typeof ThinkingTextMessageContentEventSchema>;
export type ThinkingTextMessageEndEvent = z.infer<typeof ThinkingTextMessageEndEventSchema>;
export type ToolCallStartEvent = z.infer<typeof ToolCallStartEventSchema>;
export type ToolCallArgsEvent = z.infer<typeof ToolCallArgsEventSchema>;
export type ToolCallEndEvent = z.infer<typeof ToolCallEndEventSchema>;
export type ToolCallChunkEvent = z.infer<typeof ToolCallChunkEventSchema>;
export type ToolCallResultEvent = z.infer<typeof ToolCallResultEventSchema>;
export type ThinkingStartEvent = z.infer<typeof ThinkingStartEventSchema>;
export type ThinkingEndEvent = z.infer<typeof ThinkingEndEventSchema>;
export type StateSnapshotEvent = z.infer<typeof StateSnapshotEventSchema>;
export type StateDeltaEvent = z.infer<typeof StateDeltaEventSchema>;
export type MessagesSnapshotEvent = z.infer<typeof MessagesSnapshotEventSchema>;
export type RawEvent = z.infer<typeof RawEventSchema>;
export type CustomEvent = z.infer<typeof CustomEventSchema>;
export type RunStartedEvent = z.infer<typeof RunStartedEventSchema>;
export type RunFinishedEvent = z.infer<typeof RunFinishedEventSchema>;
export type RunErrorEvent = z.infer<typeof RunErrorEventSchema>;
export type StepStartedEvent = z.infer<typeof StepStartedEventSchema>;
export type StepFinishedEvent = z.infer<typeof StepFinishedEventSchema>;



================================================
FILE: typescript-sdk/packages/core/src/index.ts
================================================
// Export all base types and schemas
export * from "./types";

// Export all event-related types and schemas
export * from "./events";



================================================
FILE: typescript-sdk/packages/core/src/types.ts
================================================
import { z } from "zod";

export const FunctionCallSchema = z.object({
  name: z.string(),
  arguments: z.string(),
});

export const ToolCallSchema = z.object({
  id: z.string(),
  type: z.literal("function"),
  function: FunctionCallSchema,
});

export const BaseMessageSchema = z.object({
  id: z.string(),
  role: z.string(),
  content: z.string().optional(),
  name: z.string().optional(),
});

export const DeveloperMessageSchema = BaseMessageSchema.extend({
  role: z.literal("developer"),
  content: z.string(),
});

export const SystemMessageSchema = BaseMessageSchema.extend({
  role: z.literal("system"),
  content: z.string(),
});

export const AssistantMessageSchema = BaseMessageSchema.extend({
  role: z.literal("assistant"),
  content: z.string().optional(),
  toolCalls: z.array(ToolCallSchema).optional(),
});

export const UserMessageSchema = BaseMessageSchema.extend({
  role: z.literal("user"),
  content: z.string(),
});

export const ToolMessageSchema = z.object({
  id: z.string(),
  content: z.string(),
  role: z.literal("tool"),
  toolCallId: z.string(),
  error: z.string().optional(),
});

export const MessageSchema = z.discriminatedUnion("role", [
  DeveloperMessageSchema,
  SystemMessageSchema,
  AssistantMessageSchema,
  UserMessageSchema,
  ToolMessageSchema,
]);

export const RoleSchema = z.union([
  z.literal("developer"),
  z.literal("system"),
  z.literal("assistant"),
  z.literal("user"),
  z.literal("tool"),
]);

export const ContextSchema = z.object({
  description: z.string(),
  value: z.string(),
});

export const ToolSchema = z.object({
  name: z.string(),
  description: z.string(),
  parameters: z.any(), // JSON Schema for the tool parameters
});

export const RunAgentInputSchema = z.object({
  threadId: z.string(),
  runId: z.string(),
  state: z.any(),
  messages: z.array(MessageSchema),
  tools: z.array(ToolSchema),
  context: z.array(ContextSchema),
  forwardedProps: z.any(),
});

export const StateSchema = z.any();

export type ToolCall = z.infer<typeof ToolCallSchema>;
export type FunctionCall = z.infer<typeof FunctionCallSchema>;
export type DeveloperMessage = z.infer<typeof DeveloperMessageSchema>;
export type SystemMessage = z.infer<typeof SystemMessageSchema>;
export type AssistantMessage = z.infer<typeof AssistantMessageSchema>;
export type UserMessage = z.infer<typeof UserMessageSchema>;
export type ToolMessage = z.infer<typeof ToolMessageSchema>;
export type Message = z.infer<typeof MessageSchema>;
export type Context = z.infer<typeof ContextSchema>;
export type Tool = z.infer<typeof ToolSchema>;
export type RunAgentInput = z.infer<typeof RunAgentInputSchema>;
export type State = z.infer<typeof StateSchema>;
export type Role = z.infer<typeof RoleSchema>;

export class AGUIError extends Error {
  constructor(message: string) {
    super(message);
  }
}



================================================
FILE: typescript-sdk/packages/core/src/__tests__/events-role-defaults.test.ts
================================================
import { TextMessageStartEventSchema, TextMessageChunkEventSchema, EventType } from "../events";

describe("Event role defaults", () => {
  it("should default TextMessageStartEvent role to 'assistant' when not provided", () => {
    const eventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      // role not provided
    };

    const parsed = TextMessageStartEventSchema.parse(eventData);
    
    expect(parsed.type).toBe(EventType.TEXT_MESSAGE_START);
    expect(parsed.messageId).toBe("test-msg");
    expect(parsed.role).toBe("assistant"); // Should default to assistant
  });

  it("should allow overriding the default role in TextMessageStartEvent", () => {
    const eventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "user",
    };

    const parsed = TextMessageStartEventSchema.parse(eventData);
    
    expect(parsed.type).toBe(EventType.TEXT_MESSAGE_START);
    expect(parsed.messageId).toBe("test-msg");
    expect(parsed.role).toBe("user"); // Should use provided role
  });

  it("should accept all valid text message roles in TextMessageStartEvent", () => {
    const textMessageRoles = ["developer", "system", "assistant", "user"];
    
    textMessageRoles.forEach(role => {
      const eventData = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: `test-msg-${role}`,
        role,
      };

      const parsed = TextMessageStartEventSchema.parse(eventData);
      expect(parsed.role).toBe(role);
    });
  });

  it("should keep role optional in TextMessageChunkEvent", () => {
    const eventDataWithoutRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      delta: "test content",
      // role not provided
    };

    const parsed1 = TextMessageChunkEventSchema.parse(eventDataWithoutRole);
    expect(parsed1.role).toBeUndefined(); // Should be undefined when not provided

    const eventDataWithRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      role: "user",
      delta: "test content",
    };

    const parsed2 = TextMessageChunkEventSchema.parse(eventDataWithRole);
    expect(parsed2.role).toBe("user"); // Should use provided role
  });

  it("should reject invalid roles", () => {
    const invalidEventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "invalid_role",
    };

    expect(() => {
      TextMessageStartEventSchema.parse(invalidEventData);
    }).toThrow();
  });

  it("should reject 'tool' role for text messages", () => {
    // Test TextMessageStartEvent with tool role
    const startEventWithToolRole = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "tool",
    };

    expect(() => {
      TextMessageStartEventSchema.parse(startEventWithToolRole);
    }).toThrow();

    // Test TextMessageChunkEvent with tool role
    const chunkEventWithToolRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      role: "tool",
      delta: "content",
    };

    expect(() => {
      TextMessageChunkEventSchema.parse(chunkEventWithToolRole);
    }).toThrow();
  });
});


================================================
FILE: typescript-sdk/packages/core/src/__tests__/index.test.ts
================================================
describe("Core package", () => {
  it("should pass a simple test", () => {
    expect(true).toBe(true);
  });
});



================================================
FILE: typescript-sdk/packages/encoder/README.md
================================================
# @ag-ui/encoder

Event encoding utilities for the **Agent-User Interaction (AG-UI) Protocol**.

`@ag-ui/encoder` handles content negotiation and format encoding for AG-UI events. It automatically chooses between Server-Sent Events (JSON) and Protocol Buffers based on client `Accept` headers, ensuring optimal transport efficiency.

## Installation

```bash
npm install @ag-ui/encoder
pnpm add @ag-ui/encoder
yarn add @ag-ui/encoder
```

## Features

- 🎯 **Content negotiation** – Automatic format selection based on `Accept` headers
- 📦 **Dual encoding** – SSE (JSON) and Protocol Buffer support
- ⚡ **Efficient binary** – Length-prefixed protobuf encoding for high-throughput scenarios
- 🔄 **Seamless fallback** – Graceful degradation to SSE when protobuf isn't supported

## Quick example

```ts
import { EventEncoder } from "@ag-ui/encoder";
import { EventType } from "@ag-ui/core";

const encoder = new EventEncoder({
  accept: "application/vnd.ag-ui.event+proto, text/event-stream",
});

const event = {
  type: EventType.TEXT_MESSAGE_CONTENT,
  messageId: "msg_123",
  delta: "Hello, world!",
};

// Returns protobuf-encoded binary data
const encoded = encoder.encodeBinary(event);
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/encoder`](https://docs.ag-ui.com/sdk/js/encoder)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/encoder/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/encoder/package.json
================================================
{
  "name": "@ag-ui/encoder",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.37",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/proto": "workspace:*"
  },
  "devDependencies": {
    "@types/jest": "^29.5.12",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/encoder/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/encoder/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/encoder/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/encoder/src/encoder.ts
================================================
import { BaseEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";
import { preferredMediaTypes } from "./media-type";

export interface EventEncoderParams {
  accept?: string;
}

export class EventEncoder {
  private acceptsProtobuf: boolean;

  constructor(params?: EventEncoderParams) {
    this.acceptsProtobuf = params?.accept ? this.isProtobufAccepted(params.accept) : false;
  }

  getContentType(): string {
    if (this.acceptsProtobuf) {
      return proto.AGUI_MEDIA_TYPE;
    } else {
      return "text/event-stream";
    }
  }

  encode(event: BaseEvent): string {
    return this.encodeSSE(event);
  }

  encodeSSE(event: BaseEvent): string {
    return `data: ${JSON.stringify(event)}\n\n`;
  }

  encodeBinary(event: BaseEvent): Uint8Array {
    if (this.acceptsProtobuf) {
      return this.encodeProtobuf(event);
    } else {
      const sseString = this.encodeSSE(event);
      // Convert string to Uint8Array using TextEncoder
      const encoder = new TextEncoder();
      return encoder.encode(sseString);
    }
  }

  encodeProtobuf(event: BaseEvent): Uint8Array {
    const messageBytes = proto.encode(event);
    const length = messageBytes.length;

    // Create a buffer for 4 bytes (for the uint32 length) plus the message bytes
    const buffer = new ArrayBuffer(4 + length);
    const dataView = new DataView(buffer);

    // Write the length as a uint32
    // Set the third parameter to `false` for big-endian or `true` for little-endian
    dataView.setUint32(0, length, false);

    // Create a Uint8Array view and copy in the message bytes after the 4-byte header
    const result = new Uint8Array(buffer);
    result.set(messageBytes, 4);

    return result;
  }

  private isProtobufAccepted(acceptHeader: string): boolean {
    // Pass the Accept header and an array with your media type
    const preferred = preferredMediaTypes(acceptHeader, [proto.AGUI_MEDIA_TYPE]);

    // If the returned array includes your media type, it's acceptable
    return preferred.includes(proto.AGUI_MEDIA_TYPE);
  }
}



================================================
FILE: typescript-sdk/packages/encoder/src/index.ts
================================================
export * from "./encoder";
export { AGUI_MEDIA_TYPE } from "@ag-ui/proto";



================================================
FILE: typescript-sdk/packages/encoder/src/media-type.ts
================================================
/**
 * negotiator
 * Copyright(c) 2012 Isaac Z. Schlueter
 * Copyright(c) 2014 Federico Romero
 * Copyright(c) 2014-2015 Douglas Christopher Wilson
 * MIT Licensed
 */

// modified from https://github.com/jshttp/negotiator/blob/master/lib/mediaType.js

/**
 * Module exports.
 * @public
 */

export function preferredMediaTypes(accept?: string, provided?: string[]): string[] {
  // RFC 2616 sec 14.2: no header = */*
  const accepts = parseAccept(accept === undefined ? "*/*" : accept || "");

  if (!provided) {
    // sorted list of all types
    return accepts
      .filter((spec): spec is MediaType => spec.q > 0)
      .sort((a, b) => {
        return b.q - a.q || b.i - a.i || 0;
      })
      .map(getFullType);
  }

  const priorities = provided.map(function getPriority(type: string, index: number) {
    return getMediaTypePriority(type, accepts, index);
  });

  // sorted list of accepted types
  return priorities
    .filter((spec): spec is Priority => spec.q > 0)
    .sort(compareSpecs)
    .map(function getType(priority: Priority) {
      return provided[priorities.indexOf(priority)];
    });
}

/**
 * Module variables.
 * @private
 */

const simpleMediaTypeRegExp = /^\s*([^\s\/;]+)\/([^;\s]+)\s*(?:;(.*))?$/;

/**
 * Media type interface
 * @private
 */
interface MediaType {
  type: string;
  subtype: string;
  params: Record<string, string>;
  q: number;
  i: number;
}

/**
 * Priority interface
 * @private
 */
interface Priority {
  o: number;
  q: number;
  s: number;
  i?: number;
}

/**
 * Parse the Accept header.
 * @private
 */
function parseAccept(accept: string): MediaType[] {
  const accepts = splitMediaTypes(accept);
  const result: MediaType[] = [];

  for (let i = 0, j = 0; i < accepts.length; i++) {
    const mediaType = parseMediaType(accepts[i].trim(), i);

    if (mediaType) {
      result[j++] = mediaType;
    }
  }

  return result;
}

/**
 * Parse a media type from the Accept header.
 * @private
 */
function parseMediaType(str: string, i: number): MediaType | null {
  const match = simpleMediaTypeRegExp.exec(str);
  if (!match) return null;

  const params: Record<string, string> = Object.create(null);
  let q = 1;
  const subtype = match[2];
  const type = match[1];

  if (match[3]) {
    const kvps = splitParameters(match[3]).map(splitKeyValuePair);

    for (let j = 0; j < kvps.length; j++) {
      const pair = kvps[j];
      const key = pair[0].toLowerCase();
      const val = pair[1];

      // get the value, unwrapping quotes
      const value = val && val[0] === '"' && val[val.length - 1] === '"' ? val.slice(1, -1) : val;

      if (key === "q") {
        q = parseFloat(value);
        break;
      }

      // store parameter
      params[key] = value;
    }
  }

  return {
    type: type,
    subtype: subtype,
    params: params,
    q: q,
    i: i,
  };
}

/**
 * Get the priority of a media type.
 * @private
 */
function getMediaTypePriority(type: string, accepted: MediaType[], index: number): Priority {
  const priority: Priority = { o: -1, q: 0, s: 0 };

  for (let i = 0; i < accepted.length; i++) {
    const spec = specify(type, accepted[i], index);

    if (spec && (priority.s - spec.s || priority.q - spec.q || priority.o - spec.o) < 0) {
      priority.o = spec.o;
      priority.q = spec.q;
      priority.s = spec.s;
      priority.i = spec.i;
    }
  }

  return priority;
}

/**
 * Get the specificity of the media type.
 * @private
 */
function specify(type: string, spec: MediaType, index: number): Priority | null {
  const p = parseMediaType(type, 0);
  let s = 0;

  if (!p) {
    return null;
  }

  if (spec.type.toLowerCase() == p.type.toLowerCase()) {
    s |= 4;
  } else if (spec.type != "*") {
    return null;
  }

  if (spec.subtype.toLowerCase() == p.subtype.toLowerCase()) {
    s |= 2;
  } else if (spec.subtype != "*") {
    return null;
  }

  const keys = Object.keys(spec.params);
  if (keys.length > 0) {
    if (
      keys.every(function (k) {
        return (
          spec.params[k] == "*" ||
          (spec.params[k] || "").toLowerCase() == (p.params[k] || "").toLowerCase()
        );
      })
    ) {
      s |= 1;
    } else {
      return null;
    }
  }

  return {
    i: index,
    o: spec.i,
    q: spec.q,
    s: s,
  };
}

/**
 * Compare two specs.
 * @private
 */
function compareSpecs(a: Priority, b: Priority): number {
  return b.q - a.q || b.s - a.s || (a.o || 0) - (b.o || 0) || (a.i || 0) - (b.i || 0) || 0;
}

/**
 * Get full type string.
 * @private
 */
function getFullType(spec: MediaType): string {
  return spec.type + "/" + spec.subtype;
}

/**
 * Check if a spec has any quality.
 * @private
 */
function isQuality(spec: Priority | MediaType): boolean {
  return spec.q > 0;
}

/**
 * Count the number of quotes in a string.
 * @private
 */
function quoteCount(string: string): number {
  let count = 0;
  let index = 0;

  while ((index = string.indexOf('"', index)) !== -1) {
    count++;
    index++;
  }

  return count;
}

/**
 * Split a key value pair.
 * @private
 */
function splitKeyValuePair(str: string): [string, string] {
  const index = str.indexOf("=");
  let key: string;
  let val: string = "";

  if (index === -1) {
    key = str;
  } else {
    key = str.slice(0, index);
    val = str.slice(index + 1);
  }

  return [key, val];
}

/**
 * Split an Accept header into media types.
 * @private
 */
function splitMediaTypes(accept: string): string[] {
  const accepts = accept.split(",");
  const result: string[] = [accepts[0]];

  for (let i = 1, j = 0; i < accepts.length; i++) {
    if (quoteCount(result[j]) % 2 == 0) {
      result[++j] = accepts[i];
    } else {
      result[j] += "," + accepts[i];
    }
  }

  // trim result
  return result;
}

/**
 * Split a string of parameters.
 * @private
 */
function splitParameters(str: string): string[] {
  const parameters = str.split(";");
  const result: string[] = [parameters[0]];

  for (let i = 1, j = 0; i < parameters.length; i++) {
    if (quoteCount(result[j]) % 2 == 0) {
      result[++j] = parameters[i];
    } else {
      result[j] += ";" + parameters[i];
    }
  }

  // trim parameters
  for (let i = 0; i < result.length; i++) {
    result[i] = result[i].trim();
  }

  return result;
}



================================================
FILE: typescript-sdk/packages/encoder/src/__tests__/encoder.test.ts
================================================
import { EventEncoder } from "../encoder";
import { BaseEvent, EventType, TextMessageStartEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";

describe("Encoder Tests", () => {
  // Create a valid TextMessageStartEvent event
  const testEvent: TextMessageStartEvent = {
    type: EventType.TEXT_MESSAGE_START,
    timestamp: 123456789,
    messageId: "msg123",
    role: "assistant",
  };

  describe("encodeBinary method", () => {
    it("should return protobuf encoded data when accept header includes protobuf media type", () => {
      // Setup an encoder with protobuf accepted
      const encoder = new EventEncoder({
        accept: `text/event-stream, ${proto.AGUI_MEDIA_TYPE}`,
      });

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // A protobuf message should start with 4 bytes for length followed by the message
      // So the length should be greater than 4 at minimum
      expect(result.length).toBeGreaterThan(4);

      // The first 4 bytes should be a uint32 representing the message length
      const dataView = new DataView(result.buffer);
      const messageLength = dataView.getUint32(0, false); // false for big-endian

      // The actual message should match the length specified in the header
      expect(result.length - 4).toBe(messageLength);
    });

    it("should return SSE encoded data when accept header doesn't include protobuf media type", () => {
      // Setup an encoder without protobuf accepted
      const encoder = new EventEncoder({
        accept: "text/event-stream",
      });

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // Convert back to string to verify it's SSE format
      const decoder = new TextDecoder();
      const resultString = decoder.decode(result);

      // Should match the SSE format with the expected JSON
      expect(resultString).toBe(`data: ${JSON.stringify(testEvent)}\n\n`);
    });

    it("should return SSE encoded data when no accept header is provided", () => {
      // Setup an encoder without any accept header
      const encoder = new EventEncoder();

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // Convert back to string to verify it's SSE format
      const decoder = new TextDecoder();
      const resultString = decoder.decode(result);

      // Should match the SSE format with the expected JSON
      expect(resultString).toBe(`data: ${JSON.stringify(testEvent)}\n\n`);
    });
  });

  describe("encodeProtobuf method", () => {
    it("should encode event as protobuf with length prefix", () => {
      const encoder = new EventEncoder();

      const result = encoder.encodeProtobuf(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // A protobuf message should start with 4 bytes for length followed by the message
      expect(result.length).toBeGreaterThan(4);

      // The first 4 bytes should be a uint32 representing the message length
      const dataView = new DataView(result.buffer);
      const messageLength = dataView.getUint32(0, false); // false for big-endian

      // The actual message should match the length specified in the header
      expect(result.length - 4).toBe(messageLength);

      // The message length should be greater than zero
      expect(messageLength).toBeGreaterThan(0);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/README.md
================================================
# @ag-ui/proto

Protocol Buffer encoding/decoding for **Agent-User Interaction (AG-UI) Protocol** events.

`@ag-ui/proto` provides high-performance binary serialization of AG-UI events using Protocol Buffers. It includes generated TypeScript definitions and utilities for converting between AG-UI's JSON event format and compact binary representation.

## Installation

```bash
npm install @ag-ui/proto
pnpm add @ag-ui/proto
yarn add @ag-ui/proto
```

## Features

- ⚡ **High performance** – Binary protobuf encoding for minimal bandwidth usage
- 🔄 **Round-trip safety** – Lossless conversion between JSON and binary formats
- 📋 **Generated types** – Auto-generated TypeScript definitions from `.proto` schemas
- 🔧 **Length-prefixed** – Standard 4-byte length headers for streaming protocols

## Quick example

```ts
import { encode, decode, AGUI_MEDIA_TYPE } from "@ag-ui/proto";
import { EventType } from "@ag-ui/core";

const event = {
  type: EventType.TEXT_MESSAGE_START,
  messageId: "msg_123",
  role: "assistant",
};

// Encode to binary protobuf format
const encoded = encode(event);

// Decode back to AG-UI event
const decoded = decode(encoded);
console.log(decoded); // Original event object
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/proto`](https://docs.ag-ui.com/sdk/js/proto)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/proto/jest.config.js
================================================
/** @type {import('jest').Config} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/proto/package.json
================================================
{
  "name": "@ag-ui/proto",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.37",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "generate": "mkdir -p ./src/generated && npx protoc --plugin=./node_modules/.bin/protoc-gen-ts_proto --ts_proto_out=./src/generated --ts_proto_opt=esModuleInterop=true,outputJsonMethods=false,outputClientImpl=false -I ./src/proto ./src/proto/*.proto",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@bufbuild/protobuf": "^2.2.5",
    "@protobuf-ts/protoc": "^2.11.1"
  },
  "devDependencies": {
    "@jest/globals": "^29.7.0",
    "@types/jest": "^29.5.14",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "ts-proto": "^2.7.0",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/proto/tsconfig.json
================================================
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/__tests__/**"]
}



================================================
FILE: typescript-sdk/packages/proto/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["esm", "cjs"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/proto/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/proto/__tests__/message-events.test.ts
================================================
import {
  BaseEvent,
  EventType,
  MessagesSnapshotEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
} from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Message Events", () => {
  describe("TextMessageStartEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg-1",
        role: "assistant",
      };

      expectRoundTripEquality(event);
    });

    it("should handle missing optional fields", () => {
      const event: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("TextMessageContentEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg-1",
        delta: "Hello, how can I help you today?",
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in content delta", () => {
      const event: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Special chars: 🚀 ñ € 😊 \n\t\"'\\`",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("TextMessageEndEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageEndEvent = {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg-1",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("MessagesSnapshotEvent", () => {
    it("should round-trip encode/decode with multiple messages", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        timestamp: Date.now(),
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "Can you help me with my task?",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "I'd be happy to help! What task do you need assistance with?",
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with tool calls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "What's the weather in San Francisco?",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Let me check the weather for you.",
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "get_weather",
                  arguments: JSON.stringify({ location: "San Francisco" }),
                },
              },
            ],
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with multiple tool calls and complex arguments", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: undefined, // Changed from null to undefined
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "analyze_data",
                  arguments: JSON.stringify({
                    dataset: "sales_2023",
                    metrics: ["revenue", "growth", "conversion"],
                    filters: {
                      region: "North America",
                      timeframe: { start: "2023-01-01", end: "2023-12-31" },
                    },
                  }),
                },
              },
              {
                id: "tool-2",
                type: "function",
                function: {
                  name: "generate_report",
                  arguments: JSON.stringify({
                    title: "Annual Sales Report",
                    format: "pdf",
                    sections: ["summary", "detailed_analysis", "recommendations"],
                  }),
                },
              },
            ],
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with undefined toolCalls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "Hello",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Hi there!",
            // No toolCalls field
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check messages length
      expect(decoded.messages).toHaveLength(event.messages.length);

      // Check first message
      expect(decoded.messages[0].id).toBe(event.messages[0].id);
      expect(decoded.messages[0].role).toBe(event.messages[0].role);
      expect(decoded.messages[0].content).toBe(event.messages[0].content);
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();

      // Check second message
      expect(decoded.messages[1].id).toBe(event.messages[1].id);
      expect(decoded.messages[1].role).toBe(event.messages[1].role);
      expect(decoded.messages[1].content).toBe(event.messages[1].content);
      expect((decoded.messages[1] as any).toolCalls).toBeUndefined();
    });

    it("should handle messages with empty toolCalls array", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: "I processed your request.",
            toolCalls: [], // Explicitly empty array
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check that empty toolCalls array is converted to undefined
      expect(decoded.messages[0].id).toBe(event.messages[0].id);
      expect(decoded.messages[0].role).toBe(event.messages[0].role);
      expect(decoded.messages[0].content).toBe(event.messages[0].content);
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();
    });

    // Test for mixed messages (one with empty toolCalls, one with non-empty)
    it("should correctly handle a mix of messages with empty and non-empty toolCalls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: "First message",
            toolCalls: [], // Empty array that should be converted to undefined
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Second message",
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "test_function",
                  arguments: "{}",
                },
              },
            ],
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check first message (empty toolCalls should be undefined)
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();

      // Check second message (non-empty toolCalls should be preserved)
      expect((decoded.messages[1] as any).toolCalls).toBeDefined();
      expect((decoded.messages[1] as any).toolCalls?.length).toBe(1);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/proto.test.ts
================================================
import { encode, decode } from "../src/proto";
import {
  BaseEvent,
  EventType,
  StateDeltaEvent,
  ToolCallStartEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";
import { describe, it, expect } from "@jest/globals";
import * as protoEvents from "../src/generated/events";

describe("Proto", () => {
  it("should encode events", () => {
    const event: BaseEvent = {
      type: EventType.TOOL_CALL_START,
      timestamp: Date.now(),
    };
    const encoded = encode(event);
    expect(encoded).toBeInstanceOf(Uint8Array);
  });
  it("should handle state delta events encoding", () => {
    const event: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: Date.now(),
      delta: [{ op: "add", path: "/foo", value: "bar" }],
    };
    const encoded = encode(event);
    expect(encoded).toBeInstanceOf(Uint8Array);
  });
  // Test for round-trip encoding/decoding
  it("should correctly round-trip encode/decode an event", () => {
    const originalEvent: ToolCallStartEvent = {
      type: EventType.TOOL_CALL_START,
      toolCallId: "123",
      toolCallName: "test",
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded);
    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);
  });
  // Test for StateDeltaEvent round-trip
  it("should correctly round-trip encode/decode a StateDeltaEvent event", () => {
    const originalEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: 1698765432123,
      delta: [
        { op: "add", path: "/foo", value: "bar" },
        { op: "remove", path: "/baz" },
      ],
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as StateDeltaEvent;

    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);
    expect(decoded.delta).toHaveLength(originalEvent.delta.length);
    // Check delta operations
    expect(decoded.delta[0].op).toBe(originalEvent.delta[0].op);
    expect(decoded.delta[0].path).toBe(originalEvent.delta[0].path);
    expect(decoded.delta[0].value).toBe(originalEvent.delta[0].value);
    expect(decoded.delta[1].op).toBe(originalEvent.delta[1].op);
    expect(decoded.delta[1].path).toBe(originalEvent.delta[1].path);
  });
  // Test for complex values
  it("should correctly handle complex values in StateDeltaEvent events", () => {
    const complexValue = {
      nested: {
        array: [1, 2, 3],
        object: { key: "value" },
      },
      boolean: true,
      number: 42,
    };
    const originalEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: 1698765432123,
      delta: [{ op: "add", path: "/complex", value: complexValue }],
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as StateDeltaEvent;
    expect(decoded.delta[0].value).toEqual(complexValue);
  });
  it("should correctly encode/decode a MessagesSnapshotEvent event with tool calls", () => {
    const originalEvent: MessagesSnapshotEvent = {
      type: EventType.MESSAGES_SNAPSHOT,
      timestamp: 1698765432123,
      messages: [
        {
          id: "msg-1",
          role: "user",
          content: "Hello, can you help me with something?",
        },
        {
          id: "msg-2",
          role: "assistant",
          content: "I'll help you analyze that data.",
          toolCalls: [
            {
              id: "tool-call-1",
              type: "function",
              function: {
                name: "analyze_data",
                arguments: JSON.stringify({
                  dataset: "sales_q2",
                  metrics: ["revenue", "growth"],
                }),
              },
            },
            {
              id: "tool-call-2",
              type: "function",
              function: {
                name: "generate_chart",
                arguments: JSON.stringify({
                  chartType: "bar",
                  data: "processed_data",
                }),
              },
            },
          ],
        },
      ],
    };

    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as MessagesSnapshotEvent;

    // Verify basic event properties
    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);

    // Verify messages array
    expect(decoded.messages).toHaveLength(originalEvent.messages.length);

    // Verify first message (user)
    expect(decoded.messages[0].id).toBe(originalEvent.messages[0].id);
    expect(decoded.messages[0].role).toBe(originalEvent.messages[0].role);
    expect(decoded.messages[0].content).toBe(originalEvent.messages[0].content);

    // Verify second message (assistant with tool calls)
    expect(decoded.messages[1].id).toBe(originalEvent.messages[1].id);
    expect(decoded.messages[1].role).toBe(originalEvent.messages[1].role);
    expect(decoded.messages[1].content).toBe(originalEvent.messages[1].content);

    // Verify tool calls
    expect((decoded.messages[1] as any).toolCalls).toBeDefined();
    expect((decoded.messages[1] as any).toolCalls).toHaveLength(
      (originalEvent.messages[1] as any).toolCalls!.length,
    );

    // Verify first tool call
    expect((decoded.messages[1] as any).toolCalls![0].id).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].id,
    );
    expect((decoded.messages[1] as any).toolCalls![0].type).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].type,
    );
    expect((decoded.messages[1] as any).toolCalls![0].function.name).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].function.name,
    );

    // Parse and compare JSON arguments
    const decodedArgs1 = JSON.parse((decoded.messages[1] as any).toolCalls![0].function.arguments);
    const originalArgs1 = JSON.parse(
      (originalEvent.messages[1] as any).toolCalls![0].function.arguments,
    );
    expect(decodedArgs1).toEqual(originalArgs1);

    // Verify second tool call
    expect((decoded.messages[1] as any).toolCalls![1].id).toBe(
      (originalEvent.messages[1] as any).toolCalls![1].id,
    );
    expect((decoded.messages[1] as any).toolCalls![1].function.name).toBe(
      (originalEvent.messages[1] as any).toolCalls![1].function.name,
    );

    const decodedArgs2 = JSON.parse((decoded.messages[1] as any).toolCalls![1].function.arguments);
    const originalArgs2 = JSON.parse(
      (originalEvent.messages[1] as any).toolCalls![1].function.arguments,
    );
    expect(decodedArgs2).toEqual(originalArgs2);
  });

  // Test for the "Invalid event" error case
  it("should throw an error when decoding an invalid event", () => {
    // Create an empty Event message without any oneof field set
    const emptyEvent = protoEvents.Event.create({});
    const encodedEmpty = protoEvents.Event.encode(emptyEvent).finish();

    // Attempt to decode the empty event should throw an error
    expect(() => decode(encodedEmpty)).toThrow("Invalid event");
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/run-events.test.ts
================================================
import {
  EventType,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
} from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Run Events and Misc Events", () => {
  describe("Run Events", () => {
    it("should round-trip encode/decode RunStartedEvent event", () => {
      const event: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        timestamp: Date.now(),
        threadId: "thread-1234",
        runId: "run-5678",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode RunFinishedEvent event", () => {
      const event: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        timestamp: Date.now(),
        threadId: "thread-1234",
        runId: "run-5678",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode RunErrorEvent event", () => {
      const event: RunErrorEvent = {
        type: EventType.RUN_ERROR,
        timestamp: Date.now(),
        message: "Failed to execute tool call",
      };

      expectRoundTripEquality(event);
    });

    it("should handle RunErrorEvent with detailed error info", () => {
      const event: RunErrorEvent = {
        type: EventType.RUN_ERROR,
        message: "API request failed",
        code: "API_ERROR",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Step Events", () => {
    it("should round-trip encode/decode StepStartedEvent event", () => {
      const event: StepStartedEvent = {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "data_analysis",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode StepFinishedEvent event", () => {
      const event: StepFinishedEvent = {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "data_analysis",
      };

      expectRoundTripEquality(event);
    });

    it("should handle StepStartedEvent with minimal fields", () => {
      const event: StepStartedEvent = {
        type: EventType.STEP_STARTED,
        stepName: "process_payment",
      };

      expectRoundTripEquality(event);
    });

    it("should handle StepFinishedEvent with minimal fields", () => {
      const event: StepFinishedEvent = {
        type: EventType.STEP_FINISHED,
        stepName: "process_payment",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("RawEvent", () => {
    it("should round-trip encode/decode RawEvent", () => {
      const event: RawEvent = {
        type: EventType.RAW,
        timestamp: Date.now(),
        event: {
          type: "user_action",
          action: "button_click",
          elementId: "submit-btn",
          timestamp: Date.now(),
        },
        source: "frontend",
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex nested data in RawEvent", () => {
      const event: RawEvent = {
        type: EventType.RAW,
        event: {
          type: "analytics_event",
          session: {
            id: "sess-12345",
            user: {
              id: "user-456",
              attributes: {
                plan: "premium",
                signupDate: "2023-01-15",
                preferences: ["feature1", "feature2"],
              },
            },
            actions: [
              { type: "page_view", path: "/home", timestamp: 1676480210000 },
              {
                type: "button_click",
                elementId: "cta-1",
                timestamp: 1676480215000,
              },
              {
                type: "form_submit",
                formId: "signup",
                timestamp: 1676480230000,
                data: { email: "user@example.com" },
              },
            ],
          },
          metadata: {
            source: "web",
            version: "1.2.3",
            environment: "production",
          },
        },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("CustomEvent", () => {
    it("should round-trip encode/decode CustomEvent", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "user_preference_updated",
        value: {
          theme: "dark",
          fontSize: "medium",
          notifications: true,
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle CustomEvent without a value", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        name: "heartbeat",
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex values in CustomEvent", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        name: "analytics_update",
        value: {
          metrics: {
            active_users: 12345,
            conversion_rate: 0.0354,
            revenue: 98765.43,
          },
          segments: [
            { name: "new_users", count: 543, growth: 0.12 },
            { name: "returning_users", count: 876, growth: -0.05 },
            { name: "power_users", count: 234, growth: 0.08 },
          ],
          period: {
            start: "2023-01-01",
            end: "2023-01-31",
            duration_days: 31,
          },
          trends: {
            daily: [10, 12, 15, 14, 18, 20, 22],
            weekly: [70, 85, 92, 105],
            monthly: [320, 370],
          },
        },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Edge Cases", () => {
    it("should handle basic fields for each event type", () => {
      const events = [
        {
          type: EventType.RUN_STARTED,
          threadId: "thread-basic",
          runId: "run-basic",
        },
        {
          type: EventType.RUN_FINISHED,
          threadId: "thread-basic",
          runId: "run-basic",
        },
        { type: EventType.CUSTOM, name: "empty" },
      ];

      for (const event of events) {
        const encoded = encode(event);
        const decoded = decode(encoded);
        expect(decoded.type).toBe(event.type);
      }
    });

    it("should handle events with all base fields", () => {
      const runEvents = [
        {
          type: EventType.RUN_STARTED,
          timestamp: Date.now(),
          threadId: "thread-full",
          runId: "run-full",
          rawEvent: { original: "data", from: "external_system" },
        },
        {
          type: EventType.RUN_FINISHED,
          timestamp: Date.now(),
          threadId: "thread-full",
          runId: "run-full",
          rawEvent: { original: "data", from: "external_system" },
        },
      ];

      const nonRunEvents = [
        {
          type: EventType.RUN_ERROR,
          message: "Test error",
          timestamp: Date.now(),
          rawEvent: { original: "data", from: "external_system" },
        },
        {
          type: EventType.CUSTOM,
          name: "full_event",
          timestamp: Date.now(),
          rawEvent: { original: "data", from: "external_system" },
        },
      ];

      for (const event of [...runEvents, ...nonRunEvents]) {
        expectRoundTripEquality(event);
      }
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/state-events.test.ts
================================================
import { EventType, StateSnapshotEvent, StateDeltaEvent } from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("State Events", () => {
  describe("StateSnapshotEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        timestamp: Date.now(),
        snapshot: {
          counter: 42,
          items: ["apple", "banana", "cherry"],
          config: {
            enabled: true,
            maxRetries: 3,
          },
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle empty snapshot object", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {},
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex nested objects", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {
          userProfile: {
            name: "John Doe",
            age: 30,
            contact: {
              email: "john@example.com",
              phone: "+1234567890",
              address: {
                street: "123 Main St",
                city: "Anytown",
                country: "USA",
                coordinates: {
                  lat: 37.7749,
                  lng: -122.4194,
                },
              },
            },
            preferences: {
              theme: "dark",
              notifications: true,
              privateProfile: false,
            },
          },
          serviceConfig: {
            endpoints: [
              {
                name: "api1",
                url: "https://api1.example.com",
                methods: ["GET", "POST"],
              },
              {
                name: "api2",
                url: "https://api2.example.com",
                methods: ["GET"],
              },
            ],
            retryPolicy: {
              maxRetries: 3,
              backoff: "exponential",
              timeouts: [1000, 2000, 4000],
            },
          },
          stats: {
            visits: 1042,
            conversions: 123,
            bounceRate: 0.25,
            dataPoints: [
              { date: "2023-01-01", value: 10 },
              { date: "2023-01-02", value: 15 },
              { date: "2023-01-03", value: 8 },
            ],
          },
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle special values in snapshot", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {
          nullValue: null,
          emptyString: "",
          zero: 0,
          negativeNumber: -123,
          floatNumber: 3.14159,
          emptyArray: [],
          emptyObject: {},
          boolValues: { true: true, false: false },
          infinityValue: Infinity,
          nanValue: NaN,
          dateString: new Date().toISOString(),
        },
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as StateSnapshotEvent;

      // Check specific values that might need special handling
      expect(decoded.snapshot.nullValue).toBe(event.snapshot.nullValue);
      expect(decoded.snapshot.emptyString).toBe(event.snapshot.emptyString);
      expect(decoded.snapshot.zero).toBe(event.snapshot.zero);
      expect(decoded.snapshot.negativeNumber).toBe(event.snapshot.negativeNumber);
      expect(decoded.snapshot.floatNumber).toBe(event.snapshot.floatNumber);
      expect(decoded.snapshot.emptyArray).toEqual(event.snapshot.emptyArray);
      expect(decoded.snapshot.emptyObject).toEqual(event.snapshot.emptyObject);
      expect(decoded.snapshot.boolValues).toEqual(event.snapshot.boolValues);
      expect(decoded.snapshot.dateString).toBe(event.snapshot.dateString);

      // Infinity/NaN don't survive JSON.stringify, so they may not be exactly equal
      if (Number.isNaN(decoded.snapshot.nanValue)) {
        expect(Number.isNaN(event.snapshot.nanValue)).toBe(true);
      }
    });
  });

  describe("StateDeltaEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        timestamp: Date.now(),
        delta: [
          { op: "add", path: "/counter", value: 42 },
          { op: "add", path: "/items", value: ["apple", "banana", "cherry"] },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle all JSON Patch operation types", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/users/123", value: { name: "John", age: 30 } },
          { op: "remove", path: "/users/456" },
          { op: "replace", path: "/users/789/name", value: "Jane Doe" },
          { op: "move", from: "/users/old", path: "/users/new" },
          {
            op: "copy",
            from: "/templates/default",
            path: "/users/123/template",
          },
          { op: "test", path: "/users/123/active", value: true },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex values in add operations", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          {
            op: "add",
            path: "/data",
            value: {
              nested: {
                array: [1, 2, 3],
                object: { key: "value" },
              },
              boolean: true,
              number: 42,
            },
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle array operations", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/items", value: [] },
          { op: "add", path: "/items/0", value: "first" },
          { op: "add", path: "/items/-", value: "last" },
          { op: "replace", path: "/items/0", value: "updated first" },
          { op: "remove", path: "/items/1" },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in paths", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/special~0field", value: "value with tilde" },
          { op: "add", path: "/special~1field", value: "value with slash" },
          {
            op: "add",
            path: "/special/field",
            value: "value with actual slash",
          },
          { op: "add", path: '/special"field', value: "value with quote" },
          {
            op: "add",
            path: "/emoji\u{1F680}field",
            value: "value with emoji",
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle empty delta array", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [],
      };

      expectRoundTripEquality(event);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/test-utils.ts
================================================
import { BaseEvent } from "@ag-ui/core";
import { encode, decode } from "../src/proto";
import { expect, describe, it } from "@jest/globals";

/**
 * Performs a round-trip encode-decode on an event and returns the decoded result
 */
export function roundTrip<T extends BaseEvent>(event: T): T {
  const encoded = encode(event);
  return decode(encoded) as T;
}

/**
 * Verifies that an event is the same after round-trip encoding and decoding
 */
export function expectRoundTripEquality<T extends BaseEvent>(event: T): void {
  const decoded = roundTrip(event);

  // Verify all properties match
  for (const key in event) {
    if (Object.prototype.hasOwnProperty.call(event, key)) {
      expect(decoded[key]).toEqual(event[key]);
    }
  }
}

// Add a simple test to prevent "Your test suite must contain at least one test" error
describe("Test Utilities", () => {
  it("should exist as a module for other tests to import from", () => {
    expect(typeof roundTrip).toBe("function");
    expect(typeof expectRoundTripEquality).toBe("function");
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/tool-call-events.test.ts
================================================
import { EventType, ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent } from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Tool Call Events", () => {
  describe("ToolCallStartEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool-1",
        toolCallName: "get_weather",
      };

      expectRoundTripEquality(event);
    });

    it("should handle event with parent message id", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-1",
        toolCallName: "search_database",
        parentMessageId: "msg-123",
      };

      expectRoundTripEquality(event);
    });

    it("should preserve all optional fields", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: 1698765432123,
        toolCallId: "tool-call-id-123",
        toolCallName: "very_long_tool_name_with_underscores",
        parentMessageId: "parent-message-id-456",
        rawEvent: { original: "event data", from: "source system" },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("ToolCallArgsEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool-1",
        delta: '{"location":"San Francisco"}',
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex JSON in delta", () => {
      const complexJson = JSON.stringify({
        query: "SELECT * FROM users",
        filters: {
          age: { min: 18, max: 65 },
          status: ["active", "pending"],
          location: {
            country: "US",
            states: ["CA", "NY", "TX"],
          },
        },
        options: {
          limit: 100,
          offset: 0,
          sort: { field: "created_at", order: "desc" },
        },
      });

      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "db-query-tool-123",
        delta: complexJson,
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in delta", () => {
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-1",
        delta: '{"text":"Special chars: 🚀 ñ € 😊 \\n\\t\\"\'\\\\"}',
      };

      expectRoundTripEquality(event);
    });

    it("should handle partial JSON in delta (streaming case)", () => {
      // Test case for when JSON might be sent in chunks
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "streaming-tool",
        delta: '{"location":"San Fran',
      };

      expectRoundTripEquality(event);
    });
  });

  describe("ToolCallEndEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool-1",
      };

      expectRoundTripEquality(event);
    });

    it("should handle minimal required fields", () => {
      const event: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-1",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Complex Tool Call Sequence", () => {
    it("should correctly encode/decode a sequence of related tool call events", () => {
      // Create a sequence of related tool call events
      const startEvent: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: 1000,
        toolCallId: "complex-tool-1",
        toolCallName: "query_database",
      };

      const argsEvent1: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: 1001,
        toolCallId: "complex-tool-1",
        delta: '{"query":"SELECT * FROM',
      };

      const argsEvent2: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: 1002,
        toolCallId: "complex-tool-1",
        delta: ' users WHERE age > 18"}',
      };

      const endEvent: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        timestamp: 1003,
        toolCallId: "complex-tool-1",
      };

      // Test each event in the sequence
      expectRoundTripEquality(startEvent);
      expectRoundTripEquality(argsEvent1);
      expectRoundTripEquality(argsEvent2);
      expectRoundTripEquality(endEvent);

      // Ensure toolCallId is preserved across events
      const decodedStart = decode(encode(startEvent)) as ToolCallStartEvent;
      const decodedArgs1 = decode(encode(argsEvent1)) as ToolCallArgsEvent;
      const decodedArgs2 = decode(encode(argsEvent2)) as ToolCallArgsEvent;
      const decodedEnd = decode(encode(endEvent)) as ToolCallEndEvent;

      // Check consistent fields across events
      expect(decodedStart.toolCallId).toBe(startEvent.toolCallId);

      expect(decodedArgs1.toolCallId).toBe(argsEvent1.toolCallId);

      expect(decodedArgs2.toolCallId).toBe(argsEvent2.toolCallId);

      expect(decodedEnd.toolCallId).toBe(endEvent.toolCallId);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/src/index.ts
================================================
export { encode, decode } from "./proto";

export const AGUI_MEDIA_TYPE = "application/vnd.ag-ui.event+proto";



================================================
FILE: typescript-sdk/packages/proto/src/proto.ts
================================================
import { BaseEvent, EventSchemas, EventType, Message } from "@ag-ui/core";
import * as protoEvents from "./generated/events";
import * as protoPatch from "./generated/patch";

function toCamelCase(str: string): string {
  return str.toLowerCase().replace(/_([a-z])/g, (_, letter) => letter.toUpperCase());
}

/**
 * Encodes an event message to a protocol buffer binary format.
 */
export function encode(event: BaseEvent): Uint8Array {
  const oneofField = toCamelCase(event.type);
  const { type, timestamp, rawEvent, ...rest } = event as any;

  // since protobuf does not support optional arrays, we need to ensure that the toolCalls array is always present
  if (type === EventType.MESSAGES_SNAPSHOT) {
    rest.messages = rest.messages.map((message: Message) => {
      const untypedMessage = message as any;
      if (untypedMessage.toolCalls === undefined) {
        return { ...message, toolCalls: [] };
      }
      return message;
    });
  }

  // custom mapping for json patch operations
  if (type === EventType.STATE_DELTA) {
    rest.delta = rest.delta.map((operation: any) => ({
      ...operation,
      op: protoPatch.JsonPatchOperationType[operation.op.toUpperCase()],
    }));
  }

  const eventMessage = {
    [oneofField]: {
      baseEvent: {
        type: protoEvents.EventType[event.type as keyof typeof protoEvents.EventType],
        timestamp,
        rawEvent,
      },
      ...rest,
    },
  };
  return protoEvents.Event.encode(eventMessage).finish();
}

/**
 * Decodes a protocol buffer binary format to an event message.
 * The format includes a 4-byte length prefix followed by the message.
 */
export function decode(data: Uint8Array): BaseEvent {
  const event = protoEvents.Event.decode(data);
  const decoded = Object.values(event).find((value) => value !== undefined);
  if (!decoded) {
    throw new Error("Invalid event");
  }
  decoded.type = protoEvents.EventType[decoded.baseEvent.type];
  decoded.timestamp = decoded.baseEvent.timestamp;
  decoded.rawEvent = decoded.baseEvent.rawEvent;

  // we want tool calls to be optional, so we need to remove them if they are empty
  if (decoded.type === EventType.MESSAGES_SNAPSHOT) {
    for (const message of (decoded as any).messages as Message[]) {
      const untypedMessage = message as any;
      if (untypedMessage.toolCalls?.length === 0) {
        untypedMessage.toolCalls = undefined;
      }
    }
  }

  // custom mapping for json patch operations
  if (decoded.type === EventType.STATE_DELTA) {
    for (const operation of (decoded as any).delta) {
      operation.op = protoPatch.JsonPatchOperationType[operation.op].toLowerCase();
      Object.keys(operation).forEach((key) => {
        if (operation[key] === undefined) {
          delete operation[key];
        }
      });
    }
  }

  Object.keys(decoded).forEach((key) => {
    if (decoded[key] === undefined) {
      delete decoded[key];
    }
  });

  return EventSchemas.parse(decoded);
}



================================================
FILE: typescript-sdk/packages/proto/src/proto/events.proto
================================================
syntax = "proto3";

package ag_ui;

import "google/protobuf/struct.proto";
import "patch.proto";
import "types.proto";

enum EventType {
  TEXT_MESSAGE_START = 0;
  TEXT_MESSAGE_CONTENT = 1;
  TEXT_MESSAGE_END = 2;
  TOOL_CALL_START = 3;
  TOOL_CALL_ARGS = 4;
  TOOL_CALL_END = 5;
  STATE_SNAPSHOT = 6;
  STATE_DELTA = 7;
  MESSAGES_SNAPSHOT = 8;
  RAW = 9;
  CUSTOM = 10;
  RUN_STARTED = 11;
  RUN_FINISHED = 12;
  RUN_ERROR = 13;
  STEP_STARTED = 14;
  STEP_FINISHED = 15;
}

message BaseEvent {
  EventType type = 1;
  optional int64 timestamp = 2;
  optional google.protobuf.Value raw_event = 3;
}

message TextMessageStartEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
  optional string role = 3;
}

message TextMessageContentEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
  string delta = 3;
}

message TextMessageEndEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
}

message ToolCallStartEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
  string tool_call_name = 3;
  optional string parent_message_id = 4;
}

message ToolCallArgsEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
  string delta = 3;
}

message ToolCallEndEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
}

message StateSnapshotEvent {
  BaseEvent base_event = 1;
  google.protobuf.Value snapshot = 2;
}

message StateDeltaEvent {
  BaseEvent base_event = 1;
  repeated JsonPatchOperation delta = 2;
}

message MessagesSnapshotEvent {
  BaseEvent base_event = 1;
  repeated Message messages = 2;
}

message RawEvent {
  BaseEvent base_event = 1;
  google.protobuf.Value event = 2;
  optional string source = 3;
}

message CustomEvent {
  BaseEvent base_event = 1;
  string name = 2;
  optional google.protobuf.Value value = 3;
}

message RunStartedEvent {
  BaseEvent base_event = 1;
  string thread_id = 2;
  string run_id = 3;
}

message RunFinishedEvent {
  BaseEvent base_event = 1;
  string thread_id = 2;
  string run_id = 3;
  optional google.protobuf.Value result = 4;
}

message RunErrorEvent {
  BaseEvent base_event = 1;
  optional string code = 2;
  string message = 3;
}

message StepStartedEvent {
  BaseEvent base_event = 1;
  string step_name = 2;
}

message StepFinishedEvent {
  BaseEvent base_event = 1;
  string step_name = 2;
}

message TextMessageChunkEvent {
  BaseEvent base_event = 1;
  optional string message_id = 2;
  optional string role = 3;
  optional string delta = 4;
}

message ToolCallChunkEvent {
  BaseEvent base_event = 1;
  optional string tool_call_id = 2;
  optional string tool_call_name = 3;
  optional string parent_message_id = 4;
  optional string delta = 5;
}

message Event {
  oneof event {
    TextMessageStartEvent text_message_start = 1;
    TextMessageContentEvent text_message_content = 2;
    TextMessageEndEvent text_message_end = 3;
    ToolCallStartEvent tool_call_start = 4;
    ToolCallArgsEvent tool_call_args = 5;
    ToolCallEndEvent tool_call_end = 6;
    StateSnapshotEvent state_snapshot = 7;
    StateDeltaEvent state_delta = 8;
    MessagesSnapshotEvent messages_snapshot = 9;
    RawEvent raw = 10;
    CustomEvent custom = 11;
    RunStartedEvent run_started = 12;
    RunFinishedEvent run_finished = 13;
    RunErrorEvent run_error = 14;
    StepStartedEvent step_started = 15;
    StepFinishedEvent step_finished = 16;
    TextMessageChunkEvent text_message_chunk = 17;
    ToolCallChunkEvent tool_call_chunk = 18;
  }
}


================================================
FILE: typescript-sdk/packages/proto/src/proto/patch.proto
================================================
syntax = "proto3";

import "google/protobuf/struct.proto";

package ag_ui;

enum JsonPatchOperationType {
  ADD = 0;
  REMOVE = 1;
  REPLACE = 2;
  MOVE = 3;
  COPY = 4;
  TEST = 5;
}

message JsonPatchOperation {
  JsonPatchOperationType op = 1;
  string path = 2;
  optional string from = 3;
  optional google.protobuf.Value value = 4;
}



================================================
FILE: typescript-sdk/packages/proto/src/proto/types.proto
================================================
syntax = "proto3";

package ag_ui;

message ToolCall {
  string id = 1;
  string type = 2; 
  message Function {
    string name = 1;
    string arguments = 2; 
  }  
  Function function = 3;
}

message Message {
  string id = 1;
  string role = 2;
  optional string content = 3;
  optional string name = 4;
  repeated ToolCall tool_calls = 5;
  optional string tool_call_id = 6;
  optional string error = 7;
}



================================================
FILE: typescript-sdk/.cursor/rules/project-rules.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
# Project Overview

This monorepo project utilizes:
- Turborepo for build system orchestration
- PNPM for package management
- Jest for unit testing

Test files are located in `__tests__` directories alongside their corresponding implementation files.

Note: To run tests, navigate to the specific package directory and execute `pnpm run test`


================================================
FILE: .github/CODEOWNERS
================================================
* @mme @ranst91 @ataibarkai @maxkorp @tylerslaton @NathanTarbert



================================================
FILE: .github/workflows/check-generated-files.yml
================================================
name: Check Generated Files

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  check-files-json:
    name: Check files.json
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Regenerate files.json
        working-directory: typescript-sdk/apps/dojo
        run: npm run generate-content-json

      - name: Check files.json
        working-directory: typescript-sdk/apps/dojo
        run: |
          if git diff --exit-code src/files.json > /dev/null; then
            echo "✅ No changes detected in dojo/src/files.json. Everything is up to date."
          else
            echo "❌ Detected changes in dojo/src/files.json."
            echo ""
            echo "Please run \`(p)npm run generate-content-json\` in the typescript-sdk/apps/dojo folder and commit the changes."
            echo ""
            echo "The detected diff was as follows:"
            echo "::group::Diff for dojo/src/files.json"
            git diff src/files.json
            echo "::endgroup::"
            exit 1
          fi





================================================
FILE: .github/workflows/dojo-e2e.yml
================================================
name: e2e

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  e2e:
    name: E2E Tests
    runs-on: depot-ubuntu-latest-8

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'

    - name: Install pnpm
      uses: pnpm/action-setup@v4
      with:
        version: 10.13.1

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6

    - name: Setup pnpm cache
      uses: actions/cache@v4
      with:
        path: ~/.local/share/pnpm/store
        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    - name: Install dependencies
      working-directory: typescript-sdk
      run: pnpm install --frozen-lockfile

    - name: Prepare dojo for e2e
      working-directory: typescript-sdk/apps/dojo
      run: node ./scripts/prep-dojo-everything.js -e2e

    - name: Install e2e dependencies
      working-directory: typescript-sdk/apps/dojo/e2e
      run: |
        pnpm install

    - name: write langgraph env files
      working-directory: typescript-sdk/integrations/langgraph
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
      run: |
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > examples/python/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> examples/python/.env
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > examples/typescript/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> examples/typescript/.env
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > python/ag_ui_langgraph/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> python/ag_ui_langgraph/.env

    - name: Run dojo+agents
      uses: JarvusInnovations/background-action@v1
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
      with:
        run: |
          node ../scripts/run-dojo-everything.js
        working-directory: typescript-sdk/apps/dojo/e2e
        wait-on: |
          http://localhost:9999
          tcp:localhost:8000
          tcp:localhost:8001
          tcp:localhost:8002
          tcp:localhost:8003
          tcp:localhost:8004
          tcp:localhost:8005
          tcp:localhost:8006
          tcp:localhost:8007
          tcp:localhost:8008
          tcp:localhost:8009

    - name: Run tests
      working-directory: typescript-sdk/apps/dojo/e2e
      env:
        BASE_URL: http://localhost:9999
      run: pnpm test

    - name: Upload traces
      if: always() # Uploads artifacts even if tests fail
      uses: actions/upload-artifact@v4
      with:
        name: playwright-traces
        path: typescript-sdk/apps/dojo/e2e/test-results/
        retention-days: 7



================================================
FILE: .github/workflows/test.yml
================================================
name: test

on:
  push:
    branches: main
  pull_request:
    branches: main

jobs:
  python:
    name: Python SDK Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v4
      with:
        path: python-sdk/.venv
        key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      working-directory: python-sdk
      run: poetry install --no-interaction --no-root

    - name: Install project
      working-directory: python-sdk
      run: poetry install --no-interaction

    - name: Run tests
      working-directory: python-sdk
      run: poetry run python -m unittest discover tests -v

  typescript:
    name: TypeScript SDK Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install protoc
      uses: arduino/setup-protoc@v3
      with:
        version: "25.x"
        repo-token: ${{ secrets.GITHUB_TOKEN }}

    - name: Install pnpm
      uses: pnpm/action-setup@v4
      with:
        version: 10.13.1

    - name: Setup pnpm cache
      uses: actions/cache@v4
      with:
        path: ~/.local/share/pnpm/store
        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    - name: Install dependencies
      working-directory: typescript-sdk
      run: pnpm install --frozen-lockfile

    - name: Test Build
      working-directory: typescript-sdk
      run: pnpm run build

    - name: Run tests
      working-directory: typescript-sdk
      run: pnpm run test

